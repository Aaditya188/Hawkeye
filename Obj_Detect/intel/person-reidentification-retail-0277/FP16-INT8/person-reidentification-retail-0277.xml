<?xml version="1.0" ?>
<net name="person-reidentification-retail-0277" version="10">
	<layers>
		<layer id="0" name="data" type="Parameter" version="opset1">
			<data element_type="f16" shape="1,3,256,128"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>3</dim>
					<dim>256</dim>
					<dim>128</dim>
				</port>
			</output>
		</layer>
		<layer id="1" name="data/reverse_input_channels4001740021/Split_input_port_1/value40051_const1202_const" type="Const" version="opset1">
			<data element_type="i64" offset="0" shape="" size="8"/>
			<output>
				<port id="0" precision="I64"/>
			</output>
		</layer>
		<layer id="2" name="data/reverse_input_channels4001740021/Split" type="Split" version="opset1">
			<data num_splits="3"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>3</dim>
					<dim>256</dim>
					<dim>128</dim>
				</port>
				<port id="1"/>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>1</dim>
					<dim>1</dim>
					<dim>256</dim>
					<dim>128</dim>
				</port>
				<port id="3" precision="FP16">
					<dim>1</dim>
					<dim>1</dim>
					<dim>256</dim>
					<dim>128</dim>
				</port>
				<port id="4" precision="FP16">
					<dim>1</dim>
					<dim>1</dim>
					<dim>256</dim>
					<dim>128</dim>
				</port>
			</output>
		</layer>
		<layer id="3" name="data/reverse_input_channels4001740021/Concat" type="Concat" version="opset1">
			<data axis="1"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>1</dim>
					<dim>256</dim>
					<dim>128</dim>
				</port>
				<port id="1">
					<dim>1</dim>
					<dim>1</dim>
					<dim>256</dim>
					<dim>128</dim>
				</port>
				<port id="2">
					<dim>1</dim>
					<dim>1</dim>
					<dim>256</dim>
					<dim>128</dim>
				</port>
			</input>
			<output>
				<port id="3" names="data" precision="FP16">
					<dim>1</dim>
					<dim>3</dim>
					<dim>256</dim>
					<dim>128</dim>
				</port>
			</output>
		</layer>
		<layer id="4" name="data/reverse_input_channels4001740023/Concat40064_const1207_const" type="Const" version="opset1">
			<data element_type="f16" offset="8" shape="1,3,1,1" size="6"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>3</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="5" name="data/scale/Fused_Mul_" type="Multiply" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>3</dim>
					<dim>256</dim>
					<dim>128</dim>
				</port>
				<port id="1">
					<dim>1</dim>
					<dim>3</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>1</dim>
					<dim>3</dim>
					<dim>256</dim>
					<dim>128</dim>
				</port>
			</output>
		</layer>
		<layer id="6" name="data/reverse_input_channels40019/Concat40048_const1209_const" type="Const" version="opset1">
			<data element_type="f16" offset="14" shape="1,3,1,1" size="6"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>3</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="7" name="data/mean/Fused_Add_" type="Add" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>3</dim>
					<dim>256</dim>
					<dim>128</dim>
				</port>
				<port id="1">
					<dim>1</dim>
					<dim>3</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>1</dim>
					<dim>3</dim>
					<dim>256</dim>
					<dim>128</dim>
				</port>
			</output>
		</layer>
		<layer id="8" name="61576161_const" type="Const" version="opset1">
			<data element_type="f16" offset="20" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="9" name="61586162_const" type="Const" version="opset1">
			<data element_type="f16" offset="22" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="10" name="61596163_const" type="Const" version="opset1">
			<data element_type="f16" offset="20" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="11" name="61606164_const" type="Const" version="opset1">
			<data element_type="f16" offset="22" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="12" name="563/Ins_Norm/MVN_/fq_input_0" type="FakeQuantize" version="opset1">
			<data auto_broadcast="numpy" levels="256"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>3</dim>
					<dim>256</dim>
					<dim>128</dim>
				</port>
				<port id="1"/>
				<port id="2"/>
				<port id="3"/>
				<port id="4"/>
			</input>
			<output>
				<port id="5" precision="FP16">
					<dim>1</dim>
					<dim>3</dim>
					<dim>256</dim>
					<dim>128</dim>
				</port>
			</output>
		</layer>
		<layer id="13" name="563/Range_input_port_0/value/Output_0/Data__const1211_const" type="Const" version="opset1">
			<data element_type="i64" offset="24" shape="" size="8"/>
			<output>
				<port id="0" precision="I64"/>
			</output>
		</layer>
		<layer id="14" name="563/Rank/shape_of" type="ShapeOf" version="opset3">
			<data output_type="i64"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>3</dim>
					<dim>256</dim>
					<dim>128</dim>
				</port>
			</input>
			<output>
				<port id="1" precision="I64">
					<dim>4</dim>
				</port>
			</output>
		</layer>
		<layer id="15" name="563/Rank/rank_of" type="ShapeOf" version="opset3">
			<data output_type="i64"/>
			<input>
				<port id="0">
					<dim>4</dim>
				</port>
			</input>
			<output>
				<port id="1" precision="I64">
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="16" name="563/Rank/0d_rank_of/value/Output_0/Data__const1214_const" type="Const" version="opset1">
			<data element_type="i64" offset="32" shape="1" size="8"/>
			<output>
				<port id="0" precision="I64">
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="17" name="563/Rank" type="Squeeze" version="opset1">
			<input>
				<port id="0">
					<dim>1</dim>
				</port>
				<port id="1">
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="I64"/>
			</output>
		</layer>
		<layer id="18" name="563/Range_input_port_2/value/Output_0/Data__const1216_const" type="Const" version="opset1">
			<data element_type="i64" offset="0" shape="" size="8"/>
			<output>
				<port id="0" precision="I64"/>
			</output>
		</layer>
		<layer id="19" name="563/Range" type="Range" version="opset4">
			<data output_type="i64"/>
			<input>
				<port id="0"/>
				<port id="1"/>
				<port id="2"/>
			</input>
			<output>
				<port id="3" precision="I64">
					<dim>2</dim>
				</port>
			</output>
		</layer>
		<layer id="20" name="563/Ins_Norm/MVN_" type="MVN" version="opset6">
			<data eps="9.999999747378752e-06" eps_mode="inside_sqrt" normalize_variance="true"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>3</dim>
					<dim>256</dim>
					<dim>128</dim>
				</port>
				<port id="1">
					<dim>2</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>1</dim>
					<dim>3</dim>
					<dim>256</dim>
					<dim>128</dim>
				</port>
			</output>
		</layer>
		<layer id="21" name="in_first.weight/EltwiseUnsqueeze23062_const1219_const" type="Const" version="opset1">
			<data element_type="f16" offset="40" shape="1,3,1,1" size="6"/>
			<output>
				<port id="0" names="in_first.weight" precision="FP16">
					<dim>1</dim>
					<dim>3</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="22" name="563/Ins_Norm/mul_" type="Multiply" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>3</dim>
					<dim>256</dim>
					<dim>128</dim>
				</port>
				<port id="1">
					<dim>1</dim>
					<dim>3</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>1</dim>
					<dim>3</dim>
					<dim>256</dim>
					<dim>128</dim>
				</port>
			</output>
		</layer>
		<layer id="23" name="in_first.bias/EltwiseUnsqueeze23066_const1221_const" type="Const" version="opset1">
			<data element_type="f16" offset="46" shape="1,3,1,1" size="6"/>
			<output>
				<port id="0" names="in_first.bias" precision="FP16">
					<dim>1</dim>
					<dim>3</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="24" name="563" type="Add" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>3</dim>
					<dim>256</dim>
					<dim>128</dim>
				</port>
				<port id="1">
					<dim>1</dim>
					<dim>3</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" names="563" precision="FP16">
					<dim>1</dim>
					<dim>3</dim>
					<dim>256</dim>
					<dim>128</dim>
				</port>
			</output>
		</layer>
		<layer id="25" name="44074411_const" type="Const" version="opset1">
			<data element_type="f16" offset="52" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="26" name="44084412_const" type="Const" version="opset1">
			<data element_type="f16" offset="54" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="27" name="44094413_const" type="Const" version="opset1">
			<data element_type="f16" offset="52" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="28" name="44104414_const" type="Const" version="opset1">
			<data element_type="f16" offset="54" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="29" name="564/fq_input_0" type="FakeQuantize" version="opset1">
			<data auto_broadcast="numpy" levels="256"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>3</dim>
					<dim>256</dim>
					<dim>128</dim>
				</port>
				<port id="1"/>
				<port id="2"/>
				<port id="3"/>
				<port id="4"/>
			</input>
			<output>
				<port id="5" precision="FP16">
					<dim>1</dim>
					<dim>3</dim>
					<dim>256</dim>
					<dim>128</dim>
				</port>
			</output>
		</layer>
		<layer id="30" name="conv1.conv.weight/quantized17547_const" type="Const" version="opset1">
			<data element_type="i8" offset="56" shape="64,3,7,7" size="9408"/>
			<output>
				<port id="0" precision="I8">
					<dim>64</dim>
					<dim>3</dim>
					<dim>7</dim>
					<dim>7</dim>
				</port>
			</output>
		</layer>
		<layer id="31" name="conv1.conv.weight/quantized/to_f16" type="Convert" version="opset1">
			<data destination_type="f16"/>
			<input>
				<port id="0">
					<dim>64</dim>
					<dim>3</dim>
					<dim>7</dim>
					<dim>7</dim>
				</port>
			</input>
			<output>
				<port id="1" precision="FP16">
					<dim>64</dim>
					<dim>3</dim>
					<dim>7</dim>
					<dim>7</dim>
				</port>
			</output>
		</layer>
		<layer id="32" name="564/fq_weights_1/zero_point17560_const" type="Const" version="opset1">
			<data element_type="f16" offset="9464" shape="64,1,1,1" size="128"/>
			<output>
				<port id="0" precision="FP16">
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="33" name="564/fq_weights_1/minus_zp" type="Subtract" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>64</dim>
					<dim>3</dim>
					<dim>7</dim>
					<dim>7</dim>
				</port>
				<port id="1">
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>64</dim>
					<dim>3</dim>
					<dim>7</dim>
					<dim>7</dim>
				</port>
			</output>
		</layer>
		<layer id="34" name="564/fq_weights_1/scale17555_const" type="Const" version="opset1">
			<data element_type="f16" offset="9592" shape="64,1,1,1" size="128"/>
			<output>
				<port id="0" precision="FP16">
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="35" name="564/fq_weights_1/mulpiply_by_scale" type="Multiply" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>64</dim>
					<dim>3</dim>
					<dim>7</dim>
					<dim>7</dim>
				</port>
				<port id="1">
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>64</dim>
					<dim>3</dim>
					<dim>7</dim>
					<dim>7</dim>
				</port>
			</output>
		</layer>
		<layer id="36" name="564" type="Convolution" version="opset1">
			<data auto_pad="explicit" dilations="1,1" pads_begin="3,3" pads_end="3,3" strides="2,2"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>3</dim>
					<dim>256</dim>
					<dim>128</dim>
				</port>
				<port id="1">
					<dim>64</dim>
					<dim>3</dim>
					<dim>7</dim>
					<dim>7</dim>
				</port>
			</input>
			<output>
				<port id="2" names="564" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>128</dim>
					<dim>64</dim>
				</port>
			</output>
		</layer>
		<layer id="37" name="28682870_const" type="Const" version="opset1">
			<data element_type="f16" offset="9720" shape="1,64,1,1" size="128"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="38" name="564/add_" type="Add" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>64</dim>
					<dim>128</dim>
					<dim>64</dim>
				</port>
				<port id="1">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>128</dim>
					<dim>64</dim>
				</port>
			</output>
		</layer>
		<layer id="39" name="76677671_const" type="Const" version="opset1">
			<data element_type="f16" offset="9848" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="40" name="76687672_const" type="Const" version="opset1">
			<data element_type="f16" offset="9850" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="41" name="76697673_const" type="Const" version="opset1">
			<data element_type="f16" offset="9848" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="42" name="76707674_const" type="Const" version="opset1">
			<data element_type="f16" offset="9850" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="43" name="565/Ins_Norm/MVN_/fq_input_0" type="FakeQuantize" version="opset1">
			<data auto_broadcast="numpy" levels="256"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>64</dim>
					<dim>128</dim>
					<dim>64</dim>
				</port>
				<port id="1"/>
				<port id="2"/>
				<port id="3"/>
				<port id="4"/>
			</input>
			<output>
				<port id="5" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>128</dim>
					<dim>64</dim>
				</port>
			</output>
		</layer>
		<layer id="44" name="565/Range_input_port_0/value/Output_0/Data__const1225_const" type="Const" version="opset1">
			<data element_type="i64" offset="24" shape="" size="8"/>
			<output>
				<port id="0" precision="I64"/>
			</output>
		</layer>
		<layer id="45" name="565/Rank/shape_of" type="ShapeOf" version="opset3">
			<data output_type="i64"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>64</dim>
					<dim>128</dim>
					<dim>64</dim>
				</port>
			</input>
			<output>
				<port id="1" precision="I64">
					<dim>4</dim>
				</port>
			</output>
		</layer>
		<layer id="46" name="565/Rank/rank_of" type="ShapeOf" version="opset3">
			<data output_type="i64"/>
			<input>
				<port id="0">
					<dim>4</dim>
				</port>
			</input>
			<output>
				<port id="1" precision="I64">
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="47" name="565/Rank/0d_rank_of/value/Output_0/Data__const1228_const" type="Const" version="opset1">
			<data element_type="i64" offset="32" shape="1" size="8"/>
			<output>
				<port id="0" precision="I64">
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="48" name="565/Rank" type="Squeeze" version="opset1">
			<input>
				<port id="0">
					<dim>1</dim>
				</port>
				<port id="1">
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="I64"/>
			</output>
		</layer>
		<layer id="49" name="565/Range_input_port_2/value/Output_0/Data__const1230_const" type="Const" version="opset1">
			<data element_type="i64" offset="0" shape="" size="8"/>
			<output>
				<port id="0" precision="I64"/>
			</output>
		</layer>
		<layer id="50" name="565/Range" type="Range" version="opset4">
			<data output_type="i64"/>
			<input>
				<port id="0"/>
				<port id="1"/>
				<port id="2"/>
			</input>
			<output>
				<port id="3" precision="I64">
					<dim>2</dim>
				</port>
			</output>
		</layer>
		<layer id="51" name="565/Ins_Norm/MVN_" type="MVN" version="opset6">
			<data eps="9.999999747378752e-06" eps_mode="inside_sqrt" normalize_variance="true"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>64</dim>
					<dim>128</dim>
					<dim>64</dim>
				</port>
				<port id="1">
					<dim>2</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>128</dim>
					<dim>64</dim>
				</port>
			</output>
		</layer>
		<layer id="52" name="conv1.bn.weight/EltwiseUnsqueeze23038_const1233_const" type="Const" version="opset1">
			<data element_type="f16" offset="9852" shape="1,64,1,1" size="128"/>
			<output>
				<port id="0" names="conv1.bn.weight" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="53" name="565/Ins_Norm/mul_" type="Multiply" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>64</dim>
					<dim>128</dim>
					<dim>64</dim>
				</port>
				<port id="1">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>128</dim>
					<dim>64</dim>
				</port>
			</output>
		</layer>
		<layer id="54" name="conv1.bn.bias/EltwiseUnsqueeze23042_const1235_const" type="Const" version="opset1">
			<data element_type="f16" offset="9980" shape="1,64,1,1" size="128"/>
			<output>
				<port id="0" names="conv1.bn.bias" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="55" name="565" type="Add" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>64</dim>
					<dim>128</dim>
					<dim>64</dim>
				</port>
				<port id="1">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" names="565" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>128</dim>
					<dim>64</dim>
				</port>
			</output>
		</layer>
		<layer id="56" name="566" type="ReLU" version="opset1">
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>64</dim>
					<dim>128</dim>
					<dim>64</dim>
				</port>
			</input>
			<output>
				<port id="1" names="566" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>128</dim>
					<dim>64</dim>
				</port>
			</output>
		</layer>
		<layer id="57" name="1082810832_const" type="Const" version="opset1">
			<data element_type="f16" offset="10108" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="58" name="1082910833_const" type="Const" version="opset1">
			<data element_type="f16" offset="10110" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="59" name="1083010834_const" type="Const" version="opset1">
			<data element_type="f16" offset="10108" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="60" name="1083110835_const" type="Const" version="opset1">
			<data element_type="f16" offset="10110" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="61" name="567/fq_input_0" type="FakeQuantize" version="opset1">
			<data auto_broadcast="numpy" levels="256"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>64</dim>
					<dim>128</dim>
					<dim>64</dim>
				</port>
				<port id="1"/>
				<port id="2"/>
				<port id="3"/>
				<port id="4"/>
			</input>
			<output>
				<port id="5" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>128</dim>
					<dim>64</dim>
				</port>
			</output>
		</layer>
		<layer id="62" name="567" type="MaxPool" version="opset1">
			<data auto_pad="explicit" kernel="3,3" pads_begin="1,1" pads_end="1,1" rounding_type="floor" strides="2,2"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>64</dim>
					<dim>128</dim>
					<dim>64</dim>
				</port>
			</input>
			<output>
				<port id="1" names="567" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
			</output>
		</layer>
		<layer id="63" name="569/mean/Fused_Mul_2435924361_const123915327/quantized20283_const" type="Const" version="opset1">
			<data element_type="i8" offset="10112" shape="64,64,1,1" size="4096"/>
			<output>
				<port id="0" precision="I8">
					<dim>64</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="64" name="569/mean/Fused_Mul_2435924361_const123915327/quantized/to_f16" type="Convert" version="opset1">
			<data destination_type="f16"/>
			<input>
				<port id="0">
					<dim>64</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="1" precision="FP16">
					<dim>64</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="65" name="568/fq_weights_1/zero_point20296_const" type="Const" version="opset1">
			<data element_type="f16" offset="14208" shape="64,1,1,1" size="128"/>
			<output>
				<port id="0" precision="FP16">
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="66" name="568/fq_weights_1/minus_zp" type="Subtract" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>64</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="1">
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>64</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="67" name="568/fq_weights_1/scale20291_const" type="Const" version="opset1">
			<data element_type="f16" offset="14336" shape="64,1,1,1" size="128"/>
			<output>
				<port id="0" precision="FP16">
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="68" name="568/fq_weights_1/mulpiply_by_scale" type="Multiply" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>64</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="1">
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>64</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="69" name="568" type="Convolution" version="opset1">
			<data auto_pad="explicit" dilations="1,1" pads_begin="0,0" pads_end="0,0" strides="1,1"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>64</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
				<port id="1">
					<dim>64</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
			</output>
		</layer>
		<layer id="70" name="data_add_217012170622712/EltwiseUnsqueeze23194_const1241_const" type="Const" version="opset1">
			<data element_type="f16" offset="14464" shape="1,64,1,1" size="128"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="71" name="569/variance/Fused_Add_" type="Add" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>64</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
				<port id="1">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" names="569" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
			</output>
		</layer>
		<layer id="72" name="570" type="ReLU" version="opset1">
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>64</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
			</input>
			<output>
				<port id="1" names="570" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
			</output>
		</layer>
		<layer id="73" name="45474551_const" type="Const" version="opset1">
			<data element_type="f16" offset="10108" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="74" name="45484552_const" type="Const" version="opset1">
			<data element_type="f16" offset="14592" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="75" name="45494553_const" type="Const" version="opset1">
			<data element_type="f16" offset="10108" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="76" name="45504554_const" type="Const" version="opset1">
			<data element_type="f16" offset="14592" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="77" name="571/fq_input_0" type="FakeQuantize" version="opset1">
			<data auto_broadcast="numpy" levels="256"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>64</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
				<port id="1"/>
				<port id="2"/>
				<port id="3"/>
				<port id="4"/>
			</input>
			<output>
				<port id="5" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
			</output>
		</layer>
		<layer id="78" name="conv2.0.conv2a.conv1.weight/quantized19155_const" type="Const" version="opset1">
			<data element_type="i8" offset="14594" shape="64,64,1,1" size="4096"/>
			<output>
				<port id="0" precision="I8">
					<dim>64</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="79" name="conv2.0.conv2a.conv1.weight/quantized/to_f16" type="Convert" version="opset1">
			<data destination_type="f16"/>
			<input>
				<port id="0">
					<dim>64</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="1" precision="FP16">
					<dim>64</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="80" name="571/fq_weights_1/zero_point19168_const" type="Const" version="opset1">
			<data element_type="f16" offset="18690" shape="64,1,1,1" size="128"/>
			<output>
				<port id="0" precision="FP16">
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="81" name="571/fq_weights_1/minus_zp" type="Subtract" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>64</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="1">
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>64</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="82" name="571/fq_weights_1/scale19163_const" type="Const" version="opset1">
			<data element_type="f16" offset="18818" shape="64,1,1,1" size="128"/>
			<output>
				<port id="0" precision="FP16">
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="83" name="571/fq_weights_1/mulpiply_by_scale" type="Multiply" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>64</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="1">
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>64</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="84" name="571" type="Convolution" version="opset1">
			<data auto_pad="explicit" dilations="1,1" pads_begin="0,0" pads_end="0,0" strides="1,1"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>64</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
				<port id="1">
					<dim>64</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" names="571" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
			</output>
		</layer>
		<layer id="85" name="28722874_const" type="Const" version="opset1">
			<data element_type="f16" offset="9720" shape="1,64,1,1" size="128"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="86" name="571/add_" type="Add" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>64</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
				<port id="1">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
			</output>
		</layer>
		<layer id="87" name="64576461_const" type="Const" version="opset1">
			<data element_type="f16" offset="18946" shape="1,64,1,1" size="128"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="88" name="64586462_const" type="Const" version="opset1">
			<data element_type="f16" offset="19074" shape="1,64,1,1" size="128"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="89" name="64596463_const" type="Const" version="opset1">
			<data element_type="f16" offset="18946" shape="1,64,1,1" size="128"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="90" name="64606464_const" type="Const" version="opset1">
			<data element_type="f16" offset="19074" shape="1,64,1,1" size="128"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="91" name="572/fq_input_0" type="FakeQuantize" version="opset1">
			<data auto_broadcast="numpy" levels="256"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>64</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
				<port id="1">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="2">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="3">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="4">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="5" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
			</output>
		</layer>
		<layer id="92" name="4207142074_const124615330/quantized20355_const" type="Const" version="opset1">
			<data element_type="i8" offset="19202" shape="64,1,3,3" size="576"/>
			<output>
				<port id="0" precision="I8">
					<dim>64</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</output>
		</layer>
		<layer id="93" name="4207142074_const124615330/quantized/to_f16" type="Convert" version="opset1">
			<data destination_type="f16"/>
			<input>
				<port id="0">
					<dim>64</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</input>
			<output>
				<port id="1" precision="FP16">
					<dim>64</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</output>
		</layer>
		<layer id="94" name="572/fq_weights_1/zero_point20368_const" type="Const" version="opset1">
			<data element_type="f16" offset="19778" shape="64,1,1,1" size="128"/>
			<output>
				<port id="0" precision="FP16">
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="95" name="572/fq_weights_1/minus_zp" type="Subtract" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>64</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
				<port id="1">
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>64</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</output>
		</layer>
		<layer id="96" name="572/fq_weights_1/scale20363_const" type="Const" version="opset1">
			<data element_type="f16" offset="19906" shape="64,1,1,1" size="128"/>
			<output>
				<port id="0" precision="FP16">
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="97" name="572/fq_weights_1/mulpiply_by_scale" type="Multiply" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>64</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
				<port id="1">
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>64</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</output>
		</layer>
		<layer id="98" name="24412/value24414_const" type="Const" version="opset1">
			<data element_type="i64" offset="20034" shape="5" size="40"/>
			<output>
				<port id="0" precision="I64">
					<dim>5</dim>
				</port>
			</output>
		</layer>
		<layer id="99" name="24412" type="Reshape" version="opset1">
			<data special_zero="true"/>
			<input>
				<port id="0">
					<dim>64</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
				<port id="1">
					<dim>5</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</output>
		</layer>
		<layer id="100" name="572" type="GroupConvolution" version="opset1">
			<data auto_pad="explicit" dilations="1,1" pads_begin="1,1" pads_end="1,1" strides="1,1"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>64</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
				<port id="1">
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
			</output>
		</layer>
		<layer id="101" name="data_add_217812178622732/EltwiseUnsqueeze23274_const1248_const" type="Const" version="opset1">
			<data element_type="f16" offset="20074" shape="1,64,1,1" size="128"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="102" name="573/variance/Fused_Add_" type="Add" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>64</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
				<port id="1">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" names="573" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
			</output>
		</layer>
		<layer id="103" name="574" type="ReLU" version="opset1">
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>64</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
			</input>
			<output>
				<port id="1" names="574" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
			</output>
		</layer>
		<layer id="104" name="75477551_const" type="Const" version="opset1">
			<data element_type="f16" offset="10108" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="105" name="75487552_const" type="Const" version="opset1">
			<data element_type="f16" offset="20202" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="106" name="75497553_const" type="Const" version="opset1">
			<data element_type="f16" offset="10108" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="107" name="75507554_const" type="Const" version="opset1">
			<data element_type="f16" offset="20202" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="108" name="611/reduce/fq_input_0" type="FakeQuantize" version="opset1">
			<data auto_broadcast="numpy" levels="256"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>64</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
				<port id="1"/>
				<port id="2"/>
				<port id="3"/>
				<port id="4"/>
			</input>
			<output>
				<port id="5" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
			</output>
		</layer>
		<layer id="109" name="1324/Output_0/Data__const1251_const" type="Const" version="opset1">
			<data element_type="i64" offset="24" shape="" size="8"/>
			<output>
				<port id="0" precision="I64"/>
			</output>
		</layer>
		<layer id="110" name="611/input_rank/shape_of" type="ShapeOf" version="opset3">
			<data output_type="i64"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>64</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
			</input>
			<output>
				<port id="1" precision="I64">
					<dim>4</dim>
				</port>
			</output>
		</layer>
		<layer id="111" name="611/input_rank/rank_of" type="ShapeOf" version="opset3">
			<data output_type="i64"/>
			<input>
				<port id="0">
					<dim>4</dim>
				</port>
			</input>
			<output>
				<port id="1" precision="I64">
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="112" name="611/input_rank/0d_rank_of/value/Output_0/Data__const1254_const" type="Const" version="opset1">
			<data element_type="i64" offset="32" shape="1" size="8"/>
			<output>
				<port id="0" precision="I64">
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="113" name="611/input_rank" type="Squeeze" version="opset1">
			<input>
				<port id="0">
					<dim>1</dim>
				</port>
				<port id="1">
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="I64"/>
			</output>
		</layer>
		<layer id="114" name="1326/Output_0/Data__const1256_const" type="Const" version="opset1">
			<data element_type="i64" offset="0" shape="" size="8"/>
			<output>
				<port id="0" precision="I64"/>
			</output>
		</layer>
		<layer id="115" name="611/global_pooling_reduce_axis" type="Range" version="opset4">
			<data output_type="i64"/>
			<input>
				<port id="0"/>
				<port id="1"/>
				<port id="2"/>
			</input>
			<output>
				<port id="3" precision="I64">
					<dim>2</dim>
				</port>
			</output>
		</layer>
		<layer id="116" name="611/reduce" type="ReduceMean" version="opset1">
			<data keep_dims="true"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>64</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
				<port id="1">
					<dim>2</dim>
				</port>
			</input>
			<output>
				<port id="2" names="611" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="117" name="Copy_conv2.0.gate.fc1.weight/Output_0/Data__const1259_const" type="Const" version="opset1">
			<data element_type="f16" offset="20204" shape="4,64,1,1" size="512"/>
			<output>
				<port id="0" names="conv2.0.gate.fc1.weight" precision="FP16">
					<dim>4</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="118" name="612/WithoutBiases" type="Convolution" version="opset1">
			<data auto_pad="explicit" dilations="1,1" pads_begin="0,0" pads_end="0,0" strides="1,1"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="1">
					<dim>4</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>1</dim>
					<dim>4</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="119" name="612/Dims1294022692/EltwiseUnsqueeze23122_const1261_const" type="Const" version="opset1">
			<data element_type="f16" offset="20716" shape="1,4,1,1" size="8"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>4</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="120" name="612" type="Add" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>4</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="1">
					<dim>1</dim>
					<dim>4</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" names="612" precision="FP16">
					<dim>1</dim>
					<dim>4</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="121" name="613" type="ReLU" version="opset1">
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>4</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="1" names="613" precision="FP16">
					<dim>1</dim>
					<dim>4</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="122" name="Copy_conv2.0.gate.fc2.weight/Output_0/Data__const1264_const" type="Const" version="opset1">
			<data element_type="f16" offset="20724" shape="64,4,1,1" size="512"/>
			<output>
				<port id="0" names="conv2.0.gate.fc2.weight" precision="FP16">
					<dim>64</dim>
					<dim>4</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="123" name="614/WithoutBiases" type="Convolution" version="opset1">
			<data auto_pad="explicit" dilations="1,1" pads_begin="0,0" pads_end="0,0" strides="1,1"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>4</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="1">
					<dim>64</dim>
					<dim>4</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="124" name="614/Dims1300622703/EltwiseUnsqueeze23166_const1266_const" type="Const" version="opset1">
			<data element_type="f16" offset="21236" shape="1,64,1,1" size="128"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="125" name="614" type="Add" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="1">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" names="614" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="126" name="615" type="Sigmoid" version="opset1">
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="1" names="615" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="127" name="47774781_const" type="Const" version="opset1">
			<data element_type="f16" offset="10108" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="128" name="47784782_const" type="Const" version="opset1">
			<data element_type="f16" offset="21364" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="129" name="47794783_const" type="Const" version="opset1">
			<data element_type="f16" offset="10108" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="130" name="47804784_const" type="Const" version="opset1">
			<data element_type="f16" offset="21364" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="131" name="616/fq_input_1" type="FakeQuantize" version="opset1">
			<data auto_broadcast="numpy" levels="256"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="1"/>
				<port id="2"/>
				<port id="3"/>
				<port id="4"/>
			</input>
			<output>
				<port id="5" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="132" name="616" type="Multiply" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>64</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
				<port id="1">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" names="616" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
			</output>
		</layer>
		<layer id="133" name="44974501_const" type="Const" version="opset1">
			<data element_type="f16" offset="10108" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="134" name="44984502_const" type="Const" version="opset1">
			<data element_type="f16" offset="21366" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="135" name="44994503_const" type="Const" version="opset1">
			<data element_type="f16" offset="10108" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="136" name="45004504_const" type="Const" version="opset1">
			<data element_type="f16" offset="21366" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="137" name="623/fq_input_0" type="FakeQuantize" version="opset1">
			<data auto_broadcast="numpy" levels="256"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>64</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
				<port id="1"/>
				<port id="2"/>
				<port id="3"/>
				<port id="4"/>
			</input>
			<output>
				<port id="5" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
			</output>
		</layer>
		<layer id="138" name="conv2.0.conv2b.0.conv1.weight/quantized20091_const" type="Const" version="opset1">
			<data element_type="i8" offset="21368" shape="64,64,1,1" size="4096"/>
			<output>
				<port id="0" precision="I8">
					<dim>64</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="139" name="conv2.0.conv2b.0.conv1.weight/quantized/to_f16" type="Convert" version="opset1">
			<data destination_type="f16"/>
			<input>
				<port id="0">
					<dim>64</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="1" precision="FP16">
					<dim>64</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="140" name="575/fq_weights_1/zero_point20104_const" type="Const" version="opset1">
			<data element_type="f16" offset="25464" shape="64,1,1,1" size="128"/>
			<output>
				<port id="0" precision="FP16">
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="141" name="575/fq_weights_1/minus_zp" type="Subtract" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>64</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="1">
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>64</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="142" name="575/fq_weights_1/scale20099_const" type="Const" version="opset1">
			<data element_type="f16" offset="25592" shape="64,1,1,1" size="128"/>
			<output>
				<port id="0" precision="FP16">
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="143" name="575/fq_weights_1/mulpiply_by_scale" type="Multiply" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>64</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="1">
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>64</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="144" name="575" type="Convolution" version="opset1">
			<data auto_pad="explicit" dilations="1,1" pads_begin="0,0" pads_end="0,0" strides="1,1"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>64</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
				<port id="1">
					<dim>64</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" names="575" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
			</output>
		</layer>
		<layer id="145" name="28762878_const" type="Const" version="opset1">
			<data element_type="f16" offset="9720" shape="1,64,1,1" size="128"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="146" name="575/add_" type="Add" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>64</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
				<port id="1">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
			</output>
		</layer>
		<layer id="147" name="74877491_const" type="Const" version="opset1">
			<data element_type="f16" offset="25720" shape="1,64,1,1" size="128"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="148" name="74887492_const" type="Const" version="opset1">
			<data element_type="f16" offset="25848" shape="1,64,1,1" size="128"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="149" name="74897493_const" type="Const" version="opset1">
			<data element_type="f16" offset="25720" shape="1,64,1,1" size="128"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="150" name="74907494_const" type="Const" version="opset1">
			<data element_type="f16" offset="25848" shape="1,64,1,1" size="128"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="151" name="576/fq_input_0" type="FakeQuantize" version="opset1">
			<data auto_broadcast="numpy" levels="256"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>64</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
				<port id="1">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="2">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="3">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="4">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="5" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
			</output>
		</layer>
		<layer id="152" name="4223942242_const127215340/quantized18987_const" type="Const" version="opset1">
			<data element_type="i8" offset="25976" shape="64,1,3,3" size="576"/>
			<output>
				<port id="0" precision="I8">
					<dim>64</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</output>
		</layer>
		<layer id="153" name="4223942242_const127215340/quantized/to_f16" type="Convert" version="opset1">
			<data destination_type="f16"/>
			<input>
				<port id="0">
					<dim>64</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</input>
			<output>
				<port id="1" precision="FP16">
					<dim>64</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</output>
		</layer>
		<layer id="154" name="576/fq_weights_1/zero_point19000_const" type="Const" version="opset1">
			<data element_type="f16" offset="26552" shape="64,1,1,1" size="128"/>
			<output>
				<port id="0" precision="FP16">
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="155" name="576/fq_weights_1/minus_zp" type="Subtract" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>64</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
				<port id="1">
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>64</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</output>
		</layer>
		<layer id="156" name="576/fq_weights_1/scale18995_const" type="Const" version="opset1">
			<data element_type="f16" offset="26680" shape="64,1,1,1" size="128"/>
			<output>
				<port id="0" precision="FP16">
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="157" name="576/fq_weights_1/mulpiply_by_scale" type="Multiply" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>64</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
				<port id="1">
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>64</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</output>
		</layer>
		<layer id="158" name="24492/value24494_const" type="Const" version="opset1">
			<data element_type="i64" offset="20034" shape="5" size="40"/>
			<output>
				<port id="0" precision="I64">
					<dim>5</dim>
				</port>
			</output>
		</layer>
		<layer id="159" name="24492" type="Reshape" version="opset1">
			<data special_zero="true"/>
			<input>
				<port id="0">
					<dim>64</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
				<port id="1">
					<dim>5</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</output>
		</layer>
		<layer id="160" name="576" type="GroupConvolution" version="opset1">
			<data auto_pad="explicit" dilations="1,1" pads_begin="1,1" pads_end="1,1" strides="1,1"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>64</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
				<port id="1">
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
			</output>
		</layer>
		<layer id="161" name="data_add_217652177022728/EltwiseUnsqueeze23258_const1274_const" type="Const" version="opset1">
			<data element_type="f16" offset="26808" shape="1,64,1,1" size="128"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="162" name="577/variance/Fused_Add_" type="Add" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>64</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
				<port id="1">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" names="577" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
			</output>
		</layer>
		<layer id="163" name="578" type="ReLU" version="opset1">
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>64</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
			</input>
			<output>
				<port id="1" names="578" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
			</output>
		</layer>
		<layer id="164" name="60176021_const" type="Const" version="opset1">
			<data element_type="f16" offset="10108" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="165" name="60186022_const" type="Const" version="opset1">
			<data element_type="f16" offset="26936" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="166" name="60196023_const" type="Const" version="opset1">
			<data element_type="f16" offset="10108" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="167" name="60206024_const" type="Const" version="opset1">
			<data element_type="f16" offset="26936" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="168" name="579/fq_input_0" type="FakeQuantize" version="opset1">
			<data auto_broadcast="numpy" levels="256"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>64</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
				<port id="1"/>
				<port id="2"/>
				<port id="3"/>
				<port id="4"/>
			</input>
			<output>
				<port id="5" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
			</output>
		</layer>
		<layer id="169" name="conv2.0.conv2b.1.conv1.weight/quantized17691_const" type="Const" version="opset1">
			<data element_type="i8" offset="26938" shape="64,64,1,1" size="4096"/>
			<output>
				<port id="0" precision="I8">
					<dim>64</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="170" name="conv2.0.conv2b.1.conv1.weight/quantized/to_f16" type="Convert" version="opset1">
			<data destination_type="f16"/>
			<input>
				<port id="0">
					<dim>64</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="1" precision="FP16">
					<dim>64</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="171" name="579/fq_weights_1/zero_point17704_const" type="Const" version="opset1">
			<data element_type="f16" offset="31034" shape="64,1,1,1" size="128"/>
			<output>
				<port id="0" precision="FP16">
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="172" name="579/fq_weights_1/minus_zp" type="Subtract" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>64</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="1">
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>64</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="173" name="579/fq_weights_1/scale17699_const" type="Const" version="opset1">
			<data element_type="f16" offset="31162" shape="64,1,1,1" size="128"/>
			<output>
				<port id="0" precision="FP16">
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="174" name="579/fq_weights_1/mulpiply_by_scale" type="Multiply" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>64</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="1">
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>64</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="175" name="579" type="Convolution" version="opset1">
			<data auto_pad="explicit" dilations="1,1" pads_begin="0,0" pads_end="0,0" strides="1,1"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>64</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
				<port id="1">
					<dim>64</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" names="579" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
			</output>
		</layer>
		<layer id="176" name="28802882_const" type="Const" version="opset1">
			<data element_type="f16" offset="9720" shape="1,64,1,1" size="128"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="177" name="579/add_" type="Add" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>64</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
				<port id="1">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
			</output>
		</layer>
		<layer id="178" name="54475451_const" type="Const" version="opset1">
			<data element_type="f16" offset="31290" shape="1,64,1,1" size="128"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="179" name="54485452_const" type="Const" version="opset1">
			<data element_type="f16" offset="31418" shape="1,64,1,1" size="128"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="180" name="54495453_const" type="Const" version="opset1">
			<data element_type="f16" offset="31290" shape="1,64,1,1" size="128"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="181" name="54505454_const" type="Const" version="opset1">
			<data element_type="f16" offset="31418" shape="1,64,1,1" size="128"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="182" name="580/fq_input_0" type="FakeQuantize" version="opset1">
			<data auto_broadcast="numpy" levels="256"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>64</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
				<port id="1">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="2">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="3">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="4">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="5" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
			</output>
		</layer>
		<layer id="183" name="4223542238_const127915343/quantized20595_const" type="Const" version="opset1">
			<data element_type="i8" offset="31546" shape="64,1,3,3" size="576"/>
			<output>
				<port id="0" precision="I8">
					<dim>64</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</output>
		</layer>
		<layer id="184" name="4223542238_const127915343/quantized/to_f16" type="Convert" version="opset1">
			<data destination_type="f16"/>
			<input>
				<port id="0">
					<dim>64</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</input>
			<output>
				<port id="1" precision="FP16">
					<dim>64</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</output>
		</layer>
		<layer id="185" name="580/fq_weights_1/zero_point20608_const" type="Const" version="opset1">
			<data element_type="f16" offset="32122" shape="64,1,1,1" size="128"/>
			<output>
				<port id="0" precision="FP16">
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="186" name="580/fq_weights_1/minus_zp" type="Subtract" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>64</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
				<port id="1">
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>64</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</output>
		</layer>
		<layer id="187" name="580/fq_weights_1/scale20603_const" type="Const" version="opset1">
			<data element_type="f16" offset="32250" shape="64,1,1,1" size="128"/>
			<output>
				<port id="0" precision="FP16">
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="188" name="580/fq_weights_1/mulpiply_by_scale" type="Multiply" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>64</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
				<port id="1">
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>64</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</output>
		</layer>
		<layer id="189" name="24388/value24390_const" type="Const" version="opset1">
			<data element_type="i64" offset="20034" shape="5" size="40"/>
			<output>
				<port id="0" precision="I64">
					<dim>5</dim>
				</port>
			</output>
		</layer>
		<layer id="190" name="24388" type="Reshape" version="opset1">
			<data special_zero="true"/>
			<input>
				<port id="0">
					<dim>64</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
				<port id="1">
					<dim>5</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</output>
		</layer>
		<layer id="191" name="580" type="GroupConvolution" version="opset1">
			<data auto_pad="explicit" dilations="1,1" pads_begin="1,1" pads_end="1,1" strides="1,1"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>64</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
				<port id="1">
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
			</output>
		</layer>
		<layer id="192" name="data_add_217732177822730/EltwiseUnsqueeze23266_const1281_const" type="Const" version="opset1">
			<data element_type="f16" offset="32378" shape="1,64,1,1" size="128"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="193" name="581/variance/Fused_Add_" type="Add" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>64</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
				<port id="1">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" names="581" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
			</output>
		</layer>
		<layer id="194" name="582" type="ReLU" version="opset1">
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>64</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
			</input>
			<output>
				<port id="1" names="582" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
			</output>
		</layer>
		<layer id="195" name="78077811_const" type="Const" version="opset1">
			<data element_type="f16" offset="10108" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="196" name="78087812_const" type="Const" version="opset1">
			<data element_type="f16" offset="32506" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="197" name="78097813_const" type="Const" version="opset1">
			<data element_type="f16" offset="10108" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="198" name="78107814_const" type="Const" version="opset1">
			<data element_type="f16" offset="32506" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="199" name="617/reduce/fq_input_0" type="FakeQuantize" version="opset1">
			<data auto_broadcast="numpy" levels="256"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>64</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
				<port id="1"/>
				<port id="2"/>
				<port id="3"/>
				<port id="4"/>
			</input>
			<output>
				<port id="5" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
			</output>
		</layer>
		<layer id="200" name="1329/Output_0/Data__const1284_const" type="Const" version="opset1">
			<data element_type="i64" offset="24" shape="" size="8"/>
			<output>
				<port id="0" precision="I64"/>
			</output>
		</layer>
		<layer id="201" name="617/input_rank/shape_of" type="ShapeOf" version="opset3">
			<data output_type="i64"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>64</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
			</input>
			<output>
				<port id="1" precision="I64">
					<dim>4</dim>
				</port>
			</output>
		</layer>
		<layer id="202" name="617/input_rank/rank_of" type="ShapeOf" version="opset3">
			<data output_type="i64"/>
			<input>
				<port id="0">
					<dim>4</dim>
				</port>
			</input>
			<output>
				<port id="1" precision="I64">
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="203" name="617/input_rank/0d_rank_of/value/Output_0/Data__const1287_const" type="Const" version="opset1">
			<data element_type="i64" offset="32" shape="1" size="8"/>
			<output>
				<port id="0" precision="I64">
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="204" name="617/input_rank" type="Squeeze" version="opset1">
			<input>
				<port id="0">
					<dim>1</dim>
				</port>
				<port id="1">
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="I64"/>
			</output>
		</layer>
		<layer id="205" name="1331/Output_0/Data__const1289_const" type="Const" version="opset1">
			<data element_type="i64" offset="0" shape="" size="8"/>
			<output>
				<port id="0" precision="I64"/>
			</output>
		</layer>
		<layer id="206" name="617/global_pooling_reduce_axis" type="Range" version="opset4">
			<data output_type="i64"/>
			<input>
				<port id="0"/>
				<port id="1"/>
				<port id="2"/>
			</input>
			<output>
				<port id="3" precision="I64">
					<dim>2</dim>
				</port>
			</output>
		</layer>
		<layer id="207" name="617/reduce" type="ReduceMean" version="opset1">
			<data keep_dims="true"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>64</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
				<port id="1">
					<dim>2</dim>
				</port>
			</input>
			<output>
				<port id="2" names="617" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="208" name="Copy_conv2.0.gate.fc1.weight/Output_0/Data_4368_const1292_const" type="Const" version="opset1">
			<data element_type="f16" offset="20204" shape="4,64,1,1" size="512"/>
			<output>
				<port id="0" names="conv2.0.gate.fc1.weight" precision="FP16">
					<dim>4</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="209" name="618/WithoutBiases" type="Convolution" version="opset1">
			<data auto_pad="explicit" dilations="1,1" pads_begin="0,0" pads_end="0,0" strides="1,1"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="1">
					<dim>4</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>1</dim>
					<dim>4</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="210" name="618/Dims1294622693/EltwiseUnsqueeze23126_const1294_const" type="Const" version="opset1">
			<data element_type="f16" offset="20716" shape="1,4,1,1" size="8"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>4</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="211" name="618" type="Add" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>4</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="1">
					<dim>1</dim>
					<dim>4</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" names="618" precision="FP16">
					<dim>1</dim>
					<dim>4</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="212" name="619" type="ReLU" version="opset1">
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>4</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="1" names="619" precision="FP16">
					<dim>1</dim>
					<dim>4</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="213" name="Copy_conv2.0.gate.fc2.weight/Output_0/Data_4376_const1297_const" type="Const" version="opset1">
			<data element_type="f16" offset="20724" shape="64,4,1,1" size="512"/>
			<output>
				<port id="0" names="conv2.0.gate.fc2.weight" precision="FP16">
					<dim>64</dim>
					<dim>4</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="214" name="620/WithoutBiases" type="Convolution" version="opset1">
			<data auto_pad="explicit" dilations="1,1" pads_begin="0,0" pads_end="0,0" strides="1,1"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>4</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="1">
					<dim>64</dim>
					<dim>4</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="215" name="620/Dims1288622683/EltwiseUnsqueeze23086_const1299_const" type="Const" version="opset1">
			<data element_type="f16" offset="21236" shape="1,64,1,1" size="128"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="216" name="620" type="Add" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="1">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" names="620" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="217" name="621" type="Sigmoid" version="opset1">
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="1" names="621" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="218" name="60876091_const" type="Const" version="opset1">
			<data element_type="f16" offset="10108" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="219" name="60886092_const" type="Const" version="opset1">
			<data element_type="f16" offset="32508" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="220" name="60896093_const" type="Const" version="opset1">
			<data element_type="f16" offset="10108" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="221" name="60906094_const" type="Const" version="opset1">
			<data element_type="f16" offset="32508" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="222" name="622/fq_input_1" type="FakeQuantize" version="opset1">
			<data auto_broadcast="numpy" levels="256"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="1"/>
				<port id="2"/>
				<port id="3"/>
				<port id="4"/>
			</input>
			<output>
				<port id="5" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="223" name="622" type="Multiply" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>64</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
				<port id="1">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" names="622" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
			</output>
		</layer>
		<layer id="224" name="45074511_const" type="Const" version="opset1">
			<data element_type="f16" offset="10108" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="225" name="45084512_const" type="Const" version="opset1">
			<data element_type="f16" offset="32510" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="226" name="45094513_const" type="Const" version="opset1">
			<data element_type="f16" offset="10108" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="227" name="45104514_const" type="Const" version="opset1">
			<data element_type="f16" offset="32510" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="228" name="623/fq_input_1" type="FakeQuantize" version="opset1">
			<data auto_broadcast="numpy" levels="256"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>64</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
				<port id="1"/>
				<port id="2"/>
				<port id="3"/>
				<port id="4"/>
			</input>
			<output>
				<port id="5" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
			</output>
		</layer>
		<layer id="229" name="623" type="Add" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>64</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
				<port id="1">
					<dim>1</dim>
					<dim>64</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
			</input>
			<output>
				<port id="2" names="623" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
			</output>
		</layer>
		<layer id="230" name="79877991_const" type="Const" version="opset1">
			<data element_type="f16" offset="10108" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="231" name="79887992_const" type="Const" version="opset1">
			<data element_type="f16" offset="32512" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="232" name="79897993_const" type="Const" version="opset1">
			<data element_type="f16" offset="10108" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="233" name="79907994_const" type="Const" version="opset1">
			<data element_type="f16" offset="32512" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="234" name="630/fq_input_0" type="FakeQuantize" version="opset1">
			<data auto_broadcast="numpy" levels="256"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>64</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
				<port id="1"/>
				<port id="2"/>
				<port id="3"/>
				<port id="4"/>
			</input>
			<output>
				<port id="5" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
			</output>
		</layer>
		<layer id="235" name="conv2.0.conv2c.0.conv1.weight/quantized20499_const" type="Const" version="opset1">
			<data element_type="i8" offset="32514" shape="64,64,1,1" size="4096"/>
			<output>
				<port id="0" precision="I8">
					<dim>64</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="236" name="conv2.0.conv2c.0.conv1.weight/quantized/to_f16" type="Convert" version="opset1">
			<data destination_type="f16"/>
			<input>
				<port id="0">
					<dim>64</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="1" precision="FP16">
					<dim>64</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="237" name="583/fq_weights_1/zero_point20512_const" type="Const" version="opset1">
			<data element_type="f16" offset="36610" shape="64,1,1,1" size="128"/>
			<output>
				<port id="0" precision="FP16">
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="238" name="583/fq_weights_1/minus_zp" type="Subtract" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>64</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="1">
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>64</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="239" name="583/fq_weights_1/scale20507_const" type="Const" version="opset1">
			<data element_type="f16" offset="36738" shape="64,1,1,1" size="128"/>
			<output>
				<port id="0" precision="FP16">
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="240" name="583/fq_weights_1/mulpiply_by_scale" type="Multiply" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>64</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="1">
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>64</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="241" name="583" type="Convolution" version="opset1">
			<data auto_pad="explicit" dilations="1,1" pads_begin="0,0" pads_end="0,0" strides="1,1"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>64</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
				<port id="1">
					<dim>64</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" names="583" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
			</output>
		</layer>
		<layer id="242" name="28842886_const" type="Const" version="opset1">
			<data element_type="f16" offset="9720" shape="1,64,1,1" size="128"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="243" name="583/add_" type="Add" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>64</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
				<port id="1">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
			</output>
		</layer>
		<layer id="244" name="61776181_const" type="Const" version="opset1">
			<data element_type="f16" offset="36866" shape="1,64,1,1" size="128"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="245" name="61786182_const" type="Const" version="opset1">
			<data element_type="f16" offset="36994" shape="1,64,1,1" size="128"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="246" name="61796183_const" type="Const" version="opset1">
			<data element_type="f16" offset="36866" shape="1,64,1,1" size="128"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="247" name="61806184_const" type="Const" version="opset1">
			<data element_type="f16" offset="36994" shape="1,64,1,1" size="128"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="248" name="584/fq_input_0" type="FakeQuantize" version="opset1">
			<data auto_broadcast="numpy" levels="256"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>64</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
				<port id="1">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="2">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="3">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="4">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="5" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
			</output>
		</layer>
		<layer id="249" name="4219542198_const130615353/quantized19827_const" type="Const" version="opset1">
			<data element_type="i8" offset="37122" shape="64,1,3,3" size="576"/>
			<output>
				<port id="0" precision="I8">
					<dim>64</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</output>
		</layer>
		<layer id="250" name="4219542198_const130615353/quantized/to_f16" type="Convert" version="opset1">
			<data destination_type="f16"/>
			<input>
				<port id="0">
					<dim>64</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</input>
			<output>
				<port id="1" precision="FP16">
					<dim>64</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</output>
		</layer>
		<layer id="251" name="584/fq_weights_1/zero_point19840_const" type="Const" version="opset1">
			<data element_type="f16" offset="37698" shape="64,1,1,1" size="128"/>
			<output>
				<port id="0" precision="FP16">
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="252" name="584/fq_weights_1/minus_zp" type="Subtract" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>64</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
				<port id="1">
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>64</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</output>
		</layer>
		<layer id="253" name="584/fq_weights_1/scale19835_const" type="Const" version="opset1">
			<data element_type="f16" offset="37826" shape="64,1,1,1" size="128"/>
			<output>
				<port id="0" precision="FP16">
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="254" name="584/fq_weights_1/mulpiply_by_scale" type="Multiply" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>64</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
				<port id="1">
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>64</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</output>
		</layer>
		<layer id="255" name="24404/value24406_const" type="Const" version="opset1">
			<data element_type="i64" offset="20034" shape="5" size="40"/>
			<output>
				<port id="0" precision="I64">
					<dim>5</dim>
				</port>
			</output>
		</layer>
		<layer id="256" name="24404" type="Reshape" version="opset1">
			<data special_zero="true"/>
			<input>
				<port id="0">
					<dim>64</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
				<port id="1">
					<dim>5</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</output>
		</layer>
		<layer id="257" name="584" type="GroupConvolution" version="opset1">
			<data auto_pad="explicit" dilations="1,1" pads_begin="1,1" pads_end="1,1" strides="1,1"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>64</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
				<port id="1">
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
			</output>
		</layer>
		<layer id="258" name="data_add_217412174622722/EltwiseUnsqueeze23234_const1308_const" type="Const" version="opset1">
			<data element_type="f16" offset="37954" shape="1,64,1,1" size="128"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="259" name="585/variance/Fused_Add_" type="Add" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>64</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
				<port id="1">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" names="585" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
			</output>
		</layer>
		<layer id="260" name="586" type="ReLU" version="opset1">
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>64</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
			</input>
			<output>
				<port id="1" names="586" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
			</output>
		</layer>
		<layer id="261" name="45274531_const" type="Const" version="opset1">
			<data element_type="f16" offset="10108" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="262" name="45284532_const" type="Const" version="opset1">
			<data element_type="f16" offset="38082" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="263" name="45294533_const" type="Const" version="opset1">
			<data element_type="f16" offset="10108" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="264" name="45304534_const" type="Const" version="opset1">
			<data element_type="f16" offset="38082" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="265" name="587/fq_input_0" type="FakeQuantize" version="opset1">
			<data auto_broadcast="numpy" levels="256"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>64</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
				<port id="1"/>
				<port id="2"/>
				<port id="3"/>
				<port id="4"/>
			</input>
			<output>
				<port id="5" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
			</output>
		</layer>
		<layer id="266" name="conv2.0.conv2c.1.conv1.weight/quantized19395_const" type="Const" version="opset1">
			<data element_type="i8" offset="38084" shape="64,64,1,1" size="4096"/>
			<output>
				<port id="0" precision="I8">
					<dim>64</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="267" name="conv2.0.conv2c.1.conv1.weight/quantized/to_f16" type="Convert" version="opset1">
			<data destination_type="f16"/>
			<input>
				<port id="0">
					<dim>64</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="1" precision="FP16">
					<dim>64</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="268" name="587/fq_weights_1/zero_point19408_const" type="Const" version="opset1">
			<data element_type="f16" offset="42180" shape="64,1,1,1" size="128"/>
			<output>
				<port id="0" precision="FP16">
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="269" name="587/fq_weights_1/minus_zp" type="Subtract" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>64</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="1">
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>64</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="270" name="587/fq_weights_1/scale19403_const" type="Const" version="opset1">
			<data element_type="f16" offset="42308" shape="64,1,1,1" size="128"/>
			<output>
				<port id="0" precision="FP16">
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="271" name="587/fq_weights_1/mulpiply_by_scale" type="Multiply" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>64</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="1">
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>64</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="272" name="587" type="Convolution" version="opset1">
			<data auto_pad="explicit" dilations="1,1" pads_begin="0,0" pads_end="0,0" strides="1,1"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>64</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
				<port id="1">
					<dim>64</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" names="587" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
			</output>
		</layer>
		<layer id="273" name="28882890_const" type="Const" version="opset1">
			<data element_type="f16" offset="9720" shape="1,64,1,1" size="128"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="274" name="587/add_" type="Add" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>64</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
				<port id="1">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
			</output>
		</layer>
		<layer id="275" name="75877591_const" type="Const" version="opset1">
			<data element_type="f16" offset="42436" shape="1,64,1,1" size="128"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="276" name="75887592_const" type="Const" version="opset1">
			<data element_type="f16" offset="42564" shape="1,64,1,1" size="128"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="277" name="75897593_const" type="Const" version="opset1">
			<data element_type="f16" offset="42436" shape="1,64,1,1" size="128"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="278" name="75907594_const" type="Const" version="opset1">
			<data element_type="f16" offset="42564" shape="1,64,1,1" size="128"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="279" name="588/fq_input_0" type="FakeQuantize" version="opset1">
			<data auto_broadcast="numpy" levels="256"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>64</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
				<port id="1">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="2">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="3">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="4">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="5" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
			</output>
		</layer>
		<layer id="280" name="4222742230_const131315356/quantized17883_const" type="Const" version="opset1">
			<data element_type="i8" offset="42692" shape="64,1,3,3" size="576"/>
			<output>
				<port id="0" precision="I8">
					<dim>64</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</output>
		</layer>
		<layer id="281" name="4222742230_const131315356/quantized/to_f16" type="Convert" version="opset1">
			<data destination_type="f16"/>
			<input>
				<port id="0">
					<dim>64</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</input>
			<output>
				<port id="1" precision="FP16">
					<dim>64</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</output>
		</layer>
		<layer id="282" name="588/fq_weights_1/zero_point17896_const" type="Const" version="opset1">
			<data element_type="f16" offset="43268" shape="64,1,1,1" size="128"/>
			<output>
				<port id="0" precision="FP16">
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="283" name="588/fq_weights_1/minus_zp" type="Subtract" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>64</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
				<port id="1">
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>64</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</output>
		</layer>
		<layer id="284" name="588/fq_weights_1/scale17891_const" type="Const" version="opset1">
			<data element_type="f16" offset="43396" shape="64,1,1,1" size="128"/>
			<output>
				<port id="0" precision="FP16">
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="285" name="588/fq_weights_1/mulpiply_by_scale" type="Multiply" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>64</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
				<port id="1">
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>64</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</output>
		</layer>
		<layer id="286" name="24444/value24446_const" type="Const" version="opset1">
			<data element_type="i64" offset="20034" shape="5" size="40"/>
			<output>
				<port id="0" precision="I64">
					<dim>5</dim>
				</port>
			</output>
		</layer>
		<layer id="287" name="24444" type="Reshape" version="opset1">
			<data special_zero="true"/>
			<input>
				<port id="0">
					<dim>64</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
				<port id="1">
					<dim>5</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</output>
		</layer>
		<layer id="288" name="588" type="GroupConvolution" version="opset1">
			<data auto_pad="explicit" dilations="1,1" pads_begin="1,1" pads_end="1,1" strides="1,1"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>64</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
				<port id="1">
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
			</output>
		</layer>
		<layer id="289" name="data_add_217492175422724/EltwiseUnsqueeze23242_const1315_const" type="Const" version="opset1">
			<data element_type="f16" offset="43524" shape="1,64,1,1" size="128"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="290" name="589/variance/Fused_Add_" type="Add" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>64</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
				<port id="1">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" names="589" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
			</output>
		</layer>
		<layer id="291" name="590" type="ReLU" version="opset1">
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>64</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
			</input>
			<output>
				<port id="1" names="590" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
			</output>
		</layer>
		<layer id="292" name="76077611_const" type="Const" version="opset1">
			<data element_type="f16" offset="10108" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="293" name="76087612_const" type="Const" version="opset1">
			<data element_type="f16" offset="43652" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="294" name="76097613_const" type="Const" version="opset1">
			<data element_type="f16" offset="10108" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="295" name="76107614_const" type="Const" version="opset1">
			<data element_type="f16" offset="43652" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="296" name="591/fq_input_0" type="FakeQuantize" version="opset1">
			<data auto_broadcast="numpy" levels="256"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>64</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
				<port id="1"/>
				<port id="2"/>
				<port id="3"/>
				<port id="4"/>
			</input>
			<output>
				<port id="5" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
			</output>
		</layer>
		<layer id="297" name="conv2.0.conv2c.2.conv1.weight/quantized19971_const" type="Const" version="opset1">
			<data element_type="i8" offset="43654" shape="64,64,1,1" size="4096"/>
			<output>
				<port id="0" precision="I8">
					<dim>64</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="298" name="conv2.0.conv2c.2.conv1.weight/quantized/to_f16" type="Convert" version="opset1">
			<data destination_type="f16"/>
			<input>
				<port id="0">
					<dim>64</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="1" precision="FP16">
					<dim>64</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="299" name="591/fq_weights_1/zero_point19984_const" type="Const" version="opset1">
			<data element_type="f16" offset="47750" shape="64,1,1,1" size="128"/>
			<output>
				<port id="0" precision="FP16">
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="300" name="591/fq_weights_1/minus_zp" type="Subtract" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>64</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="1">
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>64</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="301" name="591/fq_weights_1/scale19979_const" type="Const" version="opset1">
			<data element_type="f16" offset="47878" shape="64,1,1,1" size="128"/>
			<output>
				<port id="0" precision="FP16">
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="302" name="591/fq_weights_1/mulpiply_by_scale" type="Multiply" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>64</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="1">
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>64</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="303" name="591" type="Convolution" version="opset1">
			<data auto_pad="explicit" dilations="1,1" pads_begin="0,0" pads_end="0,0" strides="1,1"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>64</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
				<port id="1">
					<dim>64</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" names="591" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
			</output>
		</layer>
		<layer id="304" name="28922894_const" type="Const" version="opset1">
			<data element_type="f16" offset="9720" shape="1,64,1,1" size="128"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="305" name="591/add_" type="Add" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>64</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
				<port id="1">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
			</output>
		</layer>
		<layer id="306" name="74477451_const" type="Const" version="opset1">
			<data element_type="f16" offset="48006" shape="1,64,1,1" size="128"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="307" name="74487452_const" type="Const" version="opset1">
			<data element_type="f16" offset="48134" shape="1,64,1,1" size="128"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="308" name="74497453_const" type="Const" version="opset1">
			<data element_type="f16" offset="48006" shape="1,64,1,1" size="128"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="309" name="74507454_const" type="Const" version="opset1">
			<data element_type="f16" offset="48134" shape="1,64,1,1" size="128"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="310" name="592/fq_input_0" type="FakeQuantize" version="opset1">
			<data auto_broadcast="numpy" levels="256"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>64</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
				<port id="1">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="2">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="3">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="4">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="5" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
			</output>
		</layer>
		<layer id="311" name="4225942262_const132015359/quantized20235_const" type="Const" version="opset1">
			<data element_type="i8" offset="48262" shape="64,1,3,3" size="576"/>
			<output>
				<port id="0" precision="I8">
					<dim>64</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</output>
		</layer>
		<layer id="312" name="4225942262_const132015359/quantized/to_f16" type="Convert" version="opset1">
			<data destination_type="f16"/>
			<input>
				<port id="0">
					<dim>64</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</input>
			<output>
				<port id="1" precision="FP16">
					<dim>64</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</output>
		</layer>
		<layer id="313" name="592/fq_weights_1/zero_point20248_const" type="Const" version="opset1">
			<data element_type="f16" offset="48838" shape="64,1,1,1" size="128"/>
			<output>
				<port id="0" precision="FP16">
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="314" name="592/fq_weights_1/minus_zp" type="Subtract" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>64</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
				<port id="1">
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>64</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</output>
		</layer>
		<layer id="315" name="592/fq_weights_1/scale20243_const" type="Const" version="opset1">
			<data element_type="f16" offset="48966" shape="64,1,1,1" size="128"/>
			<output>
				<port id="0" precision="FP16">
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="316" name="592/fq_weights_1/mulpiply_by_scale" type="Multiply" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>64</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
				<port id="1">
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>64</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</output>
		</layer>
		<layer id="317" name="24604/value24606_const" type="Const" version="opset1">
			<data element_type="i64" offset="20034" shape="5" size="40"/>
			<output>
				<port id="0" precision="I64">
					<dim>5</dim>
				</port>
			</output>
		</layer>
		<layer id="318" name="24604" type="Reshape" version="opset1">
			<data special_zero="true"/>
			<input>
				<port id="0">
					<dim>64</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
				<port id="1">
					<dim>5</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</output>
		</layer>
		<layer id="319" name="592" type="GroupConvolution" version="opset1">
			<data auto_pad="explicit" dilations="1,1" pads_begin="1,1" pads_end="1,1" strides="1,1"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>64</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
				<port id="1">
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
			</output>
		</layer>
		<layer id="320" name="data_add_217572176222726/EltwiseUnsqueeze23250_const1322_const" type="Const" version="opset1">
			<data element_type="f16" offset="49094" shape="1,64,1,1" size="128"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="321" name="593/variance/Fused_Add_" type="Add" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>64</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
				<port id="1">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" names="593" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
			</output>
		</layer>
		<layer id="322" name="594" type="ReLU" version="opset1">
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>64</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
			</input>
			<output>
				<port id="1" names="594" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
			</output>
		</layer>
		<layer id="323" name="68676871_const" type="Const" version="opset1">
			<data element_type="f16" offset="10108" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="324" name="68686872_const" type="Const" version="opset1">
			<data element_type="f16" offset="49222" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="325" name="68696873_const" type="Const" version="opset1">
			<data element_type="f16" offset="10108" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="326" name="68706874_const" type="Const" version="opset1">
			<data element_type="f16" offset="49222" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="327" name="624/reduce/fq_input_0" type="FakeQuantize" version="opset1">
			<data auto_broadcast="numpy" levels="256"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>64</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
				<port id="1"/>
				<port id="2"/>
				<port id="3"/>
				<port id="4"/>
			</input>
			<output>
				<port id="5" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
			</output>
		</layer>
		<layer id="328" name="1334/Output_0/Data__const1325_const" type="Const" version="opset1">
			<data element_type="i64" offset="24" shape="" size="8"/>
			<output>
				<port id="0" precision="I64"/>
			</output>
		</layer>
		<layer id="329" name="624/input_rank/shape_of" type="ShapeOf" version="opset3">
			<data output_type="i64"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>64</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
			</input>
			<output>
				<port id="1" precision="I64">
					<dim>4</dim>
				</port>
			</output>
		</layer>
		<layer id="330" name="624/input_rank/rank_of" type="ShapeOf" version="opset3">
			<data output_type="i64"/>
			<input>
				<port id="0">
					<dim>4</dim>
				</port>
			</input>
			<output>
				<port id="1" precision="I64">
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="331" name="624/input_rank/0d_rank_of/value/Output_0/Data__const1328_const" type="Const" version="opset1">
			<data element_type="i64" offset="32" shape="1" size="8"/>
			<output>
				<port id="0" precision="I64">
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="332" name="624/input_rank" type="Squeeze" version="opset1">
			<input>
				<port id="0">
					<dim>1</dim>
				</port>
				<port id="1">
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="I64"/>
			</output>
		</layer>
		<layer id="333" name="1336/Output_0/Data__const1330_const" type="Const" version="opset1">
			<data element_type="i64" offset="0" shape="" size="8"/>
			<output>
				<port id="0" precision="I64"/>
			</output>
		</layer>
		<layer id="334" name="624/global_pooling_reduce_axis" type="Range" version="opset4">
			<data output_type="i64"/>
			<input>
				<port id="0"/>
				<port id="1"/>
				<port id="2"/>
			</input>
			<output>
				<port id="3" precision="I64">
					<dim>2</dim>
				</port>
			</output>
		</layer>
		<layer id="335" name="624/reduce" type="ReduceMean" version="opset1">
			<data keep_dims="true"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>64</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
				<port id="1">
					<dim>2</dim>
				</port>
			</input>
			<output>
				<port id="2" names="624" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="336" name="Copy_conv2.0.gate.fc1.weight/Output_0/Data_4369_const1333_const" type="Const" version="opset1">
			<data element_type="f16" offset="20204" shape="4,64,1,1" size="512"/>
			<output>
				<port id="0" names="conv2.0.gate.fc1.weight" precision="FP16">
					<dim>4</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="337" name="625/WithoutBiases" type="Convolution" version="opset1">
			<data auto_pad="explicit" dilations="1,1" pads_begin="0,0" pads_end="0,0" strides="1,1"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="1">
					<dim>4</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>1</dim>
					<dim>4</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="338" name="625/Dims1302422706/EltwiseUnsqueeze23178_const1335_const" type="Const" version="opset1">
			<data element_type="f16" offset="20716" shape="1,4,1,1" size="8"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>4</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="339" name="625" type="Add" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>4</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="1">
					<dim>1</dim>
					<dim>4</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" names="625" precision="FP16">
					<dim>1</dim>
					<dim>4</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="340" name="626" type="ReLU" version="opset1">
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>4</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="1" names="626" precision="FP16">
					<dim>1</dim>
					<dim>4</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="341" name="Copy_conv2.0.gate.fc2.weight/Output_0/Data_4377_const1338_const" type="Const" version="opset1">
			<data element_type="f16" offset="20724" shape="64,4,1,1" size="512"/>
			<output>
				<port id="0" names="conv2.0.gate.fc2.weight" precision="FP16">
					<dim>64</dim>
					<dim>4</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="342" name="627/WithoutBiases" type="Convolution" version="opset1">
			<data auto_pad="explicit" dilations="1,1" pads_begin="0,0" pads_end="0,0" strides="1,1"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>4</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="1">
					<dim>64</dim>
					<dim>4</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="343" name="627/Dims1300022702/EltwiseUnsqueeze23162_const1340_const" type="Const" version="opset1">
			<data element_type="f16" offset="21236" shape="1,64,1,1" size="128"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="344" name="627" type="Add" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="1">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" names="627" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="345" name="628" type="Sigmoid" version="opset1">
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="1" names="628" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="346" name="75677571_const" type="Const" version="opset1">
			<data element_type="f16" offset="10108" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="347" name="75687572_const" type="Const" version="opset1">
			<data element_type="f16" offset="49224" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="348" name="75697573_const" type="Const" version="opset1">
			<data element_type="f16" offset="10108" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="349" name="75707574_const" type="Const" version="opset1">
			<data element_type="f16" offset="49224" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="350" name="629/fq_input_1" type="FakeQuantize" version="opset1">
			<data auto_broadcast="numpy" levels="256"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="1"/>
				<port id="2"/>
				<port id="3"/>
				<port id="4"/>
			</input>
			<output>
				<port id="5" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="351" name="629" type="Multiply" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>64</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
				<port id="1">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" names="629" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
			</output>
		</layer>
		<layer id="352" name="79978001_const" type="Const" version="opset1">
			<data element_type="f16" offset="10108" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="353" name="79988002_const" type="Const" version="opset1">
			<data element_type="f16" offset="49226" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="354" name="79998003_const" type="Const" version="opset1">
			<data element_type="f16" offset="10108" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="355" name="80008004_const" type="Const" version="opset1">
			<data element_type="f16" offset="49226" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="356" name="630/fq_input_1" type="FakeQuantize" version="opset1">
			<data auto_broadcast="numpy" levels="256"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>64</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
				<port id="1"/>
				<port id="2"/>
				<port id="3"/>
				<port id="4"/>
			</input>
			<output>
				<port id="5" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
			</output>
		</layer>
		<layer id="357" name="630" type="Add" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>64</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
				<port id="1">
					<dim>1</dim>
					<dim>64</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
			</input>
			<output>
				<port id="2" names="630" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
			</output>
		</layer>
		<layer id="358" name="69876991_const" type="Const" version="opset1">
			<data element_type="f16" offset="10108" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="359" name="69886992_const" type="Const" version="opset1">
			<data element_type="f16" offset="49228" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="360" name="69896993_const" type="Const" version="opset1">
			<data element_type="f16" offset="10108" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="361" name="69906994_const" type="Const" version="opset1">
			<data element_type="f16" offset="49228" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="362" name="637/fq_input_0" type="FakeQuantize" version="opset1">
			<data auto_broadcast="numpy" levels="256"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>64</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
				<port id="1"/>
				<port id="2"/>
				<port id="3"/>
				<port id="4"/>
			</input>
			<output>
				<port id="5" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
			</output>
		</layer>
		<layer id="363" name="conv2.0.conv2d.0.conv1.weight/quantized19203_const" type="Const" version="opset1">
			<data element_type="i8" offset="49230" shape="64,64,1,1" size="4096"/>
			<output>
				<port id="0" precision="I8">
					<dim>64</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="364" name="conv2.0.conv2d.0.conv1.weight/quantized/to_f16" type="Convert" version="opset1">
			<data destination_type="f16"/>
			<input>
				<port id="0">
					<dim>64</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="1" precision="FP16">
					<dim>64</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="365" name="595/fq_weights_1/zero_point19216_const" type="Const" version="opset1">
			<data element_type="f16" offset="53326" shape="64,1,1,1" size="128"/>
			<output>
				<port id="0" precision="FP16">
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="366" name="595/fq_weights_1/minus_zp" type="Subtract" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>64</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="1">
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>64</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="367" name="595/fq_weights_1/scale19211_const" type="Const" version="opset1">
			<data element_type="f16" offset="53454" shape="64,1,1,1" size="128"/>
			<output>
				<port id="0" precision="FP16">
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="368" name="595/fq_weights_1/mulpiply_by_scale" type="Multiply" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>64</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="1">
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>64</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="369" name="595" type="Convolution" version="opset1">
			<data auto_pad="explicit" dilations="1,1" pads_begin="0,0" pads_end="0,0" strides="1,1"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>64</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
				<port id="1">
					<dim>64</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" names="595" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
			</output>
		</layer>
		<layer id="370" name="28962898_const" type="Const" version="opset1">
			<data element_type="f16" offset="9720" shape="1,64,1,1" size="128"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="371" name="595/add_" type="Add" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>64</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
				<port id="1">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
			</output>
		</layer>
		<layer id="372" name="42274231_const" type="Const" version="opset1">
			<data element_type="f16" offset="53582" shape="1,64,1,1" size="128"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="373" name="42284232_const" type="Const" version="opset1">
			<data element_type="f16" offset="53710" shape="1,64,1,1" size="128"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="374" name="42294233_const" type="Const" version="opset1">
			<data element_type="f16" offset="53582" shape="1,64,1,1" size="128"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="375" name="42304234_const" type="Const" version="opset1">
			<data element_type="f16" offset="53710" shape="1,64,1,1" size="128"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="376" name="596/fq_input_0" type="FakeQuantize" version="opset1">
			<data auto_broadcast="numpy" levels="256"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>64</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
				<port id="1">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="2">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="3">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="4">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="5" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
			</output>
		</layer>
		<layer id="377" name="4215942162_const134715369/quantized20571_const" type="Const" version="opset1">
			<data element_type="i8" offset="53838" shape="64,1,3,3" size="576"/>
			<output>
				<port id="0" precision="I8">
					<dim>64</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</output>
		</layer>
		<layer id="378" name="4215942162_const134715369/quantized/to_f16" type="Convert" version="opset1">
			<data destination_type="f16"/>
			<input>
				<port id="0">
					<dim>64</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</input>
			<output>
				<port id="1" precision="FP16">
					<dim>64</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</output>
		</layer>
		<layer id="379" name="596/fq_weights_1/zero_point20584_const" type="Const" version="opset1">
			<data element_type="f16" offset="54414" shape="64,1,1,1" size="128"/>
			<output>
				<port id="0" precision="FP16">
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="380" name="596/fq_weights_1/minus_zp" type="Subtract" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>64</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
				<port id="1">
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>64</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</output>
		</layer>
		<layer id="381" name="596/fq_weights_1/scale20579_const" type="Const" version="opset1">
			<data element_type="f16" offset="54542" shape="64,1,1,1" size="128"/>
			<output>
				<port id="0" precision="FP16">
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="382" name="596/fq_weights_1/mulpiply_by_scale" type="Multiply" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>64</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
				<port id="1">
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>64</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</output>
		</layer>
		<layer id="383" name="24504/value24506_const" type="Const" version="opset1">
			<data element_type="i64" offset="20034" shape="5" size="40"/>
			<output>
				<port id="0" precision="I64">
					<dim>5</dim>
				</port>
			</output>
		</layer>
		<layer id="384" name="24504" type="Reshape" version="opset1">
			<data special_zero="true"/>
			<input>
				<port id="0">
					<dim>64</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
				<port id="1">
					<dim>5</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</output>
		</layer>
		<layer id="385" name="596" type="GroupConvolution" version="opset1">
			<data auto_pad="explicit" dilations="1,1" pads_begin="1,1" pads_end="1,1" strides="1,1"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>64</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
				<port id="1">
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
			</output>
		</layer>
		<layer id="386" name="data_add_217092171422714/EltwiseUnsqueeze23202_const1349_const" type="Const" version="opset1">
			<data element_type="f16" offset="54670" shape="1,64,1,1" size="128"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="387" name="597/variance/Fused_Add_" type="Add" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>64</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
				<port id="1">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" names="597" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
			</output>
		</layer>
		<layer id="388" name="598" type="ReLU" version="opset1">
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>64</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
			</input>
			<output>
				<port id="1" names="598" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
			</output>
		</layer>
		<layer id="389" name="47874791_const" type="Const" version="opset1">
			<data element_type="f16" offset="10108" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="390" name="47884792_const" type="Const" version="opset1">
			<data element_type="f16" offset="54798" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="391" name="47894793_const" type="Const" version="opset1">
			<data element_type="f16" offset="10108" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="392" name="47904794_const" type="Const" version="opset1">
			<data element_type="f16" offset="54798" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="393" name="599/fq_input_0" type="FakeQuantize" version="opset1">
			<data auto_broadcast="numpy" levels="256"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>64</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
				<port id="1"/>
				<port id="2"/>
				<port id="3"/>
				<port id="4"/>
			</input>
			<output>
				<port id="5" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
			</output>
		</layer>
		<layer id="394" name="conv2.0.conv2d.1.conv1.weight/quantized19323_const" type="Const" version="opset1">
			<data element_type="i8" offset="54800" shape="64,64,1,1" size="4096"/>
			<output>
				<port id="0" precision="I8">
					<dim>64</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="395" name="conv2.0.conv2d.1.conv1.weight/quantized/to_f16" type="Convert" version="opset1">
			<data destination_type="f16"/>
			<input>
				<port id="0">
					<dim>64</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="1" precision="FP16">
					<dim>64</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="396" name="599/fq_weights_1/zero_point19336_const" type="Const" version="opset1">
			<data element_type="f16" offset="58896" shape="64,1,1,1" size="128"/>
			<output>
				<port id="0" precision="FP16">
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="397" name="599/fq_weights_1/minus_zp" type="Subtract" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>64</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="1">
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>64</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="398" name="599/fq_weights_1/scale19331_const" type="Const" version="opset1">
			<data element_type="f16" offset="59024" shape="64,1,1,1" size="128"/>
			<output>
				<port id="0" precision="FP16">
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="399" name="599/fq_weights_1/mulpiply_by_scale" type="Multiply" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>64</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="1">
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>64</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="400" name="599" type="Convolution" version="opset1">
			<data auto_pad="explicit" dilations="1,1" pads_begin="0,0" pads_end="0,0" strides="1,1"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>64</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
				<port id="1">
					<dim>64</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" names="599" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
			</output>
		</layer>
		<layer id="401" name="29002902_const" type="Const" version="opset1">
			<data element_type="f16" offset="9720" shape="1,64,1,1" size="128"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="402" name="599/add_" type="Add" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>64</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
				<port id="1">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
			</output>
		</layer>
		<layer id="403" name="69176921_const" type="Const" version="opset1">
			<data element_type="f16" offset="59152" shape="1,64,1,1" size="128"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="404" name="69186922_const" type="Const" version="opset1">
			<data element_type="f16" offset="59280" shape="1,64,1,1" size="128"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="405" name="69196923_const" type="Const" version="opset1">
			<data element_type="f16" offset="59152" shape="1,64,1,1" size="128"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="406" name="69206924_const" type="Const" version="opset1">
			<data element_type="f16" offset="59280" shape="1,64,1,1" size="128"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="407" name="600/fq_input_0" type="FakeQuantize" version="opset1">
			<data auto_broadcast="numpy" levels="256"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>64</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
				<port id="1">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="2">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="3">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="4">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="5" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
			</output>
		</layer>
		<layer id="408" name="4216342166_const135415372/quantized18699_const" type="Const" version="opset1">
			<data element_type="i8" offset="59408" shape="64,1,3,3" size="576"/>
			<output>
				<port id="0" precision="I8">
					<dim>64</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</output>
		</layer>
		<layer id="409" name="4216342166_const135415372/quantized/to_f16" type="Convert" version="opset1">
			<data destination_type="f16"/>
			<input>
				<port id="0">
					<dim>64</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</input>
			<output>
				<port id="1" precision="FP16">
					<dim>64</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</output>
		</layer>
		<layer id="410" name="600/fq_weights_1/zero_point18712_const" type="Const" version="opset1">
			<data element_type="f16" offset="59984" shape="64,1,1,1" size="128"/>
			<output>
				<port id="0" precision="FP16">
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="411" name="600/fq_weights_1/minus_zp" type="Subtract" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>64</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
				<port id="1">
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>64</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</output>
		</layer>
		<layer id="412" name="600/fq_weights_1/scale18707_const" type="Const" version="opset1">
			<data element_type="f16" offset="60112" shape="64,1,1,1" size="128"/>
			<output>
				<port id="0" precision="FP16">
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="413" name="600/fq_weights_1/mulpiply_by_scale" type="Multiply" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>64</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
				<port id="1">
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>64</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</output>
		</layer>
		<layer id="414" name="24484/value24486_const" type="Const" version="opset1">
			<data element_type="i64" offset="20034" shape="5" size="40"/>
			<output>
				<port id="0" precision="I64">
					<dim>5</dim>
				</port>
			</output>
		</layer>
		<layer id="415" name="24484" type="Reshape" version="opset1">
			<data special_zero="true"/>
			<input>
				<port id="0">
					<dim>64</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
				<port id="1">
					<dim>5</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</output>
		</layer>
		<layer id="416" name="600" type="GroupConvolution" version="opset1">
			<data auto_pad="explicit" dilations="1,1" pads_begin="1,1" pads_end="1,1" strides="1,1"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>64</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
				<port id="1">
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
			</output>
		</layer>
		<layer id="417" name="data_add_217172172222716/EltwiseUnsqueeze23210_const1356_const" type="Const" version="opset1">
			<data element_type="f16" offset="60240" shape="1,64,1,1" size="128"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="418" name="601/variance/Fused_Add_" type="Add" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>64</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
				<port id="1">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" names="601" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
			</output>
		</layer>
		<layer id="419" name="602" type="ReLU" version="opset1">
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>64</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
			</input>
			<output>
				<port id="1" names="602" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
			</output>
		</layer>
		<layer id="420" name="65576561_const" type="Const" version="opset1">
			<data element_type="f16" offset="10108" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="421" name="65586562_const" type="Const" version="opset1">
			<data element_type="f16" offset="60368" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="422" name="65596563_const" type="Const" version="opset1">
			<data element_type="f16" offset="10108" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="423" name="65606564_const" type="Const" version="opset1">
			<data element_type="f16" offset="60368" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="424" name="603/fq_input_0" type="FakeQuantize" version="opset1">
			<data auto_broadcast="numpy" levels="256"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>64</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
				<port id="1"/>
				<port id="2"/>
				<port id="3"/>
				<port id="4"/>
			</input>
			<output>
				<port id="5" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
			</output>
		</layer>
		<layer id="425" name="conv2.0.conv2d.2.conv1.weight/quantized17835_const" type="Const" version="opset1">
			<data element_type="i8" offset="60370" shape="64,64,1,1" size="4096"/>
			<output>
				<port id="0" precision="I8">
					<dim>64</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="426" name="conv2.0.conv2d.2.conv1.weight/quantized/to_f16" type="Convert" version="opset1">
			<data destination_type="f16"/>
			<input>
				<port id="0">
					<dim>64</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="1" precision="FP16">
					<dim>64</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="427" name="603/fq_weights_1/zero_point17848_const" type="Const" version="opset1">
			<data element_type="f16" offset="64466" shape="64,1,1,1" size="128"/>
			<output>
				<port id="0" precision="FP16">
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="428" name="603/fq_weights_1/minus_zp" type="Subtract" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>64</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="1">
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>64</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="429" name="603/fq_weights_1/scale17843_const" type="Const" version="opset1">
			<data element_type="f16" offset="64594" shape="64,1,1,1" size="128"/>
			<output>
				<port id="0" precision="FP16">
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="430" name="603/fq_weights_1/mulpiply_by_scale" type="Multiply" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>64</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="1">
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>64</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="431" name="603" type="Convolution" version="opset1">
			<data auto_pad="explicit" dilations="1,1" pads_begin="0,0" pads_end="0,0" strides="1,1"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>64</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
				<port id="1">
					<dim>64</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" names="603" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
			</output>
		</layer>
		<layer id="432" name="29042906_const" type="Const" version="opset1">
			<data element_type="f16" offset="9720" shape="1,64,1,1" size="128"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="433" name="603/add_" type="Add" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>64</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
				<port id="1">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
			</output>
		</layer>
		<layer id="434" name="65776581_const" type="Const" version="opset1">
			<data element_type="f16" offset="64722" shape="1,64,1,1" size="128"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="435" name="65786582_const" type="Const" version="opset1">
			<data element_type="f16" offset="64850" shape="1,64,1,1" size="128"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="436" name="65796583_const" type="Const" version="opset1">
			<data element_type="f16" offset="64722" shape="1,64,1,1" size="128"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="437" name="65806584_const" type="Const" version="opset1">
			<data element_type="f16" offset="64850" shape="1,64,1,1" size="128"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="438" name="604/fq_input_0" type="FakeQuantize" version="opset1">
			<data auto_broadcast="numpy" levels="256"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>64</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
				<port id="1">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="2">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="3">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="4">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="5" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
			</output>
		</layer>
		<layer id="439" name="4206342066_const136115375/quantized17715_const" type="Const" version="opset1">
			<data element_type="i8" offset="64978" shape="64,1,3,3" size="576"/>
			<output>
				<port id="0" precision="I8">
					<dim>64</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</output>
		</layer>
		<layer id="440" name="4206342066_const136115375/quantized/to_f16" type="Convert" version="opset1">
			<data destination_type="f16"/>
			<input>
				<port id="0">
					<dim>64</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</input>
			<output>
				<port id="1" precision="FP16">
					<dim>64</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</output>
		</layer>
		<layer id="441" name="604/fq_weights_1/zero_point17728_const" type="Const" version="opset1">
			<data element_type="f16" offset="65554" shape="64,1,1,1" size="128"/>
			<output>
				<port id="0" precision="FP16">
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="442" name="604/fq_weights_1/minus_zp" type="Subtract" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>64</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
				<port id="1">
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>64</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</output>
		</layer>
		<layer id="443" name="604/fq_weights_1/scale17723_const" type="Const" version="opset1">
			<data element_type="f16" offset="65682" shape="64,1,1,1" size="128"/>
			<output>
				<port id="0" precision="FP16">
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="444" name="604/fq_weights_1/mulpiply_by_scale" type="Multiply" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>64</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
				<port id="1">
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>64</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</output>
		</layer>
		<layer id="445" name="24476/value24478_const" type="Const" version="opset1">
			<data element_type="i64" offset="20034" shape="5" size="40"/>
			<output>
				<port id="0" precision="I64">
					<dim>5</dim>
				</port>
			</output>
		</layer>
		<layer id="446" name="24476" type="Reshape" version="opset1">
			<data special_zero="true"/>
			<input>
				<port id="0">
					<dim>64</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
				<port id="1">
					<dim>5</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</output>
		</layer>
		<layer id="447" name="604" type="GroupConvolution" version="opset1">
			<data auto_pad="explicit" dilations="1,1" pads_begin="1,1" pads_end="1,1" strides="1,1"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>64</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
				<port id="1">
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
			</output>
		</layer>
		<layer id="448" name="data_add_217252173022718/EltwiseUnsqueeze23218_const1363_const" type="Const" version="opset1">
			<data element_type="f16" offset="65810" shape="1,64,1,1" size="128"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="449" name="605/variance/Fused_Add_" type="Add" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>64</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
				<port id="1">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" names="605" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
			</output>
		</layer>
		<layer id="450" name="606" type="ReLU" version="opset1">
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>64</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
			</input>
			<output>
				<port id="1" names="606" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
			</output>
		</layer>
		<layer id="451" name="43274331_const" type="Const" version="opset1">
			<data element_type="f16" offset="10108" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="452" name="43284332_const" type="Const" version="opset1">
			<data element_type="f16" offset="65938" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="453" name="43294333_const" type="Const" version="opset1">
			<data element_type="f16" offset="10108" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="454" name="43304334_const" type="Const" version="opset1">
			<data element_type="f16" offset="65938" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="455" name="607/fq_input_0" type="FakeQuantize" version="opset1">
			<data auto_broadcast="numpy" levels="256"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>64</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
				<port id="1"/>
				<port id="2"/>
				<port id="3"/>
				<port id="4"/>
			</input>
			<output>
				<port id="5" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
			</output>
		</layer>
		<layer id="456" name="conv2.0.conv2d.3.conv1.weight/quantized18939_const" type="Const" version="opset1">
			<data element_type="i8" offset="65940" shape="64,64,1,1" size="4096"/>
			<output>
				<port id="0" precision="I8">
					<dim>64</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="457" name="conv2.0.conv2d.3.conv1.weight/quantized/to_f16" type="Convert" version="opset1">
			<data destination_type="f16"/>
			<input>
				<port id="0">
					<dim>64</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="1" precision="FP16">
					<dim>64</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="458" name="607/fq_weights_1/zero_point18952_const" type="Const" version="opset1">
			<data element_type="f16" offset="70036" shape="64,1,1,1" size="128"/>
			<output>
				<port id="0" precision="FP16">
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="459" name="607/fq_weights_1/minus_zp" type="Subtract" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>64</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="1">
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>64</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="460" name="607/fq_weights_1/scale18947_const" type="Const" version="opset1">
			<data element_type="f16" offset="70164" shape="64,1,1,1" size="128"/>
			<output>
				<port id="0" precision="FP16">
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="461" name="607/fq_weights_1/mulpiply_by_scale" type="Multiply" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>64</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="1">
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>64</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="462" name="607" type="Convolution" version="opset1">
			<data auto_pad="explicit" dilations="1,1" pads_begin="0,0" pads_end="0,0" strides="1,1"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>64</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
				<port id="1">
					<dim>64</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" names="607" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
			</output>
		</layer>
		<layer id="463" name="29082910_const" type="Const" version="opset1">
			<data element_type="f16" offset="9720" shape="1,64,1,1" size="128"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="464" name="607/add_" type="Add" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>64</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
				<port id="1">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
			</output>
		</layer>
		<layer id="465" name="50775081_const" type="Const" version="opset1">
			<data element_type="f16" offset="70292" shape="1,64,1,1" size="128"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="466" name="50785082_const" type="Const" version="opset1">
			<data element_type="f16" offset="70420" shape="1,64,1,1" size="128"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="467" name="50795083_const" type="Const" version="opset1">
			<data element_type="f16" offset="70292" shape="1,64,1,1" size="128"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="468" name="50805084_const" type="Const" version="opset1">
			<data element_type="f16" offset="70420" shape="1,64,1,1" size="128"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="469" name="608/fq_input_0" type="FakeQuantize" version="opset1">
			<data auto_broadcast="numpy" levels="256"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>64</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
				<port id="1">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="2">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="3">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="4">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="5" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
			</output>
		</layer>
		<layer id="470" name="4226742270_const136815378/quantized19587_const" type="Const" version="opset1">
			<data element_type="i8" offset="70548" shape="64,1,3,3" size="576"/>
			<output>
				<port id="0" precision="I8">
					<dim>64</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</output>
		</layer>
		<layer id="471" name="4226742270_const136815378/quantized/to_f16" type="Convert" version="opset1">
			<data destination_type="f16"/>
			<input>
				<port id="0">
					<dim>64</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</input>
			<output>
				<port id="1" precision="FP16">
					<dim>64</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</output>
		</layer>
		<layer id="472" name="608/fq_weights_1/zero_point19600_const" type="Const" version="opset1">
			<data element_type="f16" offset="71124" shape="64,1,1,1" size="128"/>
			<output>
				<port id="0" precision="FP16">
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="473" name="608/fq_weights_1/minus_zp" type="Subtract" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>64</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
				<port id="1">
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>64</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</output>
		</layer>
		<layer id="474" name="608/fq_weights_1/scale19595_const" type="Const" version="opset1">
			<data element_type="f16" offset="71252" shape="64,1,1,1" size="128"/>
			<output>
				<port id="0" precision="FP16">
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="475" name="608/fq_weights_1/mulpiply_by_scale" type="Multiply" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>64</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
				<port id="1">
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>64</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</output>
		</layer>
		<layer id="476" name="24468/value24470_const" type="Const" version="opset1">
			<data element_type="i64" offset="20034" shape="5" size="40"/>
			<output>
				<port id="0" precision="I64">
					<dim>5</dim>
				</port>
			</output>
		</layer>
		<layer id="477" name="24468" type="Reshape" version="opset1">
			<data special_zero="true"/>
			<input>
				<port id="0">
					<dim>64</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
				<port id="1">
					<dim>5</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</output>
		</layer>
		<layer id="478" name="608" type="GroupConvolution" version="opset1">
			<data auto_pad="explicit" dilations="1,1" pads_begin="1,1" pads_end="1,1" strides="1,1"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>64</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
				<port id="1">
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
			</output>
		</layer>
		<layer id="479" name="data_add_217332173822720/EltwiseUnsqueeze23226_const1370_const" type="Const" version="opset1">
			<data element_type="f16" offset="71380" shape="1,64,1,1" size="128"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="480" name="609/variance/Fused_Add_" type="Add" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>64</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
				<port id="1">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" names="609" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
			</output>
		</layer>
		<layer id="481" name="610" type="ReLU" version="opset1">
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>64</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
			</input>
			<output>
				<port id="1" names="610" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
			</output>
		</layer>
		<layer id="482" name="81478151_const" type="Const" version="opset1">
			<data element_type="f16" offset="10108" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="483" name="81488152_const" type="Const" version="opset1">
			<data element_type="f16" offset="71508" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="484" name="81498153_const" type="Const" version="opset1">
			<data element_type="f16" offset="10108" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="485" name="81508154_const" type="Const" version="opset1">
			<data element_type="f16" offset="71508" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="486" name="631/reduce/fq_input_0" type="FakeQuantize" version="opset1">
			<data auto_broadcast="numpy" levels="256"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>64</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
				<port id="1"/>
				<port id="2"/>
				<port id="3"/>
				<port id="4"/>
			</input>
			<output>
				<port id="5" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
			</output>
		</layer>
		<layer id="487" name="1339/Output_0/Data__const1373_const" type="Const" version="opset1">
			<data element_type="i64" offset="24" shape="" size="8"/>
			<output>
				<port id="0" precision="I64"/>
			</output>
		</layer>
		<layer id="488" name="631/input_rank/shape_of" type="ShapeOf" version="opset3">
			<data output_type="i64"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>64</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
			</input>
			<output>
				<port id="1" precision="I64">
					<dim>4</dim>
				</port>
			</output>
		</layer>
		<layer id="489" name="631/input_rank/rank_of" type="ShapeOf" version="opset3">
			<data output_type="i64"/>
			<input>
				<port id="0">
					<dim>4</dim>
				</port>
			</input>
			<output>
				<port id="1" precision="I64">
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="490" name="631/input_rank/0d_rank_of/value/Output_0/Data__const1376_const" type="Const" version="opset1">
			<data element_type="i64" offset="32" shape="1" size="8"/>
			<output>
				<port id="0" precision="I64">
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="491" name="631/input_rank" type="Squeeze" version="opset1">
			<input>
				<port id="0">
					<dim>1</dim>
				</port>
				<port id="1">
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="I64"/>
			</output>
		</layer>
		<layer id="492" name="1341/Output_0/Data__const1378_const" type="Const" version="opset1">
			<data element_type="i64" offset="0" shape="" size="8"/>
			<output>
				<port id="0" precision="I64"/>
			</output>
		</layer>
		<layer id="493" name="631/global_pooling_reduce_axis" type="Range" version="opset4">
			<data output_type="i64"/>
			<input>
				<port id="0"/>
				<port id="1"/>
				<port id="2"/>
			</input>
			<output>
				<port id="3" precision="I64">
					<dim>2</dim>
				</port>
			</output>
		</layer>
		<layer id="494" name="631/reduce" type="ReduceMean" version="opset1">
			<data keep_dims="true"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>64</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
				<port id="1">
					<dim>2</dim>
				</port>
			</input>
			<output>
				<port id="2" names="631" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="495" name="Copy_conv2.0.gate.fc1.weight/Output_0/Data_4370_const1381_const" type="Const" version="opset1">
			<data element_type="f16" offset="20204" shape="4,64,1,1" size="512"/>
			<output>
				<port id="0" names="conv2.0.gate.fc1.weight" precision="FP16">
					<dim>4</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="496" name="632/WithoutBiases" type="Convolution" version="opset1">
			<data auto_pad="explicit" dilations="1,1" pads_begin="0,0" pads_end="0,0" strides="1,1"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="1">
					<dim>4</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>1</dim>
					<dim>4</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="497" name="632/Dims1292222689/EltwiseUnsqueeze23110_const1383_const" type="Const" version="opset1">
			<data element_type="f16" offset="20716" shape="1,4,1,1" size="8"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>4</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="498" name="632" type="Add" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>4</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="1">
					<dim>1</dim>
					<dim>4</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" names="632" precision="FP16">
					<dim>1</dim>
					<dim>4</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="499" name="633" type="ReLU" version="opset1">
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>4</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="1" names="633" precision="FP16">
					<dim>1</dim>
					<dim>4</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="500" name="Copy_conv2.0.gate.fc2.weight/Output_0/Data_4378_const1386_const" type="Const" version="opset1">
			<data element_type="f16" offset="20724" shape="64,4,1,1" size="512"/>
			<output>
				<port id="0" names="conv2.0.gate.fc2.weight" precision="FP16">
					<dim>64</dim>
					<dim>4</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="501" name="634/WithoutBiases" type="Convolution" version="opset1">
			<data auto_pad="explicit" dilations="1,1" pads_begin="0,0" pads_end="0,0" strides="1,1"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>4</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="1">
					<dim>64</dim>
					<dim>4</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="502" name="634/Dims1299422701/EltwiseUnsqueeze23158_const1388_const" type="Const" version="opset1">
			<data element_type="f16" offset="21236" shape="1,64,1,1" size="128"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="503" name="634" type="Add" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="1">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" names="634" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="504" name="635" type="Sigmoid" version="opset1">
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="1" names="635" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="505" name="63376341_const" type="Const" version="opset1">
			<data element_type="f16" offset="10108" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="506" name="63386342_const" type="Const" version="opset1">
			<data element_type="f16" offset="71510" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="507" name="63396343_const" type="Const" version="opset1">
			<data element_type="f16" offset="10108" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="508" name="63406344_const" type="Const" version="opset1">
			<data element_type="f16" offset="71510" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="509" name="636/fq_input_1" type="FakeQuantize" version="opset1">
			<data auto_broadcast="numpy" levels="256"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="1"/>
				<port id="2"/>
				<port id="3"/>
				<port id="4"/>
			</input>
			<output>
				<port id="5" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="510" name="636" type="Multiply" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>64</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
				<port id="1">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" names="636" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
			</output>
		</layer>
		<layer id="511" name="69977001_const" type="Const" version="opset1">
			<data element_type="f16" offset="10108" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="512" name="69987002_const" type="Const" version="opset1">
			<data element_type="f16" offset="71512" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="513" name="69997003_const" type="Const" version="opset1">
			<data element_type="f16" offset="10108" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="514" name="70007004_const" type="Const" version="opset1">
			<data element_type="f16" offset="71512" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="515" name="637/fq_input_1" type="FakeQuantize" version="opset1">
			<data auto_broadcast="numpy" levels="256"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>64</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
				<port id="1"/>
				<port id="2"/>
				<port id="3"/>
				<port id="4"/>
			</input>
			<output>
				<port id="5" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
			</output>
		</layer>
		<layer id="516" name="637" type="Add" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>64</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
				<port id="1">
					<dim>1</dim>
					<dim>64</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
			</input>
			<output>
				<port id="2" names="637" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
			</output>
		</layer>
		<layer id="517" name="64176421_const" type="Const" version="opset1">
			<data element_type="f16" offset="10108" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="518" name="64186422_const" type="Const" version="opset1">
			<data element_type="f16" offset="71514" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="519" name="64196423_const" type="Const" version="opset1">
			<data element_type="f16" offset="10108" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="520" name="64206424_const" type="Const" version="opset1">
			<data element_type="f16" offset="71514" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="521" name="638/fq_input_0" type="FakeQuantize" version="opset1">
			<data auto_broadcast="numpy" levels="256"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>64</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
				<port id="1"/>
				<port id="2"/>
				<port id="3"/>
				<port id="4"/>
			</input>
			<output>
				<port id="5" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
			</output>
		</layer>
		<layer id="522" name="639/mean/Fused_Mul_2440324405_const139315387/quantized20379_const" type="Const" version="opset1">
			<data element_type="i8" offset="71516" shape="256,64,1,1" size="16384"/>
			<output>
				<port id="0" precision="I8">
					<dim>256</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="523" name="639/mean/Fused_Mul_2440324405_const139315387/quantized/to_f16" type="Convert" version="opset1">
			<data destination_type="f16"/>
			<input>
				<port id="0">
					<dim>256</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="1" precision="FP16">
					<dim>256</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="524" name="638/fq_weights_1/zero_point20392_const" type="Const" version="opset1">
			<data element_type="f16" offset="87900" shape="256,1,1,1" size="512"/>
			<output>
				<port id="0" precision="FP16">
					<dim>256</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="525" name="638/fq_weights_1/minus_zp" type="Subtract" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>256</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="1">
					<dim>256</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>256</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="526" name="638/fq_weights_1/scale20387_const" type="Const" version="opset1">
			<data element_type="f16" offset="88412" shape="256,1,1,1" size="512"/>
			<output>
				<port id="0" precision="FP16">
					<dim>256</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="527" name="638/fq_weights_1/mulpiply_by_scale" type="Multiply" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>256</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="1">
					<dim>256</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>256</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="528" name="638" type="Convolution" version="opset1">
			<data auto_pad="explicit" dilations="1,1" pads_begin="0,0" pads_end="0,0" strides="1,1"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>64</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
				<port id="1">
					<dim>256</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>1</dim>
					<dim>256</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
			</output>
		</layer>
		<layer id="529" name="data_add_217892179422734/EltwiseUnsqueeze23282_const1395_const" type="Const" version="opset1">
			<data element_type="f16" offset="88924" shape="1,256,1,1" size="512"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>256</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="530" name="639/variance/Fused_Add_" type="Add" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>256</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
				<port id="1">
					<dim>1</dim>
					<dim>256</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" names="639" precision="FP16">
					<dim>1</dim>
					<dim>256</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
			</output>
		</layer>
		<layer id="531" name="83478351_const" type="Const" version="opset1">
			<data element_type="f16" offset="89436" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="532" name="83488352_const" type="Const" version="opset1">
			<data element_type="f16" offset="89438" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="533" name="83498353_const" type="Const" version="opset1">
			<data element_type="f16" offset="89436" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="534" name="83508354_const" type="Const" version="opset1">
			<data element_type="f16" offset="89438" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="535" name="642/fq_input_0" type="FakeQuantize" version="opset1">
			<data auto_broadcast="numpy" levels="256"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>256</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
				<port id="1"/>
				<port id="2"/>
				<port id="3"/>
				<port id="4"/>
			</input>
			<output>
				<port id="5" precision="FP16">
					<dim>1</dim>
					<dim>256</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
			</output>
		</layer>
		<layer id="536" name="641/mean/Fused_Mul_2435524357_const139715389/quantized18627_const" type="Const" version="opset1">
			<data element_type="i8" offset="89440" shape="256,64,1,1" size="16384"/>
			<output>
				<port id="0" precision="I8">
					<dim>256</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="537" name="641/mean/Fused_Mul_2435524357_const139715389/quantized/to_f16" type="Convert" version="opset1">
			<data destination_type="f16"/>
			<input>
				<port id="0">
					<dim>256</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="1" precision="FP16">
					<dim>256</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="538" name="640/fq_weights_1/zero_point18640_const" type="Const" version="opset1">
			<data element_type="f16" offset="105824" shape="256,1,1,1" size="512"/>
			<output>
				<port id="0" precision="FP16">
					<dim>256</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="539" name="640/fq_weights_1/minus_zp" type="Subtract" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>256</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="1">
					<dim>256</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>256</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="540" name="640/fq_weights_1/scale18635_const" type="Const" version="opset1">
			<data element_type="f16" offset="106336" shape="256,1,1,1" size="512"/>
			<output>
				<port id="0" precision="FP16">
					<dim>256</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="541" name="640/fq_weights_1/mulpiply_by_scale" type="Multiply" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>256</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="1">
					<dim>256</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>256</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="542" name="640" type="Convolution" version="opset1">
			<data auto_pad="explicit" dilations="1,1" pads_begin="0,0" pads_end="0,0" strides="1,1"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>64</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
				<port id="1">
					<dim>256</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>1</dim>
					<dim>256</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
			</output>
		</layer>
		<layer id="543" name="data_add_216932169822710/EltwiseUnsqueeze23186_const1399_const" type="Const" version="opset1">
			<data element_type="f16" offset="106848" shape="1,256,1,1" size="512"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>256</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="544" name="641/variance/Fused_Add_" type="Add" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>256</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
				<port id="1">
					<dim>1</dim>
					<dim>256</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" names="641" precision="FP16">
					<dim>1</dim>
					<dim>256</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
			</output>
		</layer>
		<layer id="545" name="83578361_const" type="Const" version="opset1">
			<data element_type="f16" offset="107360" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="546" name="83588362_const" type="Const" version="opset1">
			<data element_type="f16" offset="107362" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="547" name="83598363_const" type="Const" version="opset1">
			<data element_type="f16" offset="107360" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="548" name="83608364_const" type="Const" version="opset1">
			<data element_type="f16" offset="107362" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="549" name="642/fq_input_1" type="FakeQuantize" version="opset1">
			<data auto_broadcast="numpy" levels="256"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>256</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
				<port id="1"/>
				<port id="2"/>
				<port id="3"/>
				<port id="4"/>
			</input>
			<output>
				<port id="5" precision="FP16">
					<dim>1</dim>
					<dim>256</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
			</output>
		</layer>
		<layer id="550" name="642" type="Add" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>256</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
				<port id="1">
					<dim>1</dim>
					<dim>256</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
			</input>
			<output>
				<port id="2" names="642" precision="FP16">
					<dim>1</dim>
					<dim>256</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
			</output>
		</layer>
		<layer id="551" name="643" type="ReLU" version="opset1">
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>256</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
			</input>
			<output>
				<port id="1" names="643" precision="FP16">
					<dim>1</dim>
					<dim>256</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
			</output>
		</layer>
		<layer id="552" name="83978401_const" type="Const" version="opset1">
			<data element_type="f16" offset="10108" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="553" name="83988402_const" type="Const" version="opset1">
			<data element_type="f16" offset="107364" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="554" name="83998403_const" type="Const" version="opset1">
			<data element_type="f16" offset="10108" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="555" name="84008404_const" type="Const" version="opset1">
			<data element_type="f16" offset="107364" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="556" name="644/fq_input_0" type="FakeQuantize" version="opset1">
			<data auto_broadcast="numpy" levels="256"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>256</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
				<port id="1"/>
				<port id="2"/>
				<port id="3"/>
				<port id="4"/>
			</input>
			<output>
				<port id="5" precision="FP16">
					<dim>1</dim>
					<dim>256</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
			</output>
		</layer>
		<layer id="557" name="645/mean/Fused_Mul_2440724409_const140315391/quantized18123_const" type="Const" version="opset1">
			<data element_type="i8" offset="107366" shape="64,256,1,1" size="16384"/>
			<output>
				<port id="0" precision="I8">
					<dim>64</dim>
					<dim>256</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="558" name="645/mean/Fused_Mul_2440724409_const140315391/quantized/to_f16" type="Convert" version="opset1">
			<data destination_type="f16"/>
			<input>
				<port id="0">
					<dim>64</dim>
					<dim>256</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="1" precision="FP16">
					<dim>64</dim>
					<dim>256</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="559" name="644/fq_weights_1/zero_point18136_const" type="Const" version="opset1">
			<data element_type="f16" offset="123750" shape="64,1,1,1" size="128"/>
			<output>
				<port id="0" precision="FP16">
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="560" name="644/fq_weights_1/minus_zp" type="Subtract" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>64</dim>
					<dim>256</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="1">
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>64</dim>
					<dim>256</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="561" name="644/fq_weights_1/scale18131_const" type="Const" version="opset1">
			<data element_type="f16" offset="123878" shape="64,1,1,1" size="128"/>
			<output>
				<port id="0" precision="FP16">
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="562" name="644/fq_weights_1/mulpiply_by_scale" type="Multiply" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>64</dim>
					<dim>256</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="1">
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>64</dim>
					<dim>256</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="563" name="644" type="Convolution" version="opset1">
			<data auto_pad="explicit" dilations="1,1" pads_begin="0,0" pads_end="0,0" strides="1,1"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>256</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
				<port id="1">
					<dim>64</dim>
					<dim>256</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
			</output>
		</layer>
		<layer id="564" name="data_add_217972180222736/EltwiseUnsqueeze23290_const1405_const" type="Const" version="opset1">
			<data element_type="f16" offset="124006" shape="1,64,1,1" size="128"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="565" name="645/variance/Fused_Add_" type="Add" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>64</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
				<port id="1">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" names="645" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
			</output>
		</layer>
		<layer id="566" name="646" type="ReLU" version="opset1">
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>64</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
			</input>
			<output>
				<port id="1" names="646" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
			</output>
		</layer>
		<layer id="567" name="65976601_const" type="Const" version="opset1">
			<data element_type="f16" offset="10108" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="568" name="65986602_const" type="Const" version="opset1">
			<data element_type="f16" offset="124134" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="569" name="65996603_const" type="Const" version="opset1">
			<data element_type="f16" offset="10108" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="570" name="66006604_const" type="Const" version="opset1">
			<data element_type="f16" offset="124134" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="571" name="647/fq_input_0" type="FakeQuantize" version="opset1">
			<data auto_broadcast="numpy" levels="256"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>64</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
				<port id="1"/>
				<port id="2"/>
				<port id="3"/>
				<port id="4"/>
			</input>
			<output>
				<port id="5" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
			</output>
		</layer>
		<layer id="572" name="conv2.1.conv2a.conv1.weight/quantized19899_const" type="Const" version="opset1">
			<data element_type="i8" offset="124136" shape="64,64,1,1" size="4096"/>
			<output>
				<port id="0" precision="I8">
					<dim>64</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="573" name="conv2.1.conv2a.conv1.weight/quantized/to_f16" type="Convert" version="opset1">
			<data destination_type="f16"/>
			<input>
				<port id="0">
					<dim>64</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="1" precision="FP16">
					<dim>64</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="574" name="647/fq_weights_1/zero_point19912_const" type="Const" version="opset1">
			<data element_type="f16" offset="128232" shape="64,1,1,1" size="128"/>
			<output>
				<port id="0" precision="FP16">
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="575" name="647/fq_weights_1/minus_zp" type="Subtract" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>64</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="1">
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>64</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="576" name="647/fq_weights_1/scale19907_const" type="Const" version="opset1">
			<data element_type="f16" offset="128360" shape="64,1,1,1" size="128"/>
			<output>
				<port id="0" precision="FP16">
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="577" name="647/fq_weights_1/mulpiply_by_scale" type="Multiply" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>64</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="1">
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>64</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="578" name="647" type="Convolution" version="opset1">
			<data auto_pad="explicit" dilations="1,1" pads_begin="0,0" pads_end="0,0" strides="1,1"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>64</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
				<port id="1">
					<dim>64</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" names="647" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
			</output>
		</layer>
		<layer id="579" name="29122914_const" type="Const" version="opset1">
			<data element_type="f16" offset="9720" shape="1,64,1,1" size="128"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="580" name="647/add_" type="Add" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>64</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
				<port id="1">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
			</output>
		</layer>
		<layer id="581" name="58375841_const" type="Const" version="opset1">
			<data element_type="f16" offset="128488" shape="1,64,1,1" size="128"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="582" name="58385842_const" type="Const" version="opset1">
			<data element_type="f16" offset="128616" shape="1,64,1,1" size="128"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="583" name="58395843_const" type="Const" version="opset1">
			<data element_type="f16" offset="128488" shape="1,64,1,1" size="128"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="584" name="58405844_const" type="Const" version="opset1">
			<data element_type="f16" offset="128616" shape="1,64,1,1" size="128"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="585" name="648/fq_input_0" type="FakeQuantize" version="opset1">
			<data auto_broadcast="numpy" levels="256"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>64</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
				<port id="1">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="2">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="3">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="4">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="5" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
			</output>
		</layer>
		<layer id="586" name="4215542158_const141015394/quantized20523_const" type="Const" version="opset1">
			<data element_type="i8" offset="128744" shape="64,1,3,3" size="576"/>
			<output>
				<port id="0" precision="I8">
					<dim>64</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</output>
		</layer>
		<layer id="587" name="4215542158_const141015394/quantized/to_f16" type="Convert" version="opset1">
			<data destination_type="f16"/>
			<input>
				<port id="0">
					<dim>64</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</input>
			<output>
				<port id="1" precision="FP16">
					<dim>64</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</output>
		</layer>
		<layer id="588" name="648/fq_weights_1/zero_point20536_const" type="Const" version="opset1">
			<data element_type="f16" offset="129320" shape="64,1,1,1" size="128"/>
			<output>
				<port id="0" precision="FP16">
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="589" name="648/fq_weights_1/minus_zp" type="Subtract" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>64</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
				<port id="1">
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>64</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</output>
		</layer>
		<layer id="590" name="648/fq_weights_1/scale20531_const" type="Const" version="opset1">
			<data element_type="f16" offset="129448" shape="64,1,1,1" size="128"/>
			<output>
				<port id="0" precision="FP16">
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="591" name="648/fq_weights_1/mulpiply_by_scale" type="Multiply" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>64</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
				<port id="1">
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>64</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</output>
		</layer>
		<layer id="592" name="24592/value24594_const" type="Const" version="opset1">
			<data element_type="i64" offset="20034" shape="5" size="40"/>
			<output>
				<port id="0" precision="I64">
					<dim>5</dim>
				</port>
			</output>
		</layer>
		<layer id="593" name="24592" type="Reshape" version="opset1">
			<data special_zero="true"/>
			<input>
				<port id="0">
					<dim>64</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
				<port id="1">
					<dim>5</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</output>
		</layer>
		<layer id="594" name="648" type="GroupConvolution" version="opset1">
			<data auto_pad="explicit" dilations="1,1" pads_begin="1,1" pads_end="1,1" strides="1,1"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>64</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
				<port id="1">
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
			</output>
		</layer>
		<layer id="595" name="data_add_218772188222756/EltwiseUnsqueeze23370_const1412_const" type="Const" version="opset1">
			<data element_type="f16" offset="129576" shape="1,64,1,1" size="128"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="596" name="649/variance/Fused_Add_" type="Add" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>64</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
				<port id="1">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" names="649" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
			</output>
		</layer>
		<layer id="597" name="650" type="ReLU" version="opset1">
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>64</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
			</input>
			<output>
				<port id="1" names="650" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
			</output>
		</layer>
		<layer id="598" name="46274631_const" type="Const" version="opset1">
			<data element_type="f16" offset="10108" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="599" name="46284632_const" type="Const" version="opset1">
			<data element_type="f16" offset="129704" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="600" name="46294633_const" type="Const" version="opset1">
			<data element_type="f16" offset="10108" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="601" name="46304634_const" type="Const" version="opset1">
			<data element_type="f16" offset="129704" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="602" name="687/reduce/fq_input_0" type="FakeQuantize" version="opset1">
			<data auto_broadcast="numpy" levels="256"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>64</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
				<port id="1"/>
				<port id="2"/>
				<port id="3"/>
				<port id="4"/>
			</input>
			<output>
				<port id="5" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
			</output>
		</layer>
		<layer id="603" name="1344/Output_0/Data__const1415_const" type="Const" version="opset1">
			<data element_type="i64" offset="24" shape="" size="8"/>
			<output>
				<port id="0" precision="I64"/>
			</output>
		</layer>
		<layer id="604" name="687/input_rank/shape_of" type="ShapeOf" version="opset3">
			<data output_type="i64"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>64</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
			</input>
			<output>
				<port id="1" precision="I64">
					<dim>4</dim>
				</port>
			</output>
		</layer>
		<layer id="605" name="687/input_rank/rank_of" type="ShapeOf" version="opset3">
			<data output_type="i64"/>
			<input>
				<port id="0">
					<dim>4</dim>
				</port>
			</input>
			<output>
				<port id="1" precision="I64">
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="606" name="687/input_rank/0d_rank_of/value/Output_0/Data__const1418_const" type="Const" version="opset1">
			<data element_type="i64" offset="32" shape="1" size="8"/>
			<output>
				<port id="0" precision="I64">
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="607" name="687/input_rank" type="Squeeze" version="opset1">
			<input>
				<port id="0">
					<dim>1</dim>
				</port>
				<port id="1">
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="I64"/>
			</output>
		</layer>
		<layer id="608" name="1346/Output_0/Data__const1420_const" type="Const" version="opset1">
			<data element_type="i64" offset="0" shape="" size="8"/>
			<output>
				<port id="0" precision="I64"/>
			</output>
		</layer>
		<layer id="609" name="687/global_pooling_reduce_axis" type="Range" version="opset4">
			<data output_type="i64"/>
			<input>
				<port id="0"/>
				<port id="1"/>
				<port id="2"/>
			</input>
			<output>
				<port id="3" precision="I64">
					<dim>2</dim>
				</port>
			</output>
		</layer>
		<layer id="610" name="687/reduce" type="ReduceMean" version="opset1">
			<data keep_dims="true"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>64</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
				<port id="1">
					<dim>2</dim>
				</port>
			</input>
			<output>
				<port id="2" names="687" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="611" name="1084810852_const" type="Const" version="opset1">
			<data element_type="f16" offset="10108" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="612" name="1084910853_const" type="Const" version="opset1">
			<data element_type="f16" offset="129706" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="613" name="1085010854_const" type="Const" version="opset1">
			<data element_type="f16" offset="10108" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="614" name="1085110855_const" type="Const" version="opset1">
			<data element_type="f16" offset="129706" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="615" name="689/fq_input_0" type="FakeQuantize" version="opset1">
			<data auto_broadcast="numpy" levels="256"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="1"/>
				<port id="2"/>
				<port id="3"/>
				<port id="4"/>
			</input>
			<output>
				<port id="5" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="616" name="689/Cast_143310_const1423_const" type="Const" version="opset1">
			<data element_type="i64" offset="129708" shape="3" size="24"/>
			<output>
				<port id="0" names="688" precision="I64">
					<dim>3</dim>
				</port>
			</output>
		</layer>
		<layer id="617" name="689" type="Reshape" version="opset1">
			<data special_zero="true"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="1">
					<dim>3</dim>
				</port>
			</input>
			<output>
				<port id="2" names="689" precision="FP16">
					<dim>1</dim>
					<dim>16</dim>
					<dim>4</dim>
				</port>
			</output>
		</layer>
		<layer id="618" name="692/Range_input_port_0/value/Output_0/Data__const1425_const" type="Const" version="opset1">
			<data element_type="i64" offset="24" shape="" size="8"/>
			<output>
				<port id="0" precision="I64"/>
			</output>
		</layer>
		<layer id="619" name="692/Rank/shape_of" type="ShapeOf" version="opset3">
			<data output_type="i64"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>16</dim>
					<dim>4</dim>
				</port>
			</input>
			<output>
				<port id="1" precision="I64">
					<dim>3</dim>
				</port>
			</output>
		</layer>
		<layer id="620" name="692/Rank/rank_of" type="ShapeOf" version="opset3">
			<data output_type="i64"/>
			<input>
				<port id="0">
					<dim>3</dim>
				</port>
			</input>
			<output>
				<port id="1" precision="I64">
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="621" name="692/Rank/0d_rank_of/value/Output_0/Data__const1428_const" type="Const" version="opset1">
			<data element_type="i64" offset="32" shape="1" size="8"/>
			<output>
				<port id="0" precision="I64">
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="622" name="692/Rank" type="Squeeze" version="opset1">
			<input>
				<port id="0">
					<dim>1</dim>
				</port>
				<port id="1">
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="I64"/>
			</output>
		</layer>
		<layer id="623" name="692/Range_input_port_2/value/Output_0/Data__const1430_const" type="Const" version="opset1">
			<data element_type="i64" offset="0" shape="" size="8"/>
			<output>
				<port id="0" precision="I64"/>
			</output>
		</layer>
		<layer id="624" name="692/Range" type="Range" version="opset4">
			<data output_type="i64"/>
			<input>
				<port id="0"/>
				<port id="1"/>
				<port id="2"/>
			</input>
			<output>
				<port id="3" precision="I64">
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="625" name="692/Ins_Norm/MVN_" type="MVN" version="opset6">
			<data eps="9.999999747378752e-06" eps_mode="inside_sqrt" normalize_variance="true"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>16</dim>
					<dim>4</dim>
				</port>
				<port id="1">
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>1</dim>
					<dim>16</dim>
					<dim>4</dim>
				</port>
			</output>
		</layer>
		<layer id="626" name="690/EltwiseUnsqueeze23070_const1433_const" type="Const" version="opset1">
			<data element_type="f16" offset="129732" shape="1,16,1" size="32"/>
			<output>
				<port id="0" names="690" precision="FP16">
					<dim>1</dim>
					<dim>16</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="627" name="692/Ins_Norm/mul_" type="Multiply" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>16</dim>
					<dim>4</dim>
				</port>
				<port id="1">
					<dim>1</dim>
					<dim>16</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>1</dim>
					<dim>16</dim>
					<dim>4</dim>
				</port>
			</output>
		</layer>
		<layer id="628" name="691/EltwiseUnsqueeze23074_const1435_const" type="Const" version="opset1">
			<data element_type="f16" offset="129764" shape="1,16,1" size="32"/>
			<output>
				<port id="0" names="691" precision="FP16">
					<dim>1</dim>
					<dim>16</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="629" name="692" type="Add" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>16</dim>
					<dim>4</dim>
				</port>
				<port id="1">
					<dim>1</dim>
					<dim>16</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" names="692" precision="FP16">
					<dim>1</dim>
					<dim>16</dim>
					<dim>4</dim>
				</port>
			</output>
		</layer>
		<layer id="630" name="1085810862_const" type="Const" version="opset1">
			<data element_type="f16" offset="129796" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="631" name="1085910863_const" type="Const" version="opset1">
			<data element_type="f16" offset="129798" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="632" name="1086010864_const" type="Const" version="opset1">
			<data element_type="f16" offset="129796" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="633" name="1086110865_const" type="Const" version="opset1">
			<data element_type="f16" offset="129798" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="634" name="694/fq_input_0" type="FakeQuantize" version="opset1">
			<data auto_broadcast="numpy" levels="256"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>16</dim>
					<dim>4</dim>
				</port>
				<port id="1"/>
				<port id="2"/>
				<port id="3"/>
				<port id="4"/>
			</input>
			<output>
				<port id="5" precision="FP16">
					<dim>1</dim>
					<dim>16</dim>
					<dim>4</dim>
				</port>
			</output>
		</layer>
		<layer id="635" name="693" type="ShapeOf" version="opset3">
			<data output_type="i64"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="1" names="693" precision="I64">
					<dim>4</dim>
				</port>
			</output>
		</layer>
		<layer id="636" name="694" type="Reshape" version="opset1">
			<data special_zero="true"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>16</dim>
					<dim>4</dim>
				</port>
				<port id="1">
					<dim>4</dim>
				</port>
			</input>
			<output>
				<port id="2" names="694" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="637" name="695/Unsqueeze/EltwiseUnsqueeze22870_const1439_const" type="Const" version="opset1">
			<data element_type="f16" offset="129800" shape="1,64,1,1" size="128"/>
			<output>
				<port id="0" names="695" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="638" name="696" type="Multiply" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="1">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" names="696" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="639" name="697/Unsqueeze/EltwiseUnsqueeze22874_const1441_const" type="Const" version="opset1">
			<data element_type="f16" offset="129928" shape="1,64,1,1" size="128"/>
			<output>
				<port id="0" names="697" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="640" name="698" type="Add" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="1">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" names="698" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="641" name="699" type="Sigmoid" version="opset1">
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="1" names="699" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="642" name="81378141_const" type="Const" version="opset1">
			<data element_type="f16" offset="10108" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="643" name="81388142_const" type="Const" version="opset1">
			<data element_type="f16" offset="130056" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="644" name="81398143_const" type="Const" version="opset1">
			<data element_type="f16" offset="10108" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="645" name="81408144_const" type="Const" version="opset1">
			<data element_type="f16" offset="130056" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="646" name="700/fq_input_1" type="FakeQuantize" version="opset1">
			<data auto_broadcast="numpy" levels="256"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="1"/>
				<port id="2"/>
				<port id="3"/>
				<port id="4"/>
			</input>
			<output>
				<port id="5" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="647" name="700" type="Multiply" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>64</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
				<port id="1">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" names="700" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
			</output>
		</layer>
		<layer id="648" name="59275931_const" type="Const" version="opset1">
			<data element_type="f16" offset="10108" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="649" name="59285932_const" type="Const" version="opset1">
			<data element_type="f16" offset="130058" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="650" name="59295933_const" type="Const" version="opset1">
			<data element_type="f16" offset="10108" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="651" name="59305934_const" type="Const" version="opset1">
			<data element_type="f16" offset="130058" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="652" name="715/fq_input_0" type="FakeQuantize" version="opset1">
			<data auto_broadcast="numpy" levels="256"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>64</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
				<port id="1"/>
				<port id="2"/>
				<port id="3"/>
				<port id="4"/>
			</input>
			<output>
				<port id="5" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
			</output>
		</layer>
		<layer id="653" name="conv2.1.conv2b.0.conv1.weight/quantized19083_const" type="Const" version="opset1">
			<data element_type="i8" offset="130060" shape="64,64,1,1" size="4096"/>
			<output>
				<port id="0" precision="I8">
					<dim>64</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="654" name="conv2.1.conv2b.0.conv1.weight/quantized/to_f16" type="Convert" version="opset1">
			<data destination_type="f16"/>
			<input>
				<port id="0">
					<dim>64</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="1" precision="FP16">
					<dim>64</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="655" name="651/fq_weights_1/zero_point19096_const" type="Const" version="opset1">
			<data element_type="f16" offset="134156" shape="64,1,1,1" size="128"/>
			<output>
				<port id="0" precision="FP16">
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="656" name="651/fq_weights_1/minus_zp" type="Subtract" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>64</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="1">
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>64</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="657" name="651/fq_weights_1/scale19091_const" type="Const" version="opset1">
			<data element_type="f16" offset="134284" shape="64,1,1,1" size="128"/>
			<output>
				<port id="0" precision="FP16">
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="658" name="651/fq_weights_1/mulpiply_by_scale" type="Multiply" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>64</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="1">
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>64</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="659" name="651" type="Convolution" version="opset1">
			<data auto_pad="explicit" dilations="1,1" pads_begin="0,0" pads_end="0,0" strides="1,1"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>64</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
				<port id="1">
					<dim>64</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" names="651" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
			</output>
		</layer>
		<layer id="660" name="29162918_const" type="Const" version="opset1">
			<data element_type="f16" offset="9720" shape="1,64,1,1" size="128"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="661" name="651/add_" type="Add" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>64</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
				<port id="1">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
			</output>
		</layer>
		<layer id="662" name="48074811_const" type="Const" version="opset1">
			<data element_type="f16" offset="134412" shape="1,64,1,1" size="128"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="663" name="48084812_const" type="Const" version="opset1">
			<data element_type="f16" offset="134540" shape="1,64,1,1" size="128"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="664" name="48094813_const" type="Const" version="opset1">
			<data element_type="f16" offset="134412" shape="1,64,1,1" size="128"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="665" name="48104814_const" type="Const" version="opset1">
			<data element_type="f16" offset="134540" shape="1,64,1,1" size="128"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="666" name="652/fq_input_0" type="FakeQuantize" version="opset1">
			<data auto_broadcast="numpy" levels="256"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>64</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
				<port id="1">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="2">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="3">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="4">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="5" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
			</output>
		</layer>
		<layer id="667" name="4205142054_const144715408/quantized19131_const" type="Const" version="opset1">
			<data element_type="i8" offset="134668" shape="64,1,3,3" size="576"/>
			<output>
				<port id="0" precision="I8">
					<dim>64</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</output>
		</layer>
		<layer id="668" name="4205142054_const144715408/quantized/to_f16" type="Convert" version="opset1">
			<data destination_type="f16"/>
			<input>
				<port id="0">
					<dim>64</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</input>
			<output>
				<port id="1" precision="FP16">
					<dim>64</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</output>
		</layer>
		<layer id="669" name="652/fq_weights_1/zero_point19144_const" type="Const" version="opset1">
			<data element_type="f16" offset="135244" shape="64,1,1,1" size="128"/>
			<output>
				<port id="0" precision="FP16">
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="670" name="652/fq_weights_1/minus_zp" type="Subtract" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>64</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
				<port id="1">
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>64</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</output>
		</layer>
		<layer id="671" name="652/fq_weights_1/scale19139_const" type="Const" version="opset1">
			<data element_type="f16" offset="135372" shape="64,1,1,1" size="128"/>
			<output>
				<port id="0" precision="FP16">
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="672" name="652/fq_weights_1/mulpiply_by_scale" type="Multiply" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>64</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
				<port id="1">
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>64</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</output>
		</layer>
		<layer id="673" name="24508/value24510_const" type="Const" version="opset1">
			<data element_type="i64" offset="20034" shape="5" size="40"/>
			<output>
				<port id="0" precision="I64">
					<dim>5</dim>
				</port>
			</output>
		</layer>
		<layer id="674" name="24508" type="Reshape" version="opset1">
			<data special_zero="true"/>
			<input>
				<port id="0">
					<dim>64</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
				<port id="1">
					<dim>5</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</output>
		</layer>
		<layer id="675" name="652" type="GroupConvolution" version="opset1">
			<data auto_pad="explicit" dilations="1,1" pads_begin="1,1" pads_end="1,1" strides="1,1"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>64</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
				<port id="1">
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
			</output>
		</layer>
		<layer id="676" name="data_add_218612186622752/EltwiseUnsqueeze23354_const1449_const" type="Const" version="opset1">
			<data element_type="f16" offset="135500" shape="1,64,1,1" size="128"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="677" name="653/variance/Fused_Add_" type="Add" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>64</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
				<port id="1">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" names="653" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
			</output>
		</layer>
		<layer id="678" name="654" type="ReLU" version="opset1">
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>64</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
			</input>
			<output>
				<port id="1" names="654" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
			</output>
		</layer>
		<layer id="679" name="53375341_const" type="Const" version="opset1">
			<data element_type="f16" offset="10108" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="680" name="53385342_const" type="Const" version="opset1">
			<data element_type="f16" offset="135628" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="681" name="53395343_const" type="Const" version="opset1">
			<data element_type="f16" offset="10108" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="682" name="53405344_const" type="Const" version="opset1">
			<data element_type="f16" offset="135628" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="683" name="655/fq_input_0" type="FakeQuantize" version="opset1">
			<data auto_broadcast="numpy" levels="256"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>64</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
				<port id="1"/>
				<port id="2"/>
				<port id="3"/>
				<port id="4"/>
			</input>
			<output>
				<port id="5" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
			</output>
		</layer>
		<layer id="684" name="conv2.1.conv2b.1.conv1.weight/quantized19275_const" type="Const" version="opset1">
			<data element_type="i8" offset="135630" shape="64,64,1,1" size="4096"/>
			<output>
				<port id="0" precision="I8">
					<dim>64</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="685" name="conv2.1.conv2b.1.conv1.weight/quantized/to_f16" type="Convert" version="opset1">
			<data destination_type="f16"/>
			<input>
				<port id="0">
					<dim>64</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="1" precision="FP16">
					<dim>64</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="686" name="655/fq_weights_1/zero_point19288_const" type="Const" version="opset1">
			<data element_type="f16" offset="139726" shape="64,1,1,1" size="128"/>
			<output>
				<port id="0" precision="FP16">
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="687" name="655/fq_weights_1/minus_zp" type="Subtract" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>64</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="1">
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>64</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="688" name="655/fq_weights_1/scale19283_const" type="Const" version="opset1">
			<data element_type="f16" offset="139854" shape="64,1,1,1" size="128"/>
			<output>
				<port id="0" precision="FP16">
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="689" name="655/fq_weights_1/mulpiply_by_scale" type="Multiply" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>64</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="1">
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>64</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="690" name="655" type="Convolution" version="opset1">
			<data auto_pad="explicit" dilations="1,1" pads_begin="0,0" pads_end="0,0" strides="1,1"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>64</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
				<port id="1">
					<dim>64</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" names="655" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
			</output>
		</layer>
		<layer id="691" name="29202922_const" type="Const" version="opset1">
			<data element_type="f16" offset="9720" shape="1,64,1,1" size="128"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="692" name="655/add_" type="Add" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>64</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
				<port id="1">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
			</output>
		</layer>
		<layer id="693" name="53075311_const" type="Const" version="opset1">
			<data element_type="f16" offset="139982" shape="1,64,1,1" size="128"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="694" name="53085312_const" type="Const" version="opset1">
			<data element_type="f16" offset="140110" shape="1,64,1,1" size="128"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="695" name="53095313_const" type="Const" version="opset1">
			<data element_type="f16" offset="139982" shape="1,64,1,1" size="128"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="696" name="53105314_const" type="Const" version="opset1">
			<data element_type="f16" offset="140110" shape="1,64,1,1" size="128"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="697" name="656/fq_input_0" type="FakeQuantize" version="opset1">
			<data auto_broadcast="numpy" levels="256"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>64</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
				<port id="1">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="2">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="3">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="4">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="5" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
			</output>
		</layer>
		<layer id="698" name="4210742110_const145415411/quantized17595_const" type="Const" version="opset1">
			<data element_type="i8" offset="140238" shape="64,1,3,3" size="576"/>
			<output>
				<port id="0" precision="I8">
					<dim>64</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</output>
		</layer>
		<layer id="699" name="4210742110_const145415411/quantized/to_f16" type="Convert" version="opset1">
			<data destination_type="f16"/>
			<input>
				<port id="0">
					<dim>64</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</input>
			<output>
				<port id="1" precision="FP16">
					<dim>64</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</output>
		</layer>
		<layer id="700" name="656/fq_weights_1/zero_point17608_const" type="Const" version="opset1">
			<data element_type="f16" offset="140814" shape="64,1,1,1" size="128"/>
			<output>
				<port id="0" precision="FP16">
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="701" name="656/fq_weights_1/minus_zp" type="Subtract" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>64</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
				<port id="1">
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>64</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</output>
		</layer>
		<layer id="702" name="656/fq_weights_1/scale17603_const" type="Const" version="opset1">
			<data element_type="f16" offset="140942" shape="64,1,1,1" size="128"/>
			<output>
				<port id="0" precision="FP16">
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="703" name="656/fq_weights_1/mulpiply_by_scale" type="Multiply" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>64</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
				<port id="1">
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>64</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</output>
		</layer>
		<layer id="704" name="24520/value24522_const" type="Const" version="opset1">
			<data element_type="i64" offset="20034" shape="5" size="40"/>
			<output>
				<port id="0" precision="I64">
					<dim>5</dim>
				</port>
			</output>
		</layer>
		<layer id="705" name="24520" type="Reshape" version="opset1">
			<data special_zero="true"/>
			<input>
				<port id="0">
					<dim>64</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
				<port id="1">
					<dim>5</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</output>
		</layer>
		<layer id="706" name="656" type="GroupConvolution" version="opset1">
			<data auto_pad="explicit" dilations="1,1" pads_begin="1,1" pads_end="1,1" strides="1,1"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>64</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
				<port id="1">
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
			</output>
		</layer>
		<layer id="707" name="data_add_218692187422754/EltwiseUnsqueeze23362_const1456_const" type="Const" version="opset1">
			<data element_type="f16" offset="141070" shape="1,64,1,1" size="128"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="708" name="657/variance/Fused_Add_" type="Add" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>64</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
				<port id="1">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" names="657" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
			</output>
		</layer>
		<layer id="709" name="658" type="ReLU" version="opset1">
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>64</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
			</input>
			<output>
				<port id="1" names="658" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
			</output>
		</layer>
		<layer id="710" name="46474651_const" type="Const" version="opset1">
			<data element_type="f16" offset="10108" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="711" name="46484652_const" type="Const" version="opset1">
			<data element_type="f16" offset="141198" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="712" name="46494653_const" type="Const" version="opset1">
			<data element_type="f16" offset="10108" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="713" name="46504654_const" type="Const" version="opset1">
			<data element_type="f16" offset="141198" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="714" name="701/reduce/fq_input_0" type="FakeQuantize" version="opset1">
			<data auto_broadcast="numpy" levels="256"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>64</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
				<port id="1"/>
				<port id="2"/>
				<port id="3"/>
				<port id="4"/>
			</input>
			<output>
				<port id="5" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
			</output>
		</layer>
		<layer id="715" name="1349/Output_0/Data__const1459_const" type="Const" version="opset1">
			<data element_type="i64" offset="24" shape="" size="8"/>
			<output>
				<port id="0" precision="I64"/>
			</output>
		</layer>
		<layer id="716" name="701/input_rank/shape_of" type="ShapeOf" version="opset3">
			<data output_type="i64"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>64</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
			</input>
			<output>
				<port id="1" precision="I64">
					<dim>4</dim>
				</port>
			</output>
		</layer>
		<layer id="717" name="701/input_rank/rank_of" type="ShapeOf" version="opset3">
			<data output_type="i64"/>
			<input>
				<port id="0">
					<dim>4</dim>
				</port>
			</input>
			<output>
				<port id="1" precision="I64">
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="718" name="701/input_rank/0d_rank_of/value/Output_0/Data__const1462_const" type="Const" version="opset1">
			<data element_type="i64" offset="32" shape="1" size="8"/>
			<output>
				<port id="0" precision="I64">
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="719" name="701/input_rank" type="Squeeze" version="opset1">
			<input>
				<port id="0">
					<dim>1</dim>
				</port>
				<port id="1">
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="I64"/>
			</output>
		</layer>
		<layer id="720" name="1351/Output_0/Data__const1464_const" type="Const" version="opset1">
			<data element_type="i64" offset="0" shape="" size="8"/>
			<output>
				<port id="0" precision="I64"/>
			</output>
		</layer>
		<layer id="721" name="701/global_pooling_reduce_axis" type="Range" version="opset4">
			<data output_type="i64"/>
			<input>
				<port id="0"/>
				<port id="1"/>
				<port id="2"/>
			</input>
			<output>
				<port id="3" precision="I64">
					<dim>2</dim>
				</port>
			</output>
		</layer>
		<layer id="722" name="701/reduce" type="ReduceMean" version="opset1">
			<data keep_dims="true"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>64</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
				<port id="1">
					<dim>2</dim>
				</port>
			</input>
			<output>
				<port id="2" names="701" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="723" name="1086810872_const" type="Const" version="opset1">
			<data element_type="f16" offset="10108" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="724" name="1086910873_const" type="Const" version="opset1">
			<data element_type="f16" offset="141200" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="725" name="1087010874_const" type="Const" version="opset1">
			<data element_type="f16" offset="10108" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="726" name="1087110875_const" type="Const" version="opset1">
			<data element_type="f16" offset="141200" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="727" name="703/fq_input_0" type="FakeQuantize" version="opset1">
			<data auto_broadcast="numpy" levels="256"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="1"/>
				<port id="2"/>
				<port id="3"/>
				<port id="4"/>
			</input>
			<output>
				<port id="5" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="728" name="703/Cast_143338_const1467_const" type="Const" version="opset1">
			<data element_type="i64" offset="129708" shape="3" size="24"/>
			<output>
				<port id="0" names="702" precision="I64">
					<dim>3</dim>
				</port>
			</output>
		</layer>
		<layer id="729" name="703" type="Reshape" version="opset1">
			<data special_zero="true"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="1">
					<dim>3</dim>
				</port>
			</input>
			<output>
				<port id="2" names="703" precision="FP16">
					<dim>1</dim>
					<dim>16</dim>
					<dim>4</dim>
				</port>
			</output>
		</layer>
		<layer id="730" name="706/Range_input_port_0/value/Output_0/Data__const1469_const" type="Const" version="opset1">
			<data element_type="i64" offset="24" shape="" size="8"/>
			<output>
				<port id="0" precision="I64"/>
			</output>
		</layer>
		<layer id="731" name="706/Rank/shape_of" type="ShapeOf" version="opset3">
			<data output_type="i64"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>16</dim>
					<dim>4</dim>
				</port>
			</input>
			<output>
				<port id="1" precision="I64">
					<dim>3</dim>
				</port>
			</output>
		</layer>
		<layer id="732" name="706/Rank/rank_of" type="ShapeOf" version="opset3">
			<data output_type="i64"/>
			<input>
				<port id="0">
					<dim>3</dim>
				</port>
			</input>
			<output>
				<port id="1" precision="I64">
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="733" name="706/Rank/0d_rank_of/value/Output_0/Data__const1472_const" type="Const" version="opset1">
			<data element_type="i64" offset="32" shape="1" size="8"/>
			<output>
				<port id="0" precision="I64">
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="734" name="706/Rank" type="Squeeze" version="opset1">
			<input>
				<port id="0">
					<dim>1</dim>
				</port>
				<port id="1">
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="I64"/>
			</output>
		</layer>
		<layer id="735" name="706/Range_input_port_2/value/Output_0/Data__const1474_const" type="Const" version="opset1">
			<data element_type="i64" offset="0" shape="" size="8"/>
			<output>
				<port id="0" precision="I64"/>
			</output>
		</layer>
		<layer id="736" name="706/Range" type="Range" version="opset4">
			<data output_type="i64"/>
			<input>
				<port id="0"/>
				<port id="1"/>
				<port id="2"/>
			</input>
			<output>
				<port id="3" precision="I64">
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="737" name="706/Ins_Norm/MVN_" type="MVN" version="opset6">
			<data eps="9.999999747378752e-06" eps_mode="inside_sqrt" normalize_variance="true"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>16</dim>
					<dim>4</dim>
				</port>
				<port id="1">
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>1</dim>
					<dim>16</dim>
					<dim>4</dim>
				</port>
			</output>
		</layer>
		<layer id="738" name="704/EltwiseUnsqueeze23046_const1477_const" type="Const" version="opset1">
			<data element_type="f16" offset="129732" shape="1,16,1" size="32"/>
			<output>
				<port id="0" names="704" precision="FP16">
					<dim>1</dim>
					<dim>16</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="739" name="706/Ins_Norm/mul_" type="Multiply" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>16</dim>
					<dim>4</dim>
				</port>
				<port id="1">
					<dim>1</dim>
					<dim>16</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>1</dim>
					<dim>16</dim>
					<dim>4</dim>
				</port>
			</output>
		</layer>
		<layer id="740" name="705/EltwiseUnsqueeze23050_const1479_const" type="Const" version="opset1">
			<data element_type="f16" offset="129764" shape="1,16,1" size="32"/>
			<output>
				<port id="0" names="705" precision="FP16">
					<dim>1</dim>
					<dim>16</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="741" name="706" type="Add" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>16</dim>
					<dim>4</dim>
				</port>
				<port id="1">
					<dim>1</dim>
					<dim>16</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" names="706" precision="FP16">
					<dim>1</dim>
					<dim>16</dim>
					<dim>4</dim>
				</port>
			</output>
		</layer>
		<layer id="742" name="1087810882_const" type="Const" version="opset1">
			<data element_type="f16" offset="141202" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="743" name="1087910883_const" type="Const" version="opset1">
			<data element_type="f16" offset="141204" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="744" name="1088010884_const" type="Const" version="opset1">
			<data element_type="f16" offset="141202" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="745" name="1088110885_const" type="Const" version="opset1">
			<data element_type="f16" offset="141204" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="746" name="708/fq_input_0" type="FakeQuantize" version="opset1">
			<data auto_broadcast="numpy" levels="256"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>16</dim>
					<dim>4</dim>
				</port>
				<port id="1"/>
				<port id="2"/>
				<port id="3"/>
				<port id="4"/>
			</input>
			<output>
				<port id="5" precision="FP16">
					<dim>1</dim>
					<dim>16</dim>
					<dim>4</dim>
				</port>
			</output>
		</layer>
		<layer id="747" name="707" type="ShapeOf" version="opset3">
			<data output_type="i64"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="1" names="707" precision="I64">
					<dim>4</dim>
				</port>
			</output>
		</layer>
		<layer id="748" name="708" type="Reshape" version="opset1">
			<data special_zero="true"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>16</dim>
					<dim>4</dim>
				</port>
				<port id="1">
					<dim>4</dim>
				</port>
			</input>
			<output>
				<port id="2" names="708" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="749" name="709/Unsqueeze/EltwiseUnsqueeze22878_const1483_const" type="Const" version="opset1">
			<data element_type="f16" offset="129800" shape="1,64,1,1" size="128"/>
			<output>
				<port id="0" names="709" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="750" name="710" type="Multiply" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="1">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" names="710" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="751" name="711/Unsqueeze/EltwiseUnsqueeze22882_const1485_const" type="Const" version="opset1">
			<data element_type="f16" offset="129928" shape="1,64,1,1" size="128"/>
			<output>
				<port id="0" names="711" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="752" name="712" type="Add" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="1">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" names="712" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="753" name="713" type="Sigmoid" version="opset1">
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="1" names="713" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="754" name="78277831_const" type="Const" version="opset1">
			<data element_type="f16" offset="10108" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="755" name="78287832_const" type="Const" version="opset1">
			<data element_type="f16" offset="141206" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="756" name="78297833_const" type="Const" version="opset1">
			<data element_type="f16" offset="10108" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="757" name="78307834_const" type="Const" version="opset1">
			<data element_type="f16" offset="141206" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="758" name="714/fq_input_1" type="FakeQuantize" version="opset1">
			<data auto_broadcast="numpy" levels="256"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="1"/>
				<port id="2"/>
				<port id="3"/>
				<port id="4"/>
			</input>
			<output>
				<port id="5" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="759" name="714" type="Multiply" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>64</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
				<port id="1">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" names="714" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
			</output>
		</layer>
		<layer id="760" name="59375941_const" type="Const" version="opset1">
			<data element_type="f16" offset="10108" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="761" name="59385942_const" type="Const" version="opset1">
			<data element_type="f16" offset="141208" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="762" name="59395943_const" type="Const" version="opset1">
			<data element_type="f16" offset="10108" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="763" name="59405944_const" type="Const" version="opset1">
			<data element_type="f16" offset="141208" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="764" name="715/fq_input_1" type="FakeQuantize" version="opset1">
			<data auto_broadcast="numpy" levels="256"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>64</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
				<port id="1"/>
				<port id="2"/>
				<port id="3"/>
				<port id="4"/>
			</input>
			<output>
				<port id="5" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
			</output>
		</layer>
		<layer id="765" name="715" type="Add" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>64</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
				<port id="1">
					<dim>1</dim>
					<dim>64</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
			</input>
			<output>
				<port id="2" names="715" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
			</output>
		</layer>
		<layer id="766" name="82378241_const" type="Const" version="opset1">
			<data element_type="f16" offset="10108" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="767" name="82388242_const" type="Const" version="opset1">
			<data element_type="f16" offset="141210" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="768" name="82398243_const" type="Const" version="opset1">
			<data element_type="f16" offset="10108" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="769" name="82408244_const" type="Const" version="opset1">
			<data element_type="f16" offset="141210" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="770" name="730/fq_input_0" type="FakeQuantize" version="opset1">
			<data auto_broadcast="numpy" levels="256"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>64</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
				<port id="1"/>
				<port id="2"/>
				<port id="3"/>
				<port id="4"/>
			</input>
			<output>
				<port id="5" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
			</output>
		</layer>
		<layer id="771" name="conv2.1.conv2c.0.conv1.weight/quantized20139_const" type="Const" version="opset1">
			<data element_type="i8" offset="141212" shape="64,64,1,1" size="4096"/>
			<output>
				<port id="0" precision="I8">
					<dim>64</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="772" name="conv2.1.conv2c.0.conv1.weight/quantized/to_f16" type="Convert" version="opset1">
			<data destination_type="f16"/>
			<input>
				<port id="0">
					<dim>64</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="1" precision="FP16">
					<dim>64</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="773" name="659/fq_weights_1/zero_point20152_const" type="Const" version="opset1">
			<data element_type="f16" offset="145308" shape="64,1,1,1" size="128"/>
			<output>
				<port id="0" precision="FP16">
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="774" name="659/fq_weights_1/minus_zp" type="Subtract" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>64</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="1">
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>64</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="775" name="659/fq_weights_1/scale20147_const" type="Const" version="opset1">
			<data element_type="f16" offset="145436" shape="64,1,1,1" size="128"/>
			<output>
				<port id="0" precision="FP16">
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="776" name="659/fq_weights_1/mulpiply_by_scale" type="Multiply" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>64</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="1">
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>64</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="777" name="659" type="Convolution" version="opset1">
			<data auto_pad="explicit" dilations="1,1" pads_begin="0,0" pads_end="0,0" strides="1,1"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>64</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
				<port id="1">
					<dim>64</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" names="659" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
			</output>
		</layer>
		<layer id="778" name="29242926_const" type="Const" version="opset1">
			<data element_type="f16" offset="9720" shape="1,64,1,1" size="128"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="779" name="659/add_" type="Add" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>64</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
				<port id="1">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
			</output>
		</layer>
		<layer id="780" name="73277331_const" type="Const" version="opset1">
			<data element_type="f16" offset="145564" shape="1,64,1,1" size="128"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="781" name="73287332_const" type="Const" version="opset1">
			<data element_type="f16" offset="145692" shape="1,64,1,1" size="128"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="782" name="73297333_const" type="Const" version="opset1">
			<data element_type="f16" offset="145564" shape="1,64,1,1" size="128"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="783" name="73307334_const" type="Const" version="opset1">
			<data element_type="f16" offset="145692" shape="1,64,1,1" size="128"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="784" name="660/fq_input_0" type="FakeQuantize" version="opset1">
			<data auto_broadcast="numpy" levels="256"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>64</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
				<port id="1">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="2">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="3">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="4">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="5" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
			</output>
		</layer>
		<layer id="785" name="4216742170_const149215425/quantized17955_const" type="Const" version="opset1">
			<data element_type="i8" offset="145820" shape="64,1,3,3" size="576"/>
			<output>
				<port id="0" precision="I8">
					<dim>64</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</output>
		</layer>
		<layer id="786" name="4216742170_const149215425/quantized/to_f16" type="Convert" version="opset1">
			<data destination_type="f16"/>
			<input>
				<port id="0">
					<dim>64</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</input>
			<output>
				<port id="1" precision="FP16">
					<dim>64</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</output>
		</layer>
		<layer id="787" name="660/fq_weights_1/zero_point17968_const" type="Const" version="opset1">
			<data element_type="f16" offset="146396" shape="64,1,1,1" size="128"/>
			<output>
				<port id="0" precision="FP16">
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="788" name="660/fq_weights_1/minus_zp" type="Subtract" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>64</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
				<port id="1">
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>64</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</output>
		</layer>
		<layer id="789" name="660/fq_weights_1/scale17963_const" type="Const" version="opset1">
			<data element_type="f16" offset="146524" shape="64,1,1,1" size="128"/>
			<output>
				<port id="0" precision="FP16">
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="790" name="660/fq_weights_1/mulpiply_by_scale" type="Multiply" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>64</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
				<port id="1">
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>64</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</output>
		</layer>
		<layer id="791" name="24436/value24438_const" type="Const" version="opset1">
			<data element_type="i64" offset="20034" shape="5" size="40"/>
			<output>
				<port id="0" precision="I64">
					<dim>5</dim>
				</port>
			</output>
		</layer>
		<layer id="792" name="24436" type="Reshape" version="opset1">
			<data special_zero="true"/>
			<input>
				<port id="0">
					<dim>64</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
				<port id="1">
					<dim>5</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</output>
		</layer>
		<layer id="793" name="660" type="GroupConvolution" version="opset1">
			<data auto_pad="explicit" dilations="1,1" pads_begin="1,1" pads_end="1,1" strides="1,1"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>64</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
				<port id="1">
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
			</output>
		</layer>
		<layer id="794" name="data_add_218372184222746/EltwiseUnsqueeze23330_const1494_const" type="Const" version="opset1">
			<data element_type="f16" offset="146652" shape="1,64,1,1" size="128"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="795" name="661/variance/Fused_Add_" type="Add" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>64</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
				<port id="1">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" names="661" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
			</output>
		</layer>
		<layer id="796" name="662" type="ReLU" version="opset1">
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>64</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
			</input>
			<output>
				<port id="1" names="662" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
			</output>
		</layer>
		<layer id="797" name="71277131_const" type="Const" version="opset1">
			<data element_type="f16" offset="10108" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="798" name="71287132_const" type="Const" version="opset1">
			<data element_type="f16" offset="146780" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="799" name="71297133_const" type="Const" version="opset1">
			<data element_type="f16" offset="10108" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="800" name="71307134_const" type="Const" version="opset1">
			<data element_type="f16" offset="146780" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="801" name="663/fq_input_0" type="FakeQuantize" version="opset1">
			<data auto_broadcast="numpy" levels="256"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>64</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
				<port id="1"/>
				<port id="2"/>
				<port id="3"/>
				<port id="4"/>
			</input>
			<output>
				<port id="5" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
			</output>
		</layer>
		<layer id="802" name="conv2.1.conv2c.1.conv1.weight/quantized18843_const" type="Const" version="opset1">
			<data element_type="i8" offset="146782" shape="64,64,1,1" size="4096"/>
			<output>
				<port id="0" precision="I8">
					<dim>64</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="803" name="conv2.1.conv2c.1.conv1.weight/quantized/to_f16" type="Convert" version="opset1">
			<data destination_type="f16"/>
			<input>
				<port id="0">
					<dim>64</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="1" precision="FP16">
					<dim>64</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="804" name="663/fq_weights_1/zero_point18856_const" type="Const" version="opset1">
			<data element_type="f16" offset="150878" shape="64,1,1,1" size="128"/>
			<output>
				<port id="0" precision="FP16">
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="805" name="663/fq_weights_1/minus_zp" type="Subtract" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>64</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="1">
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>64</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="806" name="663/fq_weights_1/scale18851_const" type="Const" version="opset1">
			<data element_type="f16" offset="151006" shape="64,1,1,1" size="128"/>
			<output>
				<port id="0" precision="FP16">
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="807" name="663/fq_weights_1/mulpiply_by_scale" type="Multiply" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>64</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="1">
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>64</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="808" name="663" type="Convolution" version="opset1">
			<data auto_pad="explicit" dilations="1,1" pads_begin="0,0" pads_end="0,0" strides="1,1"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>64</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
				<port id="1">
					<dim>64</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" names="663" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
			</output>
		</layer>
		<layer id="809" name="29282930_const" type="Const" version="opset1">
			<data element_type="f16" offset="9720" shape="1,64,1,1" size="128"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="810" name="663/add_" type="Add" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>64</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
				<port id="1">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
			</output>
		</layer>
		<layer id="811" name="59775981_const" type="Const" version="opset1">
			<data element_type="f16" offset="151134" shape="1,64,1,1" size="128"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="812" name="59785982_const" type="Const" version="opset1">
			<data element_type="f16" offset="151262" shape="1,64,1,1" size="128"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="813" name="59795983_const" type="Const" version="opset1">
			<data element_type="f16" offset="151134" shape="1,64,1,1" size="128"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="814" name="59805984_const" type="Const" version="opset1">
			<data element_type="f16" offset="151262" shape="1,64,1,1" size="128"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="815" name="664/fq_input_0" type="FakeQuantize" version="opset1">
			<data auto_broadcast="numpy" levels="256"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>64</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
				<port id="1">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="2">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="3">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="4">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="5" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
			</output>
		</layer>
		<layer id="816" name="4207942082_const149915428/quantized18075_const" type="Const" version="opset1">
			<data element_type="i8" offset="151390" shape="64,1,3,3" size="576"/>
			<output>
				<port id="0" precision="I8">
					<dim>64</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</output>
		</layer>
		<layer id="817" name="4207942082_const149915428/quantized/to_f16" type="Convert" version="opset1">
			<data destination_type="f16"/>
			<input>
				<port id="0">
					<dim>64</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</input>
			<output>
				<port id="1" precision="FP16">
					<dim>64</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</output>
		</layer>
		<layer id="818" name="664/fq_weights_1/zero_point18088_const" type="Const" version="opset1">
			<data element_type="f16" offset="151966" shape="64,1,1,1" size="128"/>
			<output>
				<port id="0" precision="FP16">
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="819" name="664/fq_weights_1/minus_zp" type="Subtract" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>64</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
				<port id="1">
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>64</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</output>
		</layer>
		<layer id="820" name="664/fq_weights_1/scale18083_const" type="Const" version="opset1">
			<data element_type="f16" offset="152094" shape="64,1,1,1" size="128"/>
			<output>
				<port id="0" precision="FP16">
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="821" name="664/fq_weights_1/mulpiply_by_scale" type="Multiply" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>64</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
				<port id="1">
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>64</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</output>
		</layer>
		<layer id="822" name="24396/value24398_const" type="Const" version="opset1">
			<data element_type="i64" offset="20034" shape="5" size="40"/>
			<output>
				<port id="0" precision="I64">
					<dim>5</dim>
				</port>
			</output>
		</layer>
		<layer id="823" name="24396" type="Reshape" version="opset1">
			<data special_zero="true"/>
			<input>
				<port id="0">
					<dim>64</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
				<port id="1">
					<dim>5</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</output>
		</layer>
		<layer id="824" name="664" type="GroupConvolution" version="opset1">
			<data auto_pad="explicit" dilations="1,1" pads_begin="1,1" pads_end="1,1" strides="1,1"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>64</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
				<port id="1">
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
			</output>
		</layer>
		<layer id="825" name="data_add_218452185022748/EltwiseUnsqueeze23338_const1501_const" type="Const" version="opset1">
			<data element_type="f16" offset="152222" shape="1,64,1,1" size="128"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="826" name="665/variance/Fused_Add_" type="Add" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>64</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
				<port id="1">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" names="665" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
			</output>
		</layer>
		<layer id="827" name="666" type="ReLU" version="opset1">
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>64</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
			</input>
			<output>
				<port id="1" names="666" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
			</output>
		</layer>
		<layer id="828" name="46074611_const" type="Const" version="opset1">
			<data element_type="f16" offset="10108" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="829" name="46084612_const" type="Const" version="opset1">
			<data element_type="f16" offset="152350" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="830" name="46094613_const" type="Const" version="opset1">
			<data element_type="f16" offset="10108" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="831" name="46104614_const" type="Const" version="opset1">
			<data element_type="f16" offset="152350" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="832" name="667/fq_input_0" type="FakeQuantize" version="opset1">
			<data auto_broadcast="numpy" levels="256"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>64</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
				<port id="1"/>
				<port id="2"/>
				<port id="3"/>
				<port id="4"/>
			</input>
			<output>
				<port id="5" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
			</output>
		</layer>
		<layer id="833" name="conv2.1.conv2c.2.conv1.weight/quantized18579_const" type="Const" version="opset1">
			<data element_type="i8" offset="152352" shape="64,64,1,1" size="4096"/>
			<output>
				<port id="0" precision="I8">
					<dim>64</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="834" name="conv2.1.conv2c.2.conv1.weight/quantized/to_f16" type="Convert" version="opset1">
			<data destination_type="f16"/>
			<input>
				<port id="0">
					<dim>64</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="1" precision="FP16">
					<dim>64</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="835" name="667/fq_weights_1/zero_point18592_const" type="Const" version="opset1">
			<data element_type="f16" offset="156448" shape="64,1,1,1" size="128"/>
			<output>
				<port id="0" precision="FP16">
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="836" name="667/fq_weights_1/minus_zp" type="Subtract" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>64</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="1">
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>64</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="837" name="667/fq_weights_1/scale18587_const" type="Const" version="opset1">
			<data element_type="f16" offset="156576" shape="64,1,1,1" size="128"/>
			<output>
				<port id="0" precision="FP16">
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="838" name="667/fq_weights_1/mulpiply_by_scale" type="Multiply" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>64</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="1">
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>64</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="839" name="667" type="Convolution" version="opset1">
			<data auto_pad="explicit" dilations="1,1" pads_begin="0,0" pads_end="0,0" strides="1,1"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>64</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
				<port id="1">
					<dim>64</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" names="667" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
			</output>
		</layer>
		<layer id="840" name="29322934_const" type="Const" version="opset1">
			<data element_type="f16" offset="9720" shape="1,64,1,1" size="128"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="841" name="667/add_" type="Add" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>64</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
				<port id="1">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
			</output>
		</layer>
		<layer id="842" name="62376241_const" type="Const" version="opset1">
			<data element_type="f16" offset="156704" shape="1,64,1,1" size="128"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="843" name="62386242_const" type="Const" version="opset1">
			<data element_type="f16" offset="156832" shape="1,64,1,1" size="128"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="844" name="62396243_const" type="Const" version="opset1">
			<data element_type="f16" offset="156704" shape="1,64,1,1" size="128"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="845" name="62406244_const" type="Const" version="opset1">
			<data element_type="f16" offset="156832" shape="1,64,1,1" size="128"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="846" name="668/fq_input_0" type="FakeQuantize" version="opset1">
			<data auto_broadcast="numpy" levels="256"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>64</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
				<port id="1">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="2">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="3">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="4">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="5" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
			</output>
		</layer>
		<layer id="847" name="4205542058_const150615431/quantized17931_const" type="Const" version="opset1">
			<data element_type="i8" offset="156960" shape="64,1,3,3" size="576"/>
			<output>
				<port id="0" precision="I8">
					<dim>64</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</output>
		</layer>
		<layer id="848" name="4205542058_const150615431/quantized/to_f16" type="Convert" version="opset1">
			<data destination_type="f16"/>
			<input>
				<port id="0">
					<dim>64</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</input>
			<output>
				<port id="1" precision="FP16">
					<dim>64</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</output>
		</layer>
		<layer id="849" name="668/fq_weights_1/zero_point17944_const" type="Const" version="opset1">
			<data element_type="f16" offset="157536" shape="64,1,1,1" size="128"/>
			<output>
				<port id="0" precision="FP16">
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="850" name="668/fq_weights_1/minus_zp" type="Subtract" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>64</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
				<port id="1">
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>64</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</output>
		</layer>
		<layer id="851" name="668/fq_weights_1/scale17939_const" type="Const" version="opset1">
			<data element_type="f16" offset="157664" shape="64,1,1,1" size="128"/>
			<output>
				<port id="0" precision="FP16">
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="852" name="668/fq_weights_1/mulpiply_by_scale" type="Multiply" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>64</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
				<port id="1">
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>64</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</output>
		</layer>
		<layer id="853" name="24540/value24542_const" type="Const" version="opset1">
			<data element_type="i64" offset="20034" shape="5" size="40"/>
			<output>
				<port id="0" precision="I64">
					<dim>5</dim>
				</port>
			</output>
		</layer>
		<layer id="854" name="24540" type="Reshape" version="opset1">
			<data special_zero="true"/>
			<input>
				<port id="0">
					<dim>64</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
				<port id="1">
					<dim>5</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</output>
		</layer>
		<layer id="855" name="668" type="GroupConvolution" version="opset1">
			<data auto_pad="explicit" dilations="1,1" pads_begin="1,1" pads_end="1,1" strides="1,1"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>64</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
				<port id="1">
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
			</output>
		</layer>
		<layer id="856" name="data_add_218532185822750/EltwiseUnsqueeze23346_const1508_const" type="Const" version="opset1">
			<data element_type="f16" offset="157792" shape="1,64,1,1" size="128"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="857" name="669/variance/Fused_Add_" type="Add" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>64</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
				<port id="1">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" names="669" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
			</output>
		</layer>
		<layer id="858" name="670" type="ReLU" version="opset1">
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>64</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
			</input>
			<output>
				<port id="1" names="670" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
			</output>
		</layer>
		<layer id="859" name="61176121_const" type="Const" version="opset1">
			<data element_type="f16" offset="10108" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="860" name="61186122_const" type="Const" version="opset1">
			<data element_type="f16" offset="157920" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="861" name="61196123_const" type="Const" version="opset1">
			<data element_type="f16" offset="10108" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="862" name="61206124_const" type="Const" version="opset1">
			<data element_type="f16" offset="157920" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="863" name="716/reduce/fq_input_0" type="FakeQuantize" version="opset1">
			<data auto_broadcast="numpy" levels="256"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>64</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
				<port id="1"/>
				<port id="2"/>
				<port id="3"/>
				<port id="4"/>
			</input>
			<output>
				<port id="5" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
			</output>
		</layer>
		<layer id="864" name="1354/Output_0/Data__const1511_const" type="Const" version="opset1">
			<data element_type="i64" offset="24" shape="" size="8"/>
			<output>
				<port id="0" precision="I64"/>
			</output>
		</layer>
		<layer id="865" name="716/input_rank/shape_of" type="ShapeOf" version="opset3">
			<data output_type="i64"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>64</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
			</input>
			<output>
				<port id="1" precision="I64">
					<dim>4</dim>
				</port>
			</output>
		</layer>
		<layer id="866" name="716/input_rank/rank_of" type="ShapeOf" version="opset3">
			<data output_type="i64"/>
			<input>
				<port id="0">
					<dim>4</dim>
				</port>
			</input>
			<output>
				<port id="1" precision="I64">
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="867" name="716/input_rank/0d_rank_of/value/Output_0/Data__const1514_const" type="Const" version="opset1">
			<data element_type="i64" offset="32" shape="1" size="8"/>
			<output>
				<port id="0" precision="I64">
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="868" name="716/input_rank" type="Squeeze" version="opset1">
			<input>
				<port id="0">
					<dim>1</dim>
				</port>
				<port id="1">
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="I64"/>
			</output>
		</layer>
		<layer id="869" name="1356/Output_0/Data__const1516_const" type="Const" version="opset1">
			<data element_type="i64" offset="0" shape="" size="8"/>
			<output>
				<port id="0" precision="I64"/>
			</output>
		</layer>
		<layer id="870" name="716/global_pooling_reduce_axis" type="Range" version="opset4">
			<data output_type="i64"/>
			<input>
				<port id="0"/>
				<port id="1"/>
				<port id="2"/>
			</input>
			<output>
				<port id="3" precision="I64">
					<dim>2</dim>
				</port>
			</output>
		</layer>
		<layer id="871" name="716/reduce" type="ReduceMean" version="opset1">
			<data keep_dims="true"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>64</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
				<port id="1">
					<dim>2</dim>
				</port>
			</input>
			<output>
				<port id="2" names="716" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="872" name="1088810892_const" type="Const" version="opset1">
			<data element_type="f16" offset="10108" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="873" name="1088910893_const" type="Const" version="opset1">
			<data element_type="f16" offset="157922" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="874" name="1089010894_const" type="Const" version="opset1">
			<data element_type="f16" offset="10108" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="875" name="1089110895_const" type="Const" version="opset1">
			<data element_type="f16" offset="157922" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="876" name="718/fq_input_0" type="FakeQuantize" version="opset1">
			<data auto_broadcast="numpy" levels="256"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="1"/>
				<port id="2"/>
				<port id="3"/>
				<port id="4"/>
			</input>
			<output>
				<port id="5" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="877" name="718/Cast_143320_const1519_const" type="Const" version="opset1">
			<data element_type="i64" offset="129708" shape="3" size="24"/>
			<output>
				<port id="0" names="717" precision="I64">
					<dim>3</dim>
				</port>
			</output>
		</layer>
		<layer id="878" name="718" type="Reshape" version="opset1">
			<data special_zero="true"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="1">
					<dim>3</dim>
				</port>
			</input>
			<output>
				<port id="2" names="718" precision="FP16">
					<dim>1</dim>
					<dim>16</dim>
					<dim>4</dim>
				</port>
			</output>
		</layer>
		<layer id="879" name="721/Range_input_port_0/value/Output_0/Data__const1521_const" type="Const" version="opset1">
			<data element_type="i64" offset="24" shape="" size="8"/>
			<output>
				<port id="0" precision="I64"/>
			</output>
		</layer>
		<layer id="880" name="721/Rank/shape_of" type="ShapeOf" version="opset3">
			<data output_type="i64"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>16</dim>
					<dim>4</dim>
				</port>
			</input>
			<output>
				<port id="1" precision="I64">
					<dim>3</dim>
				</port>
			</output>
		</layer>
		<layer id="881" name="721/Rank/rank_of" type="ShapeOf" version="opset3">
			<data output_type="i64"/>
			<input>
				<port id="0">
					<dim>3</dim>
				</port>
			</input>
			<output>
				<port id="1" precision="I64">
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="882" name="721/Rank/0d_rank_of/value/Output_0/Data__const1524_const" type="Const" version="opset1">
			<data element_type="i64" offset="32" shape="1" size="8"/>
			<output>
				<port id="0" precision="I64">
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="883" name="721/Rank" type="Squeeze" version="opset1">
			<input>
				<port id="0">
					<dim>1</dim>
				</port>
				<port id="1">
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="I64"/>
			</output>
		</layer>
		<layer id="884" name="721/Range_input_port_2/value/Output_0/Data__const1526_const" type="Const" version="opset1">
			<data element_type="i64" offset="0" shape="" size="8"/>
			<output>
				<port id="0" precision="I64"/>
			</output>
		</layer>
		<layer id="885" name="721/Range" type="Range" version="opset4">
			<data output_type="i64"/>
			<input>
				<port id="0"/>
				<port id="1"/>
				<port id="2"/>
			</input>
			<output>
				<port id="3" precision="I64">
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="886" name="721/Ins_Norm/MVN_" type="MVN" version="opset6">
			<data eps="9.999999747378752e-06" eps_mode="inside_sqrt" normalize_variance="true"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>16</dim>
					<dim>4</dim>
				</port>
				<port id="1">
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>1</dim>
					<dim>16</dim>
					<dim>4</dim>
				</port>
			</output>
		</layer>
		<layer id="887" name="719/EltwiseUnsqueeze22974_const1529_const" type="Const" version="opset1">
			<data element_type="f16" offset="129732" shape="1,16,1" size="32"/>
			<output>
				<port id="0" names="719" precision="FP16">
					<dim>1</dim>
					<dim>16</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="888" name="721/Ins_Norm/mul_" type="Multiply" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>16</dim>
					<dim>4</dim>
				</port>
				<port id="1">
					<dim>1</dim>
					<dim>16</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>1</dim>
					<dim>16</dim>
					<dim>4</dim>
				</port>
			</output>
		</layer>
		<layer id="889" name="720/EltwiseUnsqueeze22978_const1531_const" type="Const" version="opset1">
			<data element_type="f16" offset="129764" shape="1,16,1" size="32"/>
			<output>
				<port id="0" names="720" precision="FP16">
					<dim>1</dim>
					<dim>16</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="890" name="721" type="Add" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>16</dim>
					<dim>4</dim>
				</port>
				<port id="1">
					<dim>1</dim>
					<dim>16</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" names="721" precision="FP16">
					<dim>1</dim>
					<dim>16</dim>
					<dim>4</dim>
				</port>
			</output>
		</layer>
		<layer id="891" name="1089810902_const" type="Const" version="opset1">
			<data element_type="f16" offset="157924" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="892" name="1089910903_const" type="Const" version="opset1">
			<data element_type="f16" offset="157926" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="893" name="1090010904_const" type="Const" version="opset1">
			<data element_type="f16" offset="157924" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="894" name="1090110905_const" type="Const" version="opset1">
			<data element_type="f16" offset="157926" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="895" name="723/fq_input_0" type="FakeQuantize" version="opset1">
			<data auto_broadcast="numpy" levels="256"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>16</dim>
					<dim>4</dim>
				</port>
				<port id="1"/>
				<port id="2"/>
				<port id="3"/>
				<port id="4"/>
			</input>
			<output>
				<port id="5" precision="FP16">
					<dim>1</dim>
					<dim>16</dim>
					<dim>4</dim>
				</port>
			</output>
		</layer>
		<layer id="896" name="722" type="ShapeOf" version="opset3">
			<data output_type="i64"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="1" names="722" precision="I64">
					<dim>4</dim>
				</port>
			</output>
		</layer>
		<layer id="897" name="723" type="Reshape" version="opset1">
			<data special_zero="true"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>16</dim>
					<dim>4</dim>
				</port>
				<port id="1">
					<dim>4</dim>
				</port>
			</input>
			<output>
				<port id="2" names="723" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="898" name="724/Unsqueeze/EltwiseUnsqueeze22886_const1535_const" type="Const" version="opset1">
			<data element_type="f16" offset="129800" shape="1,64,1,1" size="128"/>
			<output>
				<port id="0" names="724" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="899" name="725" type="Multiply" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="1">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" names="725" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="900" name="726/Unsqueeze/EltwiseUnsqueeze22890_const1537_const" type="Const" version="opset1">
			<data element_type="f16" offset="129928" shape="1,64,1,1" size="128"/>
			<output>
				<port id="0" names="726" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="901" name="727" type="Add" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="1">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" names="727" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="902" name="728" type="Sigmoid" version="opset1">
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="1" names="728" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="903" name="60076011_const" type="Const" version="opset1">
			<data element_type="f16" offset="10108" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="904" name="60086012_const" type="Const" version="opset1">
			<data element_type="f16" offset="157928" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="905" name="60096013_const" type="Const" version="opset1">
			<data element_type="f16" offset="10108" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="906" name="60106014_const" type="Const" version="opset1">
			<data element_type="f16" offset="157928" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="907" name="729/fq_input_1" type="FakeQuantize" version="opset1">
			<data auto_broadcast="numpy" levels="256"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="1"/>
				<port id="2"/>
				<port id="3"/>
				<port id="4"/>
			</input>
			<output>
				<port id="5" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="908" name="729" type="Multiply" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>64</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
				<port id="1">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" names="729" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
			</output>
		</layer>
		<layer id="909" name="82478251_const" type="Const" version="opset1">
			<data element_type="f16" offset="10108" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="910" name="82488252_const" type="Const" version="opset1">
			<data element_type="f16" offset="157930" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="911" name="82498253_const" type="Const" version="opset1">
			<data element_type="f16" offset="10108" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="912" name="82508254_const" type="Const" version="opset1">
			<data element_type="f16" offset="157930" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="913" name="730/fq_input_1" type="FakeQuantize" version="opset1">
			<data auto_broadcast="numpy" levels="256"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>64</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
				<port id="1"/>
				<port id="2"/>
				<port id="3"/>
				<port id="4"/>
			</input>
			<output>
				<port id="5" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
			</output>
		</layer>
		<layer id="914" name="730" type="Add" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>64</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
				<port id="1">
					<dim>1</dim>
					<dim>64</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
			</input>
			<output>
				<port id="2" names="730" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
			</output>
		</layer>
		<layer id="915" name="67576761_const" type="Const" version="opset1">
			<data element_type="f16" offset="10108" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="916" name="67586762_const" type="Const" version="opset1">
			<data element_type="f16" offset="157932" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="917" name="67596763_const" type="Const" version="opset1">
			<data element_type="f16" offset="10108" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="918" name="67606764_const" type="Const" version="opset1">
			<data element_type="f16" offset="157932" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="919" name="745/fq_input_0" type="FakeQuantize" version="opset1">
			<data auto_broadcast="numpy" levels="256"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>64</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
				<port id="1"/>
				<port id="2"/>
				<port id="3"/>
				<port id="4"/>
			</input>
			<output>
				<port id="5" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
			</output>
		</layer>
		<layer id="920" name="conv2.1.conv2d.0.conv1.weight/quantized17763_const" type="Const" version="opset1">
			<data element_type="i8" offset="157934" shape="64,64,1,1" size="4096"/>
			<output>
				<port id="0" precision="I8">
					<dim>64</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="921" name="conv2.1.conv2d.0.conv1.weight/quantized/to_f16" type="Convert" version="opset1">
			<data destination_type="f16"/>
			<input>
				<port id="0">
					<dim>64</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="1" precision="FP16">
					<dim>64</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="922" name="671/fq_weights_1/zero_point17776_const" type="Const" version="opset1">
			<data element_type="f16" offset="162030" shape="64,1,1,1" size="128"/>
			<output>
				<port id="0" precision="FP16">
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="923" name="671/fq_weights_1/minus_zp" type="Subtract" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>64</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="1">
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>64</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="924" name="671/fq_weights_1/scale17771_const" type="Const" version="opset1">
			<data element_type="f16" offset="162158" shape="64,1,1,1" size="128"/>
			<output>
				<port id="0" precision="FP16">
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="925" name="671/fq_weights_1/mulpiply_by_scale" type="Multiply" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>64</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="1">
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>64</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="926" name="671" type="Convolution" version="opset1">
			<data auto_pad="explicit" dilations="1,1" pads_begin="0,0" pads_end="0,0" strides="1,1"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>64</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
				<port id="1">
					<dim>64</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" names="671" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
			</output>
		</layer>
		<layer id="927" name="29362938_const" type="Const" version="opset1">
			<data element_type="f16" offset="9720" shape="1,64,1,1" size="128"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="928" name="671/add_" type="Add" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>64</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
				<port id="1">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
			</output>
		</layer>
		<layer id="929" name="73477351_const" type="Const" version="opset1">
			<data element_type="f16" offset="162286" shape="1,64,1,1" size="128"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="930" name="73487352_const" type="Const" version="opset1">
			<data element_type="f16" offset="162414" shape="1,64,1,1" size="128"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="931" name="73497353_const" type="Const" version="opset1">
			<data element_type="f16" offset="162286" shape="1,64,1,1" size="128"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="932" name="73507354_const" type="Const" version="opset1">
			<data element_type="f16" offset="162414" shape="1,64,1,1" size="128"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="933" name="672/fq_input_0" type="FakeQuantize" version="opset1">
			<data auto_broadcast="numpy" levels="256"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>64</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
				<port id="1">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="2">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="3">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="4">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="5" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
			</output>
		</layer>
		<layer id="934" name="4225142254_const154415445/quantized19563_const" type="Const" version="opset1">
			<data element_type="i8" offset="162542" shape="64,1,3,3" size="576"/>
			<output>
				<port id="0" precision="I8">
					<dim>64</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</output>
		</layer>
		<layer id="935" name="4225142254_const154415445/quantized/to_f16" type="Convert" version="opset1">
			<data destination_type="f16"/>
			<input>
				<port id="0">
					<dim>64</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</input>
			<output>
				<port id="1" precision="FP16">
					<dim>64</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</output>
		</layer>
		<layer id="936" name="672/fq_weights_1/zero_point19576_const" type="Const" version="opset1">
			<data element_type="f16" offset="163118" shape="64,1,1,1" size="128"/>
			<output>
				<port id="0" precision="FP16">
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="937" name="672/fq_weights_1/minus_zp" type="Subtract" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>64</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
				<port id="1">
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>64</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</output>
		</layer>
		<layer id="938" name="672/fq_weights_1/scale19571_const" type="Const" version="opset1">
			<data element_type="f16" offset="163246" shape="64,1,1,1" size="128"/>
			<output>
				<port id="0" precision="FP16">
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="939" name="672/fq_weights_1/mulpiply_by_scale" type="Multiply" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>64</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
				<port id="1">
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>64</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</output>
		</layer>
		<layer id="940" name="24440/value24442_const" type="Const" version="opset1">
			<data element_type="i64" offset="20034" shape="5" size="40"/>
			<output>
				<port id="0" precision="I64">
					<dim>5</dim>
				</port>
			</output>
		</layer>
		<layer id="941" name="24440" type="Reshape" version="opset1">
			<data special_zero="true"/>
			<input>
				<port id="0">
					<dim>64</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
				<port id="1">
					<dim>5</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</output>
		</layer>
		<layer id="942" name="672" type="GroupConvolution" version="opset1">
			<data auto_pad="explicit" dilations="1,1" pads_begin="1,1" pads_end="1,1" strides="1,1"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>64</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
				<port id="1">
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
			</output>
		</layer>
		<layer id="943" name="data_add_218052181022738/EltwiseUnsqueeze23298_const1546_const" type="Const" version="opset1">
			<data element_type="f16" offset="163374" shape="1,64,1,1" size="128"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="944" name="673/variance/Fused_Add_" type="Add" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>64</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
				<port id="1">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" names="673" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
			</output>
		</layer>
		<layer id="945" name="674" type="ReLU" version="opset1">
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>64</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
			</input>
			<output>
				<port id="1" names="674" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
			</output>
		</layer>
		<layer id="946" name="50175021_const" type="Const" version="opset1">
			<data element_type="f16" offset="10108" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="947" name="50185022_const" type="Const" version="opset1">
			<data element_type="f16" offset="163502" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="948" name="50195023_const" type="Const" version="opset1">
			<data element_type="f16" offset="10108" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="949" name="50205024_const" type="Const" version="opset1">
			<data element_type="f16" offset="163502" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="950" name="675/fq_input_0" type="FakeQuantize" version="opset1">
			<data auto_broadcast="numpy" levels="256"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>64</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
				<port id="1"/>
				<port id="2"/>
				<port id="3"/>
				<port id="4"/>
			</input>
			<output>
				<port id="5" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
			</output>
		</layer>
		<layer id="951" name="conv2.1.conv2d.1.conv1.weight/quantized19107_const" type="Const" version="opset1">
			<data element_type="i8" offset="163504" shape="64,64,1,1" size="4096"/>
			<output>
				<port id="0" precision="I8">
					<dim>64</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="952" name="conv2.1.conv2d.1.conv1.weight/quantized/to_f16" type="Convert" version="opset1">
			<data destination_type="f16"/>
			<input>
				<port id="0">
					<dim>64</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="1" precision="FP16">
					<dim>64</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="953" name="675/fq_weights_1/zero_point19120_const" type="Const" version="opset1">
			<data element_type="f16" offset="167600" shape="64,1,1,1" size="128"/>
			<output>
				<port id="0" precision="FP16">
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="954" name="675/fq_weights_1/minus_zp" type="Subtract" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>64</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="1">
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>64</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="955" name="675/fq_weights_1/scale19115_const" type="Const" version="opset1">
			<data element_type="f16" offset="167728" shape="64,1,1,1" size="128"/>
			<output>
				<port id="0" precision="FP16">
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="956" name="675/fq_weights_1/mulpiply_by_scale" type="Multiply" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>64</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="1">
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>64</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="957" name="675" type="Convolution" version="opset1">
			<data auto_pad="explicit" dilations="1,1" pads_begin="0,0" pads_end="0,0" strides="1,1"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>64</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
				<port id="1">
					<dim>64</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" names="675" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
			</output>
		</layer>
		<layer id="958" name="29402942_const" type="Const" version="opset1">
			<data element_type="f16" offset="9720" shape="1,64,1,1" size="128"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="959" name="675/add_" type="Add" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>64</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
				<port id="1">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
			</output>
		</layer>
		<layer id="960" name="48774881_const" type="Const" version="opset1">
			<data element_type="f16" offset="167856" shape="1,64,1,1" size="128"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="961" name="48784882_const" type="Const" version="opset1">
			<data element_type="f16" offset="167984" shape="1,64,1,1" size="128"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="962" name="48794883_const" type="Const" version="opset1">
			<data element_type="f16" offset="167856" shape="1,64,1,1" size="128"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="963" name="48804884_const" type="Const" version="opset1">
			<data element_type="f16" offset="167984" shape="1,64,1,1" size="128"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="964" name="676/fq_input_0" type="FakeQuantize" version="opset1">
			<data auto_broadcast="numpy" levels="256"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>64</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
				<port id="1">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="2">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="3">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="4">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="5" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
			</output>
		</layer>
		<layer id="965" name="4210342106_const155115448/quantized17979_const" type="Const" version="opset1">
			<data element_type="i8" offset="168112" shape="64,1,3,3" size="576"/>
			<output>
				<port id="0" precision="I8">
					<dim>64</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</output>
		</layer>
		<layer id="966" name="4210342106_const155115448/quantized/to_f16" type="Convert" version="opset1">
			<data destination_type="f16"/>
			<input>
				<port id="0">
					<dim>64</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</input>
			<output>
				<port id="1" precision="FP16">
					<dim>64</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</output>
		</layer>
		<layer id="967" name="676/fq_weights_1/zero_point17992_const" type="Const" version="opset1">
			<data element_type="f16" offset="168688" shape="64,1,1,1" size="128"/>
			<output>
				<port id="0" precision="FP16">
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="968" name="676/fq_weights_1/minus_zp" type="Subtract" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>64</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
				<port id="1">
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>64</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</output>
		</layer>
		<layer id="969" name="676/fq_weights_1/scale17987_const" type="Const" version="opset1">
			<data element_type="f16" offset="168816" shape="64,1,1,1" size="128"/>
			<output>
				<port id="0" precision="FP16">
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="970" name="676/fq_weights_1/mulpiply_by_scale" type="Multiply" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>64</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
				<port id="1">
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>64</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</output>
		</layer>
		<layer id="971" name="24512/value24514_const" type="Const" version="opset1">
			<data element_type="i64" offset="20034" shape="5" size="40"/>
			<output>
				<port id="0" precision="I64">
					<dim>5</dim>
				</port>
			</output>
		</layer>
		<layer id="972" name="24512" type="Reshape" version="opset1">
			<data special_zero="true"/>
			<input>
				<port id="0">
					<dim>64</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
				<port id="1">
					<dim>5</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</output>
		</layer>
		<layer id="973" name="676" type="GroupConvolution" version="opset1">
			<data auto_pad="explicit" dilations="1,1" pads_begin="1,1" pads_end="1,1" strides="1,1"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>64</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
				<port id="1">
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
			</output>
		</layer>
		<layer id="974" name="data_add_218132181822740/EltwiseUnsqueeze23306_const1553_const" type="Const" version="opset1">
			<data element_type="f16" offset="168944" shape="1,64,1,1" size="128"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="975" name="677/variance/Fused_Add_" type="Add" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>64</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
				<port id="1">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" names="677" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
			</output>
		</layer>
		<layer id="976" name="678" type="ReLU" version="opset1">
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>64</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
			</input>
			<output>
				<port id="1" names="678" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
			</output>
		</layer>
		<layer id="977" name="48974901_const" type="Const" version="opset1">
			<data element_type="f16" offset="10108" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="978" name="48984902_const" type="Const" version="opset1">
			<data element_type="f16" offset="169072" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="979" name="48994903_const" type="Const" version="opset1">
			<data element_type="f16" offset="10108" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="980" name="49004904_const" type="Const" version="opset1">
			<data element_type="f16" offset="169072" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="981" name="679/fq_input_0" type="FakeQuantize" version="opset1">
			<data auto_broadcast="numpy" levels="256"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>64</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
				<port id="1"/>
				<port id="2"/>
				<port id="3"/>
				<port id="4"/>
			</input>
			<output>
				<port id="5" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
			</output>
		</layer>
		<layer id="982" name="conv2.1.conv2d.2.conv1.weight/quantized19227_const" type="Const" version="opset1">
			<data element_type="i8" offset="169074" shape="64,64,1,1" size="4096"/>
			<output>
				<port id="0" precision="I8">
					<dim>64</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="983" name="conv2.1.conv2d.2.conv1.weight/quantized/to_f16" type="Convert" version="opset1">
			<data destination_type="f16"/>
			<input>
				<port id="0">
					<dim>64</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="1" precision="FP16">
					<dim>64</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="984" name="679/fq_weights_1/zero_point19240_const" type="Const" version="opset1">
			<data element_type="f16" offset="173170" shape="64,1,1,1" size="128"/>
			<output>
				<port id="0" precision="FP16">
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="985" name="679/fq_weights_1/minus_zp" type="Subtract" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>64</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="1">
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>64</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="986" name="679/fq_weights_1/scale19235_const" type="Const" version="opset1">
			<data element_type="f16" offset="173298" shape="64,1,1,1" size="128"/>
			<output>
				<port id="0" precision="FP16">
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="987" name="679/fq_weights_1/mulpiply_by_scale" type="Multiply" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>64</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="1">
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>64</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="988" name="679" type="Convolution" version="opset1">
			<data auto_pad="explicit" dilations="1,1" pads_begin="0,0" pads_end="0,0" strides="1,1"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>64</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
				<port id="1">
					<dim>64</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" names="679" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
			</output>
		</layer>
		<layer id="989" name="29442946_const" type="Const" version="opset1">
			<data element_type="f16" offset="9720" shape="1,64,1,1" size="128"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="990" name="679/add_" type="Add" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>64</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
				<port id="1">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
			</output>
		</layer>
		<layer id="991" name="64776481_const" type="Const" version="opset1">
			<data element_type="f16" offset="173426" shape="1,64,1,1" size="128"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="992" name="64786482_const" type="Const" version="opset1">
			<data element_type="f16" offset="173554" shape="1,64,1,1" size="128"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="993" name="64796483_const" type="Const" version="opset1">
			<data element_type="f16" offset="173426" shape="1,64,1,1" size="128"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="994" name="64806484_const" type="Const" version="opset1">
			<data element_type="f16" offset="173554" shape="1,64,1,1" size="128"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="995" name="680/fq_input_0" type="FakeQuantize" version="opset1">
			<data auto_broadcast="numpy" levels="256"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>64</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
				<port id="1">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="2">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="3">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="4">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="5" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
			</output>
		</layer>
		<layer id="996" name="4227142274_const155815451/quantized19347_const" type="Const" version="opset1">
			<data element_type="i8" offset="173682" shape="64,1,3,3" size="576"/>
			<output>
				<port id="0" precision="I8">
					<dim>64</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</output>
		</layer>
		<layer id="997" name="4227142274_const155815451/quantized/to_f16" type="Convert" version="opset1">
			<data destination_type="f16"/>
			<input>
				<port id="0">
					<dim>64</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</input>
			<output>
				<port id="1" precision="FP16">
					<dim>64</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</output>
		</layer>
		<layer id="998" name="680/fq_weights_1/zero_point19360_const" type="Const" version="opset1">
			<data element_type="f16" offset="174258" shape="64,1,1,1" size="128"/>
			<output>
				<port id="0" precision="FP16">
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="999" name="680/fq_weights_1/minus_zp" type="Subtract" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>64</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
				<port id="1">
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>64</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</output>
		</layer>
		<layer id="1000" name="680/fq_weights_1/scale19355_const" type="Const" version="opset1">
			<data element_type="f16" offset="174386" shape="64,1,1,1" size="128"/>
			<output>
				<port id="0" precision="FP16">
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1001" name="680/fq_weights_1/mulpiply_by_scale" type="Multiply" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>64</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
				<port id="1">
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>64</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</output>
		</layer>
		<layer id="1002" name="24600/value24602_const" type="Const" version="opset1">
			<data element_type="i64" offset="20034" shape="5" size="40"/>
			<output>
				<port id="0" precision="I64">
					<dim>5</dim>
				</port>
			</output>
		</layer>
		<layer id="1003" name="24600" type="Reshape" version="opset1">
			<data special_zero="true"/>
			<input>
				<port id="0">
					<dim>64</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
				<port id="1">
					<dim>5</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</output>
		</layer>
		<layer id="1004" name="680" type="GroupConvolution" version="opset1">
			<data auto_pad="explicit" dilations="1,1" pads_begin="1,1" pads_end="1,1" strides="1,1"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>64</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
				<port id="1">
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
			</output>
		</layer>
		<layer id="1005" name="data_add_218212182622742/EltwiseUnsqueeze23314_const1560_const" type="Const" version="opset1">
			<data element_type="f16" offset="174514" shape="1,64,1,1" size="128"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1006" name="681/variance/Fused_Add_" type="Add" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>64</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
				<port id="1">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" names="681" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
			</output>
		</layer>
		<layer id="1007" name="682" type="ReLU" version="opset1">
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>64</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
			</input>
			<output>
				<port id="1" names="682" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
			</output>
		</layer>
		<layer id="1008" name="55875591_const" type="Const" version="opset1">
			<data element_type="f16" offset="10108" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="1009" name="55885592_const" type="Const" version="opset1">
			<data element_type="f16" offset="174642" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="1010" name="55895593_const" type="Const" version="opset1">
			<data element_type="f16" offset="10108" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="1011" name="55905594_const" type="Const" version="opset1">
			<data element_type="f16" offset="174642" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="1012" name="683/fq_input_0" type="FakeQuantize" version="opset1">
			<data auto_broadcast="numpy" levels="256"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>64</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
				<port id="1"/>
				<port id="2"/>
				<port id="3"/>
				<port id="4"/>
			</input>
			<output>
				<port id="5" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
			</output>
		</layer>
		<layer id="1013" name="conv2.1.conv2d.3.conv1.weight/quantized18267_const" type="Const" version="opset1">
			<data element_type="i8" offset="174644" shape="64,64,1,1" size="4096"/>
			<output>
				<port id="0" precision="I8">
					<dim>64</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1014" name="conv2.1.conv2d.3.conv1.weight/quantized/to_f16" type="Convert" version="opset1">
			<data destination_type="f16"/>
			<input>
				<port id="0">
					<dim>64</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="1" precision="FP16">
					<dim>64</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1015" name="683/fq_weights_1/zero_point18280_const" type="Const" version="opset1">
			<data element_type="f16" offset="178740" shape="64,1,1,1" size="128"/>
			<output>
				<port id="0" precision="FP16">
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1016" name="683/fq_weights_1/minus_zp" type="Subtract" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>64</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="1">
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>64</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1017" name="683/fq_weights_1/scale18275_const" type="Const" version="opset1">
			<data element_type="f16" offset="178868" shape="64,1,1,1" size="128"/>
			<output>
				<port id="0" precision="FP16">
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1018" name="683/fq_weights_1/mulpiply_by_scale" type="Multiply" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>64</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="1">
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>64</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1019" name="683" type="Convolution" version="opset1">
			<data auto_pad="explicit" dilations="1,1" pads_begin="0,0" pads_end="0,0" strides="1,1"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>64</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
				<port id="1">
					<dim>64</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" names="683" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
			</output>
		</layer>
		<layer id="1020" name="29482950_const" type="Const" version="opset1">
			<data element_type="f16" offset="9720" shape="1,64,1,1" size="128"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1021" name="683/add_" type="Add" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>64</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
				<port id="1">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
			</output>
		</layer>
		<layer id="1022" name="49975001_const" type="Const" version="opset1">
			<data element_type="f16" offset="178996" shape="1,64,1,1" size="128"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1023" name="49985002_const" type="Const" version="opset1">
			<data element_type="f16" offset="179124" shape="1,64,1,1" size="128"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1024" name="49995003_const" type="Const" version="opset1">
			<data element_type="f16" offset="178996" shape="1,64,1,1" size="128"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1025" name="50005004_const" type="Const" version="opset1">
			<data element_type="f16" offset="179124" shape="1,64,1,1" size="128"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1026" name="684/fq_input_0" type="FakeQuantize" version="opset1">
			<data auto_broadcast="numpy" levels="256"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>64</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
				<port id="1">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="2">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="3">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="4">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="5" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
			</output>
		</layer>
		<layer id="1027" name="4219942202_const156515454/quantized18723_const" type="Const" version="opset1">
			<data element_type="i8" offset="179252" shape="64,1,3,3" size="576"/>
			<output>
				<port id="0" precision="I8">
					<dim>64</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</output>
		</layer>
		<layer id="1028" name="4219942202_const156515454/quantized/to_f16" type="Convert" version="opset1">
			<data destination_type="f16"/>
			<input>
				<port id="0">
					<dim>64</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</input>
			<output>
				<port id="1" precision="FP16">
					<dim>64</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</output>
		</layer>
		<layer id="1029" name="684/fq_weights_1/zero_point18736_const" type="Const" version="opset1">
			<data element_type="f16" offset="179828" shape="64,1,1,1" size="128"/>
			<output>
				<port id="0" precision="FP16">
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1030" name="684/fq_weights_1/minus_zp" type="Subtract" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>64</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
				<port id="1">
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>64</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</output>
		</layer>
		<layer id="1031" name="684/fq_weights_1/scale18731_const" type="Const" version="opset1">
			<data element_type="f16" offset="179956" shape="64,1,1,1" size="128"/>
			<output>
				<port id="0" precision="FP16">
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1032" name="684/fq_weights_1/mulpiply_by_scale" type="Multiply" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>64</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
				<port id="1">
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>64</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</output>
		</layer>
		<layer id="1033" name="24516/value24518_const" type="Const" version="opset1">
			<data element_type="i64" offset="20034" shape="5" size="40"/>
			<output>
				<port id="0" precision="I64">
					<dim>5</dim>
				</port>
			</output>
		</layer>
		<layer id="1034" name="24516" type="Reshape" version="opset1">
			<data special_zero="true"/>
			<input>
				<port id="0">
					<dim>64</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
				<port id="1">
					<dim>5</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</output>
		</layer>
		<layer id="1035" name="684" type="GroupConvolution" version="opset1">
			<data auto_pad="explicit" dilations="1,1" pads_begin="1,1" pads_end="1,1" strides="1,1"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>64</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
				<port id="1">
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
			</output>
		</layer>
		<layer id="1036" name="data_add_218292183422744/EltwiseUnsqueeze23322_const1567_const" type="Const" version="opset1">
			<data element_type="f16" offset="180084" shape="1,64,1,1" size="128"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1037" name="685/variance/Fused_Add_" type="Add" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>64</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
				<port id="1">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" names="685" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
			</output>
		</layer>
		<layer id="1038" name="686" type="ReLU" version="opset1">
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>64</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
			</input>
			<output>
				<port id="1" names="686" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
			</output>
		</layer>
		<layer id="1039" name="82578261_const" type="Const" version="opset1">
			<data element_type="f16" offset="10108" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="1040" name="82588262_const" type="Const" version="opset1">
			<data element_type="f16" offset="180212" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="1041" name="82598263_const" type="Const" version="opset1">
			<data element_type="f16" offset="10108" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="1042" name="82608264_const" type="Const" version="opset1">
			<data element_type="f16" offset="180212" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="1043" name="731/reduce/fq_input_0" type="FakeQuantize" version="opset1">
			<data auto_broadcast="numpy" levels="256"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>64</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
				<port id="1"/>
				<port id="2"/>
				<port id="3"/>
				<port id="4"/>
			</input>
			<output>
				<port id="5" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
			</output>
		</layer>
		<layer id="1044" name="1359/Output_0/Data__const1570_const" type="Const" version="opset1">
			<data element_type="i64" offset="24" shape="" size="8"/>
			<output>
				<port id="0" precision="I64"/>
			</output>
		</layer>
		<layer id="1045" name="731/input_rank/shape_of" type="ShapeOf" version="opset3">
			<data output_type="i64"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>64</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
			</input>
			<output>
				<port id="1" precision="I64">
					<dim>4</dim>
				</port>
			</output>
		</layer>
		<layer id="1046" name="731/input_rank/rank_of" type="ShapeOf" version="opset3">
			<data output_type="i64"/>
			<input>
				<port id="0">
					<dim>4</dim>
				</port>
			</input>
			<output>
				<port id="1" precision="I64">
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1047" name="731/input_rank/0d_rank_of/value/Output_0/Data__const1573_const" type="Const" version="opset1">
			<data element_type="i64" offset="32" shape="1" size="8"/>
			<output>
				<port id="0" precision="I64">
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1048" name="731/input_rank" type="Squeeze" version="opset1">
			<input>
				<port id="0">
					<dim>1</dim>
				</port>
				<port id="1">
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="I64"/>
			</output>
		</layer>
		<layer id="1049" name="1361/Output_0/Data__const1575_const" type="Const" version="opset1">
			<data element_type="i64" offset="0" shape="" size="8"/>
			<output>
				<port id="0" precision="I64"/>
			</output>
		</layer>
		<layer id="1050" name="731/global_pooling_reduce_axis" type="Range" version="opset4">
			<data output_type="i64"/>
			<input>
				<port id="0"/>
				<port id="1"/>
				<port id="2"/>
			</input>
			<output>
				<port id="3" precision="I64">
					<dim>2</dim>
				</port>
			</output>
		</layer>
		<layer id="1051" name="731/reduce" type="ReduceMean" version="opset1">
			<data keep_dims="true"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>64</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
				<port id="1">
					<dim>2</dim>
				</port>
			</input>
			<output>
				<port id="2" names="731" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1052" name="1090810912_const" type="Const" version="opset1">
			<data element_type="f16" offset="10108" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="1053" name="1090910913_const" type="Const" version="opset1">
			<data element_type="f16" offset="180214" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="1054" name="1091010914_const" type="Const" version="opset1">
			<data element_type="f16" offset="10108" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="1055" name="1091110915_const" type="Const" version="opset1">
			<data element_type="f16" offset="180214" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="1056" name="733/fq_input_0" type="FakeQuantize" version="opset1">
			<data auto_broadcast="numpy" levels="256"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="1"/>
				<port id="2"/>
				<port id="3"/>
				<port id="4"/>
			</input>
			<output>
				<port id="5" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1057" name="733/Cast_143302_const1578_const" type="Const" version="opset1">
			<data element_type="i64" offset="129708" shape="3" size="24"/>
			<output>
				<port id="0" names="732" precision="I64">
					<dim>3</dim>
				</port>
			</output>
		</layer>
		<layer id="1058" name="733" type="Reshape" version="opset1">
			<data special_zero="true"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="1">
					<dim>3</dim>
				</port>
			</input>
			<output>
				<port id="2" names="733" precision="FP16">
					<dim>1</dim>
					<dim>16</dim>
					<dim>4</dim>
				</port>
			</output>
		</layer>
		<layer id="1059" name="736/Range_input_port_0/value/Output_0/Data__const1580_const" type="Const" version="opset1">
			<data element_type="i64" offset="24" shape="" size="8"/>
			<output>
				<port id="0" precision="I64"/>
			</output>
		</layer>
		<layer id="1060" name="736/Rank/shape_of" type="ShapeOf" version="opset3">
			<data output_type="i64"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>16</dim>
					<dim>4</dim>
				</port>
			</input>
			<output>
				<port id="1" precision="I64">
					<dim>3</dim>
				</port>
			</output>
		</layer>
		<layer id="1061" name="736/Rank/rank_of" type="ShapeOf" version="opset3">
			<data output_type="i64"/>
			<input>
				<port id="0">
					<dim>3</dim>
				</port>
			</input>
			<output>
				<port id="1" precision="I64">
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1062" name="736/Rank/0d_rank_of/value/Output_0/Data__const1583_const" type="Const" version="opset1">
			<data element_type="i64" offset="32" shape="1" size="8"/>
			<output>
				<port id="0" precision="I64">
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1063" name="736/Rank" type="Squeeze" version="opset1">
			<input>
				<port id="0">
					<dim>1</dim>
				</port>
				<port id="1">
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="I64"/>
			</output>
		</layer>
		<layer id="1064" name="736/Range_input_port_2/value/Output_0/Data__const1585_const" type="Const" version="opset1">
			<data element_type="i64" offset="0" shape="" size="8"/>
			<output>
				<port id="0" precision="I64"/>
			</output>
		</layer>
		<layer id="1065" name="736/Range" type="Range" version="opset4">
			<data output_type="i64"/>
			<input>
				<port id="0"/>
				<port id="1"/>
				<port id="2"/>
			</input>
			<output>
				<port id="3" precision="I64">
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1066" name="736/Ins_Norm/MVN_" type="MVN" version="opset6">
			<data eps="9.999999747378752e-06" eps_mode="inside_sqrt" normalize_variance="true"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>16</dim>
					<dim>4</dim>
				</port>
				<port id="1">
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>1</dim>
					<dim>16</dim>
					<dim>4</dim>
				</port>
			</output>
		</layer>
		<layer id="1067" name="734/EltwiseUnsqueeze23006_const1588_const" type="Const" version="opset1">
			<data element_type="f16" offset="129732" shape="1,16,1" size="32"/>
			<output>
				<port id="0" names="734" precision="FP16">
					<dim>1</dim>
					<dim>16</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1068" name="736/Ins_Norm/mul_" type="Multiply" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>16</dim>
					<dim>4</dim>
				</port>
				<port id="1">
					<dim>1</dim>
					<dim>16</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>1</dim>
					<dim>16</dim>
					<dim>4</dim>
				</port>
			</output>
		</layer>
		<layer id="1069" name="735/EltwiseUnsqueeze23010_const1590_const" type="Const" version="opset1">
			<data element_type="f16" offset="129764" shape="1,16,1" size="32"/>
			<output>
				<port id="0" names="735" precision="FP16">
					<dim>1</dim>
					<dim>16</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1070" name="736" type="Add" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>16</dim>
					<dim>4</dim>
				</port>
				<port id="1">
					<dim>1</dim>
					<dim>16</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" names="736" precision="FP16">
					<dim>1</dim>
					<dim>16</dim>
					<dim>4</dim>
				</port>
			</output>
		</layer>
		<layer id="1071" name="1091810922_const" type="Const" version="opset1">
			<data element_type="f16" offset="180216" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="1072" name="1091910923_const" type="Const" version="opset1">
			<data element_type="f16" offset="180218" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="1073" name="1092010924_const" type="Const" version="opset1">
			<data element_type="f16" offset="180216" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="1074" name="1092110925_const" type="Const" version="opset1">
			<data element_type="f16" offset="180218" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="1075" name="738/fq_input_0" type="FakeQuantize" version="opset1">
			<data auto_broadcast="numpy" levels="256"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>16</dim>
					<dim>4</dim>
				</port>
				<port id="1"/>
				<port id="2"/>
				<port id="3"/>
				<port id="4"/>
			</input>
			<output>
				<port id="5" precision="FP16">
					<dim>1</dim>
					<dim>16</dim>
					<dim>4</dim>
				</port>
			</output>
		</layer>
		<layer id="1076" name="737" type="ShapeOf" version="opset3">
			<data output_type="i64"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="1" names="737" precision="I64">
					<dim>4</dim>
				</port>
			</output>
		</layer>
		<layer id="1077" name="738" type="Reshape" version="opset1">
			<data special_zero="true"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>16</dim>
					<dim>4</dim>
				</port>
				<port id="1">
					<dim>4</dim>
				</port>
			</input>
			<output>
				<port id="2" names="738" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1078" name="739/Unsqueeze/EltwiseUnsqueeze22894_const1594_const" type="Const" version="opset1">
			<data element_type="f16" offset="129800" shape="1,64,1,1" size="128"/>
			<output>
				<port id="0" names="739" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1079" name="740" type="Multiply" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="1">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" names="740" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1080" name="741/Unsqueeze/EltwiseUnsqueeze22898_const1596_const" type="Const" version="opset1">
			<data element_type="f16" offset="129928" shape="1,64,1,1" size="128"/>
			<output>
				<port id="0" names="741" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1081" name="742" type="Add" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="1">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" names="742" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1082" name="743" type="Sigmoid" version="opset1">
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="1" names="743" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1083" name="55775581_const" type="Const" version="opset1">
			<data element_type="f16" offset="10108" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="1084" name="55785582_const" type="Const" version="opset1">
			<data element_type="f16" offset="180220" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="1085" name="55795583_const" type="Const" version="opset1">
			<data element_type="f16" offset="10108" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="1086" name="55805584_const" type="Const" version="opset1">
			<data element_type="f16" offset="180220" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="1087" name="744/fq_input_1" type="FakeQuantize" version="opset1">
			<data auto_broadcast="numpy" levels="256"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="1"/>
				<port id="2"/>
				<port id="3"/>
				<port id="4"/>
			</input>
			<output>
				<port id="5" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1088" name="744" type="Multiply" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>64</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
				<port id="1">
					<dim>1</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" names="744" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
			</output>
		</layer>
		<layer id="1089" name="67676771_const" type="Const" version="opset1">
			<data element_type="f16" offset="10108" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="1090" name="67686772_const" type="Const" version="opset1">
			<data element_type="f16" offset="180222" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="1091" name="67696773_const" type="Const" version="opset1">
			<data element_type="f16" offset="10108" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="1092" name="67706774_const" type="Const" version="opset1">
			<data element_type="f16" offset="180222" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="1093" name="745/fq_input_1" type="FakeQuantize" version="opset1">
			<data auto_broadcast="numpy" levels="256"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>64</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
				<port id="1"/>
				<port id="2"/>
				<port id="3"/>
				<port id="4"/>
			</input>
			<output>
				<port id="5" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
			</output>
		</layer>
		<layer id="1094" name="745" type="Add" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>64</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
				<port id="1">
					<dim>1</dim>
					<dim>64</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
			</input>
			<output>
				<port id="2" names="745" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
			</output>
		</layer>
		<layer id="1095" name="72477251_const" type="Const" version="opset1">
			<data element_type="f16" offset="10108" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="1096" name="72487252_const" type="Const" version="opset1">
			<data element_type="f16" offset="180224" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="1097" name="72497253_const" type="Const" version="opset1">
			<data element_type="f16" offset="10108" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="1098" name="72507254_const" type="Const" version="opset1">
			<data element_type="f16" offset="180224" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="1099" name="746/fq_input_0" type="FakeQuantize" version="opset1">
			<data auto_broadcast="numpy" levels="256"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>64</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
				<port id="1"/>
				<port id="2"/>
				<port id="3"/>
				<port id="4"/>
			</input>
			<output>
				<port id="5" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
			</output>
		</layer>
		<layer id="1100" name="747/mean/Fused_Mul_2445124453_const160115467/quantized17403_const" type="Const" version="opset1">
			<data element_type="i8" offset="180226" shape="256,64,1,1" size="16384"/>
			<output>
				<port id="0" precision="I8">
					<dim>256</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1101" name="747/mean/Fused_Mul_2445124453_const160115467/quantized/to_f16" type="Convert" version="opset1">
			<data destination_type="f16"/>
			<input>
				<port id="0">
					<dim>256</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="1" precision="FP16">
					<dim>256</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1102" name="746/fq_weights_1/zero_point17416_const" type="Const" version="opset1">
			<data element_type="f16" offset="196610" shape="256,1,1,1" size="512"/>
			<output>
				<port id="0" precision="FP16">
					<dim>256</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1103" name="746/fq_weights_1/minus_zp" type="Subtract" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>256</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="1">
					<dim>256</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>256</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1104" name="746/fq_weights_1/scale17411_const" type="Const" version="opset1">
			<data element_type="f16" offset="197122" shape="256,1,1,1" size="512"/>
			<output>
				<port id="0" precision="FP16">
					<dim>256</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1105" name="746/fq_weights_1/mulpiply_by_scale" type="Multiply" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>256</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="1">
					<dim>256</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>256</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1106" name="746" type="Convolution" version="opset1">
			<data auto_pad="explicit" dilations="1,1" pads_begin="0,0" pads_end="0,0" strides="1,1"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>64</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
				<port id="1">
					<dim>256</dim>
					<dim>64</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>1</dim>
					<dim>256</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
			</output>
		</layer>
		<layer id="1107" name="data_add_218852189022758/EltwiseUnsqueeze23378_const1603_const" type="Const" version="opset1">
			<data element_type="f16" offset="197634" shape="1,256,1,1" size="512"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>256</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1108" name="747/variance/Fused_Add_" type="Add" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>256</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
				<port id="1">
					<dim>1</dim>
					<dim>256</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" names="747" precision="FP16">
					<dim>1</dim>
					<dim>256</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
			</output>
		</layer>
		<layer id="1109" name="42074211_const" type="Const" version="opset1">
			<data element_type="f16" offset="198146" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="1110" name="42084212_const" type="Const" version="opset1">
			<data element_type="f16" offset="198148" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="1111" name="42094213_const" type="Const" version="opset1">
			<data element_type="f16" offset="198146" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="1112" name="42104214_const" type="Const" version="opset1">
			<data element_type="f16" offset="198148" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="1113" name="748/fq_input_0" type="FakeQuantize" version="opset1">
			<data auto_broadcast="numpy" levels="256"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>256</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
				<port id="1"/>
				<port id="2"/>
				<port id="3"/>
				<port id="4"/>
			</input>
			<output>
				<port id="5" precision="FP16">
					<dim>1</dim>
					<dim>256</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
			</output>
		</layer>
		<layer id="1114" name="748" type="Add" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>256</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
				<port id="1">
					<dim>1</dim>
					<dim>256</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
			</input>
			<output>
				<port id="2" names="748" precision="FP16">
					<dim>1</dim>
					<dim>256</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
			</output>
		</layer>
		<layer id="1115" name="749" type="ReLU" version="opset1">
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>256</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
			</input>
			<output>
				<port id="1" names="749" precision="FP16">
					<dim>1</dim>
					<dim>256</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
			</output>
		</layer>
		<layer id="1116" name="70877091_const" type="Const" version="opset1">
			<data element_type="f16" offset="10108" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="1117" name="70887092_const" type="Const" version="opset1">
			<data element_type="f16" offset="107362" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="1118" name="70897093_const" type="Const" version="opset1">
			<data element_type="f16" offset="10108" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="1119" name="70907094_const" type="Const" version="opset1">
			<data element_type="f16" offset="107362" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="1120" name="750/fq_input_0" type="FakeQuantize" version="opset1">
			<data auto_broadcast="numpy" levels="256"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>256</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
				<port id="1"/>
				<port id="2"/>
				<port id="3"/>
				<port id="4"/>
			</input>
			<output>
				<port id="5" precision="FP16">
					<dim>1</dim>
					<dim>256</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
			</output>
		</layer>
		<layer id="1121" name="751/mean/Fused_Mul_2445524457_const160715469/quantized20643_const" type="Const" version="opset1">
			<data element_type="i8" offset="198150" shape="256,256,1,1" size="65536"/>
			<output>
				<port id="0" precision="I8">
					<dim>256</dim>
					<dim>256</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1122" name="751/mean/Fused_Mul_2445524457_const160715469/quantized/to_f16" type="Convert" version="opset1">
			<data destination_type="f16"/>
			<input>
				<port id="0">
					<dim>256</dim>
					<dim>256</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="1" precision="FP16">
					<dim>256</dim>
					<dim>256</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1123" name="750/fq_weights_1/zero_point20656_const" type="Const" version="opset1">
			<data element_type="f16" offset="263686" shape="256,1,1,1" size="512"/>
			<output>
				<port id="0" precision="FP16">
					<dim>256</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1124" name="750/fq_weights_1/minus_zp" type="Subtract" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>256</dim>
					<dim>256</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="1">
					<dim>256</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>256</dim>
					<dim>256</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1125" name="750/fq_weights_1/scale20651_const" type="Const" version="opset1">
			<data element_type="f16" offset="264198" shape="256,1,1,1" size="512"/>
			<output>
				<port id="0" precision="FP16">
					<dim>256</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1126" name="750/fq_weights_1/mulpiply_by_scale" type="Multiply" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>256</dim>
					<dim>256</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="1">
					<dim>256</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>256</dim>
					<dim>256</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1127" name="750" type="Convolution" version="opset1">
			<data auto_pad="explicit" dilations="1,1" pads_begin="0,0" pads_end="0,0" strides="1,1"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>256</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
				<port id="1">
					<dim>256</dim>
					<dim>256</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>1</dim>
					<dim>256</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
			</output>
		</layer>
		<layer id="1128" name="data_add_218932189822760/EltwiseUnsqueeze23386_const1609_const" type="Const" version="opset1">
			<data element_type="f16" offset="264710" shape="1,256,1,1" size="512"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>256</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1129" name="751/variance/Fused_Add_" type="Add" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>256</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
				<port id="1">
					<dim>1</dim>
					<dim>256</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" names="751" precision="FP16">
					<dim>1</dim>
					<dim>256</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
			</output>
		</layer>
		<layer id="1130" name="752" type="ReLU" version="opset1">
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>256</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
			</input>
			<output>
				<port id="1" names="753,752" precision="FP16">
					<dim>1</dim>
					<dim>256</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
			</output>
		</layer>
		<layer id="1131" name="68576861_const" type="Const" version="opset1">
			<data element_type="f16" offset="10108" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="1132" name="68586862_const" type="Const" version="opset1">
			<data element_type="f16" offset="265222" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="1133" name="68596863_const" type="Const" version="opset1">
			<data element_type="f16" offset="10108" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="1134" name="68606864_const" type="Const" version="opset1">
			<data element_type="f16" offset="265222" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="1135" name="754/fq_input_0" type="FakeQuantize" version="opset1">
			<data auto_broadcast="numpy" levels="256"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>256</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
				<port id="1"/>
				<port id="2"/>
				<port id="3"/>
				<port id="4"/>
			</input>
			<output>
				<port id="5" precision="FP16">
					<dim>1</dim>
					<dim>256</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
			</output>
		</layer>
		<layer id="1136" name="754" type="AvgPool" version="opset1">
			<data auto_pad="explicit" exclude-pad="true" kernel="2,2" pads_begin="0,0" pads_end="0,0" rounding_type="floor" strides="2,2"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>256</dim>
					<dim>64</dim>
					<dim>32</dim>
				</port>
			</input>
			<output>
				<port id="1" names="754" precision="FP16">
					<dim>1</dim>
					<dim>256</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
			</output>
		</layer>
		<layer id="1137" name="73077311_const" type="Const" version="opset1">
			<data element_type="f16" offset="10108" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="1138" name="73087312_const" type="Const" version="opset1">
			<data element_type="f16" offset="265224" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="1139" name="73097313_const" type="Const" version="opset1">
			<data element_type="f16" offset="10108" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="1140" name="73107314_const" type="Const" version="opset1">
			<data element_type="f16" offset="265224" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="1141" name="755/fq_input_0" type="FakeQuantize" version="opset1">
			<data auto_broadcast="numpy" levels="256"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>256</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
				<port id="1"/>
				<port id="2"/>
				<port id="3"/>
				<port id="4"/>
			</input>
			<output>
				<port id="5" precision="FP16">
					<dim>1</dim>
					<dim>256</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
			</output>
		</layer>
		<layer id="1142" name="756/mean/Fused_Mul_2446324465_const161315471/quantized17859_const" type="Const" version="opset1">
			<data element_type="i8" offset="265226" shape="96,256,1,1" size="24576"/>
			<output>
				<port id="0" precision="I8">
					<dim>96</dim>
					<dim>256</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1143" name="756/mean/Fused_Mul_2446324465_const161315471/quantized/to_f16" type="Convert" version="opset1">
			<data destination_type="f16"/>
			<input>
				<port id="0">
					<dim>96</dim>
					<dim>256</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="1" precision="FP16">
					<dim>96</dim>
					<dim>256</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1144" name="755/fq_weights_1/zero_point17872_const" type="Const" version="opset1">
			<data element_type="f16" offset="289802" shape="96,1,1,1" size="192"/>
			<output>
				<port id="0" precision="FP16">
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1145" name="755/fq_weights_1/minus_zp" type="Subtract" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>96</dim>
					<dim>256</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="1">
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>96</dim>
					<dim>256</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1146" name="755/fq_weights_1/scale17867_const" type="Const" version="opset1">
			<data element_type="f16" offset="289994" shape="96,1,1,1" size="192"/>
			<output>
				<port id="0" precision="FP16">
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1147" name="755/fq_weights_1/mulpiply_by_scale" type="Multiply" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>96</dim>
					<dim>256</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="1">
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>96</dim>
					<dim>256</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1148" name="755" type="Convolution" version="opset1">
			<data auto_pad="explicit" dilations="1,1" pads_begin="0,0" pads_end="0,0" strides="1,1"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>256</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
				<port id="1">
					<dim>96</dim>
					<dim>256</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
			</output>
		</layer>
		<layer id="1149" name="data_add_219092191422764/EltwiseUnsqueeze23402_const1615_const" type="Const" version="opset1">
			<data element_type="f16" offset="290186" shape="1,96,1,1" size="192"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1150" name="756/variance/Fused_Add_" type="Add" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
				<port id="1">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" names="756" precision="FP16">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
			</output>
		</layer>
		<layer id="1151" name="757" type="ReLU" version="opset1">
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
			</input>
			<output>
				<port id="1" names="757" precision="FP16">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
			</output>
		</layer>
		<layer id="1152" name="64976501_const" type="Const" version="opset1">
			<data element_type="f16" offset="10108" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="1153" name="64986502_const" type="Const" version="opset1">
			<data element_type="f16" offset="290378" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="1154" name="64996503_const" type="Const" version="opset1">
			<data element_type="f16" offset="10108" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="1155" name="65006504_const" type="Const" version="opset1">
			<data element_type="f16" offset="290378" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="1156" name="758/fq_input_0" type="FakeQuantize" version="opset1">
			<data auto_broadcast="numpy" levels="256"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
				<port id="1"/>
				<port id="2"/>
				<port id="3"/>
				<port id="4"/>
			</input>
			<output>
				<port id="5" precision="FP16">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
			</output>
		</layer>
		<layer id="1157" name="conv3.0.conv2a.conv1.weight/quantized18747_const" type="Const" version="opset1">
			<data element_type="i8" offset="290380" shape="96,96,1,1" size="9216"/>
			<output>
				<port id="0" precision="I8">
					<dim>96</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1158" name="conv3.0.conv2a.conv1.weight/quantized/to_f16" type="Convert" version="opset1">
			<data destination_type="f16"/>
			<input>
				<port id="0">
					<dim>96</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="1" precision="FP16">
					<dim>96</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1159" name="758/fq_weights_1/zero_point18760_const" type="Const" version="opset1">
			<data element_type="f16" offset="299596" shape="96,1,1,1" size="192"/>
			<output>
				<port id="0" precision="FP16">
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1160" name="758/fq_weights_1/minus_zp" type="Subtract" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>96</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="1">
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>96</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1161" name="758/fq_weights_1/scale18755_const" type="Const" version="opset1">
			<data element_type="f16" offset="299788" shape="96,1,1,1" size="192"/>
			<output>
				<port id="0" precision="FP16">
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1162" name="758/fq_weights_1/mulpiply_by_scale" type="Multiply" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>96</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="1">
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>96</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1163" name="758" type="Convolution" version="opset1">
			<data auto_pad="explicit" dilations="1,1" pads_begin="0,0" pads_end="0,0" strides="1,1"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
				<port id="1">
					<dim>96</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" names="758" precision="FP16">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
			</output>
		</layer>
		<layer id="1164" name="29522954_const" type="Const" version="opset1">
			<data element_type="f16" offset="299980" shape="1,96,1,1" size="192"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1165" name="758/add_" type="Add" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
				<port id="1">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
			</output>
		</layer>
		<layer id="1166" name="80878091_const" type="Const" version="opset1">
			<data element_type="f16" offset="300172" shape="1,96,1,1" size="192"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1167" name="80888092_const" type="Const" version="opset1">
			<data element_type="f16" offset="300364" shape="1,96,1,1" size="192"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1168" name="80898093_const" type="Const" version="opset1">
			<data element_type="f16" offset="300172" shape="1,96,1,1" size="192"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1169" name="80908094_const" type="Const" version="opset1">
			<data element_type="f16" offset="300364" shape="1,96,1,1" size="192"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1170" name="759/fq_input_0" type="FakeQuantize" version="opset1">
			<data auto_broadcast="numpy" levels="256"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
				<port id="1">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="2">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="3">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="4">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="5" precision="FP16">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
			</output>
		</layer>
		<layer id="1171" name="4208742090_const162015474/quantized19611_const" type="Const" version="opset1">
			<data element_type="i8" offset="300556" shape="96,1,3,3" size="864"/>
			<output>
				<port id="0" precision="I8">
					<dim>96</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</output>
		</layer>
		<layer id="1172" name="4208742090_const162015474/quantized/to_f16" type="Convert" version="opset1">
			<data destination_type="f16"/>
			<input>
				<port id="0">
					<dim>96</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</input>
			<output>
				<port id="1" precision="FP16">
					<dim>96</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</output>
		</layer>
		<layer id="1173" name="759/fq_weights_1/zero_point19624_const" type="Const" version="opset1">
			<data element_type="f16" offset="301420" shape="96,1,1,1" size="192"/>
			<output>
				<port id="0" precision="FP16">
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1174" name="759/fq_weights_1/minus_zp" type="Subtract" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>96</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
				<port id="1">
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>96</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</output>
		</layer>
		<layer id="1175" name="759/fq_weights_1/scale19619_const" type="Const" version="opset1">
			<data element_type="f16" offset="301612" shape="96,1,1,1" size="192"/>
			<output>
				<port id="0" precision="FP16">
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1176" name="759/fq_weights_1/mulpiply_by_scale" type="Multiply" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>96</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
				<port id="1">
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>96</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</output>
		</layer>
		<layer id="1177" name="24452/value24454_const" type="Const" version="opset1">
			<data element_type="i64" offset="301804" shape="5" size="40"/>
			<output>
				<port id="0" precision="I64">
					<dim>5</dim>
				</port>
			</output>
		</layer>
		<layer id="1178" name="24452" type="Reshape" version="opset1">
			<data special_zero="true"/>
			<input>
				<port id="0">
					<dim>96</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
				<port id="1">
					<dim>5</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</output>
		</layer>
		<layer id="1179" name="759" type="GroupConvolution" version="opset1">
			<data auto_pad="explicit" dilations="1,1" pads_begin="1,1" pads_end="1,1" strides="1,1"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
				<port id="1">
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
			</output>
		</layer>
		<layer id="1180" name="data_add_219892199422784/EltwiseUnsqueeze23482_const1622_const" type="Const" version="opset1">
			<data element_type="f16" offset="301844" shape="1,96,1,1" size="192"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1181" name="760/variance/Fused_Add_" type="Add" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
				<port id="1">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" names="760" precision="FP16">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
			</output>
		</layer>
		<layer id="1182" name="761" type="ReLU" version="opset1">
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
			</input>
			<output>
				<port id="1" names="761" precision="FP16">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
			</output>
		</layer>
		<layer id="1183" name="68476851_const" type="Const" version="opset1">
			<data element_type="f16" offset="10108" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="1184" name="68486852_const" type="Const" version="opset1">
			<data element_type="f16" offset="302036" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="1185" name="68496853_const" type="Const" version="opset1">
			<data element_type="f16" offset="10108" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="1186" name="68506854_const" type="Const" version="opset1">
			<data element_type="f16" offset="302036" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="1187" name="798/reduce/fq_input_0" type="FakeQuantize" version="opset1">
			<data auto_broadcast="numpy" levels="256"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
				<port id="1"/>
				<port id="2"/>
				<port id="3"/>
				<port id="4"/>
			</input>
			<output>
				<port id="5" precision="FP16">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
			</output>
		</layer>
		<layer id="1188" name="1364/Output_0/Data__const1625_const" type="Const" version="opset1">
			<data element_type="i64" offset="24" shape="" size="8"/>
			<output>
				<port id="0" precision="I64"/>
			</output>
		</layer>
		<layer id="1189" name="798/input_rank/shape_of" type="ShapeOf" version="opset3">
			<data output_type="i64"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
			</input>
			<output>
				<port id="1" precision="I64">
					<dim>4</dim>
				</port>
			</output>
		</layer>
		<layer id="1190" name="798/input_rank/rank_of" type="ShapeOf" version="opset3">
			<data output_type="i64"/>
			<input>
				<port id="0">
					<dim>4</dim>
				</port>
			</input>
			<output>
				<port id="1" precision="I64">
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1191" name="798/input_rank/0d_rank_of/value/Output_0/Data__const1628_const" type="Const" version="opset1">
			<data element_type="i64" offset="32" shape="1" size="8"/>
			<output>
				<port id="0" precision="I64">
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1192" name="798/input_rank" type="Squeeze" version="opset1">
			<input>
				<port id="0">
					<dim>1</dim>
				</port>
				<port id="1">
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="I64"/>
			</output>
		</layer>
		<layer id="1193" name="1366/Output_0/Data__const1630_const" type="Const" version="opset1">
			<data element_type="i64" offset="0" shape="" size="8"/>
			<output>
				<port id="0" precision="I64"/>
			</output>
		</layer>
		<layer id="1194" name="798/global_pooling_reduce_axis" type="Range" version="opset4">
			<data output_type="i64"/>
			<input>
				<port id="0"/>
				<port id="1"/>
				<port id="2"/>
			</input>
			<output>
				<port id="3" precision="I64">
					<dim>2</dim>
				</port>
			</output>
		</layer>
		<layer id="1195" name="798/reduce" type="ReduceMean" version="opset1">
			<data keep_dims="true"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
				<port id="1">
					<dim>2</dim>
				</port>
			</input>
			<output>
				<port id="2" names="798" precision="FP16">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1196" name="Copy_conv3.0.gate.fc1.weight/Output_0/Data__const1633_const" type="Const" version="opset1">
			<data element_type="f16" offset="302038" shape="6,96,1,1" size="1152"/>
			<output>
				<port id="0" names="conv3.0.gate.fc1.weight" precision="FP16">
					<dim>6</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1197" name="799/WithoutBiases" type="Convolution" version="opset1">
			<data auto_pad="explicit" dilations="1,1" pads_begin="0,0" pads_end="0,0" strides="1,1"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="1">
					<dim>6</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>1</dim>
					<dim>6</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1198" name="799/Dims1295222694/EltwiseUnsqueeze23130_const1635_const" type="Const" version="opset1">
			<data element_type="f16" offset="303190" shape="1,6,1,1" size="12"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>6</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1199" name="799" type="Add" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>6</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="1">
					<dim>1</dim>
					<dim>6</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" names="799" precision="FP16">
					<dim>1</dim>
					<dim>6</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1200" name="800" type="ReLU" version="opset1">
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>6</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="1" names="800" precision="FP16">
					<dim>1</dim>
					<dim>6</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1201" name="Copy_conv3.0.gate.fc2.weight/Output_0/Data__const1638_const" type="Const" version="opset1">
			<data element_type="f16" offset="303202" shape="96,6,1,1" size="1152"/>
			<output>
				<port id="0" names="conv3.0.gate.fc2.weight" precision="FP16">
					<dim>96</dim>
					<dim>6</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1202" name="801/WithoutBiases" type="Convolution" version="opset1">
			<data auto_pad="explicit" dilations="1,1" pads_begin="0,0" pads_end="0,0" strides="1,1"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>6</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="1">
					<dim>96</dim>
					<dim>6</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1203" name="801/Dims1297022697/EltwiseUnsqueeze23142_const1640_const" type="Const" version="opset1">
			<data element_type="f16" offset="304354" shape="1,96,1,1" size="192"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1204" name="801" type="Add" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="1">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" names="801" precision="FP16">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1205" name="802" type="Sigmoid" version="opset1">
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="1" names="802" precision="FP16">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1206" name="63876391_const" type="Const" version="opset1">
			<data element_type="f16" offset="10108" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="1207" name="63886392_const" type="Const" version="opset1">
			<data element_type="f16" offset="304546" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="1208" name="63896393_const" type="Const" version="opset1">
			<data element_type="f16" offset="10108" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="1209" name="63906394_const" type="Const" version="opset1">
			<data element_type="f16" offset="304546" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="1210" name="803/fq_input_1" type="FakeQuantize" version="opset1">
			<data auto_broadcast="numpy" levels="256"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="1"/>
				<port id="2"/>
				<port id="3"/>
				<port id="4"/>
			</input>
			<output>
				<port id="5" precision="FP16">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1211" name="803" type="Multiply" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
				<port id="1">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" names="803" precision="FP16">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
			</output>
		</layer>
		<layer id="1212" name="43674371_const" type="Const" version="opset1">
			<data element_type="f16" offset="10108" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="1213" name="43684372_const" type="Const" version="opset1">
			<data element_type="f16" offset="304548" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="1214" name="43694373_const" type="Const" version="opset1">
			<data element_type="f16" offset="10108" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="1215" name="43704374_const" type="Const" version="opset1">
			<data element_type="f16" offset="304548" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="1216" name="810/fq_input_0" type="FakeQuantize" version="opset1">
			<data auto_broadcast="numpy" levels="256"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
				<port id="1"/>
				<port id="2"/>
				<port id="3"/>
				<port id="4"/>
			</input>
			<output>
				<port id="5" precision="FP16">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
			</output>
		</layer>
		<layer id="1217" name="conv3.0.conv2b.0.conv1.weight/quantized19179_const" type="Const" version="opset1">
			<data element_type="i8" offset="304550" shape="96,96,1,1" size="9216"/>
			<output>
				<port id="0" precision="I8">
					<dim>96</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1218" name="conv3.0.conv2b.0.conv1.weight/quantized/to_f16" type="Convert" version="opset1">
			<data destination_type="f16"/>
			<input>
				<port id="0">
					<dim>96</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="1" precision="FP16">
					<dim>96</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1219" name="762/fq_weights_1/zero_point19192_const" type="Const" version="opset1">
			<data element_type="f16" offset="313766" shape="96,1,1,1" size="192"/>
			<output>
				<port id="0" precision="FP16">
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1220" name="762/fq_weights_1/minus_zp" type="Subtract" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>96</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="1">
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>96</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1221" name="762/fq_weights_1/scale19187_const" type="Const" version="opset1">
			<data element_type="f16" offset="313958" shape="96,1,1,1" size="192"/>
			<output>
				<port id="0" precision="FP16">
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1222" name="762/fq_weights_1/mulpiply_by_scale" type="Multiply" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>96</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="1">
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>96</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1223" name="762" type="Convolution" version="opset1">
			<data auto_pad="explicit" dilations="1,1" pads_begin="0,0" pads_end="0,0" strides="1,1"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
				<port id="1">
					<dim>96</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" names="762" precision="FP16">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
			</output>
		</layer>
		<layer id="1224" name="29562958_const" type="Const" version="opset1">
			<data element_type="f16" offset="299980" shape="1,96,1,1" size="192"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1225" name="762/add_" type="Add" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
				<port id="1">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
			</output>
		</layer>
		<layer id="1226" name="68276831_const" type="Const" version="opset1">
			<data element_type="f16" offset="314150" shape="1,96,1,1" size="192"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1227" name="68286832_const" type="Const" version="opset1">
			<data element_type="f16" offset="314342" shape="1,96,1,1" size="192"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1228" name="68296833_const" type="Const" version="opset1">
			<data element_type="f16" offset="314150" shape="1,96,1,1" size="192"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1229" name="68306834_const" type="Const" version="opset1">
			<data element_type="f16" offset="314342" shape="1,96,1,1" size="192"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1230" name="763/fq_input_0" type="FakeQuantize" version="opset1">
			<data auto_broadcast="numpy" levels="256"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
				<port id="1">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="2">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="3">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="4">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="5" precision="FP16">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
			</output>
		</layer>
		<layer id="1231" name="4212342126_const164615484/quantized17643_const" type="Const" version="opset1">
			<data element_type="i8" offset="314534" shape="96,1,3,3" size="864"/>
			<output>
				<port id="0" precision="I8">
					<dim>96</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</output>
		</layer>
		<layer id="1232" name="4212342126_const164615484/quantized/to_f16" type="Convert" version="opset1">
			<data destination_type="f16"/>
			<input>
				<port id="0">
					<dim>96</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</input>
			<output>
				<port id="1" precision="FP16">
					<dim>96</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</output>
		</layer>
		<layer id="1233" name="763/fq_weights_1/zero_point17656_const" type="Const" version="opset1">
			<data element_type="f16" offset="315398" shape="96,1,1,1" size="192"/>
			<output>
				<port id="0" precision="FP16">
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1234" name="763/fq_weights_1/minus_zp" type="Subtract" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>96</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
				<port id="1">
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>96</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</output>
		</layer>
		<layer id="1235" name="763/fq_weights_1/scale17651_const" type="Const" version="opset1">
			<data element_type="f16" offset="315590" shape="96,1,1,1" size="192"/>
			<output>
				<port id="0" precision="FP16">
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1236" name="763/fq_weights_1/mulpiply_by_scale" type="Multiply" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>96</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
				<port id="1">
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>96</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</output>
		</layer>
		<layer id="1237" name="24548/value24550_const" type="Const" version="opset1">
			<data element_type="i64" offset="301804" shape="5" size="40"/>
			<output>
				<port id="0" precision="I64">
					<dim>5</dim>
				</port>
			</output>
		</layer>
		<layer id="1238" name="24548" type="Reshape" version="opset1">
			<data special_zero="true"/>
			<input>
				<port id="0">
					<dim>96</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
				<port id="1">
					<dim>5</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</output>
		</layer>
		<layer id="1239" name="763" type="GroupConvolution" version="opset1">
			<data auto_pad="explicit" dilations="1,1" pads_begin="1,1" pads_end="1,1" strides="1,1"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
				<port id="1">
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
			</output>
		</layer>
		<layer id="1240" name="data_add_219732197822780/EltwiseUnsqueeze23466_const1648_const" type="Const" version="opset1">
			<data element_type="f16" offset="315782" shape="1,96,1,1" size="192"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1241" name="764/variance/Fused_Add_" type="Add" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
				<port id="1">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" names="764" precision="FP16">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
			</output>
		</layer>
		<layer id="1242" name="765" type="ReLU" version="opset1">
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
			</input>
			<output>
				<port id="1" names="765" precision="FP16">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
			</output>
		</layer>
		<layer id="1243" name="63976401_const" type="Const" version="opset1">
			<data element_type="f16" offset="10108" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="1244" name="63986402_const" type="Const" version="opset1">
			<data element_type="f16" offset="315974" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="1245" name="63996403_const" type="Const" version="opset1">
			<data element_type="f16" offset="10108" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="1246" name="64006404_const" type="Const" version="opset1">
			<data element_type="f16" offset="315974" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="1247" name="766/fq_input_0" type="FakeQuantize" version="opset1">
			<data auto_broadcast="numpy" levels="256"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
				<port id="1"/>
				<port id="2"/>
				<port id="3"/>
				<port id="4"/>
			</input>
			<output>
				<port id="5" precision="FP16">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
			</output>
		</layer>
		<layer id="1248" name="conv3.0.conv2b.1.conv1.weight/quantized19683_const" type="Const" version="opset1">
			<data element_type="i8" offset="315976" shape="96,96,1,1" size="9216"/>
			<output>
				<port id="0" precision="I8">
					<dim>96</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1249" name="conv3.0.conv2b.1.conv1.weight/quantized/to_f16" type="Convert" version="opset1">
			<data destination_type="f16"/>
			<input>
				<port id="0">
					<dim>96</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="1" precision="FP16">
					<dim>96</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1250" name="766/fq_weights_1/zero_point19696_const" type="Const" version="opset1">
			<data element_type="f16" offset="325192" shape="96,1,1,1" size="192"/>
			<output>
				<port id="0" precision="FP16">
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1251" name="766/fq_weights_1/minus_zp" type="Subtract" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>96</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="1">
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>96</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1252" name="766/fq_weights_1/scale19691_const" type="Const" version="opset1">
			<data element_type="f16" offset="325384" shape="96,1,1,1" size="192"/>
			<output>
				<port id="0" precision="FP16">
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1253" name="766/fq_weights_1/mulpiply_by_scale" type="Multiply" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>96</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="1">
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>96</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1254" name="766" type="Convolution" version="opset1">
			<data auto_pad="explicit" dilations="1,1" pads_begin="0,0" pads_end="0,0" strides="1,1"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
				<port id="1">
					<dim>96</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" names="766" precision="FP16">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
			</output>
		</layer>
		<layer id="1255" name="29602962_const" type="Const" version="opset1">
			<data element_type="f16" offset="299980" shape="1,96,1,1" size="192"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1256" name="766/add_" type="Add" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
				<port id="1">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
			</output>
		</layer>
		<layer id="1257" name="76477651_const" type="Const" version="opset1">
			<data element_type="f16" offset="325576" shape="1,96,1,1" size="192"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1258" name="76487652_const" type="Const" version="opset1">
			<data element_type="f16" offset="325768" shape="1,96,1,1" size="192"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1259" name="76497653_const" type="Const" version="opset1">
			<data element_type="f16" offset="325576" shape="1,96,1,1" size="192"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1260" name="76507654_const" type="Const" version="opset1">
			<data element_type="f16" offset="325768" shape="1,96,1,1" size="192"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1261" name="767/fq_input_0" type="FakeQuantize" version="opset1">
			<data auto_broadcast="numpy" levels="256"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
				<port id="1">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="2">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="3">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="4">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="5" precision="FP16">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
			</output>
		</layer>
		<layer id="1262" name="4213142134_const165315487/quantized20331_const" type="Const" version="opset1">
			<data element_type="i8" offset="325960" shape="96,1,3,3" size="864"/>
			<output>
				<port id="0" precision="I8">
					<dim>96</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</output>
		</layer>
		<layer id="1263" name="4213142134_const165315487/quantized/to_f16" type="Convert" version="opset1">
			<data destination_type="f16"/>
			<input>
				<port id="0">
					<dim>96</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</input>
			<output>
				<port id="1" precision="FP16">
					<dim>96</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</output>
		</layer>
		<layer id="1264" name="767/fq_weights_1/zero_point20344_const" type="Const" version="opset1">
			<data element_type="f16" offset="326824" shape="96,1,1,1" size="192"/>
			<output>
				<port id="0" precision="FP16">
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1265" name="767/fq_weights_1/minus_zp" type="Subtract" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>96</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
				<port id="1">
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>96</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</output>
		</layer>
		<layer id="1266" name="767/fq_weights_1/scale20339_const" type="Const" version="opset1">
			<data element_type="f16" offset="327016" shape="96,1,1,1" size="192"/>
			<output>
				<port id="0" precision="FP16">
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1267" name="767/fq_weights_1/mulpiply_by_scale" type="Multiply" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>96</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
				<port id="1">
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>96</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</output>
		</layer>
		<layer id="1268" name="24496/value24498_const" type="Const" version="opset1">
			<data element_type="i64" offset="301804" shape="5" size="40"/>
			<output>
				<port id="0" precision="I64">
					<dim>5</dim>
				</port>
			</output>
		</layer>
		<layer id="1269" name="24496" type="Reshape" version="opset1">
			<data special_zero="true"/>
			<input>
				<port id="0">
					<dim>96</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
				<port id="1">
					<dim>5</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</output>
		</layer>
		<layer id="1270" name="767" type="GroupConvolution" version="opset1">
			<data auto_pad="explicit" dilations="1,1" pads_begin="1,1" pads_end="1,1" strides="1,1"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
				<port id="1">
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
			</output>
		</layer>
		<layer id="1271" name="data_add_219812198622782/EltwiseUnsqueeze23474_const1655_const" type="Const" version="opset1">
			<data element_type="f16" offset="327208" shape="1,96,1,1" size="192"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1272" name="768/variance/Fused_Add_" type="Add" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
				<port id="1">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" names="768" precision="FP16">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
			</output>
		</layer>
		<layer id="1273" name="769" type="ReLU" version="opset1">
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
			</input>
			<output>
				<port id="1" names="769" precision="FP16">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
			</output>
		</layer>
		<layer id="1274" name="61276131_const" type="Const" version="opset1">
			<data element_type="f16" offset="10108" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="1275" name="61286132_const" type="Const" version="opset1">
			<data element_type="f16" offset="327400" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="1276" name="61296133_const" type="Const" version="opset1">
			<data element_type="f16" offset="10108" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="1277" name="61306134_const" type="Const" version="opset1">
			<data element_type="f16" offset="327400" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="1278" name="804/reduce/fq_input_0" type="FakeQuantize" version="opset1">
			<data auto_broadcast="numpy" levels="256"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
				<port id="1"/>
				<port id="2"/>
				<port id="3"/>
				<port id="4"/>
			</input>
			<output>
				<port id="5" precision="FP16">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
			</output>
		</layer>
		<layer id="1279" name="1369/Output_0/Data__const1658_const" type="Const" version="opset1">
			<data element_type="i64" offset="24" shape="" size="8"/>
			<output>
				<port id="0" precision="I64"/>
			</output>
		</layer>
		<layer id="1280" name="804/input_rank/shape_of" type="ShapeOf" version="opset3">
			<data output_type="i64"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
			</input>
			<output>
				<port id="1" precision="I64">
					<dim>4</dim>
				</port>
			</output>
		</layer>
		<layer id="1281" name="804/input_rank/rank_of" type="ShapeOf" version="opset3">
			<data output_type="i64"/>
			<input>
				<port id="0">
					<dim>4</dim>
				</port>
			</input>
			<output>
				<port id="1" precision="I64">
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1282" name="804/input_rank/0d_rank_of/value/Output_0/Data__const1661_const" type="Const" version="opset1">
			<data element_type="i64" offset="32" shape="1" size="8"/>
			<output>
				<port id="0" precision="I64">
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1283" name="804/input_rank" type="Squeeze" version="opset1">
			<input>
				<port id="0">
					<dim>1</dim>
				</port>
				<port id="1">
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="I64"/>
			</output>
		</layer>
		<layer id="1284" name="1371/Output_0/Data__const1663_const" type="Const" version="opset1">
			<data element_type="i64" offset="0" shape="" size="8"/>
			<output>
				<port id="0" precision="I64"/>
			</output>
		</layer>
		<layer id="1285" name="804/global_pooling_reduce_axis" type="Range" version="opset4">
			<data output_type="i64"/>
			<input>
				<port id="0"/>
				<port id="1"/>
				<port id="2"/>
			</input>
			<output>
				<port id="3" precision="I64">
					<dim>2</dim>
				</port>
			</output>
		</layer>
		<layer id="1286" name="804/reduce" type="ReduceMean" version="opset1">
			<data keep_dims="true"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
				<port id="1">
					<dim>2</dim>
				</port>
			</input>
			<output>
				<port id="2" names="804" precision="FP16">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1287" name="Copy_conv3.0.gate.fc1.weight/Output_0/Data_4384_const1666_const" type="Const" version="opset1">
			<data element_type="f16" offset="302038" shape="6,96,1,1" size="1152"/>
			<output>
				<port id="0" names="conv3.0.gate.fc1.weight" precision="FP16">
					<dim>6</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1288" name="805/WithoutBiases" type="Convolution" version="opset1">
			<data auto_pad="explicit" dilations="1,1" pads_begin="0,0" pads_end="0,0" strides="1,1"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="1">
					<dim>6</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>1</dim>
					<dim>6</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1289" name="805/Dims1288022682/EltwiseUnsqueeze23082_const1668_const" type="Const" version="opset1">
			<data element_type="f16" offset="303190" shape="1,6,1,1" size="12"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>6</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1290" name="805" type="Add" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>6</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="1">
					<dim>1</dim>
					<dim>6</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" names="805" precision="FP16">
					<dim>1</dim>
					<dim>6</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1291" name="806" type="ReLU" version="opset1">
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>6</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="1" names="806" precision="FP16">
					<dim>1</dim>
					<dim>6</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1292" name="Copy_conv3.0.gate.fc2.weight/Output_0/Data_4392_const1671_const" type="Const" version="opset1">
			<data element_type="f16" offset="303202" shape="96,6,1,1" size="1152"/>
			<output>
				<port id="0" names="conv3.0.gate.fc2.weight" precision="FP16">
					<dim>96</dim>
					<dim>6</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1293" name="807/WithoutBiases" type="Convolution" version="opset1">
			<data auto_pad="explicit" dilations="1,1" pads_begin="0,0" pads_end="0,0" strides="1,1"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>6</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="1">
					<dim>96</dim>
					<dim>6</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1294" name="807/Dims1292822690/EltwiseUnsqueeze23114_const1673_const" type="Const" version="opset1">
			<data element_type="f16" offset="304354" shape="1,96,1,1" size="192"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1295" name="807" type="Add" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="1">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" names="807" precision="FP16">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1296" name="808" type="Sigmoid" version="opset1">
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="1" names="808" precision="FP16">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1297" name="54975501_const" type="Const" version="opset1">
			<data element_type="f16" offset="10108" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="1298" name="54985502_const" type="Const" version="opset1">
			<data element_type="f16" offset="327402" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="1299" name="54995503_const" type="Const" version="opset1">
			<data element_type="f16" offset="10108" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="1300" name="55005504_const" type="Const" version="opset1">
			<data element_type="f16" offset="327402" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="1301" name="809/fq_input_1" type="FakeQuantize" version="opset1">
			<data auto_broadcast="numpy" levels="256"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="1"/>
				<port id="2"/>
				<port id="3"/>
				<port id="4"/>
			</input>
			<output>
				<port id="5" precision="FP16">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1302" name="809" type="Multiply" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
				<port id="1">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" names="809" precision="FP16">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
			</output>
		</layer>
		<layer id="1303" name="43774381_const" type="Const" version="opset1">
			<data element_type="f16" offset="10108" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="1304" name="43784382_const" type="Const" version="opset1">
			<data element_type="f16" offset="327404" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="1305" name="43794383_const" type="Const" version="opset1">
			<data element_type="f16" offset="10108" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="1306" name="43804384_const" type="Const" version="opset1">
			<data element_type="f16" offset="327404" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="1307" name="810/fq_input_1" type="FakeQuantize" version="opset1">
			<data auto_broadcast="numpy" levels="256"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
				<port id="1"/>
				<port id="2"/>
				<port id="3"/>
				<port id="4"/>
			</input>
			<output>
				<port id="5" precision="FP16">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
			</output>
		</layer>
		<layer id="1308" name="810" type="Add" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
				<port id="1">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
			</input>
			<output>
				<port id="2" names="810" precision="FP16">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
			</output>
		</layer>
		<layer id="1309" name="58975901_const" type="Const" version="opset1">
			<data element_type="f16" offset="10108" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="1310" name="58985902_const" type="Const" version="opset1">
			<data element_type="f16" offset="327406" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="1311" name="58995903_const" type="Const" version="opset1">
			<data element_type="f16" offset="10108" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="1312" name="59005904_const" type="Const" version="opset1">
			<data element_type="f16" offset="327406" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="1313" name="817/fq_input_0" type="FakeQuantize" version="opset1">
			<data auto_broadcast="numpy" levels="256"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
				<port id="1"/>
				<port id="2"/>
				<port id="3"/>
				<port id="4"/>
			</input>
			<output>
				<port id="5" precision="FP16">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
			</output>
		</layer>
		<layer id="1314" name="conv3.0.conv2c.0.conv1.weight/quantized18963_const" type="Const" version="opset1">
			<data element_type="i8" offset="327408" shape="96,96,1,1" size="9216"/>
			<output>
				<port id="0" precision="I8">
					<dim>96</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1315" name="conv3.0.conv2c.0.conv1.weight/quantized/to_f16" type="Convert" version="opset1">
			<data destination_type="f16"/>
			<input>
				<port id="0">
					<dim>96</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="1" precision="FP16">
					<dim>96</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1316" name="770/fq_weights_1/zero_point18976_const" type="Const" version="opset1">
			<data element_type="f16" offset="336624" shape="96,1,1,1" size="192"/>
			<output>
				<port id="0" precision="FP16">
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1317" name="770/fq_weights_1/minus_zp" type="Subtract" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>96</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="1">
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>96</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1318" name="770/fq_weights_1/scale18971_const" type="Const" version="opset1">
			<data element_type="f16" offset="336816" shape="96,1,1,1" size="192"/>
			<output>
				<port id="0" precision="FP16">
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1319" name="770/fq_weights_1/mulpiply_by_scale" type="Multiply" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>96</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="1">
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>96</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1320" name="770" type="Convolution" version="opset1">
			<data auto_pad="explicit" dilations="1,1" pads_begin="0,0" pads_end="0,0" strides="1,1"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
				<port id="1">
					<dim>96</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" names="770" precision="FP16">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
			</output>
		</layer>
		<layer id="1321" name="29642966_const" type="Const" version="opset1">
			<data element_type="f16" offset="299980" shape="1,96,1,1" size="192"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1322" name="770/add_" type="Add" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
				<port id="1">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
			</output>
		</layer>
		<layer id="1323" name="77677771_const" type="Const" version="opset1">
			<data element_type="f16" offset="337008" shape="1,96,1,1" size="192"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1324" name="77687772_const" type="Const" version="opset1">
			<data element_type="f16" offset="337200" shape="1,96,1,1" size="192"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1325" name="77697773_const" type="Const" version="opset1">
			<data element_type="f16" offset="337008" shape="1,96,1,1" size="192"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1326" name="77707774_const" type="Const" version="opset1">
			<data element_type="f16" offset="337200" shape="1,96,1,1" size="192"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1327" name="771/fq_input_0" type="FakeQuantize" version="opset1">
			<data auto_broadcast="numpy" levels="256"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
				<port id="1">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="2">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="3">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="4">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="5" precision="FP16">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
			</output>
		</layer>
		<layer id="1328" name="4213942142_const168015497/quantized18099_const" type="Const" version="opset1">
			<data element_type="i8" offset="337392" shape="96,1,3,3" size="864"/>
			<output>
				<port id="0" precision="I8">
					<dim>96</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</output>
		</layer>
		<layer id="1329" name="4213942142_const168015497/quantized/to_f16" type="Convert" version="opset1">
			<data destination_type="f16"/>
			<input>
				<port id="0">
					<dim>96</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</input>
			<output>
				<port id="1" precision="FP16">
					<dim>96</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</output>
		</layer>
		<layer id="1330" name="771/fq_weights_1/zero_point18112_const" type="Const" version="opset1">
			<data element_type="f16" offset="338256" shape="96,1,1,1" size="192"/>
			<output>
				<port id="0" precision="FP16">
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1331" name="771/fq_weights_1/minus_zp" type="Subtract" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>96</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
				<port id="1">
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>96</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</output>
		</layer>
		<layer id="1332" name="771/fq_weights_1/scale18107_const" type="Const" version="opset1">
			<data element_type="f16" offset="338448" shape="96,1,1,1" size="192"/>
			<output>
				<port id="0" precision="FP16">
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1333" name="771/fq_weights_1/mulpiply_by_scale" type="Multiply" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>96</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
				<port id="1">
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>96</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</output>
		</layer>
		<layer id="1334" name="24560/value24562_const" type="Const" version="opset1">
			<data element_type="i64" offset="301804" shape="5" size="40"/>
			<output>
				<port id="0" precision="I64">
					<dim>5</dim>
				</port>
			</output>
		</layer>
		<layer id="1335" name="24560" type="Reshape" version="opset1">
			<data special_zero="true"/>
			<input>
				<port id="0">
					<dim>96</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
				<port id="1">
					<dim>5</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</output>
		</layer>
		<layer id="1336" name="771" type="GroupConvolution" version="opset1">
			<data auto_pad="explicit" dilations="1,1" pads_begin="1,1" pads_end="1,1" strides="1,1"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
				<port id="1">
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
			</output>
		</layer>
		<layer id="1337" name="data_add_219492195422774/EltwiseUnsqueeze23442_const1682_const" type="Const" version="opset1">
			<data element_type="f16" offset="338640" shape="1,96,1,1" size="192"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1338" name="772/variance/Fused_Add_" type="Add" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
				<port id="1">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" names="772" precision="FP16">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
			</output>
		</layer>
		<layer id="1339" name="773" type="ReLU" version="opset1">
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
			</input>
			<output>
				<port id="1" names="773" precision="FP16">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
			</output>
		</layer>
		<layer id="1340" name="56475651_const" type="Const" version="opset1">
			<data element_type="f16" offset="10108" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="1341" name="56485652_const" type="Const" version="opset1">
			<data element_type="f16" offset="338832" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="1342" name="56495653_const" type="Const" version="opset1">
			<data element_type="f16" offset="10108" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="1343" name="56505654_const" type="Const" version="opset1">
			<data element_type="f16" offset="338832" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="1344" name="774/fq_input_0" type="FakeQuantize" version="opset1">
			<data auto_broadcast="numpy" levels="256"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
				<port id="1"/>
				<port id="2"/>
				<port id="3"/>
				<port id="4"/>
			</input>
			<output>
				<port id="5" precision="FP16">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
			</output>
		</layer>
		<layer id="1345" name="conv3.0.conv2c.1.conv1.weight/quantized18675_const" type="Const" version="opset1">
			<data element_type="i8" offset="338834" shape="96,96,1,1" size="9216"/>
			<output>
				<port id="0" precision="I8">
					<dim>96</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1346" name="conv3.0.conv2c.1.conv1.weight/quantized/to_f16" type="Convert" version="opset1">
			<data destination_type="f16"/>
			<input>
				<port id="0">
					<dim>96</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="1" precision="FP16">
					<dim>96</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1347" name="774/fq_weights_1/zero_point18688_const" type="Const" version="opset1">
			<data element_type="f16" offset="348050" shape="96,1,1,1" size="192"/>
			<output>
				<port id="0" precision="FP16">
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1348" name="774/fq_weights_1/minus_zp" type="Subtract" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>96</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="1">
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>96</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1349" name="774/fq_weights_1/scale18683_const" type="Const" version="opset1">
			<data element_type="f16" offset="348242" shape="96,1,1,1" size="192"/>
			<output>
				<port id="0" precision="FP16">
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1350" name="774/fq_weights_1/mulpiply_by_scale" type="Multiply" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>96</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="1">
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>96</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1351" name="774" type="Convolution" version="opset1">
			<data auto_pad="explicit" dilations="1,1" pads_begin="0,0" pads_end="0,0" strides="1,1"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
				<port id="1">
					<dim>96</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" names="774" precision="FP16">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
			</output>
		</layer>
		<layer id="1352" name="29682970_const" type="Const" version="opset1">
			<data element_type="f16" offset="299980" shape="1,96,1,1" size="192"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1353" name="774/add_" type="Add" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
				<port id="1">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
			</output>
		</layer>
		<layer id="1354" name="81978201_const" type="Const" version="opset1">
			<data element_type="f16" offset="348434" shape="1,96,1,1" size="192"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1355" name="81988202_const" type="Const" version="opset1">
			<data element_type="f16" offset="348626" shape="1,96,1,1" size="192"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1356" name="81998203_const" type="Const" version="opset1">
			<data element_type="f16" offset="348434" shape="1,96,1,1" size="192"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1357" name="82008204_const" type="Const" version="opset1">
			<data element_type="f16" offset="348626" shape="1,96,1,1" size="192"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1358" name="775/fq_input_0" type="FakeQuantize" version="opset1">
			<data auto_broadcast="numpy" levels="256"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
				<port id="1">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="2">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="3">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="4">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="5" precision="FP16">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
			</output>
		</layer>
		<layer id="1359" name="4229142294_const168715500/quantized18651_const" type="Const" version="opset1">
			<data element_type="i8" offset="348818" shape="96,1,3,3" size="864"/>
			<output>
				<port id="0" precision="I8">
					<dim>96</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</output>
		</layer>
		<layer id="1360" name="4229142294_const168715500/quantized/to_f16" type="Convert" version="opset1">
			<data destination_type="f16"/>
			<input>
				<port id="0">
					<dim>96</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</input>
			<output>
				<port id="1" precision="FP16">
					<dim>96</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</output>
		</layer>
		<layer id="1361" name="775/fq_weights_1/zero_point18664_const" type="Const" version="opset1">
			<data element_type="f16" offset="349682" shape="96,1,1,1" size="192"/>
			<output>
				<port id="0" precision="FP16">
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1362" name="775/fq_weights_1/minus_zp" type="Subtract" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>96</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
				<port id="1">
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>96</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</output>
		</layer>
		<layer id="1363" name="775/fq_weights_1/scale18659_const" type="Const" version="opset1">
			<data element_type="f16" offset="349874" shape="96,1,1,1" size="192"/>
			<output>
				<port id="0" precision="FP16">
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1364" name="775/fq_weights_1/mulpiply_by_scale" type="Multiply" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>96</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
				<port id="1">
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>96</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</output>
		</layer>
		<layer id="1365" name="24564/value24566_const" type="Const" version="opset1">
			<data element_type="i64" offset="301804" shape="5" size="40"/>
			<output>
				<port id="0" precision="I64">
					<dim>5</dim>
				</port>
			</output>
		</layer>
		<layer id="1366" name="24564" type="Reshape" version="opset1">
			<data special_zero="true"/>
			<input>
				<port id="0">
					<dim>96</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
				<port id="1">
					<dim>5</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</output>
		</layer>
		<layer id="1367" name="775" type="GroupConvolution" version="opset1">
			<data auto_pad="explicit" dilations="1,1" pads_begin="1,1" pads_end="1,1" strides="1,1"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
				<port id="1">
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
			</output>
		</layer>
		<layer id="1368" name="data_add_219572196222776/EltwiseUnsqueeze23450_const1689_const" type="Const" version="opset1">
			<data element_type="f16" offset="350066" shape="1,96,1,1" size="192"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1369" name="776/variance/Fused_Add_" type="Add" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
				<port id="1">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" names="776" precision="FP16">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
			</output>
		</layer>
		<layer id="1370" name="777" type="ReLU" version="opset1">
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
			</input>
			<output>
				<port id="1" names="777" precision="FP16">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
			</output>
		</layer>
		<layer id="1371" name="77277731_const" type="Const" version="opset1">
			<data element_type="f16" offset="10108" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="1372" name="77287732_const" type="Const" version="opset1">
			<data element_type="f16" offset="350258" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="1373" name="77297733_const" type="Const" version="opset1">
			<data element_type="f16" offset="10108" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="1374" name="77307734_const" type="Const" version="opset1">
			<data element_type="f16" offset="350258" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="1375" name="778/fq_input_0" type="FakeQuantize" version="opset1">
			<data auto_broadcast="numpy" levels="256"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
				<port id="1"/>
				<port id="2"/>
				<port id="3"/>
				<port id="4"/>
			</input>
			<output>
				<port id="5" precision="FP16">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
			</output>
		</layer>
		<layer id="1376" name="conv3.0.conv2c.2.conv1.weight/quantized17811_const" type="Const" version="opset1">
			<data element_type="i8" offset="350260" shape="96,96,1,1" size="9216"/>
			<output>
				<port id="0" precision="I8">
					<dim>96</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1377" name="conv3.0.conv2c.2.conv1.weight/quantized/to_f16" type="Convert" version="opset1">
			<data destination_type="f16"/>
			<input>
				<port id="0">
					<dim>96</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="1" precision="FP16">
					<dim>96</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1378" name="778/fq_weights_1/zero_point17824_const" type="Const" version="opset1">
			<data element_type="f16" offset="359476" shape="96,1,1,1" size="192"/>
			<output>
				<port id="0" precision="FP16">
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1379" name="778/fq_weights_1/minus_zp" type="Subtract" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>96</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="1">
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>96</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1380" name="778/fq_weights_1/scale17819_const" type="Const" version="opset1">
			<data element_type="f16" offset="359668" shape="96,1,1,1" size="192"/>
			<output>
				<port id="0" precision="FP16">
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1381" name="778/fq_weights_1/mulpiply_by_scale" type="Multiply" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>96</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="1">
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>96</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1382" name="778" type="Convolution" version="opset1">
			<data auto_pad="explicit" dilations="1,1" pads_begin="0,0" pads_end="0,0" strides="1,1"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
				<port id="1">
					<dim>96</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" names="778" precision="FP16">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
			</output>
		</layer>
		<layer id="1383" name="29722974_const" type="Const" version="opset1">
			<data element_type="f16" offset="299980" shape="1,96,1,1" size="192"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1384" name="778/add_" type="Add" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
				<port id="1">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
			</output>
		</layer>
		<layer id="1385" name="82778281_const" type="Const" version="opset1">
			<data element_type="f16" offset="359860" shape="1,96,1,1" size="192"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1386" name="82788282_const" type="Const" version="opset1">
			<data element_type="f16" offset="360052" shape="1,96,1,1" size="192"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1387" name="82798283_const" type="Const" version="opset1">
			<data element_type="f16" offset="359860" shape="1,96,1,1" size="192"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1388" name="82808284_const" type="Const" version="opset1">
			<data element_type="f16" offset="360052" shape="1,96,1,1" size="192"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1389" name="779/fq_input_0" type="FakeQuantize" version="opset1">
			<data auto_broadcast="numpy" levels="256"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
				<port id="1">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="2">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="3">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="4">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="5" precision="FP16">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
			</output>
		</layer>
		<layer id="1390" name="4224742250_const169415503/quantized18867_const" type="Const" version="opset1">
			<data element_type="i8" offset="360244" shape="96,1,3,3" size="864"/>
			<output>
				<port id="0" precision="I8">
					<dim>96</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</output>
		</layer>
		<layer id="1391" name="4224742250_const169415503/quantized/to_f16" type="Convert" version="opset1">
			<data destination_type="f16"/>
			<input>
				<port id="0">
					<dim>96</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</input>
			<output>
				<port id="1" precision="FP16">
					<dim>96</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</output>
		</layer>
		<layer id="1392" name="779/fq_weights_1/zero_point18880_const" type="Const" version="opset1">
			<data element_type="f16" offset="361108" shape="96,1,1,1" size="192"/>
			<output>
				<port id="0" precision="FP16">
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1393" name="779/fq_weights_1/minus_zp" type="Subtract" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>96</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
				<port id="1">
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>96</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</output>
		</layer>
		<layer id="1394" name="779/fq_weights_1/scale18875_const" type="Const" version="opset1">
			<data element_type="f16" offset="361300" shape="96,1,1,1" size="192"/>
			<output>
				<port id="0" precision="FP16">
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1395" name="779/fq_weights_1/mulpiply_by_scale" type="Multiply" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>96</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
				<port id="1">
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>96</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</output>
		</layer>
		<layer id="1396" name="24464/value24466_const" type="Const" version="opset1">
			<data element_type="i64" offset="301804" shape="5" size="40"/>
			<output>
				<port id="0" precision="I64">
					<dim>5</dim>
				</port>
			</output>
		</layer>
		<layer id="1397" name="24464" type="Reshape" version="opset1">
			<data special_zero="true"/>
			<input>
				<port id="0">
					<dim>96</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
				<port id="1">
					<dim>5</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</output>
		</layer>
		<layer id="1398" name="779" type="GroupConvolution" version="opset1">
			<data auto_pad="explicit" dilations="1,1" pads_begin="1,1" pads_end="1,1" strides="1,1"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
				<port id="1">
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
			</output>
		</layer>
		<layer id="1399" name="data_add_219652197022778/EltwiseUnsqueeze23458_const1696_const" type="Const" version="opset1">
			<data element_type="f16" offset="361492" shape="1,96,1,1" size="192"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1400" name="780/variance/Fused_Add_" type="Add" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
				<port id="1">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" names="780" precision="FP16">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
			</output>
		</layer>
		<layer id="1401" name="781" type="ReLU" version="opset1">
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
			</input>
			<output>
				<port id="1" names="781" precision="FP16">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
			</output>
		</layer>
		<layer id="1402" name="44874491_const" type="Const" version="opset1">
			<data element_type="f16" offset="10108" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="1403" name="44884492_const" type="Const" version="opset1">
			<data element_type="f16" offset="361684" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="1404" name="44894493_const" type="Const" version="opset1">
			<data element_type="f16" offset="10108" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="1405" name="44904494_const" type="Const" version="opset1">
			<data element_type="f16" offset="361684" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="1406" name="811/reduce/fq_input_0" type="FakeQuantize" version="opset1">
			<data auto_broadcast="numpy" levels="256"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
				<port id="1"/>
				<port id="2"/>
				<port id="3"/>
				<port id="4"/>
			</input>
			<output>
				<port id="5" precision="FP16">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
			</output>
		</layer>
		<layer id="1407" name="1374/Output_0/Data__const1699_const" type="Const" version="opset1">
			<data element_type="i64" offset="24" shape="" size="8"/>
			<output>
				<port id="0" precision="I64"/>
			</output>
		</layer>
		<layer id="1408" name="811/input_rank/shape_of" type="ShapeOf" version="opset3">
			<data output_type="i64"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
			</input>
			<output>
				<port id="1" precision="I64">
					<dim>4</dim>
				</port>
			</output>
		</layer>
		<layer id="1409" name="811/input_rank/rank_of" type="ShapeOf" version="opset3">
			<data output_type="i64"/>
			<input>
				<port id="0">
					<dim>4</dim>
				</port>
			</input>
			<output>
				<port id="1" precision="I64">
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1410" name="811/input_rank/0d_rank_of/value/Output_0/Data__const1702_const" type="Const" version="opset1">
			<data element_type="i64" offset="32" shape="1" size="8"/>
			<output>
				<port id="0" precision="I64">
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1411" name="811/input_rank" type="Squeeze" version="opset1">
			<input>
				<port id="0">
					<dim>1</dim>
				</port>
				<port id="1">
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="I64"/>
			</output>
		</layer>
		<layer id="1412" name="1376/Output_0/Data__const1704_const" type="Const" version="opset1">
			<data element_type="i64" offset="0" shape="" size="8"/>
			<output>
				<port id="0" precision="I64"/>
			</output>
		</layer>
		<layer id="1413" name="811/global_pooling_reduce_axis" type="Range" version="opset4">
			<data output_type="i64"/>
			<input>
				<port id="0"/>
				<port id="1"/>
				<port id="2"/>
			</input>
			<output>
				<port id="3" precision="I64">
					<dim>2</dim>
				</port>
			</output>
		</layer>
		<layer id="1414" name="811/reduce" type="ReduceMean" version="opset1">
			<data keep_dims="true"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
				<port id="1">
					<dim>2</dim>
				</port>
			</input>
			<output>
				<port id="2" names="811" precision="FP16">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1415" name="Copy_conv3.0.gate.fc1.weight/Output_0/Data_4385_const1707_const" type="Const" version="opset1">
			<data element_type="f16" offset="302038" shape="6,96,1,1" size="1152"/>
			<output>
				<port id="0" names="conv3.0.gate.fc1.weight" precision="FP16">
					<dim>6</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1416" name="812/WithoutBiases" type="Convolution" version="opset1">
			<data auto_pad="explicit" dilations="1,1" pads_begin="0,0" pads_end="0,0" strides="1,1"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="1">
					<dim>6</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>1</dim>
					<dim>6</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1417" name="812/Dims1295822695/EltwiseUnsqueeze23134_const1709_const" type="Const" version="opset1">
			<data element_type="f16" offset="303190" shape="1,6,1,1" size="12"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>6</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1418" name="812" type="Add" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>6</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="1">
					<dim>1</dim>
					<dim>6</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" names="812" precision="FP16">
					<dim>1</dim>
					<dim>6</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1419" name="813" type="ReLU" version="opset1">
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>6</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="1" names="813" precision="FP16">
					<dim>1</dim>
					<dim>6</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1420" name="Copy_conv3.0.gate.fc2.weight/Output_0/Data_4393_const1712_const" type="Const" version="opset1">
			<data element_type="f16" offset="303202" shape="96,6,1,1" size="1152"/>
			<output>
				<port id="0" names="conv3.0.gate.fc2.weight" precision="FP16">
					<dim>96</dim>
					<dim>6</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1421" name="814/WithoutBiases" type="Convolution" version="opset1">
			<data auto_pad="explicit" dilations="1,1" pads_begin="0,0" pads_end="0,0" strides="1,1"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>6</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="1">
					<dim>96</dim>
					<dim>6</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1422" name="814/Dims1293422691/EltwiseUnsqueeze23118_const1714_const" type="Const" version="opset1">
			<data element_type="f16" offset="304354" shape="1,96,1,1" size="192"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1423" name="814" type="Add" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="1">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" names="814" precision="FP16">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1424" name="815" type="Sigmoid" version="opset1">
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="1" names="815" precision="FP16">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1425" name="46974701_const" type="Const" version="opset1">
			<data element_type="f16" offset="10108" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="1426" name="46984702_const" type="Const" version="opset1">
			<data element_type="f16" offset="361686" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="1427" name="46994703_const" type="Const" version="opset1">
			<data element_type="f16" offset="10108" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="1428" name="47004704_const" type="Const" version="opset1">
			<data element_type="f16" offset="361686" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="1429" name="816/fq_input_1" type="FakeQuantize" version="opset1">
			<data auto_broadcast="numpy" levels="256"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="1"/>
				<port id="2"/>
				<port id="3"/>
				<port id="4"/>
			</input>
			<output>
				<port id="5" precision="FP16">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1430" name="816" type="Multiply" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
				<port id="1">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" names="816" precision="FP16">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
			</output>
		</layer>
		<layer id="1431" name="59075911_const" type="Const" version="opset1">
			<data element_type="f16" offset="10108" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="1432" name="59085912_const" type="Const" version="opset1">
			<data element_type="f16" offset="361688" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="1433" name="59095913_const" type="Const" version="opset1">
			<data element_type="f16" offset="10108" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="1434" name="59105914_const" type="Const" version="opset1">
			<data element_type="f16" offset="361688" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="1435" name="817/fq_input_1" type="FakeQuantize" version="opset1">
			<data auto_broadcast="numpy" levels="256"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
				<port id="1"/>
				<port id="2"/>
				<port id="3"/>
				<port id="4"/>
			</input>
			<output>
				<port id="5" precision="FP16">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
			</output>
		</layer>
		<layer id="1436" name="817" type="Add" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
				<port id="1">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
			</input>
			<output>
				<port id="2" names="817" precision="FP16">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
			</output>
		</layer>
		<layer id="1437" name="63576361_const" type="Const" version="opset1">
			<data element_type="f16" offset="10108" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="1438" name="63586362_const" type="Const" version="opset1">
			<data element_type="f16" offset="361690" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="1439" name="63596363_const" type="Const" version="opset1">
			<data element_type="f16" offset="10108" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="1440" name="63606364_const" type="Const" version="opset1">
			<data element_type="f16" offset="361690" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="1441" name="824/fq_input_0" type="FakeQuantize" version="opset1">
			<data auto_broadcast="numpy" levels="256"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
				<port id="1"/>
				<port id="2"/>
				<port id="3"/>
				<port id="4"/>
			</input>
			<output>
				<port id="5" precision="FP16">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
			</output>
		</layer>
		<layer id="1442" name="conv3.0.conv2d.0.conv1.weight/quantized17427_const" type="Const" version="opset1">
			<data element_type="i8" offset="361692" shape="96,96,1,1" size="9216"/>
			<output>
				<port id="0" precision="I8">
					<dim>96</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1443" name="conv3.0.conv2d.0.conv1.weight/quantized/to_f16" type="Convert" version="opset1">
			<data destination_type="f16"/>
			<input>
				<port id="0">
					<dim>96</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="1" precision="FP16">
					<dim>96</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1444" name="782/fq_weights_1/zero_point17440_const" type="Const" version="opset1">
			<data element_type="f16" offset="370908" shape="96,1,1,1" size="192"/>
			<output>
				<port id="0" precision="FP16">
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1445" name="782/fq_weights_1/minus_zp" type="Subtract" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>96</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="1">
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>96</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1446" name="782/fq_weights_1/scale17435_const" type="Const" version="opset1">
			<data element_type="f16" offset="371100" shape="96,1,1,1" size="192"/>
			<output>
				<port id="0" precision="FP16">
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1447" name="782/fq_weights_1/mulpiply_by_scale" type="Multiply" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>96</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="1">
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>96</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1448" name="782" type="Convolution" version="opset1">
			<data auto_pad="explicit" dilations="1,1" pads_begin="0,0" pads_end="0,0" strides="1,1"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
				<port id="1">
					<dim>96</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" names="782" precision="FP16">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
			</output>
		</layer>
		<layer id="1449" name="29762978_const" type="Const" version="opset1">
			<data element_type="f16" offset="299980" shape="1,96,1,1" size="192"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1450" name="782/add_" type="Add" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
				<port id="1">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
			</output>
		</layer>
		<layer id="1451" name="62576261_const" type="Const" version="opset1">
			<data element_type="f16" offset="371292" shape="1,96,1,1" size="192"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1452" name="62586262_const" type="Const" version="opset1">
			<data element_type="f16" offset="371484" shape="1,96,1,1" size="192"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1453" name="62596263_const" type="Const" version="opset1">
			<data element_type="f16" offset="371292" shape="1,96,1,1" size="192"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1454" name="62606264_const" type="Const" version="opset1">
			<data element_type="f16" offset="371484" shape="1,96,1,1" size="192"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1455" name="783/fq_input_0" type="FakeQuantize" version="opset1">
			<data auto_broadcast="numpy" levels="256"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
				<port id="1">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="2">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="3">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="4">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="5" precision="FP16">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
			</output>
		</layer>
		<layer id="1456" name="4224342246_const172115513/quantized18483_const" type="Const" version="opset1">
			<data element_type="i8" offset="371676" shape="96,1,3,3" size="864"/>
			<output>
				<port id="0" precision="I8">
					<dim>96</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</output>
		</layer>
		<layer id="1457" name="4224342246_const172115513/quantized/to_f16" type="Convert" version="opset1">
			<data destination_type="f16"/>
			<input>
				<port id="0">
					<dim>96</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</input>
			<output>
				<port id="1" precision="FP16">
					<dim>96</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</output>
		</layer>
		<layer id="1458" name="783/fq_weights_1/zero_point18496_const" type="Const" version="opset1">
			<data element_type="f16" offset="372540" shape="96,1,1,1" size="192"/>
			<output>
				<port id="0" precision="FP16">
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1459" name="783/fq_weights_1/minus_zp" type="Subtract" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>96</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
				<port id="1">
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>96</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</output>
		</layer>
		<layer id="1460" name="783/fq_weights_1/scale18491_const" type="Const" version="opset1">
			<data element_type="f16" offset="372732" shape="96,1,1,1" size="192"/>
			<output>
				<port id="0" precision="FP16">
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1461" name="783/fq_weights_1/mulpiply_by_scale" type="Multiply" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>96</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
				<port id="1">
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>96</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</output>
		</layer>
		<layer id="1462" name="24408/value24410_const" type="Const" version="opset1">
			<data element_type="i64" offset="301804" shape="5" size="40"/>
			<output>
				<port id="0" precision="I64">
					<dim>5</dim>
				</port>
			</output>
		</layer>
		<layer id="1463" name="24408" type="Reshape" version="opset1">
			<data special_zero="true"/>
			<input>
				<port id="0">
					<dim>96</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
				<port id="1">
					<dim>5</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</output>
		</layer>
		<layer id="1464" name="783" type="GroupConvolution" version="opset1">
			<data auto_pad="explicit" dilations="1,1" pads_begin="1,1" pads_end="1,1" strides="1,1"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
				<port id="1">
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
			</output>
		</layer>
		<layer id="1465" name="data_add_219172192222766/EltwiseUnsqueeze23410_const1723_const" type="Const" version="opset1">
			<data element_type="f16" offset="372924" shape="1,96,1,1" size="192"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1466" name="784/variance/Fused_Add_" type="Add" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
				<port id="1">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" names="784" precision="FP16">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
			</output>
		</layer>
		<layer id="1467" name="785" type="ReLU" version="opset1">
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
			</input>
			<output>
				<port id="1" names="785" precision="FP16">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
			</output>
		</layer>
		<layer id="1468" name="70677071_const" type="Const" version="opset1">
			<data element_type="f16" offset="10108" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="1469" name="70687072_const" type="Const" version="opset1">
			<data element_type="f16" offset="373116" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="1470" name="70697073_const" type="Const" version="opset1">
			<data element_type="f16" offset="10108" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="1471" name="70707074_const" type="Const" version="opset1">
			<data element_type="f16" offset="373116" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="1472" name="786/fq_input_0" type="FakeQuantize" version="opset1">
			<data auto_broadcast="numpy" levels="256"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
				<port id="1"/>
				<port id="2"/>
				<port id="3"/>
				<port id="4"/>
			</input>
			<output>
				<port id="5" precision="FP16">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
			</output>
		</layer>
		<layer id="1473" name="conv3.0.conv2d.1.conv1.weight/quantized17619_const" type="Const" version="opset1">
			<data element_type="i8" offset="373118" shape="96,96,1,1" size="9216"/>
			<output>
				<port id="0" precision="I8">
					<dim>96</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1474" name="conv3.0.conv2d.1.conv1.weight/quantized/to_f16" type="Convert" version="opset1">
			<data destination_type="f16"/>
			<input>
				<port id="0">
					<dim>96</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="1" precision="FP16">
					<dim>96</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1475" name="786/fq_weights_1/zero_point17632_const" type="Const" version="opset1">
			<data element_type="f16" offset="382334" shape="96,1,1,1" size="192"/>
			<output>
				<port id="0" precision="FP16">
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1476" name="786/fq_weights_1/minus_zp" type="Subtract" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>96</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="1">
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>96</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1477" name="786/fq_weights_1/scale17627_const" type="Const" version="opset1">
			<data element_type="f16" offset="382526" shape="96,1,1,1" size="192"/>
			<output>
				<port id="0" precision="FP16">
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1478" name="786/fq_weights_1/mulpiply_by_scale" type="Multiply" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>96</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="1">
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>96</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1479" name="786" type="Convolution" version="opset1">
			<data auto_pad="explicit" dilations="1,1" pads_begin="0,0" pads_end="0,0" strides="1,1"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
				<port id="1">
					<dim>96</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" names="786" precision="FP16">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
			</output>
		</layer>
		<layer id="1480" name="29802982_const" type="Const" version="opset1">
			<data element_type="f16" offset="299980" shape="1,96,1,1" size="192"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1481" name="786/add_" type="Add" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
				<port id="1">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
			</output>
		</layer>
		<layer id="1482" name="55275531_const" type="Const" version="opset1">
			<data element_type="f16" offset="382718" shape="1,96,1,1" size="192"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1483" name="55285532_const" type="Const" version="opset1">
			<data element_type="f16" offset="382910" shape="1,96,1,1" size="192"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1484" name="55295533_const" type="Const" version="opset1">
			<data element_type="f16" offset="382718" shape="1,96,1,1" size="192"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1485" name="55305534_const" type="Const" version="opset1">
			<data element_type="f16" offset="382910" shape="1,96,1,1" size="192"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1486" name="787/fq_input_0" type="FakeQuantize" version="opset1">
			<data auto_broadcast="numpy" levels="256"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
				<port id="1">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="2">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="3">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="4">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="5" precision="FP16">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
			</output>
		</layer>
		<layer id="1487" name="4209142094_const172815516/quantized19011_const" type="Const" version="opset1">
			<data element_type="i8" offset="383102" shape="96,1,3,3" size="864"/>
			<output>
				<port id="0" precision="I8">
					<dim>96</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</output>
		</layer>
		<layer id="1488" name="4209142094_const172815516/quantized/to_f16" type="Convert" version="opset1">
			<data destination_type="f16"/>
			<input>
				<port id="0">
					<dim>96</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</input>
			<output>
				<port id="1" precision="FP16">
					<dim>96</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</output>
		</layer>
		<layer id="1489" name="787/fq_weights_1/zero_point19024_const" type="Const" version="opset1">
			<data element_type="f16" offset="383966" shape="96,1,1,1" size="192"/>
			<output>
				<port id="0" precision="FP16">
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1490" name="787/fq_weights_1/minus_zp" type="Subtract" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>96</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
				<port id="1">
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>96</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</output>
		</layer>
		<layer id="1491" name="787/fq_weights_1/scale19019_const" type="Const" version="opset1">
			<data element_type="f16" offset="384158" shape="96,1,1,1" size="192"/>
			<output>
				<port id="0" precision="FP16">
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1492" name="787/fq_weights_1/mulpiply_by_scale" type="Multiply" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>96</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
				<port id="1">
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>96</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</output>
		</layer>
		<layer id="1493" name="24584/value24586_const" type="Const" version="opset1">
			<data element_type="i64" offset="301804" shape="5" size="40"/>
			<output>
				<port id="0" precision="I64">
					<dim>5</dim>
				</port>
			</output>
		</layer>
		<layer id="1494" name="24584" type="Reshape" version="opset1">
			<data special_zero="true"/>
			<input>
				<port id="0">
					<dim>96</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
				<port id="1">
					<dim>5</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</output>
		</layer>
		<layer id="1495" name="787" type="GroupConvolution" version="opset1">
			<data auto_pad="explicit" dilations="1,1" pads_begin="1,1" pads_end="1,1" strides="1,1"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
				<port id="1">
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
			</output>
		</layer>
		<layer id="1496" name="data_add_219252193022768/EltwiseUnsqueeze23418_const1730_const" type="Const" version="opset1">
			<data element_type="f16" offset="384350" shape="1,96,1,1" size="192"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1497" name="788/variance/Fused_Add_" type="Add" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
				<port id="1">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" names="788" precision="FP16">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
			</output>
		</layer>
		<layer id="1498" name="789" type="ReLU" version="opset1">
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
			</input>
			<output>
				<port id="1" names="789" precision="FP16">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
			</output>
		</layer>
		<layer id="1499" name="74277431_const" type="Const" version="opset1">
			<data element_type="f16" offset="10108" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="1500" name="74287432_const" type="Const" version="opset1">
			<data element_type="f16" offset="361690" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="1501" name="74297433_const" type="Const" version="opset1">
			<data element_type="f16" offset="10108" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="1502" name="74307434_const" type="Const" version="opset1">
			<data element_type="f16" offset="361690" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="1503" name="790/fq_input_0" type="FakeQuantize" version="opset1">
			<data auto_broadcast="numpy" levels="256"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
				<port id="1"/>
				<port id="2"/>
				<port id="3"/>
				<port id="4"/>
			</input>
			<output>
				<port id="5" precision="FP16">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
			</output>
		</layer>
		<layer id="1504" name="conv3.0.conv2d.2.conv1.weight/quantized19875_const" type="Const" version="opset1">
			<data element_type="i8" offset="384542" shape="96,96,1,1" size="9216"/>
			<output>
				<port id="0" precision="I8">
					<dim>96</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1505" name="conv3.0.conv2d.2.conv1.weight/quantized/to_f16" type="Convert" version="opset1">
			<data destination_type="f16"/>
			<input>
				<port id="0">
					<dim>96</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="1" precision="FP16">
					<dim>96</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1506" name="790/fq_weights_1/zero_point19888_const" type="Const" version="opset1">
			<data element_type="f16" offset="393758" shape="96,1,1,1" size="192"/>
			<output>
				<port id="0" precision="FP16">
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1507" name="790/fq_weights_1/minus_zp" type="Subtract" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>96</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="1">
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>96</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1508" name="790/fq_weights_1/scale19883_const" type="Const" version="opset1">
			<data element_type="f16" offset="393950" shape="96,1,1,1" size="192"/>
			<output>
				<port id="0" precision="FP16">
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1509" name="790/fq_weights_1/mulpiply_by_scale" type="Multiply" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>96</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="1">
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>96</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1510" name="790" type="Convolution" version="opset1">
			<data auto_pad="explicit" dilations="1,1" pads_begin="0,0" pads_end="0,0" strides="1,1"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
				<port id="1">
					<dim>96</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" names="790" precision="FP16">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
			</output>
		</layer>
		<layer id="1511" name="29842986_const" type="Const" version="opset1">
			<data element_type="f16" offset="299980" shape="1,96,1,1" size="192"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1512" name="790/add_" type="Add" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
				<port id="1">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
			</output>
		</layer>
		<layer id="1513" name="74077411_const" type="Const" version="opset1">
			<data element_type="f16" offset="394142" shape="1,96,1,1" size="192"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1514" name="74087412_const" type="Const" version="opset1">
			<data element_type="f16" offset="394334" shape="1,96,1,1" size="192"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1515" name="74097413_const" type="Const" version="opset1">
			<data element_type="f16" offset="394142" shape="1,96,1,1" size="192"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1516" name="74107414_const" type="Const" version="opset1">
			<data element_type="f16" offset="394334" shape="1,96,1,1" size="192"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1517" name="791/fq_input_0" type="FakeQuantize" version="opset1">
			<data auto_broadcast="numpy" levels="256"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
				<port id="1">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="2">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="3">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="4">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="5" precision="FP16">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
			</output>
		</layer>
		<layer id="1518" name="4211142114_const173515519/quantized20163_const" type="Const" version="opset1">
			<data element_type="i8" offset="394526" shape="96,1,3,3" size="864"/>
			<output>
				<port id="0" precision="I8">
					<dim>96</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</output>
		</layer>
		<layer id="1519" name="4211142114_const173515519/quantized/to_f16" type="Convert" version="opset1">
			<data destination_type="f16"/>
			<input>
				<port id="0">
					<dim>96</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</input>
			<output>
				<port id="1" precision="FP16">
					<dim>96</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</output>
		</layer>
		<layer id="1520" name="791/fq_weights_1/zero_point20176_const" type="Const" version="opset1">
			<data element_type="f16" offset="395390" shape="96,1,1,1" size="192"/>
			<output>
				<port id="0" precision="FP16">
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1521" name="791/fq_weights_1/minus_zp" type="Subtract" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>96</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
				<port id="1">
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>96</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</output>
		</layer>
		<layer id="1522" name="791/fq_weights_1/scale20171_const" type="Const" version="opset1">
			<data element_type="f16" offset="395582" shape="96,1,1,1" size="192"/>
			<output>
				<port id="0" precision="FP16">
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1523" name="791/fq_weights_1/mulpiply_by_scale" type="Multiply" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>96</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
				<port id="1">
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>96</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</output>
		</layer>
		<layer id="1524" name="24552/value24554_const" type="Const" version="opset1">
			<data element_type="i64" offset="301804" shape="5" size="40"/>
			<output>
				<port id="0" precision="I64">
					<dim>5</dim>
				</port>
			</output>
		</layer>
		<layer id="1525" name="24552" type="Reshape" version="opset1">
			<data special_zero="true"/>
			<input>
				<port id="0">
					<dim>96</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
				<port id="1">
					<dim>5</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</output>
		</layer>
		<layer id="1526" name="791" type="GroupConvolution" version="opset1">
			<data auto_pad="explicit" dilations="1,1" pads_begin="1,1" pads_end="1,1" strides="1,1"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
				<port id="1">
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
			</output>
		</layer>
		<layer id="1527" name="data_add_219332193822770/EltwiseUnsqueeze23426_const1737_const" type="Const" version="opset1">
			<data element_type="f16" offset="395774" shape="1,96,1,1" size="192"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1528" name="792/variance/Fused_Add_" type="Add" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
				<port id="1">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" names="792" precision="FP16">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
			</output>
		</layer>
		<layer id="1529" name="793" type="ReLU" version="opset1">
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
			</input>
			<output>
				<port id="1" names="793" precision="FP16">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
			</output>
		</layer>
		<layer id="1530" name="48374841_const" type="Const" version="opset1">
			<data element_type="f16" offset="10108" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="1531" name="48384842_const" type="Const" version="opset1">
			<data element_type="f16" offset="395966" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="1532" name="48394843_const" type="Const" version="opset1">
			<data element_type="f16" offset="10108" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="1533" name="48404844_const" type="Const" version="opset1">
			<data element_type="f16" offset="395966" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="1534" name="794/fq_input_0" type="FakeQuantize" version="opset1">
			<data auto_broadcast="numpy" levels="256"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
				<port id="1"/>
				<port id="2"/>
				<port id="3"/>
				<port id="4"/>
			</input>
			<output>
				<port id="5" precision="FP16">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
			</output>
		</layer>
		<layer id="1535" name="conv3.0.conv2d.3.conv1.weight/quantized18459_const" type="Const" version="opset1">
			<data element_type="i8" offset="395968" shape="96,96,1,1" size="9216"/>
			<output>
				<port id="0" precision="I8">
					<dim>96</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1536" name="conv3.0.conv2d.3.conv1.weight/quantized/to_f16" type="Convert" version="opset1">
			<data destination_type="f16"/>
			<input>
				<port id="0">
					<dim>96</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="1" precision="FP16">
					<dim>96</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1537" name="794/fq_weights_1/zero_point18472_const" type="Const" version="opset1">
			<data element_type="f16" offset="405184" shape="96,1,1,1" size="192"/>
			<output>
				<port id="0" precision="FP16">
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1538" name="794/fq_weights_1/minus_zp" type="Subtract" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>96</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="1">
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>96</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1539" name="794/fq_weights_1/scale18467_const" type="Const" version="opset1">
			<data element_type="f16" offset="405376" shape="96,1,1,1" size="192"/>
			<output>
				<port id="0" precision="FP16">
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1540" name="794/fq_weights_1/mulpiply_by_scale" type="Multiply" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>96</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="1">
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>96</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1541" name="794" type="Convolution" version="opset1">
			<data auto_pad="explicit" dilations="1,1" pads_begin="0,0" pads_end="0,0" strides="1,1"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
				<port id="1">
					<dim>96</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" names="794" precision="FP16">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
			</output>
		</layer>
		<layer id="1542" name="29882990_const" type="Const" version="opset1">
			<data element_type="f16" offset="299980" shape="1,96,1,1" size="192"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1543" name="794/add_" type="Add" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
				<port id="1">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
			</output>
		</layer>
		<layer id="1544" name="72677271_const" type="Const" version="opset1">
			<data element_type="f16" offset="405568" shape="1,96,1,1" size="192"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1545" name="72687272_const" type="Const" version="opset1">
			<data element_type="f16" offset="405760" shape="1,96,1,1" size="192"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1546" name="72697273_const" type="Const" version="opset1">
			<data element_type="f16" offset="405568" shape="1,96,1,1" size="192"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1547" name="72707274_const" type="Const" version="opset1">
			<data element_type="f16" offset="405760" shape="1,96,1,1" size="192"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1548" name="795/fq_input_0" type="FakeQuantize" version="opset1">
			<data auto_broadcast="numpy" levels="256"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
				<port id="1">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="2">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="3">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="4">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="5" precision="FP16">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
			</output>
		</layer>
		<layer id="1549" name="4217942182_const174215522/quantized19755_const" type="Const" version="opset1">
			<data element_type="i8" offset="405952" shape="96,1,3,3" size="864"/>
			<output>
				<port id="0" precision="I8">
					<dim>96</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</output>
		</layer>
		<layer id="1550" name="4217942182_const174215522/quantized/to_f16" type="Convert" version="opset1">
			<data destination_type="f16"/>
			<input>
				<port id="0">
					<dim>96</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</input>
			<output>
				<port id="1" precision="FP16">
					<dim>96</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</output>
		</layer>
		<layer id="1551" name="795/fq_weights_1/zero_point19768_const" type="Const" version="opset1">
			<data element_type="f16" offset="406816" shape="96,1,1,1" size="192"/>
			<output>
				<port id="0" precision="FP16">
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1552" name="795/fq_weights_1/minus_zp" type="Subtract" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>96</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
				<port id="1">
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>96</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</output>
		</layer>
		<layer id="1553" name="795/fq_weights_1/scale19763_const" type="Const" version="opset1">
			<data element_type="f16" offset="407008" shape="96,1,1,1" size="192"/>
			<output>
				<port id="0" precision="FP16">
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1554" name="795/fq_weights_1/mulpiply_by_scale" type="Multiply" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>96</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
				<port id="1">
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>96</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</output>
		</layer>
		<layer id="1555" name="24432/value24434_const" type="Const" version="opset1">
			<data element_type="i64" offset="301804" shape="5" size="40"/>
			<output>
				<port id="0" precision="I64">
					<dim>5</dim>
				</port>
			</output>
		</layer>
		<layer id="1556" name="24432" type="Reshape" version="opset1">
			<data special_zero="true"/>
			<input>
				<port id="0">
					<dim>96</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
				<port id="1">
					<dim>5</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</output>
		</layer>
		<layer id="1557" name="795" type="GroupConvolution" version="opset1">
			<data auto_pad="explicit" dilations="1,1" pads_begin="1,1" pads_end="1,1" strides="1,1"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
				<port id="1">
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
			</output>
		</layer>
		<layer id="1558" name="data_add_219412194622772/EltwiseUnsqueeze23434_const1744_const" type="Const" version="opset1">
			<data element_type="f16" offset="407200" shape="1,96,1,1" size="192"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1559" name="796/variance/Fused_Add_" type="Add" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
				<port id="1">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" names="796" precision="FP16">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
			</output>
		</layer>
		<layer id="1560" name="797" type="ReLU" version="opset1">
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
			</input>
			<output>
				<port id="1" names="797" precision="FP16">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
			</output>
		</layer>
		<layer id="1561" name="83678371_const" type="Const" version="opset1">
			<data element_type="f16" offset="10108" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="1562" name="83688372_const" type="Const" version="opset1">
			<data element_type="f16" offset="407392" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="1563" name="83698373_const" type="Const" version="opset1">
			<data element_type="f16" offset="10108" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="1564" name="83708374_const" type="Const" version="opset1">
			<data element_type="f16" offset="407392" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="1565" name="818/reduce/fq_input_0" type="FakeQuantize" version="opset1">
			<data auto_broadcast="numpy" levels="256"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
				<port id="1"/>
				<port id="2"/>
				<port id="3"/>
				<port id="4"/>
			</input>
			<output>
				<port id="5" precision="FP16">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
			</output>
		</layer>
		<layer id="1566" name="1379/Output_0/Data__const1747_const" type="Const" version="opset1">
			<data element_type="i64" offset="24" shape="" size="8"/>
			<output>
				<port id="0" precision="I64"/>
			</output>
		</layer>
		<layer id="1567" name="818/input_rank/shape_of" type="ShapeOf" version="opset3">
			<data output_type="i64"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
			</input>
			<output>
				<port id="1" precision="I64">
					<dim>4</dim>
				</port>
			</output>
		</layer>
		<layer id="1568" name="818/input_rank/rank_of" type="ShapeOf" version="opset3">
			<data output_type="i64"/>
			<input>
				<port id="0">
					<dim>4</dim>
				</port>
			</input>
			<output>
				<port id="1" precision="I64">
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1569" name="818/input_rank/0d_rank_of/value/Output_0/Data__const1750_const" type="Const" version="opset1">
			<data element_type="i64" offset="32" shape="1" size="8"/>
			<output>
				<port id="0" precision="I64">
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1570" name="818/input_rank" type="Squeeze" version="opset1">
			<input>
				<port id="0">
					<dim>1</dim>
				</port>
				<port id="1">
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="I64"/>
			</output>
		</layer>
		<layer id="1571" name="1381/Output_0/Data__const1752_const" type="Const" version="opset1">
			<data element_type="i64" offset="0" shape="" size="8"/>
			<output>
				<port id="0" precision="I64"/>
			</output>
		</layer>
		<layer id="1572" name="818/global_pooling_reduce_axis" type="Range" version="opset4">
			<data output_type="i64"/>
			<input>
				<port id="0"/>
				<port id="1"/>
				<port id="2"/>
			</input>
			<output>
				<port id="3" precision="I64">
					<dim>2</dim>
				</port>
			</output>
		</layer>
		<layer id="1573" name="818/reduce" type="ReduceMean" version="opset1">
			<data keep_dims="true"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
				<port id="1">
					<dim>2</dim>
				</port>
			</input>
			<output>
				<port id="2" names="818" precision="FP16">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1574" name="Copy_conv3.0.gate.fc1.weight/Output_0/Data_4386_const1755_const" type="Const" version="opset1">
			<data element_type="f16" offset="302038" shape="6,96,1,1" size="1152"/>
			<output>
				<port id="0" names="conv3.0.gate.fc1.weight" precision="FP16">
					<dim>6</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1575" name="819/WithoutBiases" type="Convolution" version="opset1">
			<data auto_pad="explicit" dilations="1,1" pads_begin="0,0" pads_end="0,0" strides="1,1"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="1">
					<dim>6</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>1</dim>
					<dim>6</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1576" name="819/Dims1301222704/EltwiseUnsqueeze23170_const1757_const" type="Const" version="opset1">
			<data element_type="f16" offset="303190" shape="1,6,1,1" size="12"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>6</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1577" name="819" type="Add" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>6</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="1">
					<dim>1</dim>
					<dim>6</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" names="819" precision="FP16">
					<dim>1</dim>
					<dim>6</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1578" name="820" type="ReLU" version="opset1">
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>6</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="1" names="820" precision="FP16">
					<dim>1</dim>
					<dim>6</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1579" name="Copy_conv3.0.gate.fc2.weight/Output_0/Data_4394_const1760_const" type="Const" version="opset1">
			<data element_type="f16" offset="303202" shape="96,6,1,1" size="1152"/>
			<output>
				<port id="0" names="conv3.0.gate.fc2.weight" precision="FP16">
					<dim>96</dim>
					<dim>6</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1580" name="821/WithoutBiases" type="Convolution" version="opset1">
			<data auto_pad="explicit" dilations="1,1" pads_begin="0,0" pads_end="0,0" strides="1,1"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>6</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="1">
					<dim>96</dim>
					<dim>6</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1581" name="821/Dims1297622698/EltwiseUnsqueeze23146_const1762_const" type="Const" version="opset1">
			<data element_type="f16" offset="304354" shape="1,96,1,1" size="192"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1582" name="821" type="Add" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="1">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" names="821" precision="FP16">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1583" name="822" type="Sigmoid" version="opset1">
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="1" names="822" precision="FP16">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1584" name="51575161_const" type="Const" version="opset1">
			<data element_type="f16" offset="10108" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="1585" name="51585162_const" type="Const" version="opset1">
			<data element_type="f16" offset="407394" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="1586" name="51595163_const" type="Const" version="opset1">
			<data element_type="f16" offset="10108" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="1587" name="51605164_const" type="Const" version="opset1">
			<data element_type="f16" offset="407394" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="1588" name="823/fq_input_1" type="FakeQuantize" version="opset1">
			<data auto_broadcast="numpy" levels="256"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="1"/>
				<port id="2"/>
				<port id="3"/>
				<port id="4"/>
			</input>
			<output>
				<port id="5" precision="FP16">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1589" name="823" type="Multiply" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
				<port id="1">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" names="823" precision="FP16">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
			</output>
		</layer>
		<layer id="1590" name="63676371_const" type="Const" version="opset1">
			<data element_type="f16" offset="10108" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="1591" name="63686372_const" type="Const" version="opset1">
			<data element_type="f16" offset="407396" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="1592" name="63696373_const" type="Const" version="opset1">
			<data element_type="f16" offset="10108" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="1593" name="63706374_const" type="Const" version="opset1">
			<data element_type="f16" offset="407396" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="1594" name="824/fq_input_1" type="FakeQuantize" version="opset1">
			<data auto_broadcast="numpy" levels="256"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
				<port id="1"/>
				<port id="2"/>
				<port id="3"/>
				<port id="4"/>
			</input>
			<output>
				<port id="5" precision="FP16">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
			</output>
		</layer>
		<layer id="1595" name="824" type="Add" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
				<port id="1">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
			</input>
			<output>
				<port id="2" names="824" precision="FP16">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
			</output>
		</layer>
		<layer id="1596" name="53875391_const" type="Const" version="opset1">
			<data element_type="f16" offset="10108" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="1597" name="53885392_const" type="Const" version="opset1">
			<data element_type="f16" offset="407398" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="1598" name="53895393_const" type="Const" version="opset1">
			<data element_type="f16" offset="10108" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="1599" name="53905394_const" type="Const" version="opset1">
			<data element_type="f16" offset="407398" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="1600" name="825/fq_input_0" type="FakeQuantize" version="opset1">
			<data auto_broadcast="numpy" levels="256"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
				<port id="1"/>
				<port id="2"/>
				<port id="3"/>
				<port id="4"/>
			</input>
			<output>
				<port id="5" precision="FP16">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
			</output>
		</layer>
		<layer id="1601" name="826/mean/Fused_Mul_2450724509_const176715531/quantized19923_const" type="Const" version="opset1">
			<data element_type="i8" offset="407400" shape="384,96,1,1" size="36864"/>
			<output>
				<port id="0" precision="I8">
					<dim>384</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1602" name="826/mean/Fused_Mul_2450724509_const176715531/quantized/to_f16" type="Convert" version="opset1">
			<data destination_type="f16"/>
			<input>
				<port id="0">
					<dim>384</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="1" precision="FP16">
					<dim>384</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1603" name="825/fq_weights_1/zero_point19936_const" type="Const" version="opset1">
			<data element_type="f16" offset="444264" shape="384,1,1,1" size="768"/>
			<output>
				<port id="0" precision="FP16">
					<dim>384</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1604" name="825/fq_weights_1/minus_zp" type="Subtract" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>384</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="1">
					<dim>384</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>384</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1605" name="825/fq_weights_1/scale19931_const" type="Const" version="opset1">
			<data element_type="f16" offset="445032" shape="384,1,1,1" size="768"/>
			<output>
				<port id="0" precision="FP16">
					<dim>384</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1606" name="825/fq_weights_1/mulpiply_by_scale" type="Multiply" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>384</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="1">
					<dim>384</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>384</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1607" name="825" type="Convolution" version="opset1">
			<data auto_pad="explicit" dilations="1,1" pads_begin="0,0" pads_end="0,0" strides="1,1"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
				<port id="1">
					<dim>384</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>1</dim>
					<dim>384</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
			</output>
		</layer>
		<layer id="1608" name="data_add_219972200222786/EltwiseUnsqueeze23490_const1769_const" type="Const" version="opset1">
			<data element_type="f16" offset="445800" shape="1,384,1,1" size="768"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>384</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1609" name="826/variance/Fused_Add_" type="Add" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>384</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
				<port id="1">
					<dim>1</dim>
					<dim>384</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" names="826" precision="FP16">
					<dim>1</dim>
					<dim>384</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
			</output>
		</layer>
		<layer id="1610" name="72877291_const" type="Const" version="opset1">
			<data element_type="f16" offset="446568" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="1611" name="72887292_const" type="Const" version="opset1">
			<data element_type="f16" offset="446570" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="1612" name="72897293_const" type="Const" version="opset1">
			<data element_type="f16" offset="446568" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="1613" name="72907294_const" type="Const" version="opset1">
			<data element_type="f16" offset="446570" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="1614" name="829/fq_input_0" type="FakeQuantize" version="opset1">
			<data auto_broadcast="numpy" levels="256"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>384</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
				<port id="1"/>
				<port id="2"/>
				<port id="3"/>
				<port id="4"/>
			</input>
			<output>
				<port id="5" precision="FP16">
					<dim>1</dim>
					<dim>384</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
			</output>
		</layer>
		<layer id="1615" name="828/mean/Fused_Mul_2445924461_const177115533/quantized18819_const" type="Const" version="opset1">
			<data element_type="i8" offset="446572" shape="384,256,1,1" size="98304"/>
			<output>
				<port id="0" precision="I8">
					<dim>384</dim>
					<dim>256</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1616" name="828/mean/Fused_Mul_2445924461_const177115533/quantized/to_f16" type="Convert" version="opset1">
			<data destination_type="f16"/>
			<input>
				<port id="0">
					<dim>384</dim>
					<dim>256</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="1" precision="FP16">
					<dim>384</dim>
					<dim>256</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1617" name="827/fq_weights_1/zero_point18832_const" type="Const" version="opset1">
			<data element_type="f16" offset="544876" shape="384,1,1,1" size="768"/>
			<output>
				<port id="0" precision="FP16">
					<dim>384</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1618" name="827/fq_weights_1/minus_zp" type="Subtract" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>384</dim>
					<dim>256</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="1">
					<dim>384</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>384</dim>
					<dim>256</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1619" name="827/fq_weights_1/scale18827_const" type="Const" version="opset1">
			<data element_type="f16" offset="545644" shape="384,1,1,1" size="768"/>
			<output>
				<port id="0" precision="FP16">
					<dim>384</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1620" name="827/fq_weights_1/mulpiply_by_scale" type="Multiply" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>384</dim>
					<dim>256</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="1">
					<dim>384</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>384</dim>
					<dim>256</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1621" name="827" type="Convolution" version="opset1">
			<data auto_pad="explicit" dilations="1,1" pads_begin="0,0" pads_end="0,0" strides="1,1"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>256</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
				<port id="1">
					<dim>384</dim>
					<dim>256</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>1</dim>
					<dim>384</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
			</output>
		</layer>
		<layer id="1622" name="data_add_219012190622762/EltwiseUnsqueeze23394_const1773_const" type="Const" version="opset1">
			<data element_type="f16" offset="546412" shape="1,384,1,1" size="768"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>384</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1623" name="828/variance/Fused_Add_" type="Add" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>384</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
				<port id="1">
					<dim>1</dim>
					<dim>384</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" names="828" precision="FP16">
					<dim>1</dim>
					<dim>384</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
			</output>
		</layer>
		<layer id="1624" name="72977301_const" type="Const" version="opset1">
			<data element_type="f16" offset="547180" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="1625" name="72987302_const" type="Const" version="opset1">
			<data element_type="f16" offset="547182" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="1626" name="72997303_const" type="Const" version="opset1">
			<data element_type="f16" offset="547180" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="1627" name="73007304_const" type="Const" version="opset1">
			<data element_type="f16" offset="547182" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="1628" name="829/fq_input_1" type="FakeQuantize" version="opset1">
			<data auto_broadcast="numpy" levels="256"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>384</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
				<port id="1"/>
				<port id="2"/>
				<port id="3"/>
				<port id="4"/>
			</input>
			<output>
				<port id="5" precision="FP16">
					<dim>1</dim>
					<dim>384</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
			</output>
		</layer>
		<layer id="1629" name="829" type="Add" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>384</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
				<port id="1">
					<dim>1</dim>
					<dim>384</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
			</input>
			<output>
				<port id="2" names="829" precision="FP16">
					<dim>1</dim>
					<dim>384</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
			</output>
		</layer>
		<layer id="1630" name="830" type="ReLU" version="opset1">
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>384</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
			</input>
			<output>
				<port id="1" names="830" precision="FP16">
					<dim>1</dim>
					<dim>384</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
			</output>
		</layer>
		<layer id="1631" name="46574661_const" type="Const" version="opset1">
			<data element_type="f16" offset="10108" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="1632" name="46584662_const" type="Const" version="opset1">
			<data element_type="f16" offset="547184" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="1633" name="46594663_const" type="Const" version="opset1">
			<data element_type="f16" offset="10108" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="1634" name="46604664_const" type="Const" version="opset1">
			<data element_type="f16" offset="547184" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="1635" name="831/fq_input_0" type="FakeQuantize" version="opset1">
			<data auto_broadcast="numpy" levels="256"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>384</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
				<port id="1"/>
				<port id="2"/>
				<port id="3"/>
				<port id="4"/>
			</input>
			<output>
				<port id="5" precision="FP16">
					<dim>1</dim>
					<dim>384</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
			</output>
		</layer>
		<layer id="1636" name="832/mean/Fused_Mul_2451124513_const177715535/quantized18891_const" type="Const" version="opset1">
			<data element_type="i8" offset="547186" shape="96,384,1,1" size="36864"/>
			<output>
				<port id="0" precision="I8">
					<dim>96</dim>
					<dim>384</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1637" name="832/mean/Fused_Mul_2451124513_const177715535/quantized/to_f16" type="Convert" version="opset1">
			<data destination_type="f16"/>
			<input>
				<port id="0">
					<dim>96</dim>
					<dim>384</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="1" precision="FP16">
					<dim>96</dim>
					<dim>384</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1638" name="831/fq_weights_1/zero_point18904_const" type="Const" version="opset1">
			<data element_type="f16" offset="584050" shape="96,1,1,1" size="192"/>
			<output>
				<port id="0" precision="FP16">
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1639" name="831/fq_weights_1/minus_zp" type="Subtract" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>96</dim>
					<dim>384</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="1">
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>96</dim>
					<dim>384</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1640" name="831/fq_weights_1/scale18899_const" type="Const" version="opset1">
			<data element_type="f16" offset="584242" shape="96,1,1,1" size="192"/>
			<output>
				<port id="0" precision="FP16">
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1641" name="831/fq_weights_1/mulpiply_by_scale" type="Multiply" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>96</dim>
					<dim>384</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="1">
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>96</dim>
					<dim>384</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1642" name="831" type="Convolution" version="opset1">
			<data auto_pad="explicit" dilations="1,1" pads_begin="0,0" pads_end="0,0" strides="1,1"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>384</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
				<port id="1">
					<dim>96</dim>
					<dim>384</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
			</output>
		</layer>
		<layer id="1643" name="data_add_220052201022788/EltwiseUnsqueeze23498_const1779_const" type="Const" version="opset1">
			<data element_type="f16" offset="584434" shape="1,96,1,1" size="192"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1644" name="832/variance/Fused_Add_" type="Add" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
				<port id="1">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" names="832" precision="FP16">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
			</output>
		</layer>
		<layer id="1645" name="833" type="ReLU" version="opset1">
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
			</input>
			<output>
				<port id="1" names="833" precision="FP16">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
			</output>
		</layer>
		<layer id="1646" name="65176521_const" type="Const" version="opset1">
			<data element_type="f16" offset="10108" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="1647" name="65186522_const" type="Const" version="opset1">
			<data element_type="f16" offset="584626" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="1648" name="65196523_const" type="Const" version="opset1">
			<data element_type="f16" offset="10108" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="1649" name="65206524_const" type="Const" version="opset1">
			<data element_type="f16" offset="584626" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="1650" name="834/fq_input_0" type="FakeQuantize" version="opset1">
			<data auto_broadcast="numpy" levels="256"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
				<port id="1"/>
				<port id="2"/>
				<port id="3"/>
				<port id="4"/>
			</input>
			<output>
				<port id="5" precision="FP16">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
			</output>
		</layer>
		<layer id="1651" name="conv3.1.conv2a.conv1.weight/quantized17739_const" type="Const" version="opset1">
			<data element_type="i8" offset="584628" shape="96,96,1,1" size="9216"/>
			<output>
				<port id="0" precision="I8">
					<dim>96</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1652" name="conv3.1.conv2a.conv1.weight/quantized/to_f16" type="Convert" version="opset1">
			<data destination_type="f16"/>
			<input>
				<port id="0">
					<dim>96</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="1" precision="FP16">
					<dim>96</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1653" name="834/fq_weights_1/zero_point17752_const" type="Const" version="opset1">
			<data element_type="f16" offset="593844" shape="96,1,1,1" size="192"/>
			<output>
				<port id="0" precision="FP16">
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1654" name="834/fq_weights_1/minus_zp" type="Subtract" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>96</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="1">
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>96</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1655" name="834/fq_weights_1/scale17747_const" type="Const" version="opset1">
			<data element_type="f16" offset="594036" shape="96,1,1,1" size="192"/>
			<output>
				<port id="0" precision="FP16">
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1656" name="834/fq_weights_1/mulpiply_by_scale" type="Multiply" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>96</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="1">
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>96</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1657" name="834" type="Convolution" version="opset1">
			<data auto_pad="explicit" dilations="1,1" pads_begin="0,0" pads_end="0,0" strides="1,1"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
				<port id="1">
					<dim>96</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" names="834" precision="FP16">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
			</output>
		</layer>
		<layer id="1658" name="29922994_const" type="Const" version="opset1">
			<data element_type="f16" offset="299980" shape="1,96,1,1" size="192"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1659" name="834/add_" type="Add" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
				<port id="1">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
			</output>
		</layer>
		<layer id="1660" name="70477051_const" type="Const" version="opset1">
			<data element_type="f16" offset="594228" shape="1,96,1,1" size="192"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1661" name="70487052_const" type="Const" version="opset1">
			<data element_type="f16" offset="594420" shape="1,96,1,1" size="192"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1662" name="70497053_const" type="Const" version="opset1">
			<data element_type="f16" offset="594228" shape="1,96,1,1" size="192"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1663" name="70507054_const" type="Const" version="opset1">
			<data element_type="f16" offset="594420" shape="1,96,1,1" size="192"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1664" name="835/fq_input_0" type="FakeQuantize" version="opset1">
			<data auto_broadcast="numpy" levels="256"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
				<port id="1">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="2">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="3">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="4">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="5" precision="FP16">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
			</output>
		</layer>
		<layer id="1665" name="4218742190_const178415538/quantized18315_const" type="Const" version="opset1">
			<data element_type="i8" offset="594612" shape="96,1,3,3" size="864"/>
			<output>
				<port id="0" precision="I8">
					<dim>96</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</output>
		</layer>
		<layer id="1666" name="4218742190_const178415538/quantized/to_f16" type="Convert" version="opset1">
			<data destination_type="f16"/>
			<input>
				<port id="0">
					<dim>96</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</input>
			<output>
				<port id="1" precision="FP16">
					<dim>96</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</output>
		</layer>
		<layer id="1667" name="835/fq_weights_1/zero_point18328_const" type="Const" version="opset1">
			<data element_type="f16" offset="595476" shape="96,1,1,1" size="192"/>
			<output>
				<port id="0" precision="FP16">
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1668" name="835/fq_weights_1/minus_zp" type="Subtract" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>96</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
				<port id="1">
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>96</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</output>
		</layer>
		<layer id="1669" name="835/fq_weights_1/scale18323_const" type="Const" version="opset1">
			<data element_type="f16" offset="595668" shape="96,1,1,1" size="192"/>
			<output>
				<port id="0" precision="FP16">
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1670" name="835/fq_weights_1/mulpiply_by_scale" type="Multiply" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>96</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
				<port id="1">
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>96</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</output>
		</layer>
		<layer id="1671" name="24428/value24430_const" type="Const" version="opset1">
			<data element_type="i64" offset="301804" shape="5" size="40"/>
			<output>
				<port id="0" precision="I64">
					<dim>5</dim>
				</port>
			</output>
		</layer>
		<layer id="1672" name="24428" type="Reshape" version="opset1">
			<data special_zero="true"/>
			<input>
				<port id="0">
					<dim>96</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
				<port id="1">
					<dim>5</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</output>
		</layer>
		<layer id="1673" name="835" type="GroupConvolution" version="opset1">
			<data auto_pad="explicit" dilations="1,1" pads_begin="1,1" pads_end="1,1" strides="1,1"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
				<port id="1">
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
			</output>
		</layer>
		<layer id="1674" name="data_add_220852209022808/EltwiseUnsqueeze23578_const1786_const" type="Const" version="opset1">
			<data element_type="f16" offset="595860" shape="1,96,1,1" size="192"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1675" name="836/variance/Fused_Add_" type="Add" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
				<port id="1">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" names="836" precision="FP16">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
			</output>
		</layer>
		<layer id="1676" name="837" type="ReLU" version="opset1">
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
			</input>
			<output>
				<port id="1" names="837" precision="FP16">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
			</output>
		</layer>
		<layer id="1677" name="52975301_const" type="Const" version="opset1">
			<data element_type="f16" offset="10108" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="1678" name="52985302_const" type="Const" version="opset1">
			<data element_type="f16" offset="596052" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="1679" name="52995303_const" type="Const" version="opset1">
			<data element_type="f16" offset="10108" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="1680" name="53005304_const" type="Const" version="opset1">
			<data element_type="f16" offset="596052" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="1681" name="874/reduce/fq_input_0" type="FakeQuantize" version="opset1">
			<data auto_broadcast="numpy" levels="256"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
				<port id="1"/>
				<port id="2"/>
				<port id="3"/>
				<port id="4"/>
			</input>
			<output>
				<port id="5" precision="FP16">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
			</output>
		</layer>
		<layer id="1682" name="1384/Output_0/Data__const1789_const" type="Const" version="opset1">
			<data element_type="i64" offset="24" shape="" size="8"/>
			<output>
				<port id="0" precision="I64"/>
			</output>
		</layer>
		<layer id="1683" name="874/input_rank/shape_of" type="ShapeOf" version="opset3">
			<data output_type="i64"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
			</input>
			<output>
				<port id="1" precision="I64">
					<dim>4</dim>
				</port>
			</output>
		</layer>
		<layer id="1684" name="874/input_rank/rank_of" type="ShapeOf" version="opset3">
			<data output_type="i64"/>
			<input>
				<port id="0">
					<dim>4</dim>
				</port>
			</input>
			<output>
				<port id="1" precision="I64">
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1685" name="874/input_rank/0d_rank_of/value/Output_0/Data__const1792_const" type="Const" version="opset1">
			<data element_type="i64" offset="32" shape="1" size="8"/>
			<output>
				<port id="0" precision="I64">
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1686" name="874/input_rank" type="Squeeze" version="opset1">
			<input>
				<port id="0">
					<dim>1</dim>
				</port>
				<port id="1">
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="I64"/>
			</output>
		</layer>
		<layer id="1687" name="1386/Output_0/Data__const1794_const" type="Const" version="opset1">
			<data element_type="i64" offset="0" shape="" size="8"/>
			<output>
				<port id="0" precision="I64"/>
			</output>
		</layer>
		<layer id="1688" name="874/global_pooling_reduce_axis" type="Range" version="opset4">
			<data output_type="i64"/>
			<input>
				<port id="0"/>
				<port id="1"/>
				<port id="2"/>
			</input>
			<output>
				<port id="3" precision="I64">
					<dim>2</dim>
				</port>
			</output>
		</layer>
		<layer id="1689" name="874/reduce" type="ReduceMean" version="opset1">
			<data keep_dims="true"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
				<port id="1">
					<dim>2</dim>
				</port>
			</input>
			<output>
				<port id="2" names="874" precision="FP16">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1690" name="1092810932_const" type="Const" version="opset1">
			<data element_type="f16" offset="10108" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="1691" name="1092910933_const" type="Const" version="opset1">
			<data element_type="f16" offset="596054" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="1692" name="1093010934_const" type="Const" version="opset1">
			<data element_type="f16" offset="10108" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="1693" name="1093110935_const" type="Const" version="opset1">
			<data element_type="f16" offset="596054" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="1694" name="876/fq_input_0" type="FakeQuantize" version="opset1">
			<data auto_broadcast="numpy" levels="256"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="1"/>
				<port id="2"/>
				<port id="3"/>
				<port id="4"/>
			</input>
			<output>
				<port id="5" precision="FP16">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1695" name="876/Cast_143334_const1797_const" type="Const" version="opset1">
			<data element_type="i64" offset="129708" shape="3" size="24"/>
			<output>
				<port id="0" names="875" precision="I64">
					<dim>3</dim>
				</port>
			</output>
		</layer>
		<layer id="1696" name="876" type="Reshape" version="opset1">
			<data special_zero="true"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="1">
					<dim>3</dim>
				</port>
			</input>
			<output>
				<port id="2" names="876" precision="FP16">
					<dim>1</dim>
					<dim>16</dim>
					<dim>6</dim>
				</port>
			</output>
		</layer>
		<layer id="1697" name="879/Range_input_port_0/value/Output_0/Data__const1799_const" type="Const" version="opset1">
			<data element_type="i64" offset="24" shape="" size="8"/>
			<output>
				<port id="0" precision="I64"/>
			</output>
		</layer>
		<layer id="1698" name="879/Rank/shape_of" type="ShapeOf" version="opset3">
			<data output_type="i64"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>16</dim>
					<dim>6</dim>
				</port>
			</input>
			<output>
				<port id="1" precision="I64">
					<dim>3</dim>
				</port>
			</output>
		</layer>
		<layer id="1699" name="879/Rank/rank_of" type="ShapeOf" version="opset3">
			<data output_type="i64"/>
			<input>
				<port id="0">
					<dim>3</dim>
				</port>
			</input>
			<output>
				<port id="1" precision="I64">
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1700" name="879/Rank/0d_rank_of/value/Output_0/Data__const1802_const" type="Const" version="opset1">
			<data element_type="i64" offset="32" shape="1" size="8"/>
			<output>
				<port id="0" precision="I64">
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1701" name="879/Rank" type="Squeeze" version="opset1">
			<input>
				<port id="0">
					<dim>1</dim>
				</port>
				<port id="1">
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="I64"/>
			</output>
		</layer>
		<layer id="1702" name="879/Range_input_port_2/value/Output_0/Data__const1804_const" type="Const" version="opset1">
			<data element_type="i64" offset="0" shape="" size="8"/>
			<output>
				<port id="0" precision="I64"/>
			</output>
		</layer>
		<layer id="1703" name="879/Range" type="Range" version="opset4">
			<data output_type="i64"/>
			<input>
				<port id="0"/>
				<port id="1"/>
				<port id="2"/>
			</input>
			<output>
				<port id="3" precision="I64">
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1704" name="879/Ins_Norm/MVN_" type="MVN" version="opset6">
			<data eps="9.999999747378752e-06" eps_mode="inside_sqrt" normalize_variance="true"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>16</dim>
					<dim>6</dim>
				</port>
				<port id="1">
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>1</dim>
					<dim>16</dim>
					<dim>6</dim>
				</port>
			</output>
		</layer>
		<layer id="1705" name="877/EltwiseUnsqueeze23030_const1807_const" type="Const" version="opset1">
			<data element_type="f16" offset="129732" shape="1,16,1" size="32"/>
			<output>
				<port id="0" names="877" precision="FP16">
					<dim>1</dim>
					<dim>16</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1706" name="879/Ins_Norm/mul_" type="Multiply" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>16</dim>
					<dim>6</dim>
				</port>
				<port id="1">
					<dim>1</dim>
					<dim>16</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>1</dim>
					<dim>16</dim>
					<dim>6</dim>
				</port>
			</output>
		</layer>
		<layer id="1707" name="878/EltwiseUnsqueeze23034_const1809_const" type="Const" version="opset1">
			<data element_type="f16" offset="129764" shape="1,16,1" size="32"/>
			<output>
				<port id="0" names="878" precision="FP16">
					<dim>1</dim>
					<dim>16</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1708" name="879" type="Add" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>16</dim>
					<dim>6</dim>
				</port>
				<port id="1">
					<dim>1</dim>
					<dim>16</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" names="879" precision="FP16">
					<dim>1</dim>
					<dim>16</dim>
					<dim>6</dim>
				</port>
			</output>
		</layer>
		<layer id="1709" name="1093810942_const" type="Const" version="opset1">
			<data element_type="f16" offset="596056" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="1710" name="1093910943_const" type="Const" version="opset1">
			<data element_type="f16" offset="596058" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="1711" name="1094010944_const" type="Const" version="opset1">
			<data element_type="f16" offset="596056" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="1712" name="1094110945_const" type="Const" version="opset1">
			<data element_type="f16" offset="596058" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="1713" name="881/fq_input_0" type="FakeQuantize" version="opset1">
			<data auto_broadcast="numpy" levels="256"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>16</dim>
					<dim>6</dim>
				</port>
				<port id="1"/>
				<port id="2"/>
				<port id="3"/>
				<port id="4"/>
			</input>
			<output>
				<port id="5" precision="FP16">
					<dim>1</dim>
					<dim>16</dim>
					<dim>6</dim>
				</port>
			</output>
		</layer>
		<layer id="1714" name="880" type="ShapeOf" version="opset3">
			<data output_type="i64"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="1" names="880" precision="I64">
					<dim>4</dim>
				</port>
			</output>
		</layer>
		<layer id="1715" name="881" type="Reshape" version="opset1">
			<data special_zero="true"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>16</dim>
					<dim>6</dim>
				</port>
				<port id="1">
					<dim>4</dim>
				</port>
			</input>
			<output>
				<port id="2" names="881" precision="FP16">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1716" name="882/Unsqueeze/EltwiseUnsqueeze22902_const1813_const" type="Const" version="opset1">
			<data element_type="f16" offset="596060" shape="1,96,1,1" size="192"/>
			<output>
				<port id="0" names="882" precision="FP16">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1717" name="883" type="Multiply" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="1">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" names="883" precision="FP16">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1718" name="884/Unsqueeze/EltwiseUnsqueeze22906_const1815_const" type="Const" version="opset1">
			<data element_type="f16" offset="596252" shape="1,96,1,1" size="192"/>
			<output>
				<port id="0" names="884" precision="FP16">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1719" name="885" type="Add" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="1">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" names="885" precision="FP16">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1720" name="886" type="Sigmoid" version="opset1">
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="1" names="886" precision="FP16">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1721" name="43174321_const" type="Const" version="opset1">
			<data element_type="f16" offset="10108" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="1722" name="43184322_const" type="Const" version="opset1">
			<data element_type="f16" offset="596444" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="1723" name="43194323_const" type="Const" version="opset1">
			<data element_type="f16" offset="10108" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="1724" name="43204324_const" type="Const" version="opset1">
			<data element_type="f16" offset="596444" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="1725" name="887/fq_input_1" type="FakeQuantize" version="opset1">
			<data auto_broadcast="numpy" levels="256"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="1"/>
				<port id="2"/>
				<port id="3"/>
				<port id="4"/>
			</input>
			<output>
				<port id="5" precision="FP16">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1726" name="887" type="Multiply" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
				<port id="1">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" names="887" precision="FP16">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
			</output>
		</layer>
		<layer id="1727" name="64376441_const" type="Const" version="opset1">
			<data element_type="f16" offset="10108" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="1728" name="64386442_const" type="Const" version="opset1">
			<data element_type="f16" offset="596446" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="1729" name="64396443_const" type="Const" version="opset1">
			<data element_type="f16" offset="10108" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="1730" name="64406444_const" type="Const" version="opset1">
			<data element_type="f16" offset="596446" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="1731" name="902/fq_input_0" type="FakeQuantize" version="opset1">
			<data auto_broadcast="numpy" levels="256"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
				<port id="1"/>
				<port id="2"/>
				<port id="3"/>
				<port id="4"/>
			</input>
			<output>
				<port id="5" precision="FP16">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
			</output>
		</layer>
		<layer id="1732" name="conv3.1.conv2b.0.conv1.weight/quantized19851_const" type="Const" version="opset1">
			<data element_type="i8" offset="596448" shape="96,96,1,1" size="9216"/>
			<output>
				<port id="0" precision="I8">
					<dim>96</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1733" name="conv3.1.conv2b.0.conv1.weight/quantized/to_f16" type="Convert" version="opset1">
			<data destination_type="f16"/>
			<input>
				<port id="0">
					<dim>96</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="1" precision="FP16">
					<dim>96</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1734" name="838/fq_weights_1/zero_point19864_const" type="Const" version="opset1">
			<data element_type="f16" offset="605664" shape="96,1,1,1" size="192"/>
			<output>
				<port id="0" precision="FP16">
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1735" name="838/fq_weights_1/minus_zp" type="Subtract" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>96</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="1">
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>96</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1736" name="838/fq_weights_1/scale19859_const" type="Const" version="opset1">
			<data element_type="f16" offset="605856" shape="96,1,1,1" size="192"/>
			<output>
				<port id="0" precision="FP16">
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1737" name="838/fq_weights_1/mulpiply_by_scale" type="Multiply" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>96</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="1">
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>96</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1738" name="838" type="Convolution" version="opset1">
			<data auto_pad="explicit" dilations="1,1" pads_begin="0,0" pads_end="0,0" strides="1,1"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
				<port id="1">
					<dim>96</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" names="838" precision="FP16">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
			</output>
		</layer>
		<layer id="1739" name="29962998_const" type="Const" version="opset1">
			<data element_type="f16" offset="299980" shape="1,96,1,1" size="192"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1740" name="838/add_" type="Add" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
				<port id="1">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
			</output>
		</layer>
		<layer id="1741" name="72277231_const" type="Const" version="opset1">
			<data element_type="f16" offset="606048" shape="1,96,1,1" size="192"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1742" name="72287232_const" type="Const" version="opset1">
			<data element_type="f16" offset="606240" shape="1,96,1,1" size="192"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1743" name="72297233_const" type="Const" version="opset1">
			<data element_type="f16" offset="606048" shape="1,96,1,1" size="192"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1744" name="72307234_const" type="Const" version="opset1">
			<data element_type="f16" offset="606240" shape="1,96,1,1" size="192"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1745" name="839/fq_input_0" type="FakeQuantize" version="opset1">
			<data auto_broadcast="numpy" levels="256"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
				<port id="1">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="2">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="3">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="4">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="5" precision="FP16">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
			</output>
		</layer>
		<layer id="1746" name="4207542078_const182115552/quantized20475_const" type="Const" version="opset1">
			<data element_type="i8" offset="606432" shape="96,1,3,3" size="864"/>
			<output>
				<port id="0" precision="I8">
					<dim>96</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</output>
		</layer>
		<layer id="1747" name="4207542078_const182115552/quantized/to_f16" type="Convert" version="opset1">
			<data destination_type="f16"/>
			<input>
				<port id="0">
					<dim>96</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</input>
			<output>
				<port id="1" precision="FP16">
					<dim>96</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</output>
		</layer>
		<layer id="1748" name="839/fq_weights_1/zero_point20488_const" type="Const" version="opset1">
			<data element_type="f16" offset="607296" shape="96,1,1,1" size="192"/>
			<output>
				<port id="0" precision="FP16">
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1749" name="839/fq_weights_1/minus_zp" type="Subtract" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>96</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
				<port id="1">
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>96</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</output>
		</layer>
		<layer id="1750" name="839/fq_weights_1/scale20483_const" type="Const" version="opset1">
			<data element_type="f16" offset="607488" shape="96,1,1,1" size="192"/>
			<output>
				<port id="0" precision="FP16">
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1751" name="839/fq_weights_1/mulpiply_by_scale" type="Multiply" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>96</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
				<port id="1">
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>96</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</output>
		</layer>
		<layer id="1752" name="24488/value24490_const" type="Const" version="opset1">
			<data element_type="i64" offset="301804" shape="5" size="40"/>
			<output>
				<port id="0" precision="I64">
					<dim>5</dim>
				</port>
			</output>
		</layer>
		<layer id="1753" name="24488" type="Reshape" version="opset1">
			<data special_zero="true"/>
			<input>
				<port id="0">
					<dim>96</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
				<port id="1">
					<dim>5</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</output>
		</layer>
		<layer id="1754" name="839" type="GroupConvolution" version="opset1">
			<data auto_pad="explicit" dilations="1,1" pads_begin="1,1" pads_end="1,1" strides="1,1"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
				<port id="1">
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
			</output>
		</layer>
		<layer id="1755" name="data_add_220692207422804/EltwiseUnsqueeze23562_const1823_const" type="Const" version="opset1">
			<data element_type="f16" offset="607680" shape="1,96,1,1" size="192"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1756" name="840/variance/Fused_Add_" type="Add" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
				<port id="1">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" names="840" precision="FP16">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
			</output>
		</layer>
		<layer id="1757" name="841" type="ReLU" version="opset1">
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
			</input>
			<output>
				<port id="1" names="841" precision="FP16">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
			</output>
		</layer>
		<layer id="1758" name="83178321_const" type="Const" version="opset1">
			<data element_type="f16" offset="10108" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="1759" name="83188322_const" type="Const" version="opset1">
			<data element_type="f16" offset="607872" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="1760" name="83198323_const" type="Const" version="opset1">
			<data element_type="f16" offset="10108" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="1761" name="83208324_const" type="Const" version="opset1">
			<data element_type="f16" offset="607872" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="1762" name="842/fq_input_0" type="FakeQuantize" version="opset1">
			<data auto_broadcast="numpy" levels="256"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
				<port id="1"/>
				<port id="2"/>
				<port id="3"/>
				<port id="4"/>
			</input>
			<output>
				<port id="5" precision="FP16">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
			</output>
		</layer>
		<layer id="1763" name="conv3.1.conv2b.1.conv1.weight/quantized20619_const" type="Const" version="opset1">
			<data element_type="i8" offset="607874" shape="96,96,1,1" size="9216"/>
			<output>
				<port id="0" precision="I8">
					<dim>96</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1764" name="conv3.1.conv2b.1.conv1.weight/quantized/to_f16" type="Convert" version="opset1">
			<data destination_type="f16"/>
			<input>
				<port id="0">
					<dim>96</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="1" precision="FP16">
					<dim>96</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1765" name="842/fq_weights_1/zero_point20632_const" type="Const" version="opset1">
			<data element_type="f16" offset="617090" shape="96,1,1,1" size="192"/>
			<output>
				<port id="0" precision="FP16">
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1766" name="842/fq_weights_1/minus_zp" type="Subtract" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>96</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="1">
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>96</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1767" name="842/fq_weights_1/scale20627_const" type="Const" version="opset1">
			<data element_type="f16" offset="617282" shape="96,1,1,1" size="192"/>
			<output>
				<port id="0" precision="FP16">
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1768" name="842/fq_weights_1/mulpiply_by_scale" type="Multiply" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>96</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="1">
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>96</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1769" name="842" type="Convolution" version="opset1">
			<data auto_pad="explicit" dilations="1,1" pads_begin="0,0" pads_end="0,0" strides="1,1"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
				<port id="1">
					<dim>96</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" names="842" precision="FP16">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
			</output>
		</layer>
		<layer id="1770" name="30003002_const" type="Const" version="opset1">
			<data element_type="f16" offset="299980" shape="1,96,1,1" size="192"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1771" name="842/add_" type="Add" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
				<port id="1">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
			</output>
		</layer>
		<layer id="1772" name="61376141_const" type="Const" version="opset1">
			<data element_type="f16" offset="617474" shape="1,96,1,1" size="192"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1773" name="61386142_const" type="Const" version="opset1">
			<data element_type="f16" offset="617666" shape="1,96,1,1" size="192"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1774" name="61396143_const" type="Const" version="opset1">
			<data element_type="f16" offset="617474" shape="1,96,1,1" size="192"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1775" name="61406144_const" type="Const" version="opset1">
			<data element_type="f16" offset="617666" shape="1,96,1,1" size="192"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1776" name="843/fq_input_0" type="FakeQuantize" version="opset1">
			<data auto_broadcast="numpy" levels="256"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
				<port id="1">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="2">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="3">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="4">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="5" precision="FP16">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
			</output>
		</layer>
		<layer id="1777" name="4209542098_const182815555/quantized18411_const" type="Const" version="opset1">
			<data element_type="i8" offset="617858" shape="96,1,3,3" size="864"/>
			<output>
				<port id="0" precision="I8">
					<dim>96</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</output>
		</layer>
		<layer id="1778" name="4209542098_const182815555/quantized/to_f16" type="Convert" version="opset1">
			<data destination_type="f16"/>
			<input>
				<port id="0">
					<dim>96</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</input>
			<output>
				<port id="1" precision="FP16">
					<dim>96</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</output>
		</layer>
		<layer id="1779" name="843/fq_weights_1/zero_point18424_const" type="Const" version="opset1">
			<data element_type="f16" offset="618722" shape="96,1,1,1" size="192"/>
			<output>
				<port id="0" precision="FP16">
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1780" name="843/fq_weights_1/minus_zp" type="Subtract" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>96</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
				<port id="1">
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>96</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</output>
		</layer>
		<layer id="1781" name="843/fq_weights_1/scale18419_const" type="Const" version="opset1">
			<data element_type="f16" offset="618914" shape="96,1,1,1" size="192"/>
			<output>
				<port id="0" precision="FP16">
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1782" name="843/fq_weights_1/mulpiply_by_scale" type="Multiply" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>96</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
				<port id="1">
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>96</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</output>
		</layer>
		<layer id="1783" name="24528/value24530_const" type="Const" version="opset1">
			<data element_type="i64" offset="301804" shape="5" size="40"/>
			<output>
				<port id="0" precision="I64">
					<dim>5</dim>
				</port>
			</output>
		</layer>
		<layer id="1784" name="24528" type="Reshape" version="opset1">
			<data special_zero="true"/>
			<input>
				<port id="0">
					<dim>96</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
				<port id="1">
					<dim>5</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</output>
		</layer>
		<layer id="1785" name="843" type="GroupConvolution" version="opset1">
			<data auto_pad="explicit" dilations="1,1" pads_begin="1,1" pads_end="1,1" strides="1,1"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
				<port id="1">
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
			</output>
		</layer>
		<layer id="1786" name="data_add_220772208222806/EltwiseUnsqueeze23570_const1830_const" type="Const" version="opset1">
			<data element_type="f16" offset="619106" shape="1,96,1,1" size="192"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1787" name="844/variance/Fused_Add_" type="Add" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
				<port id="1">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" names="844" precision="FP16">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
			</output>
		</layer>
		<layer id="1788" name="845" type="ReLU" version="opset1">
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
			</input>
			<output>
				<port id="1" names="845" precision="FP16">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
			</output>
		</layer>
		<layer id="1789" name="61676171_const" type="Const" version="opset1">
			<data element_type="f16" offset="10108" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="1790" name="61686172_const" type="Const" version="opset1">
			<data element_type="f16" offset="619298" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="1791" name="61696173_const" type="Const" version="opset1">
			<data element_type="f16" offset="10108" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="1792" name="61706174_const" type="Const" version="opset1">
			<data element_type="f16" offset="619298" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="1793" name="888/reduce/fq_input_0" type="FakeQuantize" version="opset1">
			<data auto_broadcast="numpy" levels="256"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
				<port id="1"/>
				<port id="2"/>
				<port id="3"/>
				<port id="4"/>
			</input>
			<output>
				<port id="5" precision="FP16">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
			</output>
		</layer>
		<layer id="1794" name="1389/Output_0/Data__const1833_const" type="Const" version="opset1">
			<data element_type="i64" offset="24" shape="" size="8"/>
			<output>
				<port id="0" precision="I64"/>
			</output>
		</layer>
		<layer id="1795" name="888/input_rank/shape_of" type="ShapeOf" version="opset3">
			<data output_type="i64"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
			</input>
			<output>
				<port id="1" precision="I64">
					<dim>4</dim>
				</port>
			</output>
		</layer>
		<layer id="1796" name="888/input_rank/rank_of" type="ShapeOf" version="opset3">
			<data output_type="i64"/>
			<input>
				<port id="0">
					<dim>4</dim>
				</port>
			</input>
			<output>
				<port id="1" precision="I64">
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1797" name="888/input_rank/0d_rank_of/value/Output_0/Data__const1836_const" type="Const" version="opset1">
			<data element_type="i64" offset="32" shape="1" size="8"/>
			<output>
				<port id="0" precision="I64">
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1798" name="888/input_rank" type="Squeeze" version="opset1">
			<input>
				<port id="0">
					<dim>1</dim>
				</port>
				<port id="1">
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="I64"/>
			</output>
		</layer>
		<layer id="1799" name="1391/Output_0/Data__const1838_const" type="Const" version="opset1">
			<data element_type="i64" offset="0" shape="" size="8"/>
			<output>
				<port id="0" precision="I64"/>
			</output>
		</layer>
		<layer id="1800" name="888/global_pooling_reduce_axis" type="Range" version="opset4">
			<data output_type="i64"/>
			<input>
				<port id="0"/>
				<port id="1"/>
				<port id="2"/>
			</input>
			<output>
				<port id="3" precision="I64">
					<dim>2</dim>
				</port>
			</output>
		</layer>
		<layer id="1801" name="888/reduce" type="ReduceMean" version="opset1">
			<data keep_dims="true"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
				<port id="1">
					<dim>2</dim>
				</port>
			</input>
			<output>
				<port id="2" names="888" precision="FP16">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1802" name="1094810952_const" type="Const" version="opset1">
			<data element_type="f16" offset="10108" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="1803" name="1094910953_const" type="Const" version="opset1">
			<data element_type="f16" offset="619300" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="1804" name="1095010954_const" type="Const" version="opset1">
			<data element_type="f16" offset="10108" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="1805" name="1095110955_const" type="Const" version="opset1">
			<data element_type="f16" offset="619300" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="1806" name="890/fq_input_0" type="FakeQuantize" version="opset1">
			<data auto_broadcast="numpy" levels="256"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="1"/>
				<port id="2"/>
				<port id="3"/>
				<port id="4"/>
			</input>
			<output>
				<port id="5" precision="FP16">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1807" name="890/Cast_143296_const1841_const" type="Const" version="opset1">
			<data element_type="i64" offset="129708" shape="3" size="24"/>
			<output>
				<port id="0" names="889" precision="I64">
					<dim>3</dim>
				</port>
			</output>
		</layer>
		<layer id="1808" name="890" type="Reshape" version="opset1">
			<data special_zero="true"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="1">
					<dim>3</dim>
				</port>
			</input>
			<output>
				<port id="2" names="890" precision="FP16">
					<dim>1</dim>
					<dim>16</dim>
					<dim>6</dim>
				</port>
			</output>
		</layer>
		<layer id="1809" name="893/Range_input_port_0/value/Output_0/Data__const1843_const" type="Const" version="opset1">
			<data element_type="i64" offset="24" shape="" size="8"/>
			<output>
				<port id="0" precision="I64"/>
			</output>
		</layer>
		<layer id="1810" name="893/Rank/shape_of" type="ShapeOf" version="opset3">
			<data output_type="i64"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>16</dim>
					<dim>6</dim>
				</port>
			</input>
			<output>
				<port id="1" precision="I64">
					<dim>3</dim>
				</port>
			</output>
		</layer>
		<layer id="1811" name="893/Rank/rank_of" type="ShapeOf" version="opset3">
			<data output_type="i64"/>
			<input>
				<port id="0">
					<dim>3</dim>
				</port>
			</input>
			<output>
				<port id="1" precision="I64">
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1812" name="893/Rank/0d_rank_of/value/Output_0/Data__const1846_const" type="Const" version="opset1">
			<data element_type="i64" offset="32" shape="1" size="8"/>
			<output>
				<port id="0" precision="I64">
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1813" name="893/Rank" type="Squeeze" version="opset1">
			<input>
				<port id="0">
					<dim>1</dim>
				</port>
				<port id="1">
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="I64"/>
			</output>
		</layer>
		<layer id="1814" name="893/Range_input_port_2/value/Output_0/Data__const1848_const" type="Const" version="opset1">
			<data element_type="i64" offset="0" shape="" size="8"/>
			<output>
				<port id="0" precision="I64"/>
			</output>
		</layer>
		<layer id="1815" name="893/Range" type="Range" version="opset4">
			<data output_type="i64"/>
			<input>
				<port id="0"/>
				<port id="1"/>
				<port id="2"/>
			</input>
			<output>
				<port id="3" precision="I64">
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1816" name="893/Ins_Norm/MVN_" type="MVN" version="opset6">
			<data eps="9.999999747378752e-06" eps_mode="inside_sqrt" normalize_variance="true"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>16</dim>
					<dim>6</dim>
				</port>
				<port id="1">
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>1</dim>
					<dim>16</dim>
					<dim>6</dim>
				</port>
			</output>
		</layer>
		<layer id="1817" name="891/EltwiseUnsqueeze23014_const1851_const" type="Const" version="opset1">
			<data element_type="f16" offset="129732" shape="1,16,1" size="32"/>
			<output>
				<port id="0" names="891" precision="FP16">
					<dim>1</dim>
					<dim>16</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1818" name="893/Ins_Norm/mul_" type="Multiply" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>16</dim>
					<dim>6</dim>
				</port>
				<port id="1">
					<dim>1</dim>
					<dim>16</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>1</dim>
					<dim>16</dim>
					<dim>6</dim>
				</port>
			</output>
		</layer>
		<layer id="1819" name="892/EltwiseUnsqueeze23018_const1853_const" type="Const" version="opset1">
			<data element_type="f16" offset="129764" shape="1,16,1" size="32"/>
			<output>
				<port id="0" names="892" precision="FP16">
					<dim>1</dim>
					<dim>16</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1820" name="893" type="Add" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>16</dim>
					<dim>6</dim>
				</port>
				<port id="1">
					<dim>1</dim>
					<dim>16</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" names="893" precision="FP16">
					<dim>1</dim>
					<dim>16</dim>
					<dim>6</dim>
				</port>
			</output>
		</layer>
		<layer id="1821" name="1095810962_const" type="Const" version="opset1">
			<data element_type="f16" offset="619302" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="1822" name="1095910963_const" type="Const" version="opset1">
			<data element_type="f16" offset="619304" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="1823" name="1096010964_const" type="Const" version="opset1">
			<data element_type="f16" offset="619302" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="1824" name="1096110965_const" type="Const" version="opset1">
			<data element_type="f16" offset="619304" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="1825" name="895/fq_input_0" type="FakeQuantize" version="opset1">
			<data auto_broadcast="numpy" levels="256"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>16</dim>
					<dim>6</dim>
				</port>
				<port id="1"/>
				<port id="2"/>
				<port id="3"/>
				<port id="4"/>
			</input>
			<output>
				<port id="5" precision="FP16">
					<dim>1</dim>
					<dim>16</dim>
					<dim>6</dim>
				</port>
			</output>
		</layer>
		<layer id="1826" name="894" type="ShapeOf" version="opset3">
			<data output_type="i64"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="1" names="894" precision="I64">
					<dim>4</dim>
				</port>
			</output>
		</layer>
		<layer id="1827" name="895" type="Reshape" version="opset1">
			<data special_zero="true"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>16</dim>
					<dim>6</dim>
				</port>
				<port id="1">
					<dim>4</dim>
				</port>
			</input>
			<output>
				<port id="2" names="895" precision="FP16">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1828" name="896/Unsqueeze/EltwiseUnsqueeze22910_const1857_const" type="Const" version="opset1">
			<data element_type="f16" offset="596060" shape="1,96,1,1" size="192"/>
			<output>
				<port id="0" names="896" precision="FP16">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1829" name="897" type="Multiply" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="1">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" names="897" precision="FP16">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1830" name="898/Unsqueeze/EltwiseUnsqueeze22914_const1859_const" type="Const" version="opset1">
			<data element_type="f16" offset="596252" shape="1,96,1,1" size="192"/>
			<output>
				<port id="0" names="898" precision="FP16">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1831" name="899" type="Add" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="1">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" names="899" precision="FP16">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1832" name="900" type="Sigmoid" version="opset1">
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="1" names="900" precision="FP16">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1833" name="69576961_const" type="Const" version="opset1">
			<data element_type="f16" offset="10108" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="1834" name="69586962_const" type="Const" version="opset1">
			<data element_type="f16" offset="619306" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="1835" name="69596963_const" type="Const" version="opset1">
			<data element_type="f16" offset="10108" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="1836" name="69606964_const" type="Const" version="opset1">
			<data element_type="f16" offset="619306" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="1837" name="901/fq_input_1" type="FakeQuantize" version="opset1">
			<data auto_broadcast="numpy" levels="256"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="1"/>
				<port id="2"/>
				<port id="3"/>
				<port id="4"/>
			</input>
			<output>
				<port id="5" precision="FP16">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1838" name="901" type="Multiply" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
				<port id="1">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" names="901" precision="FP16">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
			</output>
		</layer>
		<layer id="1839" name="64476451_const" type="Const" version="opset1">
			<data element_type="f16" offset="10108" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="1840" name="64486452_const" type="Const" version="opset1">
			<data element_type="f16" offset="619308" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="1841" name="64496453_const" type="Const" version="opset1">
			<data element_type="f16" offset="10108" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="1842" name="64506454_const" type="Const" version="opset1">
			<data element_type="f16" offset="619308" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="1843" name="902/fq_input_1" type="FakeQuantize" version="opset1">
			<data auto_broadcast="numpy" levels="256"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
				<port id="1"/>
				<port id="2"/>
				<port id="3"/>
				<port id="4"/>
			</input>
			<output>
				<port id="5" precision="FP16">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
			</output>
		</layer>
		<layer id="1844" name="902" type="Add" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
				<port id="1">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
			</input>
			<output>
				<port id="2" names="902" precision="FP16">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
			</output>
		</layer>
		<layer id="1845" name="71877191_const" type="Const" version="opset1">
			<data element_type="f16" offset="10108" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="1846" name="71887192_const" type="Const" version="opset1">
			<data element_type="f16" offset="619310" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="1847" name="71897193_const" type="Const" version="opset1">
			<data element_type="f16" offset="10108" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="1848" name="71907194_const" type="Const" version="opset1">
			<data element_type="f16" offset="619310" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="1849" name="917/fq_input_0" type="FakeQuantize" version="opset1">
			<data auto_broadcast="numpy" levels="256"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
				<port id="1"/>
				<port id="2"/>
				<port id="3"/>
				<port id="4"/>
			</input>
			<output>
				<port id="5" precision="FP16">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
			</output>
		</layer>
		<layer id="1850" name="conv3.1.conv2c.0.conv1.weight/quantized18387_const" type="Const" version="opset1">
			<data element_type="i8" offset="619312" shape="96,96,1,1" size="9216"/>
			<output>
				<port id="0" precision="I8">
					<dim>96</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1851" name="conv3.1.conv2c.0.conv1.weight/quantized/to_f16" type="Convert" version="opset1">
			<data destination_type="f16"/>
			<input>
				<port id="0">
					<dim>96</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="1" precision="FP16">
					<dim>96</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1852" name="846/fq_weights_1/zero_point18400_const" type="Const" version="opset1">
			<data element_type="f16" offset="628528" shape="96,1,1,1" size="192"/>
			<output>
				<port id="0" precision="FP16">
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1853" name="846/fq_weights_1/minus_zp" type="Subtract" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>96</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="1">
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>96</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1854" name="846/fq_weights_1/scale18395_const" type="Const" version="opset1">
			<data element_type="f16" offset="628720" shape="96,1,1,1" size="192"/>
			<output>
				<port id="0" precision="FP16">
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1855" name="846/fq_weights_1/mulpiply_by_scale" type="Multiply" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>96</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="1">
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>96</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1856" name="846" type="Convolution" version="opset1">
			<data auto_pad="explicit" dilations="1,1" pads_begin="0,0" pads_end="0,0" strides="1,1"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
				<port id="1">
					<dim>96</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" names="846" precision="FP16">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
			</output>
		</layer>
		<layer id="1857" name="30043006_const" type="Const" version="opset1">
			<data element_type="f16" offset="299980" shape="1,96,1,1" size="192"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1858" name="846/add_" type="Add" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
				<port id="1">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
			</output>
		</layer>
		<layer id="1859" name="76977701_const" type="Const" version="opset1">
			<data element_type="f16" offset="628912" shape="1,96,1,1" size="192"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1860" name="76987702_const" type="Const" version="opset1">
			<data element_type="f16" offset="629104" shape="1,96,1,1" size="192"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1861" name="76997703_const" type="Const" version="opset1">
			<data element_type="f16" offset="628912" shape="1,96,1,1" size="192"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1862" name="77007704_const" type="Const" version="opset1">
			<data element_type="f16" offset="629104" shape="1,96,1,1" size="192"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1863" name="847/fq_input_0" type="FakeQuantize" version="opset1">
			<data auto_broadcast="numpy" levels="256"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
				<port id="1">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="2">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="3">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="4">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="5" precision="FP16">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
			</output>
		</layer>
		<layer id="1864" name="4209942102_const186615569/quantized20715_const" type="Const" version="opset1">
			<data element_type="i8" offset="629296" shape="96,1,3,3" size="864"/>
			<output>
				<port id="0" precision="I8">
					<dim>96</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</output>
		</layer>
		<layer id="1865" name="4209942102_const186615569/quantized/to_f16" type="Convert" version="opset1">
			<data destination_type="f16"/>
			<input>
				<port id="0">
					<dim>96</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</input>
			<output>
				<port id="1" precision="FP16">
					<dim>96</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</output>
		</layer>
		<layer id="1866" name="847/fq_weights_1/zero_point20728_const" type="Const" version="opset1">
			<data element_type="f16" offset="630160" shape="96,1,1,1" size="192"/>
			<output>
				<port id="0" precision="FP16">
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1867" name="847/fq_weights_1/minus_zp" type="Subtract" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>96</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
				<port id="1">
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>96</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</output>
		</layer>
		<layer id="1868" name="847/fq_weights_1/scale20723_const" type="Const" version="opset1">
			<data element_type="f16" offset="630352" shape="96,1,1,1" size="192"/>
			<output>
				<port id="0" precision="FP16">
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1869" name="847/fq_weights_1/mulpiply_by_scale" type="Multiply" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>96</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
				<port id="1">
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>96</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</output>
		</layer>
		<layer id="1870" name="24500/value24502_const" type="Const" version="opset1">
			<data element_type="i64" offset="301804" shape="5" size="40"/>
			<output>
				<port id="0" precision="I64">
					<dim>5</dim>
				</port>
			</output>
		</layer>
		<layer id="1871" name="24500" type="Reshape" version="opset1">
			<data special_zero="true"/>
			<input>
				<port id="0">
					<dim>96</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
				<port id="1">
					<dim>5</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</output>
		</layer>
		<layer id="1872" name="847" type="GroupConvolution" version="opset1">
			<data auto_pad="explicit" dilations="1,1" pads_begin="1,1" pads_end="1,1" strides="1,1"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
				<port id="1">
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
			</output>
		</layer>
		<layer id="1873" name="data_add_220452205022798/EltwiseUnsqueeze23538_const1868_const" type="Const" version="opset1">
			<data element_type="f16" offset="630544" shape="1,96,1,1" size="192"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1874" name="848/variance/Fused_Add_" type="Add" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
				<port id="1">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" names="848" precision="FP16">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
			</output>
		</layer>
		<layer id="1875" name="849" type="ReLU" version="opset1">
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
			</input>
			<output>
				<port id="1" names="849" precision="FP16">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
			</output>
		</layer>
		<layer id="1876" name="58175821_const" type="Const" version="opset1">
			<data element_type="f16" offset="10108" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="1877" name="58185822_const" type="Const" version="opset1">
			<data element_type="f16" offset="630736" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="1878" name="58195823_const" type="Const" version="opset1">
			<data element_type="f16" offset="10108" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="1879" name="58205824_const" type="Const" version="opset1">
			<data element_type="f16" offset="630736" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="1880" name="850/fq_input_0" type="FakeQuantize" version="opset1">
			<data auto_broadcast="numpy" levels="256"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
				<port id="1"/>
				<port id="2"/>
				<port id="3"/>
				<port id="4"/>
			</input>
			<output>
				<port id="5" precision="FP16">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
			</output>
		</layer>
		<layer id="1881" name="conv3.1.conv2c.1.conv1.weight/quantized18243_const" type="Const" version="opset1">
			<data element_type="i8" offset="630738" shape="96,96,1,1" size="9216"/>
			<output>
				<port id="0" precision="I8">
					<dim>96</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1882" name="conv3.1.conv2c.1.conv1.weight/quantized/to_f16" type="Convert" version="opset1">
			<data destination_type="f16"/>
			<input>
				<port id="0">
					<dim>96</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="1" precision="FP16">
					<dim>96</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1883" name="850/fq_weights_1/zero_point18256_const" type="Const" version="opset1">
			<data element_type="f16" offset="639954" shape="96,1,1,1" size="192"/>
			<output>
				<port id="0" precision="FP16">
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1884" name="850/fq_weights_1/minus_zp" type="Subtract" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>96</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="1">
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>96</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1885" name="850/fq_weights_1/scale18251_const" type="Const" version="opset1">
			<data element_type="f16" offset="640146" shape="96,1,1,1" size="192"/>
			<output>
				<port id="0" precision="FP16">
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1886" name="850/fq_weights_1/mulpiply_by_scale" type="Multiply" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>96</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="1">
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>96</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1887" name="850" type="Convolution" version="opset1">
			<data auto_pad="explicit" dilations="1,1" pads_begin="0,0" pads_end="0,0" strides="1,1"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
				<port id="1">
					<dim>96</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" names="850" precision="FP16">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
			</output>
		</layer>
		<layer id="1888" name="30083010_const" type="Const" version="opset1">
			<data element_type="f16" offset="299980" shape="1,96,1,1" size="192"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1889" name="850/add_" type="Add" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
				<port id="1">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
			</output>
		</layer>
		<layer id="1890" name="67176721_const" type="Const" version="opset1">
			<data element_type="f16" offset="640338" shape="1,96,1,1" size="192"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1891" name="67186722_const" type="Const" version="opset1">
			<data element_type="f16" offset="640530" shape="1,96,1,1" size="192"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1892" name="67196723_const" type="Const" version="opset1">
			<data element_type="f16" offset="640338" shape="1,96,1,1" size="192"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1893" name="67206724_const" type="Const" version="opset1">
			<data element_type="f16" offset="640530" shape="1,96,1,1" size="192"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1894" name="851/fq_input_0" type="FakeQuantize" version="opset1">
			<data auto_broadcast="numpy" levels="256"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
				<port id="1">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="2">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="3">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="4">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="5" precision="FP16">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
			</output>
		</layer>
		<layer id="1895" name="4222342226_const187315572/quantized19251_const" type="Const" version="opset1">
			<data element_type="i8" offset="640722" shape="96,1,3,3" size="864"/>
			<output>
				<port id="0" precision="I8">
					<dim>96</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</output>
		</layer>
		<layer id="1896" name="4222342226_const187315572/quantized/to_f16" type="Convert" version="opset1">
			<data destination_type="f16"/>
			<input>
				<port id="0">
					<dim>96</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</input>
			<output>
				<port id="1" precision="FP16">
					<dim>96</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</output>
		</layer>
		<layer id="1897" name="851/fq_weights_1/zero_point19264_const" type="Const" version="opset1">
			<data element_type="f16" offset="641586" shape="96,1,1,1" size="192"/>
			<output>
				<port id="0" precision="FP16">
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1898" name="851/fq_weights_1/minus_zp" type="Subtract" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>96</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
				<port id="1">
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>96</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</output>
		</layer>
		<layer id="1899" name="851/fq_weights_1/scale19259_const" type="Const" version="opset1">
			<data element_type="f16" offset="641778" shape="96,1,1,1" size="192"/>
			<output>
				<port id="0" precision="FP16">
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1900" name="851/fq_weights_1/mulpiply_by_scale" type="Multiply" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>96</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
				<port id="1">
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>96</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</output>
		</layer>
		<layer id="1901" name="24544/value24546_const" type="Const" version="opset1">
			<data element_type="i64" offset="301804" shape="5" size="40"/>
			<output>
				<port id="0" precision="I64">
					<dim>5</dim>
				</port>
			</output>
		</layer>
		<layer id="1902" name="24544" type="Reshape" version="opset1">
			<data special_zero="true"/>
			<input>
				<port id="0">
					<dim>96</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
				<port id="1">
					<dim>5</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</output>
		</layer>
		<layer id="1903" name="851" type="GroupConvolution" version="opset1">
			<data auto_pad="explicit" dilations="1,1" pads_begin="1,1" pads_end="1,1" strides="1,1"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
				<port id="1">
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
			</output>
		</layer>
		<layer id="1904" name="data_add_220532205822800/EltwiseUnsqueeze23546_const1875_const" type="Const" version="opset1">
			<data element_type="f16" offset="641970" shape="1,96,1,1" size="192"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1905" name="852/variance/Fused_Add_" type="Add" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
				<port id="1">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" names="852" precision="FP16">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
			</output>
		</layer>
		<layer id="1906" name="853" type="ReLU" version="opset1">
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
			</input>
			<output>
				<port id="1" names="853" precision="FP16">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
			</output>
		</layer>
		<layer id="1907" name="48574861_const" type="Const" version="opset1">
			<data element_type="f16" offset="10108" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="1908" name="48584862_const" type="Const" version="opset1">
			<data element_type="f16" offset="642162" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="1909" name="48594863_const" type="Const" version="opset1">
			<data element_type="f16" offset="10108" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="1910" name="48604864_const" type="Const" version="opset1">
			<data element_type="f16" offset="642162" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="1911" name="854/fq_input_0" type="FakeQuantize" version="opset1">
			<data auto_broadcast="numpy" levels="256"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
				<port id="1"/>
				<port id="2"/>
				<port id="3"/>
				<port id="4"/>
			</input>
			<output>
				<port id="5" precision="FP16">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
			</output>
		</layer>
		<layer id="1912" name="conv3.1.conv2c.2.conv1.weight/quantized19539_const" type="Const" version="opset1">
			<data element_type="i8" offset="642164" shape="96,96,1,1" size="9216"/>
			<output>
				<port id="0" precision="I8">
					<dim>96</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1913" name="conv3.1.conv2c.2.conv1.weight/quantized/to_f16" type="Convert" version="opset1">
			<data destination_type="f16"/>
			<input>
				<port id="0">
					<dim>96</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="1" precision="FP16">
					<dim>96</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1914" name="854/fq_weights_1/zero_point19552_const" type="Const" version="opset1">
			<data element_type="f16" offset="651380" shape="96,1,1,1" size="192"/>
			<output>
				<port id="0" precision="FP16">
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1915" name="854/fq_weights_1/minus_zp" type="Subtract" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>96</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="1">
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>96</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1916" name="854/fq_weights_1/scale19547_const" type="Const" version="opset1">
			<data element_type="f16" offset="651572" shape="96,1,1,1" size="192"/>
			<output>
				<port id="0" precision="FP16">
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1917" name="854/fq_weights_1/mulpiply_by_scale" type="Multiply" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>96</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="1">
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>96</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1918" name="854" type="Convolution" version="opset1">
			<data auto_pad="explicit" dilations="1,1" pads_begin="0,0" pads_end="0,0" strides="1,1"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
				<port id="1">
					<dim>96</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" names="854" precision="FP16">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
			</output>
		</layer>
		<layer id="1919" name="30123014_const" type="Const" version="opset1">
			<data element_type="f16" offset="299980" shape="1,96,1,1" size="192"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1920" name="854/add_" type="Add" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
				<port id="1">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
			</output>
		</layer>
		<layer id="1921" name="50975101_const" type="Const" version="opset1">
			<data element_type="f16" offset="651764" shape="1,96,1,1" size="192"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1922" name="50985102_const" type="Const" version="opset1">
			<data element_type="f16" offset="651956" shape="1,96,1,1" size="192"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1923" name="50995103_const" type="Const" version="opset1">
			<data element_type="f16" offset="651764" shape="1,96,1,1" size="192"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1924" name="51005104_const" type="Const" version="opset1">
			<data element_type="f16" offset="651956" shape="1,96,1,1" size="192"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1925" name="855/fq_input_0" type="FakeQuantize" version="opset1">
			<data auto_broadcast="numpy" levels="256"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
				<port id="1">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="2">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="3">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="4">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="5" precision="FP16">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
			</output>
		</layer>
		<layer id="1926" name="4213542138_const188015575/quantized18171_const" type="Const" version="opset1">
			<data element_type="i8" offset="652148" shape="96,1,3,3" size="864"/>
			<output>
				<port id="0" precision="I8">
					<dim>96</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</output>
		</layer>
		<layer id="1927" name="4213542138_const188015575/quantized/to_f16" type="Convert" version="opset1">
			<data destination_type="f16"/>
			<input>
				<port id="0">
					<dim>96</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</input>
			<output>
				<port id="1" precision="FP16">
					<dim>96</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</output>
		</layer>
		<layer id="1928" name="855/fq_weights_1/zero_point18184_const" type="Const" version="opset1">
			<data element_type="f16" offset="653012" shape="96,1,1,1" size="192"/>
			<output>
				<port id="0" precision="FP16">
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1929" name="855/fq_weights_1/minus_zp" type="Subtract" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>96</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
				<port id="1">
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>96</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</output>
		</layer>
		<layer id="1930" name="855/fq_weights_1/scale18179_const" type="Const" version="opset1">
			<data element_type="f16" offset="653204" shape="96,1,1,1" size="192"/>
			<output>
				<port id="0" precision="FP16">
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1931" name="855/fq_weights_1/mulpiply_by_scale" type="Multiply" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>96</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
				<port id="1">
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>96</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</output>
		</layer>
		<layer id="1932" name="24472/value24474_const" type="Const" version="opset1">
			<data element_type="i64" offset="301804" shape="5" size="40"/>
			<output>
				<port id="0" precision="I64">
					<dim>5</dim>
				</port>
			</output>
		</layer>
		<layer id="1933" name="24472" type="Reshape" version="opset1">
			<data special_zero="true"/>
			<input>
				<port id="0">
					<dim>96</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
				<port id="1">
					<dim>5</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</output>
		</layer>
		<layer id="1934" name="855" type="GroupConvolution" version="opset1">
			<data auto_pad="explicit" dilations="1,1" pads_begin="1,1" pads_end="1,1" strides="1,1"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
				<port id="1">
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
			</output>
		</layer>
		<layer id="1935" name="data_add_220612206622802/EltwiseUnsqueeze23554_const1882_const" type="Const" version="opset1">
			<data element_type="f16" offset="653396" shape="1,96,1,1" size="192"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1936" name="856/variance/Fused_Add_" type="Add" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
				<port id="1">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" names="856" precision="FP16">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
			</output>
		</layer>
		<layer id="1937" name="857" type="ReLU" version="opset1">
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
			</input>
			<output>
				<port id="1" names="857" precision="FP16">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
			</output>
		</layer>
		<layer id="1938" name="75777581_const" type="Const" version="opset1">
			<data element_type="f16" offset="10108" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="1939" name="75787582_const" type="Const" version="opset1">
			<data element_type="f16" offset="653588" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="1940" name="75797583_const" type="Const" version="opset1">
			<data element_type="f16" offset="10108" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="1941" name="75807584_const" type="Const" version="opset1">
			<data element_type="f16" offset="653588" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="1942" name="903/reduce/fq_input_0" type="FakeQuantize" version="opset1">
			<data auto_broadcast="numpy" levels="256"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
				<port id="1"/>
				<port id="2"/>
				<port id="3"/>
				<port id="4"/>
			</input>
			<output>
				<port id="5" precision="FP16">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
			</output>
		</layer>
		<layer id="1943" name="1394/Output_0/Data__const1885_const" type="Const" version="opset1">
			<data element_type="i64" offset="24" shape="" size="8"/>
			<output>
				<port id="0" precision="I64"/>
			</output>
		</layer>
		<layer id="1944" name="903/input_rank/shape_of" type="ShapeOf" version="opset3">
			<data output_type="i64"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
			</input>
			<output>
				<port id="1" precision="I64">
					<dim>4</dim>
				</port>
			</output>
		</layer>
		<layer id="1945" name="903/input_rank/rank_of" type="ShapeOf" version="opset3">
			<data output_type="i64"/>
			<input>
				<port id="0">
					<dim>4</dim>
				</port>
			</input>
			<output>
				<port id="1" precision="I64">
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1946" name="903/input_rank/0d_rank_of/value/Output_0/Data__const1888_const" type="Const" version="opset1">
			<data element_type="i64" offset="32" shape="1" size="8"/>
			<output>
				<port id="0" precision="I64">
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1947" name="903/input_rank" type="Squeeze" version="opset1">
			<input>
				<port id="0">
					<dim>1</dim>
				</port>
				<port id="1">
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="I64"/>
			</output>
		</layer>
		<layer id="1948" name="1396/Output_0/Data__const1890_const" type="Const" version="opset1">
			<data element_type="i64" offset="0" shape="" size="8"/>
			<output>
				<port id="0" precision="I64"/>
			</output>
		</layer>
		<layer id="1949" name="903/global_pooling_reduce_axis" type="Range" version="opset4">
			<data output_type="i64"/>
			<input>
				<port id="0"/>
				<port id="1"/>
				<port id="2"/>
			</input>
			<output>
				<port id="3" precision="I64">
					<dim>2</dim>
				</port>
			</output>
		</layer>
		<layer id="1950" name="903/reduce" type="ReduceMean" version="opset1">
			<data keep_dims="true"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
				<port id="1">
					<dim>2</dim>
				</port>
			</input>
			<output>
				<port id="2" names="903" precision="FP16">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1951" name="1096810972_const" type="Const" version="opset1">
			<data element_type="f16" offset="10108" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="1952" name="1096910973_const" type="Const" version="opset1">
			<data element_type="f16" offset="129706" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="1953" name="1097010974_const" type="Const" version="opset1">
			<data element_type="f16" offset="10108" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="1954" name="1097110975_const" type="Const" version="opset1">
			<data element_type="f16" offset="129706" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="1955" name="905/fq_input_0" type="FakeQuantize" version="opset1">
			<data auto_broadcast="numpy" levels="256"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="1"/>
				<port id="2"/>
				<port id="3"/>
				<port id="4"/>
			</input>
			<output>
				<port id="5" precision="FP16">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1956" name="905/Cast_143268_const1893_const" type="Const" version="opset1">
			<data element_type="i64" offset="129708" shape="3" size="24"/>
			<output>
				<port id="0" names="904" precision="I64">
					<dim>3</dim>
				</port>
			</output>
		</layer>
		<layer id="1957" name="905" type="Reshape" version="opset1">
			<data special_zero="true"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="1">
					<dim>3</dim>
				</port>
			</input>
			<output>
				<port id="2" names="905" precision="FP16">
					<dim>1</dim>
					<dim>16</dim>
					<dim>6</dim>
				</port>
			</output>
		</layer>
		<layer id="1958" name="908/Range_input_port_0/value/Output_0/Data__const1895_const" type="Const" version="opset1">
			<data element_type="i64" offset="24" shape="" size="8"/>
			<output>
				<port id="0" precision="I64"/>
			</output>
		</layer>
		<layer id="1959" name="908/Rank/shape_of" type="ShapeOf" version="opset3">
			<data output_type="i64"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>16</dim>
					<dim>6</dim>
				</port>
			</input>
			<output>
				<port id="1" precision="I64">
					<dim>3</dim>
				</port>
			</output>
		</layer>
		<layer id="1960" name="908/Rank/rank_of" type="ShapeOf" version="opset3">
			<data output_type="i64"/>
			<input>
				<port id="0">
					<dim>3</dim>
				</port>
			</input>
			<output>
				<port id="1" precision="I64">
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1961" name="908/Rank/0d_rank_of/value/Output_0/Data__const1898_const" type="Const" version="opset1">
			<data element_type="i64" offset="32" shape="1" size="8"/>
			<output>
				<port id="0" precision="I64">
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1962" name="908/Rank" type="Squeeze" version="opset1">
			<input>
				<port id="0">
					<dim>1</dim>
				</port>
				<port id="1">
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="I64"/>
			</output>
		</layer>
		<layer id="1963" name="908/Range_input_port_2/value/Output_0/Data__const1900_const" type="Const" version="opset1">
			<data element_type="i64" offset="0" shape="" size="8"/>
			<output>
				<port id="0" precision="I64"/>
			</output>
		</layer>
		<layer id="1964" name="908/Range" type="Range" version="opset4">
			<data output_type="i64"/>
			<input>
				<port id="0"/>
				<port id="1"/>
				<port id="2"/>
			</input>
			<output>
				<port id="3" precision="I64">
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1965" name="908/Ins_Norm/MVN_" type="MVN" version="opset6">
			<data eps="9.999999747378752e-06" eps_mode="inside_sqrt" normalize_variance="true"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>16</dim>
					<dim>6</dim>
				</port>
				<port id="1">
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>1</dim>
					<dim>16</dim>
					<dim>6</dim>
				</port>
			</output>
		</layer>
		<layer id="1966" name="906/EltwiseUnsqueeze23022_const1903_const" type="Const" version="opset1">
			<data element_type="f16" offset="129732" shape="1,16,1" size="32"/>
			<output>
				<port id="0" names="906" precision="FP16">
					<dim>1</dim>
					<dim>16</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1967" name="908/Ins_Norm/mul_" type="Multiply" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>16</dim>
					<dim>6</dim>
				</port>
				<port id="1">
					<dim>1</dim>
					<dim>16</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>1</dim>
					<dim>16</dim>
					<dim>6</dim>
				</port>
			</output>
		</layer>
		<layer id="1968" name="907/EltwiseUnsqueeze23026_const1905_const" type="Const" version="opset1">
			<data element_type="f16" offset="129764" shape="1,16,1" size="32"/>
			<output>
				<port id="0" names="907" precision="FP16">
					<dim>1</dim>
					<dim>16</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1969" name="908" type="Add" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>16</dim>
					<dim>6</dim>
				</port>
				<port id="1">
					<dim>1</dim>
					<dim>16</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" names="908" precision="FP16">
					<dim>1</dim>
					<dim>16</dim>
					<dim>6</dim>
				</port>
			</output>
		</layer>
		<layer id="1970" name="1097810982_const" type="Const" version="opset1">
			<data element_type="f16" offset="653590" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="1971" name="1097910983_const" type="Const" version="opset1">
			<data element_type="f16" offset="653592" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="1972" name="1098010984_const" type="Const" version="opset1">
			<data element_type="f16" offset="653590" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="1973" name="1098110985_const" type="Const" version="opset1">
			<data element_type="f16" offset="653592" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="1974" name="910/fq_input_0" type="FakeQuantize" version="opset1">
			<data auto_broadcast="numpy" levels="256"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>16</dim>
					<dim>6</dim>
				</port>
				<port id="1"/>
				<port id="2"/>
				<port id="3"/>
				<port id="4"/>
			</input>
			<output>
				<port id="5" precision="FP16">
					<dim>1</dim>
					<dim>16</dim>
					<dim>6</dim>
				</port>
			</output>
		</layer>
		<layer id="1975" name="909" type="ShapeOf" version="opset3">
			<data output_type="i64"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="1" names="909" precision="I64">
					<dim>4</dim>
				</port>
			</output>
		</layer>
		<layer id="1976" name="910" type="Reshape" version="opset1">
			<data special_zero="true"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>16</dim>
					<dim>6</dim>
				</port>
				<port id="1">
					<dim>4</dim>
				</port>
			</input>
			<output>
				<port id="2" names="910" precision="FP16">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1977" name="911/Unsqueeze/EltwiseUnsqueeze22918_const1909_const" type="Const" version="opset1">
			<data element_type="f16" offset="596060" shape="1,96,1,1" size="192"/>
			<output>
				<port id="0" names="911" precision="FP16">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1978" name="912" type="Multiply" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="1">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" names="912" precision="FP16">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1979" name="913/Unsqueeze/EltwiseUnsqueeze22922_const1911_const" type="Const" version="opset1">
			<data element_type="f16" offset="596252" shape="1,96,1,1" size="192"/>
			<output>
				<port id="0" names="913" precision="FP16">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1980" name="914" type="Add" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="1">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" names="914" precision="FP16">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1981" name="915" type="Sigmoid" version="opset1">
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="1" names="915" precision="FP16">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1982" name="80178021_const" type="Const" version="opset1">
			<data element_type="f16" offset="10108" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="1983" name="80188022_const" type="Const" version="opset1">
			<data element_type="f16" offset="653594" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="1984" name="80198023_const" type="Const" version="opset1">
			<data element_type="f16" offset="10108" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="1985" name="80208024_const" type="Const" version="opset1">
			<data element_type="f16" offset="653594" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="1986" name="916/fq_input_1" type="FakeQuantize" version="opset1">
			<data auto_broadcast="numpy" levels="256"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="1"/>
				<port id="2"/>
				<port id="3"/>
				<port id="4"/>
			</input>
			<output>
				<port id="5" precision="FP16">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="1987" name="916" type="Multiply" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
				<port id="1">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" names="916" precision="FP16">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
			</output>
		</layer>
		<layer id="1988" name="71977201_const" type="Const" version="opset1">
			<data element_type="f16" offset="10108" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="1989" name="71987202_const" type="Const" version="opset1">
			<data element_type="f16" offset="653596" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="1990" name="71997203_const" type="Const" version="opset1">
			<data element_type="f16" offset="10108" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="1991" name="72007204_const" type="Const" version="opset1">
			<data element_type="f16" offset="653596" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="1992" name="917/fq_input_1" type="FakeQuantize" version="opset1">
			<data auto_broadcast="numpy" levels="256"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
				<port id="1"/>
				<port id="2"/>
				<port id="3"/>
				<port id="4"/>
			</input>
			<output>
				<port id="5" precision="FP16">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
			</output>
		</layer>
		<layer id="1993" name="917" type="Add" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
				<port id="1">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
			</input>
			<output>
				<port id="2" names="917" precision="FP16">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
			</output>
		</layer>
		<layer id="1994" name="71677171_const" type="Const" version="opset1">
			<data element_type="f16" offset="10108" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="1995" name="71687172_const" type="Const" version="opset1">
			<data element_type="f16" offset="653598" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="1996" name="71697173_const" type="Const" version="opset1">
			<data element_type="f16" offset="10108" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="1997" name="71707174_const" type="Const" version="opset1">
			<data element_type="f16" offset="653598" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="1998" name="932/fq_input_0" type="FakeQuantize" version="opset1">
			<data auto_broadcast="numpy" levels="256"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
				<port id="1"/>
				<port id="2"/>
				<port id="3"/>
				<port id="4"/>
			</input>
			<output>
				<port id="5" precision="FP16">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
			</output>
		</layer>
		<layer id="1999" name="conv3.1.conv2d.0.conv1.weight/quantized19491_const" type="Const" version="opset1">
			<data element_type="i8" offset="653600" shape="96,96,1,1" size="9216"/>
			<output>
				<port id="0" precision="I8">
					<dim>96</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2000" name="conv3.1.conv2d.0.conv1.weight/quantized/to_f16" type="Convert" version="opset1">
			<data destination_type="f16"/>
			<input>
				<port id="0">
					<dim>96</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="1" precision="FP16">
					<dim>96</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2001" name="858/fq_weights_1/zero_point19504_const" type="Const" version="opset1">
			<data element_type="f16" offset="662816" shape="96,1,1,1" size="192"/>
			<output>
				<port id="0" precision="FP16">
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2002" name="858/fq_weights_1/minus_zp" type="Subtract" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>96</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="1">
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>96</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2003" name="858/fq_weights_1/scale19499_const" type="Const" version="opset1">
			<data element_type="f16" offset="663008" shape="96,1,1,1" size="192"/>
			<output>
				<port id="0" precision="FP16">
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2004" name="858/fq_weights_1/mulpiply_by_scale" type="Multiply" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>96</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="1">
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>96</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2005" name="858" type="Convolution" version="opset1">
			<data auto_pad="explicit" dilations="1,1" pads_begin="0,0" pads_end="0,0" strides="1,1"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
				<port id="1">
					<dim>96</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" names="858" precision="FP16">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
			</output>
		</layer>
		<layer id="2006" name="30163018_const" type="Const" version="opset1">
			<data element_type="f16" offset="299980" shape="1,96,1,1" size="192"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2007" name="858/add_" type="Add" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
				<port id="1">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
			</output>
		</layer>
		<layer id="2008" name="43474351_const" type="Const" version="opset1">
			<data element_type="f16" offset="663200" shape="1,96,1,1" size="192"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2009" name="43484352_const" type="Const" version="opset1">
			<data element_type="f16" offset="663392" shape="1,96,1,1" size="192"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2010" name="43494353_const" type="Const" version="opset1">
			<data element_type="f16" offset="663200" shape="1,96,1,1" size="192"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2011" name="43504354_const" type="Const" version="opset1">
			<data element_type="f16" offset="663392" shape="1,96,1,1" size="192"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2012" name="859/fq_input_0" type="FakeQuantize" version="opset1">
			<data auto_broadcast="numpy" levels="256"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
				<port id="1">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="2">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="3">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="4">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="5" precision="FP16">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
			</output>
		</layer>
		<layer id="2013" name="4219142194_const191815589/quantized18195_const" type="Const" version="opset1">
			<data element_type="i8" offset="663584" shape="96,1,3,3" size="864"/>
			<output>
				<port id="0" precision="I8">
					<dim>96</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</output>
		</layer>
		<layer id="2014" name="4219142194_const191815589/quantized/to_f16" type="Convert" version="opset1">
			<data destination_type="f16"/>
			<input>
				<port id="0">
					<dim>96</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</input>
			<output>
				<port id="1" precision="FP16">
					<dim>96</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</output>
		</layer>
		<layer id="2015" name="859/fq_weights_1/zero_point18208_const" type="Const" version="opset1">
			<data element_type="f16" offset="664448" shape="96,1,1,1" size="192"/>
			<output>
				<port id="0" precision="FP16">
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2016" name="859/fq_weights_1/minus_zp" type="Subtract" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>96</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
				<port id="1">
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>96</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</output>
		</layer>
		<layer id="2017" name="859/fq_weights_1/scale18203_const" type="Const" version="opset1">
			<data element_type="f16" offset="664640" shape="96,1,1,1" size="192"/>
			<output>
				<port id="0" precision="FP16">
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2018" name="859/fq_weights_1/mulpiply_by_scale" type="Multiply" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>96</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
				<port id="1">
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>96</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</output>
		</layer>
		<layer id="2019" name="24376/value24378_const" type="Const" version="opset1">
			<data element_type="i64" offset="301804" shape="5" size="40"/>
			<output>
				<port id="0" precision="I64">
					<dim>5</dim>
				</port>
			</output>
		</layer>
		<layer id="2020" name="24376" type="Reshape" version="opset1">
			<data special_zero="true"/>
			<input>
				<port id="0">
					<dim>96</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
				<port id="1">
					<dim>5</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</output>
		</layer>
		<layer id="2021" name="859" type="GroupConvolution" version="opset1">
			<data auto_pad="explicit" dilations="1,1" pads_begin="1,1" pads_end="1,1" strides="1,1"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
				<port id="1">
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
			</output>
		</layer>
		<layer id="2022" name="data_add_220132201822790/EltwiseUnsqueeze23506_const1920_const" type="Const" version="opset1">
			<data element_type="f16" offset="664832" shape="1,96,1,1" size="192"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2023" name="860/variance/Fused_Add_" type="Add" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
				<port id="1">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" names="860" precision="FP16">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
			</output>
		</layer>
		<layer id="2024" name="861" type="ReLU" version="opset1">
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
			</input>
			<output>
				<port id="1" names="861" precision="FP16">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
			</output>
		</layer>
		<layer id="2025" name="56275631_const" type="Const" version="opset1">
			<data element_type="f16" offset="10108" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="2026" name="56285632_const" type="Const" version="opset1">
			<data element_type="f16" offset="665024" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="2027" name="56295633_const" type="Const" version="opset1">
			<data element_type="f16" offset="10108" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="2028" name="56305634_const" type="Const" version="opset1">
			<data element_type="f16" offset="665024" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="2029" name="862/fq_input_0" type="FakeQuantize" version="opset1">
			<data auto_broadcast="numpy" levels="256"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
				<port id="1"/>
				<port id="2"/>
				<port id="3"/>
				<port id="4"/>
			</input>
			<output>
				<port id="5" precision="FP16">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
			</output>
		</layer>
		<layer id="2030" name="conv3.1.conv2d.1.conv1.weight/quantized19419_const" type="Const" version="opset1">
			<data element_type="i8" offset="665026" shape="96,96,1,1" size="9216"/>
			<output>
				<port id="0" precision="I8">
					<dim>96</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2031" name="conv3.1.conv2d.1.conv1.weight/quantized/to_f16" type="Convert" version="opset1">
			<data destination_type="f16"/>
			<input>
				<port id="0">
					<dim>96</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="1" precision="FP16">
					<dim>96</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2032" name="862/fq_weights_1/zero_point19432_const" type="Const" version="opset1">
			<data element_type="f16" offset="674242" shape="96,1,1,1" size="192"/>
			<output>
				<port id="0" precision="FP16">
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2033" name="862/fq_weights_1/minus_zp" type="Subtract" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>96</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="1">
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>96</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2034" name="862/fq_weights_1/scale19427_const" type="Const" version="opset1">
			<data element_type="f16" offset="674434" shape="96,1,1,1" size="192"/>
			<output>
				<port id="0" precision="FP16">
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2035" name="862/fq_weights_1/mulpiply_by_scale" type="Multiply" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>96</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="1">
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>96</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2036" name="862" type="Convolution" version="opset1">
			<data auto_pad="explicit" dilations="1,1" pads_begin="0,0" pads_end="0,0" strides="1,1"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
				<port id="1">
					<dim>96</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" names="862" precision="FP16">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
			</output>
		</layer>
		<layer id="2037" name="30203022_const" type="Const" version="opset1">
			<data element_type="f16" offset="299980" shape="1,96,1,1" size="192"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2038" name="862/add_" type="Add" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
				<port id="1">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
			</output>
		</layer>
		<layer id="2039" name="51275131_const" type="Const" version="opset1">
			<data element_type="f16" offset="674626" shape="1,96,1,1" size="192"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2040" name="51285132_const" type="Const" version="opset1">
			<data element_type="f16" offset="674818" shape="1,96,1,1" size="192"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2041" name="51295133_const" type="Const" version="opset1">
			<data element_type="f16" offset="674626" shape="1,96,1,1" size="192"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2042" name="51305134_const" type="Const" version="opset1">
			<data element_type="f16" offset="674818" shape="1,96,1,1" size="192"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2043" name="863/fq_input_0" type="FakeQuantize" version="opset1">
			<data auto_broadcast="numpy" levels="256"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
				<port id="1">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="2">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="3">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="4">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="5" precision="FP16">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
			</output>
		</layer>
		<layer id="2044" name="4205942062_const192515592/quantized19659_const" type="Const" version="opset1">
			<data element_type="i8" offset="675010" shape="96,1,3,3" size="864"/>
			<output>
				<port id="0" precision="I8">
					<dim>96</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</output>
		</layer>
		<layer id="2045" name="4205942062_const192515592/quantized/to_f16" type="Convert" version="opset1">
			<data destination_type="f16"/>
			<input>
				<port id="0">
					<dim>96</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</input>
			<output>
				<port id="1" precision="FP16">
					<dim>96</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</output>
		</layer>
		<layer id="2046" name="863/fq_weights_1/zero_point19672_const" type="Const" version="opset1">
			<data element_type="f16" offset="675874" shape="96,1,1,1" size="192"/>
			<output>
				<port id="0" precision="FP16">
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2047" name="863/fq_weights_1/minus_zp" type="Subtract" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>96</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
				<port id="1">
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>96</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</output>
		</layer>
		<layer id="2048" name="863/fq_weights_1/scale19667_const" type="Const" version="opset1">
			<data element_type="f16" offset="676066" shape="96,1,1,1" size="192"/>
			<output>
				<port id="0" precision="FP16">
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2049" name="863/fq_weights_1/mulpiply_by_scale" type="Multiply" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>96</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
				<port id="1">
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>96</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</output>
		</layer>
		<layer id="2050" name="24572/value24574_const" type="Const" version="opset1">
			<data element_type="i64" offset="301804" shape="5" size="40"/>
			<output>
				<port id="0" precision="I64">
					<dim>5</dim>
				</port>
			</output>
		</layer>
		<layer id="2051" name="24572" type="Reshape" version="opset1">
			<data special_zero="true"/>
			<input>
				<port id="0">
					<dim>96</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
				<port id="1">
					<dim>5</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</output>
		</layer>
		<layer id="2052" name="863" type="GroupConvolution" version="opset1">
			<data auto_pad="explicit" dilations="1,1" pads_begin="1,1" pads_end="1,1" strides="1,1"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
				<port id="1">
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
			</output>
		</layer>
		<layer id="2053" name="data_add_220212202622792/EltwiseUnsqueeze23514_const1927_const" type="Const" version="opset1">
			<data element_type="f16" offset="676258" shape="1,96,1,1" size="192"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2054" name="864/variance/Fused_Add_" type="Add" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
				<port id="1">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" names="864" precision="FP16">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
			</output>
		</layer>
		<layer id="2055" name="865" type="ReLU" version="opset1">
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
			</input>
			<output>
				<port id="1" names="865" precision="FP16">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
			</output>
		</layer>
		<layer id="2056" name="80478051_const" type="Const" version="opset1">
			<data element_type="f16" offset="10108" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="2057" name="80488052_const" type="Const" version="opset1">
			<data element_type="f16" offset="676450" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="2058" name="80498053_const" type="Const" version="opset1">
			<data element_type="f16" offset="10108" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="2059" name="80508054_const" type="Const" version="opset1">
			<data element_type="f16" offset="676450" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="2060" name="866/fq_input_0" type="FakeQuantize" version="opset1">
			<data auto_broadcast="numpy" levels="256"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
				<port id="1"/>
				<port id="2"/>
				<port id="3"/>
				<port id="4"/>
			</input>
			<output>
				<port id="5" precision="FP16">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
			</output>
		</layer>
		<layer id="2061" name="conv3.1.conv2d.2.conv1.weight/quantized20739_const" type="Const" version="opset1">
			<data element_type="i8" offset="676452" shape="96,96,1,1" size="9216"/>
			<output>
				<port id="0" precision="I8">
					<dim>96</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2062" name="conv3.1.conv2d.2.conv1.weight/quantized/to_f16" type="Convert" version="opset1">
			<data destination_type="f16"/>
			<input>
				<port id="0">
					<dim>96</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="1" precision="FP16">
					<dim>96</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2063" name="866/fq_weights_1/zero_point20752_const" type="Const" version="opset1">
			<data element_type="f16" offset="685668" shape="96,1,1,1" size="192"/>
			<output>
				<port id="0" precision="FP16">
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2064" name="866/fq_weights_1/minus_zp" type="Subtract" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>96</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="1">
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>96</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2065" name="866/fq_weights_1/scale20747_const" type="Const" version="opset1">
			<data element_type="f16" offset="685860" shape="96,1,1,1" size="192"/>
			<output>
				<port id="0" precision="FP16">
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2066" name="866/fq_weights_1/mulpiply_by_scale" type="Multiply" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>96</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="1">
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>96</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2067" name="866" type="Convolution" version="opset1">
			<data auto_pad="explicit" dilations="1,1" pads_begin="0,0" pads_end="0,0" strides="1,1"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
				<port id="1">
					<dim>96</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" names="866" precision="FP16">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
			</output>
		</layer>
		<layer id="2068" name="30243026_const" type="Const" version="opset1">
			<data element_type="f16" offset="299980" shape="1,96,1,1" size="192"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2069" name="866/add_" type="Add" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
				<port id="1">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
			</output>
		</layer>
		<layer id="2070" name="56875691_const" type="Const" version="opset1">
			<data element_type="f16" offset="686052" shape="1,96,1,1" size="192"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2071" name="56885692_const" type="Const" version="opset1">
			<data element_type="f16" offset="686244" shape="1,96,1,1" size="192"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2072" name="56895693_const" type="Const" version="opset1">
			<data element_type="f16" offset="686052" shape="1,96,1,1" size="192"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2073" name="56905694_const" type="Const" version="opset1">
			<data element_type="f16" offset="686244" shape="1,96,1,1" size="192"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2074" name="867/fq_input_0" type="FakeQuantize" version="opset1">
			<data auto_broadcast="numpy" levels="256"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
				<port id="1">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="2">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="3">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="4">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="5" precision="FP16">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
			</output>
		</layer>
		<layer id="2075" name="4211942122_const193215595/quantized18339_const" type="Const" version="opset1">
			<data element_type="i8" offset="686436" shape="96,1,3,3" size="864"/>
			<output>
				<port id="0" precision="I8">
					<dim>96</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</output>
		</layer>
		<layer id="2076" name="4211942122_const193215595/quantized/to_f16" type="Convert" version="opset1">
			<data destination_type="f16"/>
			<input>
				<port id="0">
					<dim>96</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</input>
			<output>
				<port id="1" precision="FP16">
					<dim>96</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</output>
		</layer>
		<layer id="2077" name="867/fq_weights_1/zero_point18352_const" type="Const" version="opset1">
			<data element_type="f16" offset="687300" shape="96,1,1,1" size="192"/>
			<output>
				<port id="0" precision="FP16">
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2078" name="867/fq_weights_1/minus_zp" type="Subtract" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>96</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
				<port id="1">
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>96</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</output>
		</layer>
		<layer id="2079" name="867/fq_weights_1/scale18347_const" type="Const" version="opset1">
			<data element_type="f16" offset="687492" shape="96,1,1,1" size="192"/>
			<output>
				<port id="0" precision="FP16">
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2080" name="867/fq_weights_1/mulpiply_by_scale" type="Multiply" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>96</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
				<port id="1">
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>96</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</output>
		</layer>
		<layer id="2081" name="24588/value24590_const" type="Const" version="opset1">
			<data element_type="i64" offset="301804" shape="5" size="40"/>
			<output>
				<port id="0" precision="I64">
					<dim>5</dim>
				</port>
			</output>
		</layer>
		<layer id="2082" name="24588" type="Reshape" version="opset1">
			<data special_zero="true"/>
			<input>
				<port id="0">
					<dim>96</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
				<port id="1">
					<dim>5</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</output>
		</layer>
		<layer id="2083" name="867" type="GroupConvolution" version="opset1">
			<data auto_pad="explicit" dilations="1,1" pads_begin="1,1" pads_end="1,1" strides="1,1"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
				<port id="1">
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
			</output>
		</layer>
		<layer id="2084" name="data_add_220292203422794/EltwiseUnsqueeze23522_const1934_const" type="Const" version="opset1">
			<data element_type="f16" offset="687684" shape="1,96,1,1" size="192"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2085" name="868/variance/Fused_Add_" type="Add" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
				<port id="1">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" names="868" precision="FP16">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
			</output>
		</layer>
		<layer id="2086" name="869" type="ReLU" version="opset1">
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
			</input>
			<output>
				<port id="1" names="869" precision="FP16">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
			</output>
		</layer>
		<layer id="2087" name="54675471_const" type="Const" version="opset1">
			<data element_type="f16" offset="10108" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="2088" name="54685472_const" type="Const" version="opset1">
			<data element_type="f16" offset="687876" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="2089" name="54695473_const" type="Const" version="opset1">
			<data element_type="f16" offset="10108" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="2090" name="54705474_const" type="Const" version="opset1">
			<data element_type="f16" offset="687876" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="2091" name="870/fq_input_0" type="FakeQuantize" version="opset1">
			<data auto_broadcast="numpy" levels="256"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
				<port id="1"/>
				<port id="2"/>
				<port id="3"/>
				<port id="4"/>
			</input>
			<output>
				<port id="5" precision="FP16">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
			</output>
		</layer>
		<layer id="2092" name="conv3.1.conv2d.3.conv1.weight/quantized18555_const" type="Const" version="opset1">
			<data element_type="i8" offset="687878" shape="96,96,1,1" size="9216"/>
			<output>
				<port id="0" precision="I8">
					<dim>96</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2093" name="conv3.1.conv2d.3.conv1.weight/quantized/to_f16" type="Convert" version="opset1">
			<data destination_type="f16"/>
			<input>
				<port id="0">
					<dim>96</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="1" precision="FP16">
					<dim>96</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2094" name="870/fq_weights_1/zero_point18568_const" type="Const" version="opset1">
			<data element_type="f16" offset="697094" shape="96,1,1,1" size="192"/>
			<output>
				<port id="0" precision="FP16">
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2095" name="870/fq_weights_1/minus_zp" type="Subtract" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>96</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="1">
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>96</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2096" name="870/fq_weights_1/scale18563_const" type="Const" version="opset1">
			<data element_type="f16" offset="697286" shape="96,1,1,1" size="192"/>
			<output>
				<port id="0" precision="FP16">
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2097" name="870/fq_weights_1/mulpiply_by_scale" type="Multiply" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>96</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="1">
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>96</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2098" name="870" type="Convolution" version="opset1">
			<data auto_pad="explicit" dilations="1,1" pads_begin="0,0" pads_end="0,0" strides="1,1"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
				<port id="1">
					<dim>96</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" names="870" precision="FP16">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
			</output>
		</layer>
		<layer id="2099" name="30283030_const" type="Const" version="opset1">
			<data element_type="f16" offset="299980" shape="1,96,1,1" size="192"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2100" name="870/add_" type="Add" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
				<port id="1">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
			</output>
		</layer>
		<layer id="2101" name="68976901_const" type="Const" version="opset1">
			<data element_type="f16" offset="697478" shape="1,96,1,1" size="192"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2102" name="68986902_const" type="Const" version="opset1">
			<data element_type="f16" offset="697670" shape="1,96,1,1" size="192"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2103" name="68996903_const" type="Const" version="opset1">
			<data element_type="f16" offset="697478" shape="1,96,1,1" size="192"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2104" name="69006904_const" type="Const" version="opset1">
			<data element_type="f16" offset="697670" shape="1,96,1,1" size="192"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2105" name="871/fq_input_0" type="FakeQuantize" version="opset1">
			<data auto_broadcast="numpy" levels="256"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
				<port id="1">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="2">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="3">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="4">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="5" precision="FP16">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
			</output>
		</layer>
		<layer id="2106" name="4228742290_const193915598/quantized19707_const" type="Const" version="opset1">
			<data element_type="i8" offset="697862" shape="96,1,3,3" size="864"/>
			<output>
				<port id="0" precision="I8">
					<dim>96</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</output>
		</layer>
		<layer id="2107" name="4228742290_const193915598/quantized/to_f16" type="Convert" version="opset1">
			<data destination_type="f16"/>
			<input>
				<port id="0">
					<dim>96</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</input>
			<output>
				<port id="1" precision="FP16">
					<dim>96</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</output>
		</layer>
		<layer id="2108" name="871/fq_weights_1/zero_point19720_const" type="Const" version="opset1">
			<data element_type="f16" offset="698726" shape="96,1,1,1" size="192"/>
			<output>
				<port id="0" precision="FP16">
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2109" name="871/fq_weights_1/minus_zp" type="Subtract" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>96</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
				<port id="1">
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>96</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</output>
		</layer>
		<layer id="2110" name="871/fq_weights_1/scale19715_const" type="Const" version="opset1">
			<data element_type="f16" offset="698918" shape="96,1,1,1" size="192"/>
			<output>
				<port id="0" precision="FP16">
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2111" name="871/fq_weights_1/mulpiply_by_scale" type="Multiply" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>96</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
				<port id="1">
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>96</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</output>
		</layer>
		<layer id="2112" name="24420/value24422_const" type="Const" version="opset1">
			<data element_type="i64" offset="301804" shape="5" size="40"/>
			<output>
				<port id="0" precision="I64">
					<dim>5</dim>
				</port>
			</output>
		</layer>
		<layer id="2113" name="24420" type="Reshape" version="opset1">
			<data special_zero="true"/>
			<input>
				<port id="0">
					<dim>96</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
				<port id="1">
					<dim>5</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</output>
		</layer>
		<layer id="2114" name="871" type="GroupConvolution" version="opset1">
			<data auto_pad="explicit" dilations="1,1" pads_begin="1,1" pads_end="1,1" strides="1,1"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
				<port id="1">
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
			</output>
		</layer>
		<layer id="2115" name="data_add_220372204222796/EltwiseUnsqueeze23530_const1941_const" type="Const" version="opset1">
			<data element_type="f16" offset="699110" shape="1,96,1,1" size="192"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2116" name="872/variance/Fused_Add_" type="Add" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
				<port id="1">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" names="872" precision="FP16">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
			</output>
		</layer>
		<layer id="2117" name="873" type="ReLU" version="opset1">
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
			</input>
			<output>
				<port id="1" names="873" precision="FP16">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
			</output>
		</layer>
		<layer id="2118" name="69376941_const" type="Const" version="opset1">
			<data element_type="f16" offset="10108" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="2119" name="69386942_const" type="Const" version="opset1">
			<data element_type="f16" offset="699302" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="2120" name="69396943_const" type="Const" version="opset1">
			<data element_type="f16" offset="10108" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="2121" name="69406944_const" type="Const" version="opset1">
			<data element_type="f16" offset="699302" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="2122" name="918/reduce/fq_input_0" type="FakeQuantize" version="opset1">
			<data auto_broadcast="numpy" levels="256"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
				<port id="1"/>
				<port id="2"/>
				<port id="3"/>
				<port id="4"/>
			</input>
			<output>
				<port id="5" precision="FP16">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
			</output>
		</layer>
		<layer id="2123" name="1399/Output_0/Data__const1944_const" type="Const" version="opset1">
			<data element_type="i64" offset="24" shape="" size="8"/>
			<output>
				<port id="0" precision="I64"/>
			</output>
		</layer>
		<layer id="2124" name="918/input_rank/shape_of" type="ShapeOf" version="opset3">
			<data output_type="i64"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
			</input>
			<output>
				<port id="1" precision="I64">
					<dim>4</dim>
				</port>
			</output>
		</layer>
		<layer id="2125" name="918/input_rank/rank_of" type="ShapeOf" version="opset3">
			<data output_type="i64"/>
			<input>
				<port id="0">
					<dim>4</dim>
				</port>
			</input>
			<output>
				<port id="1" precision="I64">
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2126" name="918/input_rank/0d_rank_of/value/Output_0/Data__const1947_const" type="Const" version="opset1">
			<data element_type="i64" offset="32" shape="1" size="8"/>
			<output>
				<port id="0" precision="I64">
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2127" name="918/input_rank" type="Squeeze" version="opset1">
			<input>
				<port id="0">
					<dim>1</dim>
				</port>
				<port id="1">
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="I64"/>
			</output>
		</layer>
		<layer id="2128" name="1401/Output_0/Data__const1949_const" type="Const" version="opset1">
			<data element_type="i64" offset="0" shape="" size="8"/>
			<output>
				<port id="0" precision="I64"/>
			</output>
		</layer>
		<layer id="2129" name="918/global_pooling_reduce_axis" type="Range" version="opset4">
			<data output_type="i64"/>
			<input>
				<port id="0"/>
				<port id="1"/>
				<port id="2"/>
			</input>
			<output>
				<port id="3" precision="I64">
					<dim>2</dim>
				</port>
			</output>
		</layer>
		<layer id="2130" name="918/reduce" type="ReduceMean" version="opset1">
			<data keep_dims="true"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
				<port id="1">
					<dim>2</dim>
				</port>
			</input>
			<output>
				<port id="2" names="918" precision="FP16">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2131" name="1098810992_const" type="Const" version="opset1">
			<data element_type="f16" offset="10108" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="2132" name="1098910993_const" type="Const" version="opset1">
			<data element_type="f16" offset="699304" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="2133" name="1099010994_const" type="Const" version="opset1">
			<data element_type="f16" offset="10108" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="2134" name="1099110995_const" type="Const" version="opset1">
			<data element_type="f16" offset="699304" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="2135" name="920/fq_input_0" type="FakeQuantize" version="opset1">
			<data auto_broadcast="numpy" levels="256"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="1"/>
				<port id="2"/>
				<port id="3"/>
				<port id="4"/>
			</input>
			<output>
				<port id="5" precision="FP16">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2136" name="920/Cast_143328_const1952_const" type="Const" version="opset1">
			<data element_type="i64" offset="129708" shape="3" size="24"/>
			<output>
				<port id="0" names="919" precision="I64">
					<dim>3</dim>
				</port>
			</output>
		</layer>
		<layer id="2137" name="920" type="Reshape" version="opset1">
			<data special_zero="true"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="1">
					<dim>3</dim>
				</port>
			</input>
			<output>
				<port id="2" names="920" precision="FP16">
					<dim>1</dim>
					<dim>16</dim>
					<dim>6</dim>
				</port>
			</output>
		</layer>
		<layer id="2138" name="923/Range_input_port_0/value/Output_0/Data__const1954_const" type="Const" version="opset1">
			<data element_type="i64" offset="24" shape="" size="8"/>
			<output>
				<port id="0" precision="I64"/>
			</output>
		</layer>
		<layer id="2139" name="923/Rank/shape_of" type="ShapeOf" version="opset3">
			<data output_type="i64"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>16</dim>
					<dim>6</dim>
				</port>
			</input>
			<output>
				<port id="1" precision="I64">
					<dim>3</dim>
				</port>
			</output>
		</layer>
		<layer id="2140" name="923/Rank/rank_of" type="ShapeOf" version="opset3">
			<data output_type="i64"/>
			<input>
				<port id="0">
					<dim>3</dim>
				</port>
			</input>
			<output>
				<port id="1" precision="I64">
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2141" name="923/Rank/0d_rank_of/value/Output_0/Data__const1957_const" type="Const" version="opset1">
			<data element_type="i64" offset="32" shape="1" size="8"/>
			<output>
				<port id="0" precision="I64">
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2142" name="923/Rank" type="Squeeze" version="opset1">
			<input>
				<port id="0">
					<dim>1</dim>
				</port>
				<port id="1">
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="I64"/>
			</output>
		</layer>
		<layer id="2143" name="923/Range_input_port_2/value/Output_0/Data__const1959_const" type="Const" version="opset1">
			<data element_type="i64" offset="0" shape="" size="8"/>
			<output>
				<port id="0" precision="I64"/>
			</output>
		</layer>
		<layer id="2144" name="923/Range" type="Range" version="opset4">
			<data output_type="i64"/>
			<input>
				<port id="0"/>
				<port id="1"/>
				<port id="2"/>
			</input>
			<output>
				<port id="3" precision="I64">
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2145" name="923/Ins_Norm/MVN_" type="MVN" version="opset6">
			<data eps="9.999999747378752e-06" eps_mode="inside_sqrt" normalize_variance="true"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>16</dim>
					<dim>6</dim>
				</port>
				<port id="1">
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>1</dim>
					<dim>16</dim>
					<dim>6</dim>
				</port>
			</output>
		</layer>
		<layer id="2146" name="921/EltwiseUnsqueeze22998_const1962_const" type="Const" version="opset1">
			<data element_type="f16" offset="129732" shape="1,16,1" size="32"/>
			<output>
				<port id="0" names="921" precision="FP16">
					<dim>1</dim>
					<dim>16</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2147" name="923/Ins_Norm/mul_" type="Multiply" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>16</dim>
					<dim>6</dim>
				</port>
				<port id="1">
					<dim>1</dim>
					<dim>16</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>1</dim>
					<dim>16</dim>
					<dim>6</dim>
				</port>
			</output>
		</layer>
		<layer id="2148" name="922/EltwiseUnsqueeze23002_const1964_const" type="Const" version="opset1">
			<data element_type="f16" offset="129764" shape="1,16,1" size="32"/>
			<output>
				<port id="0" names="922" precision="FP16">
					<dim>1</dim>
					<dim>16</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2149" name="923" type="Add" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>16</dim>
					<dim>6</dim>
				</port>
				<port id="1">
					<dim>1</dim>
					<dim>16</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" names="923" precision="FP16">
					<dim>1</dim>
					<dim>16</dim>
					<dim>6</dim>
				</port>
			</output>
		</layer>
		<layer id="2150" name="1099811002_const" type="Const" version="opset1">
			<data element_type="f16" offset="699306" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="2151" name="1099911003_const" type="Const" version="opset1">
			<data element_type="f16" offset="699308" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="2152" name="1100011004_const" type="Const" version="opset1">
			<data element_type="f16" offset="699306" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="2153" name="1100111005_const" type="Const" version="opset1">
			<data element_type="f16" offset="699308" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="2154" name="925/fq_input_0" type="FakeQuantize" version="opset1">
			<data auto_broadcast="numpy" levels="256"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>16</dim>
					<dim>6</dim>
				</port>
				<port id="1"/>
				<port id="2"/>
				<port id="3"/>
				<port id="4"/>
			</input>
			<output>
				<port id="5" precision="FP16">
					<dim>1</dim>
					<dim>16</dim>
					<dim>6</dim>
				</port>
			</output>
		</layer>
		<layer id="2155" name="924" type="ShapeOf" version="opset3">
			<data output_type="i64"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="1" names="924" precision="I64">
					<dim>4</dim>
				</port>
			</output>
		</layer>
		<layer id="2156" name="925" type="Reshape" version="opset1">
			<data special_zero="true"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>16</dim>
					<dim>6</dim>
				</port>
				<port id="1">
					<dim>4</dim>
				</port>
			</input>
			<output>
				<port id="2" names="925" precision="FP16">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2157" name="926/Unsqueeze/EltwiseUnsqueeze22926_const1968_const" type="Const" version="opset1">
			<data element_type="f16" offset="596060" shape="1,96,1,1" size="192"/>
			<output>
				<port id="0" names="926" precision="FP16">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2158" name="927" type="Multiply" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="1">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" names="927" precision="FP16">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2159" name="928/Unsqueeze/EltwiseUnsqueeze22930_const1970_const" type="Const" version="opset1">
			<data element_type="f16" offset="596252" shape="1,96,1,1" size="192"/>
			<output>
				<port id="0" names="928" precision="FP16">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2160" name="929" type="Add" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="1">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" names="929" precision="FP16">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2161" name="930" type="Sigmoid" version="opset1">
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="1" names="930" precision="FP16">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2162" name="59575961_const" type="Const" version="opset1">
			<data element_type="f16" offset="10108" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="2163" name="59585962_const" type="Const" version="opset1">
			<data element_type="f16" offset="699310" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="2164" name="59595963_const" type="Const" version="opset1">
			<data element_type="f16" offset="10108" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="2165" name="59605964_const" type="Const" version="opset1">
			<data element_type="f16" offset="699310" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="2166" name="931/fq_input_1" type="FakeQuantize" version="opset1">
			<data auto_broadcast="numpy" levels="256"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="1"/>
				<port id="2"/>
				<port id="3"/>
				<port id="4"/>
			</input>
			<output>
				<port id="5" precision="FP16">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2167" name="931" type="Multiply" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
				<port id="1">
					<dim>1</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" names="931" precision="FP16">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
			</output>
		</layer>
		<layer id="2168" name="71777181_const" type="Const" version="opset1">
			<data element_type="f16" offset="10108" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="2169" name="71787182_const" type="Const" version="opset1">
			<data element_type="f16" offset="699312" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="2170" name="71797183_const" type="Const" version="opset1">
			<data element_type="f16" offset="10108" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="2171" name="71807184_const" type="Const" version="opset1">
			<data element_type="f16" offset="699312" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="2172" name="932/fq_input_1" type="FakeQuantize" version="opset1">
			<data auto_broadcast="numpy" levels="256"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
				<port id="1"/>
				<port id="2"/>
				<port id="3"/>
				<port id="4"/>
			</input>
			<output>
				<port id="5" precision="FP16">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
			</output>
		</layer>
		<layer id="2173" name="932" type="Add" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
				<port id="1">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
			</input>
			<output>
				<port id="2" names="932" precision="FP16">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
			</output>
		</layer>
		<layer id="2174" name="77877791_const" type="Const" version="opset1">
			<data element_type="f16" offset="10108" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="2175" name="77887792_const" type="Const" version="opset1">
			<data element_type="f16" offset="699314" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="2176" name="77897793_const" type="Const" version="opset1">
			<data element_type="f16" offset="10108" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="2177" name="77907794_const" type="Const" version="opset1">
			<data element_type="f16" offset="699314" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="2178" name="933/fq_input_0" type="FakeQuantize" version="opset1">
			<data auto_broadcast="numpy" levels="256"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
				<port id="1"/>
				<port id="2"/>
				<port id="3"/>
				<port id="4"/>
			</input>
			<output>
				<port id="5" precision="FP16">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
			</output>
		</layer>
		<layer id="2179" name="934/mean/Fused_Mul_2455524557_const197515611/quantized20259_const" type="Const" version="opset1">
			<data element_type="i8" offset="699316" shape="384,96,1,1" size="36864"/>
			<output>
				<port id="0" precision="I8">
					<dim>384</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2180" name="934/mean/Fused_Mul_2455524557_const197515611/quantized/to_f16" type="Convert" version="opset1">
			<data destination_type="f16"/>
			<input>
				<port id="0">
					<dim>384</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="1" precision="FP16">
					<dim>384</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2181" name="933/fq_weights_1/zero_point20272_const" type="Const" version="opset1">
			<data element_type="f16" offset="736180" shape="384,1,1,1" size="768"/>
			<output>
				<port id="0" precision="FP16">
					<dim>384</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2182" name="933/fq_weights_1/minus_zp" type="Subtract" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>384</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="1">
					<dim>384</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>384</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2183" name="933/fq_weights_1/scale20267_const" type="Const" version="opset1">
			<data element_type="f16" offset="736948" shape="384,1,1,1" size="768"/>
			<output>
				<port id="0" precision="FP16">
					<dim>384</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2184" name="933/fq_weights_1/mulpiply_by_scale" type="Multiply" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>384</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="1">
					<dim>384</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>384</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2185" name="933" type="Convolution" version="opset1">
			<data auto_pad="explicit" dilations="1,1" pads_begin="0,0" pads_end="0,0" strides="1,1"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>96</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
				<port id="1">
					<dim>384</dim>
					<dim>96</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>1</dim>
					<dim>384</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
			</output>
		</layer>
		<layer id="2186" name="data_add_220932209822810/EltwiseUnsqueeze23586_const1977_const" type="Const" version="opset1">
			<data element_type="f16" offset="737716" shape="1,384,1,1" size="768"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>384</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2187" name="934/variance/Fused_Add_" type="Add" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>384</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
				<port id="1">
					<dim>1</dim>
					<dim>384</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" names="934" precision="FP16">
					<dim>1</dim>
					<dim>384</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
			</output>
		</layer>
		<layer id="2188" name="60576061_const" type="Const" version="opset1">
			<data element_type="f16" offset="738484" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="2189" name="60586062_const" type="Const" version="opset1">
			<data element_type="f16" offset="738486" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="2190" name="60596063_const" type="Const" version="opset1">
			<data element_type="f16" offset="738484" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="2191" name="60606064_const" type="Const" version="opset1">
			<data element_type="f16" offset="738486" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="2192" name="935/fq_input_0" type="FakeQuantize" version="opset1">
			<data auto_broadcast="numpy" levels="256"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>384</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
				<port id="1"/>
				<port id="2"/>
				<port id="3"/>
				<port id="4"/>
			</input>
			<output>
				<port id="5" precision="FP16">
					<dim>1</dim>
					<dim>384</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
			</output>
		</layer>
		<layer id="2193" name="935" type="Add" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>384</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
				<port id="1">
					<dim>1</dim>
					<dim>384</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
			</input>
			<output>
				<port id="2" names="935" precision="FP16">
					<dim>1</dim>
					<dim>384</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
			</output>
		</layer>
		<layer id="2194" name="936" type="ReLU" version="opset1">
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>384</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
			</input>
			<output>
				<port id="1" names="936" precision="FP16">
					<dim>1</dim>
					<dim>384</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
			</output>
		</layer>
		<layer id="2195" name="57775781_const" type="Const" version="opset1">
			<data element_type="f16" offset="10108" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="2196" name="57785782_const" type="Const" version="opset1">
			<data element_type="f16" offset="738488" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="2197" name="57795783_const" type="Const" version="opset1">
			<data element_type="f16" offset="10108" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="2198" name="57805784_const" type="Const" version="opset1">
			<data element_type="f16" offset="738488" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="2199" name="937/fq_input_0" type="FakeQuantize" version="opset1">
			<data auto_broadcast="numpy" levels="256"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>384</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
				<port id="1"/>
				<port id="2"/>
				<port id="3"/>
				<port id="4"/>
			</input>
			<output>
				<port id="5" precision="FP16">
					<dim>1</dim>
					<dim>384</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
			</output>
		</layer>
		<layer id="2200" name="938/mean/Fused_Mul_2455924561_const198115613/quantized17523_const" type="Const" version="opset1">
			<data element_type="i8" offset="738490" shape="384,384,1,1" size="147456"/>
			<output>
				<port id="0" precision="I8">
					<dim>384</dim>
					<dim>384</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2201" name="938/mean/Fused_Mul_2455924561_const198115613/quantized/to_f16" type="Convert" version="opset1">
			<data destination_type="f16"/>
			<input>
				<port id="0">
					<dim>384</dim>
					<dim>384</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="1" precision="FP16">
					<dim>384</dim>
					<dim>384</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2202" name="937/fq_weights_1/zero_point17536_const" type="Const" version="opset1">
			<data element_type="f16" offset="885946" shape="384,1,1,1" size="768"/>
			<output>
				<port id="0" precision="FP16">
					<dim>384</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2203" name="937/fq_weights_1/minus_zp" type="Subtract" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>384</dim>
					<dim>384</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="1">
					<dim>384</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>384</dim>
					<dim>384</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2204" name="937/fq_weights_1/scale17531_const" type="Const" version="opset1">
			<data element_type="f16" offset="886714" shape="384,1,1,1" size="768"/>
			<output>
				<port id="0" precision="FP16">
					<dim>384</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2205" name="937/fq_weights_1/mulpiply_by_scale" type="Multiply" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>384</dim>
					<dim>384</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="1">
					<dim>384</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>384</dim>
					<dim>384</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2206" name="937" type="Convolution" version="opset1">
			<data auto_pad="explicit" dilations="1,1" pads_begin="0,0" pads_end="0,0" strides="1,1"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>384</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
				<port id="1">
					<dim>384</dim>
					<dim>384</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>1</dim>
					<dim>384</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
			</output>
		</layer>
		<layer id="2207" name="data_add_221012210622812/EltwiseUnsqueeze23594_const1983_const" type="Const" version="opset1">
			<data element_type="f16" offset="887482" shape="1,384,1,1" size="768"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>384</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2208" name="938/variance/Fused_Add_" type="Add" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>384</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
				<port id="1">
					<dim>1</dim>
					<dim>384</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" names="938" precision="FP16">
					<dim>1</dim>
					<dim>384</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
			</output>
		</layer>
		<layer id="2209" name="939" type="ReLU" version="opset1">
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>384</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
			</input>
			<output>
				<port id="1" names="940,939" precision="FP16">
					<dim>1</dim>
					<dim>384</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
			</output>
		</layer>
		<layer id="2210" name="53575361_const" type="Const" version="opset1">
			<data element_type="f16" offset="10108" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="2211" name="53585362_const" type="Const" version="opset1">
			<data element_type="f16" offset="888250" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="2212" name="53595363_const" type="Const" version="opset1">
			<data element_type="f16" offset="10108" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="2213" name="53605364_const" type="Const" version="opset1">
			<data element_type="f16" offset="888250" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="2214" name="941/fq_input_0" type="FakeQuantize" version="opset1">
			<data auto_broadcast="numpy" levels="256"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>384</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
				<port id="1"/>
				<port id="2"/>
				<port id="3"/>
				<port id="4"/>
			</input>
			<output>
				<port id="5" precision="FP16">
					<dim>1</dim>
					<dim>384</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
			</output>
		</layer>
		<layer id="2215" name="941" type="AvgPool" version="opset1">
			<data auto_pad="explicit" exclude-pad="true" kernel="2,2" pads_begin="0,0" pads_end="0,0" rounding_type="floor" strides="2,2"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>384</dim>
					<dim>32</dim>
					<dim>16</dim>
				</port>
			</input>
			<output>
				<port id="1" names="941" precision="FP16">
					<dim>1</dim>
					<dim>384</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
			</output>
		</layer>
		<layer id="2216" name="42474251_const" type="Const" version="opset1">
			<data element_type="f16" offset="10108" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="2217" name="42484252_const" type="Const" version="opset1">
			<data element_type="f16" offset="888252" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="2218" name="42494253_const" type="Const" version="opset1">
			<data element_type="f16" offset="10108" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="2219" name="42504254_const" type="Const" version="opset1">
			<data element_type="f16" offset="888252" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="2220" name="1014/fq_input_0" type="FakeQuantize" version="opset1">
			<data auto_broadcast="numpy" levels="256"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>384</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
				<port id="1"/>
				<port id="2"/>
				<port id="3"/>
				<port id="4"/>
			</input>
			<output>
				<port id="5" precision="FP16">
					<dim>1</dim>
					<dim>384</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
			</output>
		</layer>
		<layer id="2221" name="943/mean/Fused_Mul_2456724569_const198715615/quantized18147_const" type="Const" version="opset1">
			<data element_type="i8" offset="888254" shape="128,384,1,1" size="49152"/>
			<output>
				<port id="0" precision="I8">
					<dim>128</dim>
					<dim>384</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2222" name="943/mean/Fused_Mul_2456724569_const198715615/quantized/to_f16" type="Convert" version="opset1">
			<data destination_type="f16"/>
			<input>
				<port id="0">
					<dim>128</dim>
					<dim>384</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="1" precision="FP16">
					<dim>128</dim>
					<dim>384</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2223" name="942/fq_weights_1/zero_point18160_const" type="Const" version="opset1">
			<data element_type="f16" offset="937406" shape="128,1,1,1" size="256"/>
			<output>
				<port id="0" precision="FP16">
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2224" name="942/fq_weights_1/minus_zp" type="Subtract" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>128</dim>
					<dim>384</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="1">
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>128</dim>
					<dim>384</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2225" name="942/fq_weights_1/scale18155_const" type="Const" version="opset1">
			<data element_type="f16" offset="937662" shape="128,1,1,1" size="256"/>
			<output>
				<port id="0" precision="FP16">
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2226" name="942/fq_weights_1/mulpiply_by_scale" type="Multiply" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>128</dim>
					<dim>384</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="1">
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>128</dim>
					<dim>384</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2227" name="942" type="Convolution" version="opset1">
			<data auto_pad="explicit" dilations="1,1" pads_begin="0,0" pads_end="0,0" strides="1,1"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>384</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
				<port id="1">
					<dim>128</dim>
					<dim>384</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>1</dim>
					<dim>128</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
			</output>
		</layer>
		<layer id="2228" name="data_add_221172212222816/EltwiseUnsqueeze23610_const1989_const" type="Const" version="opset1">
			<data element_type="f16" offset="937918" shape="1,128,1,1" size="256"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2229" name="943/variance/Fused_Add_" type="Add" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>128</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
				<port id="1">
					<dim>1</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" names="943" precision="FP16">
					<dim>1</dim>
					<dim>128</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
			</output>
		</layer>
		<layer id="2230" name="944" type="ReLU" version="opset1">
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>128</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
			</input>
			<output>
				<port id="1" names="944" precision="FP16">
					<dim>1</dim>
					<dim>128</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
			</output>
		</layer>
		<layer id="2231" name="51875191_const" type="Const" version="opset1">
			<data element_type="f16" offset="10108" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="2232" name="51885192_const" type="Const" version="opset1">
			<data element_type="f16" offset="938174" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="2233" name="51895193_const" type="Const" version="opset1">
			<data element_type="f16" offset="10108" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="2234" name="51905194_const" type="Const" version="opset1">
			<data element_type="f16" offset="938174" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="2235" name="945/fq_input_0" type="FakeQuantize" version="opset1">
			<data auto_broadcast="numpy" levels="256"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>128</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
				<port id="1"/>
				<port id="2"/>
				<port id="3"/>
				<port id="4"/>
			</input>
			<output>
				<port id="5" precision="FP16">
					<dim>1</dim>
					<dim>128</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
			</output>
		</layer>
		<layer id="2236" name="conv4.0.conv2a.conv1.weight/quantized18795_const" type="Const" version="opset1">
			<data element_type="i8" offset="938176" shape="128,128,1,1" size="16384"/>
			<output>
				<port id="0" precision="I8">
					<dim>128</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2237" name="conv4.0.conv2a.conv1.weight/quantized/to_f16" type="Convert" version="opset1">
			<data destination_type="f16"/>
			<input>
				<port id="0">
					<dim>128</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="1" precision="FP16">
					<dim>128</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2238" name="945/fq_weights_1/zero_point18808_const" type="Const" version="opset1">
			<data element_type="f16" offset="954560" shape="128,1,1,1" size="256"/>
			<output>
				<port id="0" precision="FP16">
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2239" name="945/fq_weights_1/minus_zp" type="Subtract" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>128</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="1">
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>128</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2240" name="945/fq_weights_1/scale18803_const" type="Const" version="opset1">
			<data element_type="f16" offset="954816" shape="128,1,1,1" size="256"/>
			<output>
				<port id="0" precision="FP16">
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2241" name="945/fq_weights_1/mulpiply_by_scale" type="Multiply" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>128</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="1">
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>128</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2242" name="945" type="Convolution" version="opset1">
			<data auto_pad="explicit" dilations="1,1" pads_begin="0,0" pads_end="0,0" strides="1,1"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>128</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
				<port id="1">
					<dim>128</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" names="945" precision="FP16">
					<dim>1</dim>
					<dim>128</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
			</output>
		</layer>
		<layer id="2243" name="30323034_const" type="Const" version="opset1">
			<data element_type="f16" offset="955072" shape="1,128,1,1" size="256"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2244" name="945/add_" type="Add" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>128</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
				<port id="1">
					<dim>1</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>1</dim>
					<dim>128</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
			</output>
		</layer>
		<layer id="2245" name="78877891_const" type="Const" version="opset1">
			<data element_type="f16" offset="955328" shape="1,128,1,1" size="256"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2246" name="78887892_const" type="Const" version="opset1">
			<data element_type="f16" offset="955584" shape="1,128,1,1" size="256"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2247" name="78897893_const" type="Const" version="opset1">
			<data element_type="f16" offset="955328" shape="1,128,1,1" size="256"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2248" name="78907894_const" type="Const" version="opset1">
			<data element_type="f16" offset="955584" shape="1,128,1,1" size="256"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2249" name="946/fq_input_0" type="FakeQuantize" version="opset1">
			<data auto_broadcast="numpy" levels="256"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>128</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
				<port id="1">
					<dim>1</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="2">
					<dim>1</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="3">
					<dim>1</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="4">
					<dim>1</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="5" precision="FP16">
					<dim>1</dim>
					<dim>128</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
			</output>
		</layer>
		<layer id="2250" name="4214742150_const199415618/quantized20451_const" type="Const" version="opset1">
			<data element_type="i8" offset="955840" shape="128,1,3,3" size="1152"/>
			<output>
				<port id="0" precision="I8">
					<dim>128</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</output>
		</layer>
		<layer id="2251" name="4214742150_const199415618/quantized/to_f16" type="Convert" version="opset1">
			<data destination_type="f16"/>
			<input>
				<port id="0">
					<dim>128</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</input>
			<output>
				<port id="1" precision="FP16">
					<dim>128</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</output>
		</layer>
		<layer id="2252" name="946/fq_weights_1/zero_point20464_const" type="Const" version="opset1">
			<data element_type="f16" offset="956992" shape="128,1,1,1" size="256"/>
			<output>
				<port id="0" precision="FP16">
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2253" name="946/fq_weights_1/minus_zp" type="Subtract" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>128</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
				<port id="1">
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>128</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</output>
		</layer>
		<layer id="2254" name="946/fq_weights_1/scale20459_const" type="Const" version="opset1">
			<data element_type="f16" offset="957248" shape="128,1,1,1" size="256"/>
			<output>
				<port id="0" precision="FP16">
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2255" name="946/fq_weights_1/mulpiply_by_scale" type="Multiply" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>128</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
				<port id="1">
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>128</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</output>
		</layer>
		<layer id="2256" name="24612/value24614_const" type="Const" version="opset1">
			<data element_type="i64" offset="957504" shape="5" size="40"/>
			<output>
				<port id="0" precision="I64">
					<dim>5</dim>
				</port>
			</output>
		</layer>
		<layer id="2257" name="24612" type="Reshape" version="opset1">
			<data special_zero="true"/>
			<input>
				<port id="0">
					<dim>128</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
				<port id="1">
					<dim>5</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</output>
		</layer>
		<layer id="2258" name="946" type="GroupConvolution" version="opset1">
			<data auto_pad="explicit" dilations="1,1" pads_begin="1,1" pads_end="1,1" strides="1,1"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>128</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
				<port id="1">
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>1</dim>
					<dim>128</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
			</output>
		</layer>
		<layer id="2259" name="data_add_221972220222836/EltwiseUnsqueeze23690_const1996_const" type="Const" version="opset1">
			<data element_type="f16" offset="957544" shape="1,128,1,1" size="256"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2260" name="947/variance/Fused_Add_" type="Add" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>128</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
				<port id="1">
					<dim>1</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" names="947" precision="FP16">
					<dim>1</dim>
					<dim>128</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
			</output>
		</layer>
		<layer id="2261" name="948" type="ReLU" version="opset1">
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>128</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
			</input>
			<output>
				<port id="1" names="948" precision="FP16">
					<dim>1</dim>
					<dim>128</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
			</output>
		</layer>
		<layer id="2262" name="49874991_const" type="Const" version="opset1">
			<data element_type="f16" offset="10108" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="2263" name="49884992_const" type="Const" version="opset1">
			<data element_type="f16" offset="957800" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="2264" name="49894993_const" type="Const" version="opset1">
			<data element_type="f16" offset="10108" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="2265" name="49904994_const" type="Const" version="opset1">
			<data element_type="f16" offset="957800" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="2266" name="985/reduce/fq_input_0" type="FakeQuantize" version="opset1">
			<data auto_broadcast="numpy" levels="256"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>128</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
				<port id="1"/>
				<port id="2"/>
				<port id="3"/>
				<port id="4"/>
			</input>
			<output>
				<port id="5" precision="FP16">
					<dim>1</dim>
					<dim>128</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
			</output>
		</layer>
		<layer id="2267" name="1404/Output_0/Data__const1999_const" type="Const" version="opset1">
			<data element_type="i64" offset="24" shape="" size="8"/>
			<output>
				<port id="0" precision="I64"/>
			</output>
		</layer>
		<layer id="2268" name="985/input_rank/shape_of" type="ShapeOf" version="opset3">
			<data output_type="i64"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>128</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
			</input>
			<output>
				<port id="1" precision="I64">
					<dim>4</dim>
				</port>
			</output>
		</layer>
		<layer id="2269" name="985/input_rank/rank_of" type="ShapeOf" version="opset3">
			<data output_type="i64"/>
			<input>
				<port id="0">
					<dim>4</dim>
				</port>
			</input>
			<output>
				<port id="1" precision="I64">
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2270" name="985/input_rank/0d_rank_of/value/Output_0/Data__const2002_const" type="Const" version="opset1">
			<data element_type="i64" offset="32" shape="1" size="8"/>
			<output>
				<port id="0" precision="I64">
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2271" name="985/input_rank" type="Squeeze" version="opset1">
			<input>
				<port id="0">
					<dim>1</dim>
				</port>
				<port id="1">
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="I64"/>
			</output>
		</layer>
		<layer id="2272" name="1406/Output_0/Data__const2004_const" type="Const" version="opset1">
			<data element_type="i64" offset="0" shape="" size="8"/>
			<output>
				<port id="0" precision="I64"/>
			</output>
		</layer>
		<layer id="2273" name="985/global_pooling_reduce_axis" type="Range" version="opset4">
			<data output_type="i64"/>
			<input>
				<port id="0"/>
				<port id="1"/>
				<port id="2"/>
			</input>
			<output>
				<port id="3" precision="I64">
					<dim>2</dim>
				</port>
			</output>
		</layer>
		<layer id="2274" name="985/reduce" type="ReduceMean" version="opset1">
			<data keep_dims="true"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>128</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
				<port id="1">
					<dim>2</dim>
				</port>
			</input>
			<output>
				<port id="2" names="985" precision="FP16">
					<dim>1</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2275" name="Copy_conv4.0.gate.fc1.weight/Output_0/Data__const2007_const" type="Const" version="opset1">
			<data element_type="f16" offset="957802" shape="8,128,1,1" size="2048"/>
			<output>
				<port id="0" names="conv4.0.gate.fc1.weight" precision="FP16">
					<dim>8</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2276" name="986/WithoutBiases" type="Convolution" version="opset1">
			<data auto_pad="explicit" dilations="1,1" pads_begin="0,0" pads_end="0,0" strides="1,1"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="1">
					<dim>8</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>1</dim>
					<dim>8</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2277" name="986/Dims1291022687/EltwiseUnsqueeze23102_const2009_const" type="Const" version="opset1">
			<data element_type="f16" offset="959850" shape="1,8,1,1" size="16"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>8</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2278" name="986" type="Add" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>8</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="1">
					<dim>1</dim>
					<dim>8</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" names="986" precision="FP16">
					<dim>1</dim>
					<dim>8</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2279" name="987" type="ReLU" version="opset1">
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>8</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="1" names="987" precision="FP16">
					<dim>1</dim>
					<dim>8</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2280" name="Copy_conv4.0.gate.fc2.weight/Output_0/Data__const2012_const" type="Const" version="opset1">
			<data element_type="f16" offset="959866" shape="128,8,1,1" size="2048"/>
			<output>
				<port id="0" names="conv4.0.gate.fc2.weight" precision="FP16">
					<dim>128</dim>
					<dim>8</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2281" name="988/WithoutBiases" type="Convolution" version="opset1">
			<data auto_pad="explicit" dilations="1,1" pads_begin="0,0" pads_end="0,0" strides="1,1"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>8</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="1">
					<dim>128</dim>
					<dim>8</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>1</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2282" name="988/Dims1290422686/EltwiseUnsqueeze23098_const2014_const" type="Const" version="opset1">
			<data element_type="f16" offset="961914" shape="1,128,1,1" size="256"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2283" name="988" type="Add" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="1">
					<dim>1</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" names="988" precision="FP16">
					<dim>1</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2284" name="989" type="Sigmoid" version="opset1">
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="1" names="989" precision="FP16">
					<dim>1</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2285" name="63176321_const" type="Const" version="opset1">
			<data element_type="f16" offset="10108" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="2286" name="63186322_const" type="Const" version="opset1">
			<data element_type="f16" offset="962170" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="2287" name="63196323_const" type="Const" version="opset1">
			<data element_type="f16" offset="10108" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="2288" name="63206324_const" type="Const" version="opset1">
			<data element_type="f16" offset="962170" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="2289" name="990/fq_input_1" type="FakeQuantize" version="opset1">
			<data auto_broadcast="numpy" levels="256"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="1"/>
				<port id="2"/>
				<port id="3"/>
				<port id="4"/>
			</input>
			<output>
				<port id="5" precision="FP16">
					<dim>1</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2290" name="990" type="Multiply" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>128</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
				<port id="1">
					<dim>1</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" names="990" precision="FP16">
					<dim>1</dim>
					<dim>128</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
			</output>
		</layer>
		<layer id="2291" name="69676971_const" type="Const" version="opset1">
			<data element_type="f16" offset="10108" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="2292" name="69686972_const" type="Const" version="opset1">
			<data element_type="f16" offset="962172" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="2293" name="69696973_const" type="Const" version="opset1">
			<data element_type="f16" offset="10108" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="2294" name="69706974_const" type="Const" version="opset1">
			<data element_type="f16" offset="962172" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="2295" name="997/fq_input_0" type="FakeQuantize" version="opset1">
			<data auto_broadcast="numpy" levels="256"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>128</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
				<port id="1"/>
				<port id="2"/>
				<port id="3"/>
				<port id="4"/>
			</input>
			<output>
				<port id="5" precision="FP16">
					<dim>1</dim>
					<dim>128</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
			</output>
		</layer>
		<layer id="2296" name="conv4.0.conv2b.0.conv1.weight/quantized19635_const" type="Const" version="opset1">
			<data element_type="i8" offset="962174" shape="128,128,1,1" size="16384"/>
			<output>
				<port id="0" precision="I8">
					<dim>128</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2297" name="conv4.0.conv2b.0.conv1.weight/quantized/to_f16" type="Convert" version="opset1">
			<data destination_type="f16"/>
			<input>
				<port id="0">
					<dim>128</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="1" precision="FP16">
					<dim>128</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2298" name="949/fq_weights_1/zero_point19648_const" type="Const" version="opset1">
			<data element_type="f16" offset="978558" shape="128,1,1,1" size="256"/>
			<output>
				<port id="0" precision="FP16">
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2299" name="949/fq_weights_1/minus_zp" type="Subtract" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>128</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="1">
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>128</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2300" name="949/fq_weights_1/scale19643_const" type="Const" version="opset1">
			<data element_type="f16" offset="978814" shape="128,1,1,1" size="256"/>
			<output>
				<port id="0" precision="FP16">
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2301" name="949/fq_weights_1/mulpiply_by_scale" type="Multiply" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>128</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="1">
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>128</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2302" name="949" type="Convolution" version="opset1">
			<data auto_pad="explicit" dilations="1,1" pads_begin="0,0" pads_end="0,0" strides="1,1"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>128</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
				<port id="1">
					<dim>128</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" names="949" precision="FP16">
					<dim>1</dim>
					<dim>128</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
			</output>
		</layer>
		<layer id="2303" name="30363038_const" type="Const" version="opset1">
			<data element_type="f16" offset="955072" shape="1,128,1,1" size="256"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2304" name="949/add_" type="Add" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>128</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
				<port id="1">
					<dim>1</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>1</dim>
					<dim>128</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
			</output>
		</layer>
		<layer id="2305" name="75077511_const" type="Const" version="opset1">
			<data element_type="f16" offset="979070" shape="1,128,1,1" size="256"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2306" name="75087512_const" type="Const" version="opset1">
			<data element_type="f16" offset="979326" shape="1,128,1,1" size="256"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2307" name="75097513_const" type="Const" version="opset1">
			<data element_type="f16" offset="979070" shape="1,128,1,1" size="256"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2308" name="75107514_const" type="Const" version="opset1">
			<data element_type="f16" offset="979326" shape="1,128,1,1" size="256"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2309" name="950/fq_input_0" type="FakeQuantize" version="opset1">
			<data auto_broadcast="numpy" levels="256"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>128</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
				<port id="1">
					<dim>1</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="2">
					<dim>1</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="3">
					<dim>1</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="4">
					<dim>1</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="5" precision="FP16">
					<dim>1</dim>
					<dim>128</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
			</output>
		</layer>
		<layer id="2310" name="4217142174_const202015628/quantized20211_const" type="Const" version="opset1">
			<data element_type="i8" offset="979582" shape="128,1,3,3" size="1152"/>
			<output>
				<port id="0" precision="I8">
					<dim>128</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</output>
		</layer>
		<layer id="2311" name="4217142174_const202015628/quantized/to_f16" type="Convert" version="opset1">
			<data destination_type="f16"/>
			<input>
				<port id="0">
					<dim>128</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</input>
			<output>
				<port id="1" precision="FP16">
					<dim>128</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</output>
		</layer>
		<layer id="2312" name="950/fq_weights_1/zero_point20224_const" type="Const" version="opset1">
			<data element_type="f16" offset="980734" shape="128,1,1,1" size="256"/>
			<output>
				<port id="0" precision="FP16">
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2313" name="950/fq_weights_1/minus_zp" type="Subtract" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>128</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
				<port id="1">
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>128</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</output>
		</layer>
		<layer id="2314" name="950/fq_weights_1/scale20219_const" type="Const" version="opset1">
			<data element_type="f16" offset="980990" shape="128,1,1,1" size="256"/>
			<output>
				<port id="0" precision="FP16">
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2315" name="950/fq_weights_1/mulpiply_by_scale" type="Multiply" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>128</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
				<port id="1">
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>128</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</output>
		</layer>
		<layer id="2316" name="24556/value24558_const" type="Const" version="opset1">
			<data element_type="i64" offset="957504" shape="5" size="40"/>
			<output>
				<port id="0" precision="I64">
					<dim>5</dim>
				</port>
			</output>
		</layer>
		<layer id="2317" name="24556" type="Reshape" version="opset1">
			<data special_zero="true"/>
			<input>
				<port id="0">
					<dim>128</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
				<port id="1">
					<dim>5</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</output>
		</layer>
		<layer id="2318" name="950" type="GroupConvolution" version="opset1">
			<data auto_pad="explicit" dilations="1,1" pads_begin="1,1" pads_end="1,1" strides="1,1"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>128</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
				<port id="1">
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>1</dim>
					<dim>128</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
			</output>
		</layer>
		<layer id="2319" name="data_add_221812218622832/EltwiseUnsqueeze23674_const2022_const" type="Const" version="opset1">
			<data element_type="f16" offset="981246" shape="1,128,1,1" size="256"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2320" name="951/variance/Fused_Add_" type="Add" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>128</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
				<port id="1">
					<dim>1</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" names="951" precision="FP16">
					<dim>1</dim>
					<dim>128</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
			</output>
		</layer>
		<layer id="2321" name="952" type="ReLU" version="opset1">
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>128</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
			</input>
			<output>
				<port id="1" names="952" precision="FP16">
					<dim>1</dim>
					<dim>128</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
			</output>
		</layer>
		<layer id="2322" name="74677471_const" type="Const" version="opset1">
			<data element_type="f16" offset="10108" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="2323" name="74687472_const" type="Const" version="opset1">
			<data element_type="f16" offset="981502" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="2324" name="74697473_const" type="Const" version="opset1">
			<data element_type="f16" offset="10108" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="2325" name="74707474_const" type="Const" version="opset1">
			<data element_type="f16" offset="981502" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="2326" name="953/fq_input_0" type="FakeQuantize" version="opset1">
			<data auto_broadcast="numpy" levels="256"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>128</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
				<port id="1"/>
				<port id="2"/>
				<port id="3"/>
				<port id="4"/>
			</input>
			<output>
				<port id="5" precision="FP16">
					<dim>1</dim>
					<dim>128</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
			</output>
		</layer>
		<layer id="2327" name="conv4.0.conv2b.1.conv1.weight/quantized18363_const" type="Const" version="opset1">
			<data element_type="i8" offset="981504" shape="128,128,1,1" size="16384"/>
			<output>
				<port id="0" precision="I8">
					<dim>128</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2328" name="conv4.0.conv2b.1.conv1.weight/quantized/to_f16" type="Convert" version="opset1">
			<data destination_type="f16"/>
			<input>
				<port id="0">
					<dim>128</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="1" precision="FP16">
					<dim>128</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2329" name="953/fq_weights_1/zero_point18376_const" type="Const" version="opset1">
			<data element_type="f16" offset="997888" shape="128,1,1,1" size="256"/>
			<output>
				<port id="0" precision="FP16">
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2330" name="953/fq_weights_1/minus_zp" type="Subtract" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>128</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="1">
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>128</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2331" name="953/fq_weights_1/scale18371_const" type="Const" version="opset1">
			<data element_type="f16" offset="998144" shape="128,1,1,1" size="256"/>
			<output>
				<port id="0" precision="FP16">
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2332" name="953/fq_weights_1/mulpiply_by_scale" type="Multiply" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>128</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="1">
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>128</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2333" name="953" type="Convolution" version="opset1">
			<data auto_pad="explicit" dilations="1,1" pads_begin="0,0" pads_end="0,0" strides="1,1"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>128</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
				<port id="1">
					<dim>128</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" names="953" precision="FP16">
					<dim>1</dim>
					<dim>128</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
			</output>
		</layer>
		<layer id="2334" name="30403042_const" type="Const" version="opset1">
			<data element_type="f16" offset="955072" shape="1,128,1,1" size="256"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2335" name="953/add_" type="Add" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>128</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
				<port id="1">
					<dim>1</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>1</dim>
					<dim>128</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
			</output>
		</layer>
		<layer id="2336" name="67876791_const" type="Const" version="opset1">
			<data element_type="f16" offset="998400" shape="1,128,1,1" size="256"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2337" name="67886792_const" type="Const" version="opset1">
			<data element_type="f16" offset="998656" shape="1,128,1,1" size="256"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2338" name="67896793_const" type="Const" version="opset1">
			<data element_type="f16" offset="998400" shape="1,128,1,1" size="256"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2339" name="67906794_const" type="Const" version="opset1">
			<data element_type="f16" offset="998656" shape="1,128,1,1" size="256"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2340" name="954/fq_input_0" type="FakeQuantize" version="opset1">
			<data auto_broadcast="numpy" levels="256"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>128</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
				<port id="1">
					<dim>1</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="2">
					<dim>1</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="3">
					<dim>1</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="4">
					<dim>1</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="5" precision="FP16">
					<dim>1</dim>
					<dim>128</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
			</output>
		</layer>
		<layer id="2341" name="4221942222_const202715631/quantized18507_const" type="Const" version="opset1">
			<data element_type="i8" offset="998912" shape="128,1,3,3" size="1152"/>
			<output>
				<port id="0" precision="I8">
					<dim>128</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</output>
		</layer>
		<layer id="2342" name="4221942222_const202715631/quantized/to_f16" type="Convert" version="opset1">
			<data destination_type="f16"/>
			<input>
				<port id="0">
					<dim>128</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</input>
			<output>
				<port id="1" precision="FP16">
					<dim>128</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</output>
		</layer>
		<layer id="2343" name="954/fq_weights_1/zero_point18520_const" type="Const" version="opset1">
			<data element_type="f16" offset="1000064" shape="128,1,1,1" size="256"/>
			<output>
				<port id="0" precision="FP16">
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2344" name="954/fq_weights_1/minus_zp" type="Subtract" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>128</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
				<port id="1">
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>128</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</output>
		</layer>
		<layer id="2345" name="954/fq_weights_1/scale18515_const" type="Const" version="opset1">
			<data element_type="f16" offset="1000320" shape="128,1,1,1" size="256"/>
			<output>
				<port id="0" precision="FP16">
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2346" name="954/fq_weights_1/mulpiply_by_scale" type="Multiply" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>128</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
				<port id="1">
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>128</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</output>
		</layer>
		<layer id="2347" name="24416/value24418_const" type="Const" version="opset1">
			<data element_type="i64" offset="957504" shape="5" size="40"/>
			<output>
				<port id="0" precision="I64">
					<dim>5</dim>
				</port>
			</output>
		</layer>
		<layer id="2348" name="24416" type="Reshape" version="opset1">
			<data special_zero="true"/>
			<input>
				<port id="0">
					<dim>128</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
				<port id="1">
					<dim>5</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</output>
		</layer>
		<layer id="2349" name="954" type="GroupConvolution" version="opset1">
			<data auto_pad="explicit" dilations="1,1" pads_begin="1,1" pads_end="1,1" strides="1,1"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>128</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
				<port id="1">
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>1</dim>
					<dim>128</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
			</output>
		</layer>
		<layer id="2350" name="data_add_221892219422834/EltwiseUnsqueeze23682_const2029_const" type="Const" version="opset1">
			<data element_type="f16" offset="1000576" shape="1,128,1,1" size="256"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2351" name="955/variance/Fused_Add_" type="Add" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>128</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
				<port id="1">
					<dim>1</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" names="955" precision="FP16">
					<dim>1</dim>
					<dim>128</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
			</output>
		</layer>
		<layer id="2352" name="956" type="ReLU" version="opset1">
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>128</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
			</input>
			<output>
				<port id="1" names="956" precision="FP16">
					<dim>1</dim>
					<dim>128</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
			</output>
		</layer>
		<layer id="2353" name="65476551_const" type="Const" version="opset1">
			<data element_type="f16" offset="10108" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="2354" name="65486552_const" type="Const" version="opset1">
			<data element_type="f16" offset="1000832" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="2355" name="65496553_const" type="Const" version="opset1">
			<data element_type="f16" offset="10108" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="2356" name="65506554_const" type="Const" version="opset1">
			<data element_type="f16" offset="1000832" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="2357" name="991/reduce/fq_input_0" type="FakeQuantize" version="opset1">
			<data auto_broadcast="numpy" levels="256"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>128</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
				<port id="1"/>
				<port id="2"/>
				<port id="3"/>
				<port id="4"/>
			</input>
			<output>
				<port id="5" precision="FP16">
					<dim>1</dim>
					<dim>128</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
			</output>
		</layer>
		<layer id="2358" name="1409/Output_0/Data__const2032_const" type="Const" version="opset1">
			<data element_type="i64" offset="24" shape="" size="8"/>
			<output>
				<port id="0" precision="I64"/>
			</output>
		</layer>
		<layer id="2359" name="991/input_rank/shape_of" type="ShapeOf" version="opset3">
			<data output_type="i64"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>128</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
			</input>
			<output>
				<port id="1" precision="I64">
					<dim>4</dim>
				</port>
			</output>
		</layer>
		<layer id="2360" name="991/input_rank/rank_of" type="ShapeOf" version="opset3">
			<data output_type="i64"/>
			<input>
				<port id="0">
					<dim>4</dim>
				</port>
			</input>
			<output>
				<port id="1" precision="I64">
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2361" name="991/input_rank/0d_rank_of/value/Output_0/Data__const2035_const" type="Const" version="opset1">
			<data element_type="i64" offset="32" shape="1" size="8"/>
			<output>
				<port id="0" precision="I64">
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2362" name="991/input_rank" type="Squeeze" version="opset1">
			<input>
				<port id="0">
					<dim>1</dim>
				</port>
				<port id="1">
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="I64"/>
			</output>
		</layer>
		<layer id="2363" name="1411/Output_0/Data__const2037_const" type="Const" version="opset1">
			<data element_type="i64" offset="0" shape="" size="8"/>
			<output>
				<port id="0" precision="I64"/>
			</output>
		</layer>
		<layer id="2364" name="991/global_pooling_reduce_axis" type="Range" version="opset4">
			<data output_type="i64"/>
			<input>
				<port id="0"/>
				<port id="1"/>
				<port id="2"/>
			</input>
			<output>
				<port id="3" precision="I64">
					<dim>2</dim>
				</port>
			</output>
		</layer>
		<layer id="2365" name="991/reduce" type="ReduceMean" version="opset1">
			<data keep_dims="true"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>128</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
				<port id="1">
					<dim>2</dim>
				</port>
			</input>
			<output>
				<port id="2" names="991" precision="FP16">
					<dim>1</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2366" name="Copy_conv4.0.gate.fc1.weight/Output_0/Data_4400_const2040_const" type="Const" version="opset1">
			<data element_type="f16" offset="957802" shape="8,128,1,1" size="2048"/>
			<output>
				<port id="0" names="conv4.0.gate.fc1.weight" precision="FP16">
					<dim>8</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2367" name="992/WithoutBiases" type="Convolution" version="opset1">
			<data auto_pad="explicit" dilations="1,1" pads_begin="0,0" pads_end="0,0" strides="1,1"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="1">
					<dim>8</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>1</dim>
					<dim>8</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2368" name="992/Dims1298822700/EltwiseUnsqueeze23154_const2042_const" type="Const" version="opset1">
			<data element_type="f16" offset="959850" shape="1,8,1,1" size="16"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>8</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2369" name="992" type="Add" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>8</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="1">
					<dim>1</dim>
					<dim>8</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" names="992" precision="FP16">
					<dim>1</dim>
					<dim>8</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2370" name="993" type="ReLU" version="opset1">
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>8</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="1" names="993" precision="FP16">
					<dim>1</dim>
					<dim>8</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2371" name="Copy_conv4.0.gate.fc2.weight/Output_0/Data_4408_const2045_const" type="Const" version="opset1">
			<data element_type="f16" offset="959866" shape="128,8,1,1" size="2048"/>
			<output>
				<port id="0" names="conv4.0.gate.fc2.weight" precision="FP16">
					<dim>128</dim>
					<dim>8</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2372" name="994/WithoutBiases" type="Convolution" version="opset1">
			<data auto_pad="explicit" dilations="1,1" pads_begin="0,0" pads_end="0,0" strides="1,1"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>8</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="1">
					<dim>128</dim>
					<dim>8</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>1</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2373" name="994/Dims1298222699/EltwiseUnsqueeze23150_const2047_const" type="Const" version="opset1">
			<data element_type="f16" offset="961914" shape="1,128,1,1" size="256"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2374" name="994" type="Add" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="1">
					<dim>1</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" names="994" precision="FP16">
					<dim>1</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2375" name="995" type="Sigmoid" version="opset1">
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="1" names="995" precision="FP16">
					<dim>1</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2376" name="57375741_const" type="Const" version="opset1">
			<data element_type="f16" offset="10108" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="2377" name="57385742_const" type="Const" version="opset1">
			<data element_type="f16" offset="1000834" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="2378" name="57395743_const" type="Const" version="opset1">
			<data element_type="f16" offset="10108" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="2379" name="57405744_const" type="Const" version="opset1">
			<data element_type="f16" offset="1000834" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="2380" name="996/fq_input_1" type="FakeQuantize" version="opset1">
			<data auto_broadcast="numpy" levels="256"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="1"/>
				<port id="2"/>
				<port id="3"/>
				<port id="4"/>
			</input>
			<output>
				<port id="5" precision="FP16">
					<dim>1</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2381" name="996" type="Multiply" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>128</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
				<port id="1">
					<dim>1</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" names="996" precision="FP16">
					<dim>1</dim>
					<dim>128</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
			</output>
		</layer>
		<layer id="2382" name="69776981_const" type="Const" version="opset1">
			<data element_type="f16" offset="10108" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="2383" name="69786982_const" type="Const" version="opset1">
			<data element_type="f16" offset="1000836" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="2384" name="69796983_const" type="Const" version="opset1">
			<data element_type="f16" offset="10108" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="2385" name="69806984_const" type="Const" version="opset1">
			<data element_type="f16" offset="1000836" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="2386" name="997/fq_input_1" type="FakeQuantize" version="opset1">
			<data auto_broadcast="numpy" levels="256"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>128</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
				<port id="1"/>
				<port id="2"/>
				<port id="3"/>
				<port id="4"/>
			</input>
			<output>
				<port id="5" precision="FP16">
					<dim>1</dim>
					<dim>128</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
			</output>
		</layer>
		<layer id="2387" name="997" type="Add" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>128</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
				<port id="1">
					<dim>1</dim>
					<dim>128</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
			</input>
			<output>
				<port id="2" names="997" precision="FP16">
					<dim>1</dim>
					<dim>128</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
			</output>
		</layer>
		<layer id="2388" name="47074711_const" type="Const" version="opset1">
			<data element_type="f16" offset="10108" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="2389" name="47084712_const" type="Const" version="opset1">
			<data element_type="f16" offset="1000838" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="2390" name="47094713_const" type="Const" version="opset1">
			<data element_type="f16" offset="10108" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="2391" name="47104714_const" type="Const" version="opset1">
			<data element_type="f16" offset="1000838" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="2392" name="1004/fq_input_0" type="FakeQuantize" version="opset1">
			<data auto_broadcast="numpy" levels="256"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>128</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
				<port id="1"/>
				<port id="2"/>
				<port id="3"/>
				<port id="4"/>
			</input>
			<output>
				<port id="5" precision="FP16">
					<dim>1</dim>
					<dim>128</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
			</output>
		</layer>
		<layer id="2393" name="conv4.0.conv2c.0.conv1.weight/quantized17379_const" type="Const" version="opset1">
			<data element_type="i8" offset="1000840" shape="128,128,1,1" size="16384"/>
			<output>
				<port id="0" precision="I8">
					<dim>128</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2394" name="conv4.0.conv2c.0.conv1.weight/quantized/to_f16" type="Convert" version="opset1">
			<data destination_type="f16"/>
			<input>
				<port id="0">
					<dim>128</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="1" precision="FP16">
					<dim>128</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2395" name="957/fq_weights_1/zero_point17392_const" type="Const" version="opset1">
			<data element_type="f16" offset="1017224" shape="128,1,1,1" size="256"/>
			<output>
				<port id="0" precision="FP16">
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2396" name="957/fq_weights_1/minus_zp" type="Subtract" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>128</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="1">
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>128</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2397" name="957/fq_weights_1/scale17387_const" type="Const" version="opset1">
			<data element_type="f16" offset="1017480" shape="128,1,1,1" size="256"/>
			<output>
				<port id="0" precision="FP16">
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2398" name="957/fq_weights_1/mulpiply_by_scale" type="Multiply" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>128</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="1">
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>128</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2399" name="957" type="Convolution" version="opset1">
			<data auto_pad="explicit" dilations="1,1" pads_begin="0,0" pads_end="0,0" strides="1,1"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>128</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
				<port id="1">
					<dim>128</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" names="957" precision="FP16">
					<dim>1</dim>
					<dim>128</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
			</output>
		</layer>
		<layer id="2400" name="30443046_const" type="Const" version="opset1">
			<data element_type="f16" offset="955072" shape="1,128,1,1" size="256"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2401" name="957/add_" type="Add" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>128</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
				<port id="1">
					<dim>1</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>1</dim>
					<dim>128</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
			</output>
		</layer>
		<layer id="2402" name="58575861_const" type="Const" version="opset1">
			<data element_type="f16" offset="1017736" shape="1,128,1,1" size="256"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2403" name="58585862_const" type="Const" version="opset1">
			<data element_type="f16" offset="1017992" shape="1,128,1,1" size="256"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2404" name="58595863_const" type="Const" version="opset1">
			<data element_type="f16" offset="1017736" shape="1,128,1,1" size="256"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2405" name="58605864_const" type="Const" version="opset1">
			<data element_type="f16" offset="1017992" shape="1,128,1,1" size="256"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2406" name="958/fq_input_0" type="FakeQuantize" version="opset1">
			<data auto_broadcast="numpy" levels="256"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>128</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
				<port id="1">
					<dim>1</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="2">
					<dim>1</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="3">
					<dim>1</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="4">
					<dim>1</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="5" precision="FP16">
					<dim>1</dim>
					<dim>128</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
			</output>
		</layer>
		<layer id="2407" name="4211542118_const205415641/quantized20043_const" type="Const" version="opset1">
			<data element_type="i8" offset="1018248" shape="128,1,3,3" size="1152"/>
			<output>
				<port id="0" precision="I8">
					<dim>128</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</output>
		</layer>
		<layer id="2408" name="4211542118_const205415641/quantized/to_f16" type="Convert" version="opset1">
			<data destination_type="f16"/>
			<input>
				<port id="0">
					<dim>128</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</input>
			<output>
				<port id="1" precision="FP16">
					<dim>128</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</output>
		</layer>
		<layer id="2409" name="958/fq_weights_1/zero_point20056_const" type="Const" version="opset1">
			<data element_type="f16" offset="1019400" shape="128,1,1,1" size="256"/>
			<output>
				<port id="0" precision="FP16">
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2410" name="958/fq_weights_1/minus_zp" type="Subtract" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>128</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
				<port id="1">
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>128</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</output>
		</layer>
		<layer id="2411" name="958/fq_weights_1/scale20051_const" type="Const" version="opset1">
			<data element_type="f16" offset="1019656" shape="128,1,1,1" size="256"/>
			<output>
				<port id="0" precision="FP16">
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2412" name="958/fq_weights_1/mulpiply_by_scale" type="Multiply" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>128</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
				<port id="1">
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>128</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</output>
		</layer>
		<layer id="2413" name="24596/value24598_const" type="Const" version="opset1">
			<data element_type="i64" offset="957504" shape="5" size="40"/>
			<output>
				<port id="0" precision="I64">
					<dim>5</dim>
				</port>
			</output>
		</layer>
		<layer id="2414" name="24596" type="Reshape" version="opset1">
			<data special_zero="true"/>
			<input>
				<port id="0">
					<dim>128</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
				<port id="1">
					<dim>5</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</output>
		</layer>
		<layer id="2415" name="958" type="GroupConvolution" version="opset1">
			<data auto_pad="explicit" dilations="1,1" pads_begin="1,1" pads_end="1,1" strides="1,1"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>128</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
				<port id="1">
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>1</dim>
					<dim>128</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
			</output>
		</layer>
		<layer id="2416" name="data_add_221572216222826/EltwiseUnsqueeze23650_const2056_const" type="Const" version="opset1">
			<data element_type="f16" offset="1019912" shape="1,128,1,1" size="256"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2417" name="959/variance/Fused_Add_" type="Add" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>128</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
				<port id="1">
					<dim>1</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" names="959" precision="FP16">
					<dim>1</dim>
					<dim>128</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
			</output>
		</layer>
		<layer id="2418" name="960" type="ReLU" version="opset1">
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>128</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
			</input>
			<output>
				<port id="1" names="960" precision="FP16">
					<dim>1</dim>
					<dim>128</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
			</output>
		</layer>
		<layer id="2419" name="68776881_const" type="Const" version="opset1">
			<data element_type="f16" offset="10108" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="2420" name="68786882_const" type="Const" version="opset1">
			<data element_type="f16" offset="1020168" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="2421" name="68796883_const" type="Const" version="opset1">
			<data element_type="f16" offset="10108" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="2422" name="68806884_const" type="Const" version="opset1">
			<data element_type="f16" offset="1020168" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="2423" name="961/fq_input_0" type="FakeQuantize" version="opset1">
			<data auto_broadcast="numpy" levels="256"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>128</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
				<port id="1"/>
				<port id="2"/>
				<port id="3"/>
				<port id="4"/>
			</input>
			<output>
				<port id="5" precision="FP16">
					<dim>1</dim>
					<dim>128</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
			</output>
		</layer>
		<layer id="2424" name="conv4.0.conv2c.1.conv1.weight/quantized18051_const" type="Const" version="opset1">
			<data element_type="i8" offset="1020170" shape="128,128,1,1" size="16384"/>
			<output>
				<port id="0" precision="I8">
					<dim>128</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2425" name="conv4.0.conv2c.1.conv1.weight/quantized/to_f16" type="Convert" version="opset1">
			<data destination_type="f16"/>
			<input>
				<port id="0">
					<dim>128</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="1" precision="FP16">
					<dim>128</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2426" name="961/fq_weights_1/zero_point18064_const" type="Const" version="opset1">
			<data element_type="f16" offset="1036554" shape="128,1,1,1" size="256"/>
			<output>
				<port id="0" precision="FP16">
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2427" name="961/fq_weights_1/minus_zp" type="Subtract" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>128</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="1">
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>128</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2428" name="961/fq_weights_1/scale18059_const" type="Const" version="opset1">
			<data element_type="f16" offset="1036810" shape="128,1,1,1" size="256"/>
			<output>
				<port id="0" precision="FP16">
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2429" name="961/fq_weights_1/mulpiply_by_scale" type="Multiply" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>128</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="1">
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>128</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2430" name="961" type="Convolution" version="opset1">
			<data auto_pad="explicit" dilations="1,1" pads_begin="0,0" pads_end="0,0" strides="1,1"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>128</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
				<port id="1">
					<dim>128</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" names="961" precision="FP16">
					<dim>1</dim>
					<dim>128</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
			</output>
		</layer>
		<layer id="2431" name="30483050_const" type="Const" version="opset1">
			<data element_type="f16" offset="955072" shape="1,128,1,1" size="256"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2432" name="961/add_" type="Add" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>128</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
				<port id="1">
					<dim>1</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>1</dim>
					<dim>128</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
			</output>
		</layer>
		<layer id="2433" name="55475551_const" type="Const" version="opset1">
			<data element_type="f16" offset="1037066" shape="1,128,1,1" size="256"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2434" name="55485552_const" type="Const" version="opset1">
			<data element_type="f16" offset="1037322" shape="1,128,1,1" size="256"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2435" name="55495553_const" type="Const" version="opset1">
			<data element_type="f16" offset="1037066" shape="1,128,1,1" size="256"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2436" name="55505554_const" type="Const" version="opset1">
			<data element_type="f16" offset="1037322" shape="1,128,1,1" size="256"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2437" name="962/fq_input_0" type="FakeQuantize" version="opset1">
			<data auto_broadcast="numpy" levels="256"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>128</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
				<port id="1">
					<dim>1</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="2">
					<dim>1</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="3">
					<dim>1</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="4">
					<dim>1</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="5" precision="FP16">
					<dim>1</dim>
					<dim>128</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
			</output>
		</layer>
		<layer id="2438" name="4226342266_const206115644/quantized19779_const" type="Const" version="opset1">
			<data element_type="i8" offset="1037578" shape="128,1,3,3" size="1152"/>
			<output>
				<port id="0" precision="I8">
					<dim>128</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</output>
		</layer>
		<layer id="2439" name="4226342266_const206115644/quantized/to_f16" type="Convert" version="opset1">
			<data destination_type="f16"/>
			<input>
				<port id="0">
					<dim>128</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</input>
			<output>
				<port id="1" precision="FP16">
					<dim>128</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</output>
		</layer>
		<layer id="2440" name="962/fq_weights_1/zero_point19792_const" type="Const" version="opset1">
			<data element_type="f16" offset="1038730" shape="128,1,1,1" size="256"/>
			<output>
				<port id="0" precision="FP16">
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2441" name="962/fq_weights_1/minus_zp" type="Subtract" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>128</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
				<port id="1">
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>128</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</output>
		</layer>
		<layer id="2442" name="962/fq_weights_1/scale19787_const" type="Const" version="opset1">
			<data element_type="f16" offset="1038986" shape="128,1,1,1" size="256"/>
			<output>
				<port id="0" precision="FP16">
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2443" name="962/fq_weights_1/mulpiply_by_scale" type="Multiply" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>128</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
				<port id="1">
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>128</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</output>
		</layer>
		<layer id="2444" name="24392/value24394_const" type="Const" version="opset1">
			<data element_type="i64" offset="957504" shape="5" size="40"/>
			<output>
				<port id="0" precision="I64">
					<dim>5</dim>
				</port>
			</output>
		</layer>
		<layer id="2445" name="24392" type="Reshape" version="opset1">
			<data special_zero="true"/>
			<input>
				<port id="0">
					<dim>128</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
				<port id="1">
					<dim>5</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</output>
		</layer>
		<layer id="2446" name="962" type="GroupConvolution" version="opset1">
			<data auto_pad="explicit" dilations="1,1" pads_begin="1,1" pads_end="1,1" strides="1,1"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>128</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
				<port id="1">
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>1</dim>
					<dim>128</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
			</output>
		</layer>
		<layer id="2447" name="data_add_221652217022828/EltwiseUnsqueeze23658_const2063_const" type="Const" version="opset1">
			<data element_type="f16" offset="1039242" shape="1,128,1,1" size="256"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2448" name="963/variance/Fused_Add_" type="Add" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>128</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
				<port id="1">
					<dim>1</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" names="963" precision="FP16">
					<dim>1</dim>
					<dim>128</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
			</output>
		</layer>
		<layer id="2449" name="964" type="ReLU" version="opset1">
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>128</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
			</input>
			<output>
				<port id="1" names="964" precision="FP16">
					<dim>1</dim>
					<dim>128</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
			</output>
		</layer>
		<layer id="2450" name="71077111_const" type="Const" version="opset1">
			<data element_type="f16" offset="10108" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="2451" name="71087112_const" type="Const" version="opset1">
			<data element_type="f16" offset="1039498" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="2452" name="71097113_const" type="Const" version="opset1">
			<data element_type="f16" offset="10108" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="2453" name="71107114_const" type="Const" version="opset1">
			<data element_type="f16" offset="1039498" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="2454" name="965/fq_input_0" type="FakeQuantize" version="opset1">
			<data auto_broadcast="numpy" levels="256"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>128</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
				<port id="1"/>
				<port id="2"/>
				<port id="3"/>
				<port id="4"/>
			</input>
			<output>
				<port id="5" precision="FP16">
					<dim>1</dim>
					<dim>128</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
			</output>
		</layer>
		<layer id="2455" name="conv4.0.conv2c.2.conv1.weight/quantized17475_const" type="Const" version="opset1">
			<data element_type="i8" offset="1039500" shape="128,128,1,1" size="16384"/>
			<output>
				<port id="0" precision="I8">
					<dim>128</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2456" name="conv4.0.conv2c.2.conv1.weight/quantized/to_f16" type="Convert" version="opset1">
			<data destination_type="f16"/>
			<input>
				<port id="0">
					<dim>128</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="1" precision="FP16">
					<dim>128</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2457" name="965/fq_weights_1/zero_point17488_const" type="Const" version="opset1">
			<data element_type="f16" offset="1055884" shape="128,1,1,1" size="256"/>
			<output>
				<port id="0" precision="FP16">
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2458" name="965/fq_weights_1/minus_zp" type="Subtract" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>128</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="1">
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>128</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2459" name="965/fq_weights_1/scale17483_const" type="Const" version="opset1">
			<data element_type="f16" offset="1056140" shape="128,1,1,1" size="256"/>
			<output>
				<port id="0" precision="FP16">
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2460" name="965/fq_weights_1/mulpiply_by_scale" type="Multiply" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>128</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="1">
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>128</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2461" name="965" type="Convolution" version="opset1">
			<data auto_pad="explicit" dilations="1,1" pads_begin="0,0" pads_end="0,0" strides="1,1"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>128</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
				<port id="1">
					<dim>128</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" names="965" precision="FP16">
					<dim>1</dim>
					<dim>128</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
			</output>
		</layer>
		<layer id="2462" name="30523054_const" type="Const" version="opset1">
			<data element_type="f16" offset="955072" shape="1,128,1,1" size="256"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2463" name="965/add_" type="Add" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>128</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
				<port id="1">
					<dim>1</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>1</dim>
					<dim>128</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
			</output>
		</layer>
		<layer id="2464" name="81578161_const" type="Const" version="opset1">
			<data element_type="f16" offset="1056396" shape="1,128,1,1" size="256"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2465" name="81588162_const" type="Const" version="opset1">
			<data element_type="f16" offset="1056652" shape="1,128,1,1" size="256"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2466" name="81598163_const" type="Const" version="opset1">
			<data element_type="f16" offset="1056396" shape="1,128,1,1" size="256"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2467" name="81608164_const" type="Const" version="opset1">
			<data element_type="f16" offset="1056652" shape="1,128,1,1" size="256"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2468" name="966/fq_input_0" type="FakeQuantize" version="opset1">
			<data auto_broadcast="numpy" levels="256"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>128</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
				<port id="1">
					<dim>1</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="2">
					<dim>1</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="3">
					<dim>1</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="4">
					<dim>1</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="5" precision="FP16">
					<dim>1</dim>
					<dim>128</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
			</output>
		</layer>
		<layer id="2469" name="4217542178_const206815647/quantized18771_const" type="Const" version="opset1">
			<data element_type="i8" offset="1056908" shape="128,1,3,3" size="1152"/>
			<output>
				<port id="0" precision="I8">
					<dim>128</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</output>
		</layer>
		<layer id="2470" name="4217542178_const206815647/quantized/to_f16" type="Convert" version="opset1">
			<data destination_type="f16"/>
			<input>
				<port id="0">
					<dim>128</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</input>
			<output>
				<port id="1" precision="FP16">
					<dim>128</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</output>
		</layer>
		<layer id="2471" name="966/fq_weights_1/zero_point18784_const" type="Const" version="opset1">
			<data element_type="f16" offset="1058060" shape="128,1,1,1" size="256"/>
			<output>
				<port id="0" precision="FP16">
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2472" name="966/fq_weights_1/minus_zp" type="Subtract" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>128</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
				<port id="1">
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>128</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</output>
		</layer>
		<layer id="2473" name="966/fq_weights_1/scale18779_const" type="Const" version="opset1">
			<data element_type="f16" offset="1058316" shape="128,1,1,1" size="256"/>
			<output>
				<port id="0" precision="FP16">
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2474" name="966/fq_weights_1/mulpiply_by_scale" type="Multiply" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>128</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
				<port id="1">
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>128</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</output>
		</layer>
		<layer id="2475" name="24456/value24458_const" type="Const" version="opset1">
			<data element_type="i64" offset="957504" shape="5" size="40"/>
			<output>
				<port id="0" precision="I64">
					<dim>5</dim>
				</port>
			</output>
		</layer>
		<layer id="2476" name="24456" type="Reshape" version="opset1">
			<data special_zero="true"/>
			<input>
				<port id="0">
					<dim>128</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
				<port id="1">
					<dim>5</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</output>
		</layer>
		<layer id="2477" name="966" type="GroupConvolution" version="opset1">
			<data auto_pad="explicit" dilations="1,1" pads_begin="1,1" pads_end="1,1" strides="1,1"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>128</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
				<port id="1">
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>1</dim>
					<dim>128</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
			</output>
		</layer>
		<layer id="2478" name="data_add_221732217822830/EltwiseUnsqueeze23666_const2070_const" type="Const" version="opset1">
			<data element_type="f16" offset="1058572" shape="1,128,1,1" size="256"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2479" name="967/variance/Fused_Add_" type="Add" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>128</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
				<port id="1">
					<dim>1</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" names="967" precision="FP16">
					<dim>1</dim>
					<dim>128</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
			</output>
		</layer>
		<layer id="2480" name="968" type="ReLU" version="opset1">
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>128</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
			</input>
			<output>
				<port id="1" names="968" precision="FP16">
					<dim>1</dim>
					<dim>128</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
			</output>
		</layer>
		<layer id="2481" name="56675671_const" type="Const" version="opset1">
			<data element_type="f16" offset="10108" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="2482" name="56685672_const" type="Const" version="opset1">
			<data element_type="f16" offset="1058828" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="2483" name="56695673_const" type="Const" version="opset1">
			<data element_type="f16" offset="10108" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="2484" name="56705674_const" type="Const" version="opset1">
			<data element_type="f16" offset="1058828" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="2485" name="1003/fq_input_0" type="FakeQuantize" version="opset1">
			<data auto_broadcast="numpy" levels="256"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>128</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
				<port id="1"/>
				<port id="2"/>
				<port id="3"/>
				<port id="4"/>
			</input>
			<output>
				<port id="5" precision="FP16">
					<dim>1</dim>
					<dim>128</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
			</output>
		</layer>
		<layer id="2486" name="1414/Output_0/Data__const2073_const" type="Const" version="opset1">
			<data element_type="i64" offset="24" shape="" size="8"/>
			<output>
				<port id="0" precision="I64"/>
			</output>
		</layer>
		<layer id="2487" name="998/input_rank/shape_of" type="ShapeOf" version="opset3">
			<data output_type="i64"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>128</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
			</input>
			<output>
				<port id="1" precision="I64">
					<dim>4</dim>
				</port>
			</output>
		</layer>
		<layer id="2488" name="998/input_rank/rank_of" type="ShapeOf" version="opset3">
			<data output_type="i64"/>
			<input>
				<port id="0">
					<dim>4</dim>
				</port>
			</input>
			<output>
				<port id="1" precision="I64">
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2489" name="998/input_rank/0d_rank_of/value/Output_0/Data__const2076_const" type="Const" version="opset1">
			<data element_type="i64" offset="32" shape="1" size="8"/>
			<output>
				<port id="0" precision="I64">
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2490" name="998/input_rank" type="Squeeze" version="opset1">
			<input>
				<port id="0">
					<dim>1</dim>
				</port>
				<port id="1">
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="I64"/>
			</output>
		</layer>
		<layer id="2491" name="1416/Output_0/Data__const2078_const" type="Const" version="opset1">
			<data element_type="i64" offset="0" shape="" size="8"/>
			<output>
				<port id="0" precision="I64"/>
			</output>
		</layer>
		<layer id="2492" name="998/global_pooling_reduce_axis" type="Range" version="opset4">
			<data output_type="i64"/>
			<input>
				<port id="0"/>
				<port id="1"/>
				<port id="2"/>
			</input>
			<output>
				<port id="3" precision="I64">
					<dim>2</dim>
				</port>
			</output>
		</layer>
		<layer id="2493" name="998/reduce" type="ReduceMean" version="opset1">
			<data keep_dims="true"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>128</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
				<port id="1">
					<dim>2</dim>
				</port>
			</input>
			<output>
				<port id="2" names="998" precision="FP16">
					<dim>1</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2494" name="Copy_conv4.0.gate.fc1.weight/Output_0/Data_4401_const2081_const" type="Const" version="opset1">
			<data element_type="f16" offset="957802" shape="8,128,1,1" size="2048"/>
			<output>
				<port id="0" names="conv4.0.gate.fc1.weight" precision="FP16">
					<dim>8</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2495" name="999/WithoutBiases" type="Convolution" version="opset1">
			<data auto_pad="explicit" dilations="1,1" pads_begin="0,0" pads_end="0,0" strides="1,1"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="1">
					<dim>8</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>1</dim>
					<dim>8</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2496" name="999/Dims1289822685/EltwiseUnsqueeze23094_const2083_const" type="Const" version="opset1">
			<data element_type="f16" offset="959850" shape="1,8,1,1" size="16"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>8</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2497" name="999" type="Add" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>8</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="1">
					<dim>1</dim>
					<dim>8</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" names="999" precision="FP16">
					<dim>1</dim>
					<dim>8</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2498" name="1000" type="ReLU" version="opset1">
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>8</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="1" names="1000" precision="FP16">
					<dim>1</dim>
					<dim>8</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2499" name="Copy_conv4.0.gate.fc2.weight/Output_0/Data_4409_const2086_const" type="Const" version="opset1">
			<data element_type="f16" offset="959866" shape="128,8,1,1" size="2048"/>
			<output>
				<port id="0" names="conv4.0.gate.fc2.weight" precision="FP16">
					<dim>128</dim>
					<dim>8</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2500" name="1001/WithoutBiases" type="Convolution" version="opset1">
			<data auto_pad="explicit" dilations="1,1" pads_begin="0,0" pads_end="0,0" strides="1,1"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>8</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="1">
					<dim>128</dim>
					<dim>8</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>1</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2501" name="1001/Dims1301822705/EltwiseUnsqueeze23174_const2088_const" type="Const" version="opset1">
			<data element_type="f16" offset="961914" shape="1,128,1,1" size="256"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2502" name="1001" type="Add" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="1">
					<dim>1</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" names="1001" precision="FP16">
					<dim>1</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2503" name="1002" type="Sigmoid" version="opset1">
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="1" names="1002" precision="FP16">
					<dim>1</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2504" name="56775681_const" type="Const" version="opset1">
			<data element_type="f16" offset="10108" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="2505" name="56785682_const" type="Const" version="opset1">
			<data element_type="f16" offset="1058830" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="2506" name="56795683_const" type="Const" version="opset1">
			<data element_type="f16" offset="10108" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="2507" name="56805684_const" type="Const" version="opset1">
			<data element_type="f16" offset="1058830" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="2508" name="1003/fq_input_1" type="FakeQuantize" version="opset1">
			<data auto_broadcast="numpy" levels="256"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="1"/>
				<port id="2"/>
				<port id="3"/>
				<port id="4"/>
			</input>
			<output>
				<port id="5" precision="FP16">
					<dim>1</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2509" name="1003" type="Multiply" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>128</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
				<port id="1">
					<dim>1</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" names="1003" precision="FP16">
					<dim>1</dim>
					<dim>128</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
			</output>
		</layer>
		<layer id="2510" name="47174721_const" type="Const" version="opset1">
			<data element_type="f16" offset="10108" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="2511" name="47184722_const" type="Const" version="opset1">
			<data element_type="f16" offset="1058832" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="2512" name="47194723_const" type="Const" version="opset1">
			<data element_type="f16" offset="10108" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="2513" name="47204724_const" type="Const" version="opset1">
			<data element_type="f16" offset="1058832" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="2514" name="1004/fq_input_1" type="FakeQuantize" version="opset1">
			<data auto_broadcast="numpy" levels="256"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>128</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
				<port id="1"/>
				<port id="2"/>
				<port id="3"/>
				<port id="4"/>
			</input>
			<output>
				<port id="5" precision="FP16">
					<dim>1</dim>
					<dim>128</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
			</output>
		</layer>
		<layer id="2515" name="1004" type="Add" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>128</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
				<port id="1">
					<dim>1</dim>
					<dim>128</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
			</input>
			<output>
				<port id="2" names="1004" precision="FP16">
					<dim>1</dim>
					<dim>128</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
			</output>
		</layer>
		<layer id="2516" name="80678071_const" type="Const" version="opset1">
			<data element_type="f16" offset="10108" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="2517" name="80688072_const" type="Const" version="opset1">
			<data element_type="f16" offset="1058834" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="2518" name="80698073_const" type="Const" version="opset1">
			<data element_type="f16" offset="10108" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="2519" name="80708074_const" type="Const" version="opset1">
			<data element_type="f16" offset="1058834" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="2520" name="1011/fq_input_0" type="FakeQuantize" version="opset1">
			<data auto_broadcast="numpy" levels="256"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>128</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
				<port id="1"/>
				<port id="2"/>
				<port id="3"/>
				<port id="4"/>
			</input>
			<output>
				<port id="5" precision="FP16">
					<dim>1</dim>
					<dim>128</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
			</output>
		</layer>
		<layer id="2521" name="conv4.0.conv2d.0.conv1.weight/quantized19995_const" type="Const" version="opset1">
			<data element_type="i8" offset="1058836" shape="128,128,1,1" size="16384"/>
			<output>
				<port id="0" precision="I8">
					<dim>128</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2522" name="conv4.0.conv2d.0.conv1.weight/quantized/to_f16" type="Convert" version="opset1">
			<data destination_type="f16"/>
			<input>
				<port id="0">
					<dim>128</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="1" precision="FP16">
					<dim>128</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2523" name="969/fq_weights_1/zero_point20008_const" type="Const" version="opset1">
			<data element_type="f16" offset="1075220" shape="128,1,1,1" size="256"/>
			<output>
				<port id="0" precision="FP16">
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2524" name="969/fq_weights_1/minus_zp" type="Subtract" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>128</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="1">
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>128</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2525" name="969/fq_weights_1/scale20003_const" type="Const" version="opset1">
			<data element_type="f16" offset="1075476" shape="128,1,1,1" size="256"/>
			<output>
				<port id="0" precision="FP16">
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2526" name="969/fq_weights_1/mulpiply_by_scale" type="Multiply" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>128</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="1">
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>128</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2527" name="969" type="Convolution" version="opset1">
			<data auto_pad="explicit" dilations="1,1" pads_begin="0,0" pads_end="0,0" strides="1,1"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>128</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
				<port id="1">
					<dim>128</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" names="969" precision="FP16">
					<dim>1</dim>
					<dim>128</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
			</output>
		</layer>
		<layer id="2528" name="30563058_const" type="Const" version="opset1">
			<data element_type="f16" offset="955072" shape="1,128,1,1" size="256"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2529" name="969/add_" type="Add" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>128</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
				<port id="1">
					<dim>1</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>1</dim>
					<dim>128</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
			</output>
		</layer>
		<layer id="2530" name="60976101_const" type="Const" version="opset1">
			<data element_type="f16" offset="1075732" shape="1,128,1,1" size="256"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2531" name="60986102_const" type="Const" version="opset1">
			<data element_type="f16" offset="1075988" shape="1,128,1,1" size="256"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2532" name="60996103_const" type="Const" version="opset1">
			<data element_type="f16" offset="1075732" shape="1,128,1,1" size="256"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2533" name="61006104_const" type="Const" version="opset1">
			<data element_type="f16" offset="1075988" shape="1,128,1,1" size="256"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2534" name="970/fq_input_0" type="FakeQuantize" version="opset1">
			<data auto_broadcast="numpy" levels="256"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>128</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
				<port id="1">
					<dim>1</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="2">
					<dim>1</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="3">
					<dim>1</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="4">
					<dim>1</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="5" precision="FP16">
					<dim>1</dim>
					<dim>128</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
			</output>
		</layer>
		<layer id="2535" name="4225542258_const209515657/quantized19731_const" type="Const" version="opset1">
			<data element_type="i8" offset="1076244" shape="128,1,3,3" size="1152"/>
			<output>
				<port id="0" precision="I8">
					<dim>128</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</output>
		</layer>
		<layer id="2536" name="4225542258_const209515657/quantized/to_f16" type="Convert" version="opset1">
			<data destination_type="f16"/>
			<input>
				<port id="0">
					<dim>128</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</input>
			<output>
				<port id="1" precision="FP16">
					<dim>128</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</output>
		</layer>
		<layer id="2537" name="970/fq_weights_1/zero_point19744_const" type="Const" version="opset1">
			<data element_type="f16" offset="1077396" shape="128,1,1,1" size="256"/>
			<output>
				<port id="0" precision="FP16">
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2538" name="970/fq_weights_1/minus_zp" type="Subtract" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>128</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
				<port id="1">
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>128</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</output>
		</layer>
		<layer id="2539" name="970/fq_weights_1/scale19739_const" type="Const" version="opset1">
			<data element_type="f16" offset="1077652" shape="128,1,1,1" size="256"/>
			<output>
				<port id="0" precision="FP16">
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2540" name="970/fq_weights_1/mulpiply_by_scale" type="Multiply" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>128</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
				<port id="1">
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>128</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</output>
		</layer>
		<layer id="2541" name="24400/value24402_const" type="Const" version="opset1">
			<data element_type="i64" offset="957504" shape="5" size="40"/>
			<output>
				<port id="0" precision="I64">
					<dim>5</dim>
				</port>
			</output>
		</layer>
		<layer id="2542" name="24400" type="Reshape" version="opset1">
			<data special_zero="true"/>
			<input>
				<port id="0">
					<dim>128</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
				<port id="1">
					<dim>5</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</output>
		</layer>
		<layer id="2543" name="970" type="GroupConvolution" version="opset1">
			<data auto_pad="explicit" dilations="1,1" pads_begin="1,1" pads_end="1,1" strides="1,1"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>128</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
				<port id="1">
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>1</dim>
					<dim>128</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
			</output>
		</layer>
		<layer id="2544" name="data_add_221252213022818/EltwiseUnsqueeze23618_const2097_const" type="Const" version="opset1">
			<data element_type="f16" offset="1077908" shape="1,128,1,1" size="256"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2545" name="971/variance/Fused_Add_" type="Add" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>128</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
				<port id="1">
					<dim>1</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" names="971" precision="FP16">
					<dim>1</dim>
					<dim>128</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
			</output>
		</layer>
		<layer id="2546" name="972" type="ReLU" version="opset1">
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>128</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
			</input>
			<output>
				<port id="1" names="972" precision="FP16">
					<dim>1</dim>
					<dim>128</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
			</output>
		</layer>
		<layer id="2547" name="44474451_const" type="Const" version="opset1">
			<data element_type="f16" offset="10108" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="2548" name="44484452_const" type="Const" version="opset1">
			<data element_type="f16" offset="1078164" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="2549" name="44494453_const" type="Const" version="opset1">
			<data element_type="f16" offset="10108" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="2550" name="44504454_const" type="Const" version="opset1">
			<data element_type="f16" offset="1078164" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="2551" name="973/fq_input_0" type="FakeQuantize" version="opset1">
			<data auto_broadcast="numpy" levels="256"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>128</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
				<port id="1"/>
				<port id="2"/>
				<port id="3"/>
				<port id="4"/>
			</input>
			<output>
				<port id="5" precision="FP16">
					<dim>1</dim>
					<dim>128</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
			</output>
		</layer>
		<layer id="2552" name="conv4.0.conv2d.1.conv1.weight/quantized18027_const" type="Const" version="opset1">
			<data element_type="i8" offset="1078166" shape="128,128,1,1" size="16384"/>
			<output>
				<port id="0" precision="I8">
					<dim>128</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2553" name="conv4.0.conv2d.1.conv1.weight/quantized/to_f16" type="Convert" version="opset1">
			<data destination_type="f16"/>
			<input>
				<port id="0">
					<dim>128</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="1" precision="FP16">
					<dim>128</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2554" name="973/fq_weights_1/zero_point18040_const" type="Const" version="opset1">
			<data element_type="f16" offset="1094550" shape="128,1,1,1" size="256"/>
			<output>
				<port id="0" precision="FP16">
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2555" name="973/fq_weights_1/minus_zp" type="Subtract" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>128</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="1">
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>128</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2556" name="973/fq_weights_1/scale18035_const" type="Const" version="opset1">
			<data element_type="f16" offset="1094806" shape="128,1,1,1" size="256"/>
			<output>
				<port id="0" precision="FP16">
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2557" name="973/fq_weights_1/mulpiply_by_scale" type="Multiply" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>128</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="1">
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>128</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2558" name="973" type="Convolution" version="opset1">
			<data auto_pad="explicit" dilations="1,1" pads_begin="0,0" pads_end="0,0" strides="1,1"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>128</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
				<port id="1">
					<dim>128</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" names="973" precision="FP16">
					<dim>1</dim>
					<dim>128</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
			</output>
		</layer>
		<layer id="2559" name="30603062_const" type="Const" version="opset1">
			<data element_type="f16" offset="955072" shape="1,128,1,1" size="256"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2560" name="973/add_" type="Add" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>128</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
				<port id="1">
					<dim>1</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>1</dim>
					<dim>128</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
			</output>
		</layer>
		<layer id="2561" name="54075411_const" type="Const" version="opset1">
			<data element_type="f16" offset="1095062" shape="1,128,1,1" size="256"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2562" name="54085412_const" type="Const" version="opset1">
			<data element_type="f16" offset="1095318" shape="1,128,1,1" size="256"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2563" name="54095413_const" type="Const" version="opset1">
			<data element_type="f16" offset="1095062" shape="1,128,1,1" size="256"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2564" name="54105414_const" type="Const" version="opset1">
			<data element_type="f16" offset="1095318" shape="1,128,1,1" size="256"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2565" name="974/fq_input_0" type="FakeQuantize" version="opset1">
			<data auto_broadcast="numpy" levels="256"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>128</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
				<port id="1">
					<dim>1</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="2">
					<dim>1</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="3">
					<dim>1</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="4">
					<dim>1</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="5" precision="FP16">
					<dim>1</dim>
					<dim>128</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
			</output>
		</layer>
		<layer id="2566" name="4220742210_const210215660/quantized18219_const" type="Const" version="opset1">
			<data element_type="i8" offset="1095574" shape="128,1,3,3" size="1152"/>
			<output>
				<port id="0" precision="I8">
					<dim>128</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</output>
		</layer>
		<layer id="2567" name="4220742210_const210215660/quantized/to_f16" type="Convert" version="opset1">
			<data destination_type="f16"/>
			<input>
				<port id="0">
					<dim>128</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</input>
			<output>
				<port id="1" precision="FP16">
					<dim>128</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</output>
		</layer>
		<layer id="2568" name="974/fq_weights_1/zero_point18232_const" type="Const" version="opset1">
			<data element_type="f16" offset="1096726" shape="128,1,1,1" size="256"/>
			<output>
				<port id="0" precision="FP16">
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2569" name="974/fq_weights_1/minus_zp" type="Subtract" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>128</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
				<port id="1">
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>128</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</output>
		</layer>
		<layer id="2570" name="974/fq_weights_1/scale18227_const" type="Const" version="opset1">
			<data element_type="f16" offset="1096982" shape="128,1,1,1" size="256"/>
			<output>
				<port id="0" precision="FP16">
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2571" name="974/fq_weights_1/mulpiply_by_scale" type="Multiply" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>128</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
				<port id="1">
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>128</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</output>
		</layer>
		<layer id="2572" name="24580/value24582_const" type="Const" version="opset1">
			<data element_type="i64" offset="957504" shape="5" size="40"/>
			<output>
				<port id="0" precision="I64">
					<dim>5</dim>
				</port>
			</output>
		</layer>
		<layer id="2573" name="24580" type="Reshape" version="opset1">
			<data special_zero="true"/>
			<input>
				<port id="0">
					<dim>128</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
				<port id="1">
					<dim>5</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</output>
		</layer>
		<layer id="2574" name="974" type="GroupConvolution" version="opset1">
			<data auto_pad="explicit" dilations="1,1" pads_begin="1,1" pads_end="1,1" strides="1,1"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>128</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
				<port id="1">
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>1</dim>
					<dim>128</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
			</output>
		</layer>
		<layer id="2575" name="data_add_221332213822820/EltwiseUnsqueeze23626_const2104_const" type="Const" version="opset1">
			<data element_type="f16" offset="1097238" shape="1,128,1,1" size="256"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2576" name="975/variance/Fused_Add_" type="Add" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>128</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
				<port id="1">
					<dim>1</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" names="975" precision="FP16">
					<dim>1</dim>
					<dim>128</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
			</output>
		</layer>
		<layer id="2577" name="976" type="ReLU" version="opset1">
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>128</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
			</input>
			<output>
				<port id="1" names="976" precision="FP16">
					<dim>1</dim>
					<dim>128</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
			</output>
		</layer>
		<layer id="2578" name="82978301_const" type="Const" version="opset1">
			<data element_type="f16" offset="10108" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="2579" name="82988302_const" type="Const" version="opset1">
			<data element_type="f16" offset="1097494" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="2580" name="82998303_const" type="Const" version="opset1">
			<data element_type="f16" offset="10108" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="2581" name="83008304_const" type="Const" version="opset1">
			<data element_type="f16" offset="1097494" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="2582" name="977/fq_input_0" type="FakeQuantize" version="opset1">
			<data auto_broadcast="numpy" levels="256"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>128</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
				<port id="1"/>
				<port id="2"/>
				<port id="3"/>
				<port id="4"/>
			</input>
			<output>
				<port id="5" precision="FP16">
					<dim>1</dim>
					<dim>128</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
			</output>
		</layer>
		<layer id="2583" name="conv4.0.conv2d.2.conv1.weight/quantized20187_const" type="Const" version="opset1">
			<data element_type="i8" offset="1097496" shape="128,128,1,1" size="16384"/>
			<output>
				<port id="0" precision="I8">
					<dim>128</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2584" name="conv4.0.conv2d.2.conv1.weight/quantized/to_f16" type="Convert" version="opset1">
			<data destination_type="f16"/>
			<input>
				<port id="0">
					<dim>128</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="1" precision="FP16">
					<dim>128</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2585" name="977/fq_weights_1/zero_point20200_const" type="Const" version="opset1">
			<data element_type="f16" offset="1113880" shape="128,1,1,1" size="256"/>
			<output>
				<port id="0" precision="FP16">
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2586" name="977/fq_weights_1/minus_zp" type="Subtract" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>128</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="1">
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>128</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2587" name="977/fq_weights_1/scale20195_const" type="Const" version="opset1">
			<data element_type="f16" offset="1114136" shape="128,1,1,1" size="256"/>
			<output>
				<port id="0" precision="FP16">
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2588" name="977/fq_weights_1/mulpiply_by_scale" type="Multiply" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>128</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="1">
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>128</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2589" name="977" type="Convolution" version="opset1">
			<data auto_pad="explicit" dilations="1,1" pads_begin="0,0" pads_end="0,0" strides="1,1"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>128</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
				<port id="1">
					<dim>128</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" names="977" precision="FP16">
					<dim>1</dim>
					<dim>128</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
			</output>
		</layer>
		<layer id="2590" name="30643066_const" type="Const" version="opset1">
			<data element_type="f16" offset="955072" shape="1,128,1,1" size="256"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2591" name="977/add_" type="Add" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>128</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
				<port id="1">
					<dim>1</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>1</dim>
					<dim>128</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
			</output>
		</layer>
		<layer id="2592" name="70277031_const" type="Const" version="opset1">
			<data element_type="f16" offset="1114392" shape="1,128,1,1" size="256"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2593" name="70287032_const" type="Const" version="opset1">
			<data element_type="f16" offset="1114648" shape="1,128,1,1" size="256"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2594" name="70297033_const" type="Const" version="opset1">
			<data element_type="f16" offset="1114392" shape="1,128,1,1" size="256"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2595" name="70307034_const" type="Const" version="opset1">
			<data element_type="f16" offset="1114648" shape="1,128,1,1" size="256"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2596" name="978/fq_input_0" type="FakeQuantize" version="opset1">
			<data auto_broadcast="numpy" levels="256"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>128</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
				<port id="1">
					<dim>1</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="2">
					<dim>1</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="3">
					<dim>1</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="4">
					<dim>1</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="5" precision="FP16">
					<dim>1</dim>
					<dim>128</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
			</output>
		</layer>
		<layer id="2597" name="4218342186_const210915663/quantized20547_const" type="Const" version="opset1">
			<data element_type="i8" offset="1114904" shape="128,1,3,3" size="1152"/>
			<output>
				<port id="0" precision="I8">
					<dim>128</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</output>
		</layer>
		<layer id="2598" name="4218342186_const210915663/quantized/to_f16" type="Convert" version="opset1">
			<data destination_type="f16"/>
			<input>
				<port id="0">
					<dim>128</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</input>
			<output>
				<port id="1" precision="FP16">
					<dim>128</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</output>
		</layer>
		<layer id="2599" name="978/fq_weights_1/zero_point20560_const" type="Const" version="opset1">
			<data element_type="f16" offset="1116056" shape="128,1,1,1" size="256"/>
			<output>
				<port id="0" precision="FP16">
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2600" name="978/fq_weights_1/minus_zp" type="Subtract" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>128</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
				<port id="1">
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>128</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</output>
		</layer>
		<layer id="2601" name="978/fq_weights_1/scale20555_const" type="Const" version="opset1">
			<data element_type="f16" offset="1116312" shape="128,1,1,1" size="256"/>
			<output>
				<port id="0" precision="FP16">
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2602" name="978/fq_weights_1/mulpiply_by_scale" type="Multiply" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>128</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
				<port id="1">
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>128</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</output>
		</layer>
		<layer id="2603" name="24424/value24426_const" type="Const" version="opset1">
			<data element_type="i64" offset="957504" shape="5" size="40"/>
			<output>
				<port id="0" precision="I64">
					<dim>5</dim>
				</port>
			</output>
		</layer>
		<layer id="2604" name="24424" type="Reshape" version="opset1">
			<data special_zero="true"/>
			<input>
				<port id="0">
					<dim>128</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
				<port id="1">
					<dim>5</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</output>
		</layer>
		<layer id="2605" name="978" type="GroupConvolution" version="opset1">
			<data auto_pad="explicit" dilations="1,1" pads_begin="1,1" pads_end="1,1" strides="1,1"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>128</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
				<port id="1">
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>1</dim>
					<dim>128</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
			</output>
		</layer>
		<layer id="2606" name="data_add_221412214622822/EltwiseUnsqueeze23634_const2111_const" type="Const" version="opset1">
			<data element_type="f16" offset="1116568" shape="1,128,1,1" size="256"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2607" name="979/variance/Fused_Add_" type="Add" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>128</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
				<port id="1">
					<dim>1</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" names="979" precision="FP16">
					<dim>1</dim>
					<dim>128</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
			</output>
		</layer>
		<layer id="2608" name="980" type="ReLU" version="opset1">
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>128</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
			</input>
			<output>
				<port id="1" names="980" precision="FP16">
					<dim>1</dim>
					<dim>128</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
			</output>
		</layer>
		<layer id="2609" name="67376741_const" type="Const" version="opset1">
			<data element_type="f16" offset="10108" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="2610" name="67386742_const" type="Const" version="opset1">
			<data element_type="f16" offset="1116824" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="2611" name="67396743_const" type="Const" version="opset1">
			<data element_type="f16" offset="10108" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="2612" name="67406744_const" type="Const" version="opset1">
			<data element_type="f16" offset="1116824" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="2613" name="981/fq_input_0" type="FakeQuantize" version="opset1">
			<data auto_broadcast="numpy" levels="256"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>128</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
				<port id="1"/>
				<port id="2"/>
				<port id="3"/>
				<port id="4"/>
			</input>
			<output>
				<port id="5" precision="FP16">
					<dim>1</dim>
					<dim>128</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
			</output>
		</layer>
		<layer id="2614" name="conv4.0.conv2d.3.conv1.weight/quantized19299_const" type="Const" version="opset1">
			<data element_type="i8" offset="1116826" shape="128,128,1,1" size="16384"/>
			<output>
				<port id="0" precision="I8">
					<dim>128</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2615" name="conv4.0.conv2d.3.conv1.weight/quantized/to_f16" type="Convert" version="opset1">
			<data destination_type="f16"/>
			<input>
				<port id="0">
					<dim>128</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="1" precision="FP16">
					<dim>128</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2616" name="981/fq_weights_1/zero_point19312_const" type="Const" version="opset1">
			<data element_type="f16" offset="1133210" shape="128,1,1,1" size="256"/>
			<output>
				<port id="0" precision="FP16">
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2617" name="981/fq_weights_1/minus_zp" type="Subtract" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>128</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="1">
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>128</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2618" name="981/fq_weights_1/scale19307_const" type="Const" version="opset1">
			<data element_type="f16" offset="1133466" shape="128,1,1,1" size="256"/>
			<output>
				<port id="0" precision="FP16">
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2619" name="981/fq_weights_1/mulpiply_by_scale" type="Multiply" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>128</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="1">
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>128</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2620" name="981" type="Convolution" version="opset1">
			<data auto_pad="explicit" dilations="1,1" pads_begin="0,0" pads_end="0,0" strides="1,1"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>128</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
				<port id="1">
					<dim>128</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" names="981" precision="FP16">
					<dim>1</dim>
					<dim>128</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
			</output>
		</layer>
		<layer id="2621" name="30683070_const" type="Const" version="opset1">
			<data element_type="f16" offset="955072" shape="1,128,1,1" size="256"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2622" name="981/add_" type="Add" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>128</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
				<port id="1">
					<dim>1</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>1</dim>
					<dim>128</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
			</output>
		</layer>
		<layer id="2623" name="44274431_const" type="Const" version="opset1">
			<data element_type="f16" offset="1133722" shape="1,128,1,1" size="256"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2624" name="44284432_const" type="Const" version="opset1">
			<data element_type="f16" offset="1133978" shape="1,128,1,1" size="256"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2625" name="44294433_const" type="Const" version="opset1">
			<data element_type="f16" offset="1133722" shape="1,128,1,1" size="256"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2626" name="44304434_const" type="Const" version="opset1">
			<data element_type="f16" offset="1133978" shape="1,128,1,1" size="256"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2627" name="982/fq_input_0" type="FakeQuantize" version="opset1">
			<data auto_broadcast="numpy" levels="256"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>128</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
				<port id="1">
					<dim>1</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="2">
					<dim>1</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="3">
					<dim>1</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="4">
					<dim>1</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="5" precision="FP16">
					<dim>1</dim>
					<dim>128</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
			</output>
		</layer>
		<layer id="2628" name="4212742130_const211615666/quantized20403_const" type="Const" version="opset1">
			<data element_type="i8" offset="1134234" shape="128,1,3,3" size="1152"/>
			<output>
				<port id="0" precision="I8">
					<dim>128</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</output>
		</layer>
		<layer id="2629" name="4212742130_const211615666/quantized/to_f16" type="Convert" version="opset1">
			<data destination_type="f16"/>
			<input>
				<port id="0">
					<dim>128</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</input>
			<output>
				<port id="1" precision="FP16">
					<dim>128</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</output>
		</layer>
		<layer id="2630" name="982/fq_weights_1/zero_point20416_const" type="Const" version="opset1">
			<data element_type="f16" offset="1135386" shape="128,1,1,1" size="256"/>
			<output>
				<port id="0" precision="FP16">
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2631" name="982/fq_weights_1/minus_zp" type="Subtract" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>128</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
				<port id="1">
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>128</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</output>
		</layer>
		<layer id="2632" name="982/fq_weights_1/scale20411_const" type="Const" version="opset1">
			<data element_type="f16" offset="1135642" shape="128,1,1,1" size="256"/>
			<output>
				<port id="0" precision="FP16">
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2633" name="982/fq_weights_1/mulpiply_by_scale" type="Multiply" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>128</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
				<port id="1">
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>128</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</output>
		</layer>
		<layer id="2634" name="24380/value24382_const" type="Const" version="opset1">
			<data element_type="i64" offset="957504" shape="5" size="40"/>
			<output>
				<port id="0" precision="I64">
					<dim>5</dim>
				</port>
			</output>
		</layer>
		<layer id="2635" name="24380" type="Reshape" version="opset1">
			<data special_zero="true"/>
			<input>
				<port id="0">
					<dim>128</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
				<port id="1">
					<dim>5</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</output>
		</layer>
		<layer id="2636" name="982" type="GroupConvolution" version="opset1">
			<data auto_pad="explicit" dilations="1,1" pads_begin="1,1" pads_end="1,1" strides="1,1"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>128</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
				<port id="1">
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>1</dim>
					<dim>128</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
			</output>
		</layer>
		<layer id="2637" name="data_add_221492215422824/EltwiseUnsqueeze23642_const2118_const" type="Const" version="opset1">
			<data element_type="f16" offset="1135898" shape="1,128,1,1" size="256"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2638" name="983/variance/Fused_Add_" type="Add" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>128</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
				<port id="1">
					<dim>1</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" names="983" precision="FP16">
					<dim>1</dim>
					<dim>128</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
			</output>
		</layer>
		<layer id="2639" name="984" type="ReLU" version="opset1">
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>128</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
			</input>
			<output>
				<port id="1" names="984" precision="FP16">
					<dim>1</dim>
					<dim>128</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
			</output>
		</layer>
		<layer id="2640" name="52475251_const" type="Const" version="opset1">
			<data element_type="f16" offset="10108" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="2641" name="52485252_const" type="Const" version="opset1">
			<data element_type="f16" offset="1136154" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="2642" name="52495253_const" type="Const" version="opset1">
			<data element_type="f16" offset="10108" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="2643" name="52505254_const" type="Const" version="opset1">
			<data element_type="f16" offset="1136154" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="2644" name="1005/reduce/fq_input_0" type="FakeQuantize" version="opset1">
			<data auto_broadcast="numpy" levels="256"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>128</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
				<port id="1"/>
				<port id="2"/>
				<port id="3"/>
				<port id="4"/>
			</input>
			<output>
				<port id="5" precision="FP16">
					<dim>1</dim>
					<dim>128</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
			</output>
		</layer>
		<layer id="2645" name="1419/Output_0/Data__const2121_const" type="Const" version="opset1">
			<data element_type="i64" offset="24" shape="" size="8"/>
			<output>
				<port id="0" precision="I64"/>
			</output>
		</layer>
		<layer id="2646" name="1005/input_rank/shape_of" type="ShapeOf" version="opset3">
			<data output_type="i64"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>128</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
			</input>
			<output>
				<port id="1" precision="I64">
					<dim>4</dim>
				</port>
			</output>
		</layer>
		<layer id="2647" name="1005/input_rank/rank_of" type="ShapeOf" version="opset3">
			<data output_type="i64"/>
			<input>
				<port id="0">
					<dim>4</dim>
				</port>
			</input>
			<output>
				<port id="1" precision="I64">
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2648" name="1005/input_rank/0d_rank_of/value/Output_0/Data__const2124_const" type="Const" version="opset1">
			<data element_type="i64" offset="32" shape="1" size="8"/>
			<output>
				<port id="0" precision="I64">
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2649" name="1005/input_rank" type="Squeeze" version="opset1">
			<input>
				<port id="0">
					<dim>1</dim>
				</port>
				<port id="1">
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="I64"/>
			</output>
		</layer>
		<layer id="2650" name="1421/Output_0/Data__const2126_const" type="Const" version="opset1">
			<data element_type="i64" offset="0" shape="" size="8"/>
			<output>
				<port id="0" precision="I64"/>
			</output>
		</layer>
		<layer id="2651" name="1005/global_pooling_reduce_axis" type="Range" version="opset4">
			<data output_type="i64"/>
			<input>
				<port id="0"/>
				<port id="1"/>
				<port id="2"/>
			</input>
			<output>
				<port id="3" precision="I64">
					<dim>2</dim>
				</port>
			</output>
		</layer>
		<layer id="2652" name="1005/reduce" type="ReduceMean" version="opset1">
			<data keep_dims="true"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>128</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
				<port id="1">
					<dim>2</dim>
				</port>
			</input>
			<output>
				<port id="2" names="1005" precision="FP16">
					<dim>1</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2653" name="Copy_conv4.0.gate.fc1.weight/Output_0/Data_4402_const2129_const" type="Const" version="opset1">
			<data element_type="f16" offset="957802" shape="8,128,1,1" size="2048"/>
			<output>
				<port id="0" names="conv4.0.gate.fc1.weight" precision="FP16">
					<dim>8</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2654" name="1006/WithoutBiases" type="Convolution" version="opset1">
			<data auto_pad="explicit" dilations="1,1" pads_begin="0,0" pads_end="0,0" strides="1,1"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="1">
					<dim>8</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>1</dim>
					<dim>8</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2655" name="1006/Dims1296422696/EltwiseUnsqueeze23138_const2131_const" type="Const" version="opset1">
			<data element_type="f16" offset="959850" shape="1,8,1,1" size="16"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>8</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2656" name="1006" type="Add" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>8</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="1">
					<dim>1</dim>
					<dim>8</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" names="1006" precision="FP16">
					<dim>1</dim>
					<dim>8</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2657" name="1007" type="ReLU" version="opset1">
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>8</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="1" names="1007" precision="FP16">
					<dim>1</dim>
					<dim>8</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2658" name="Copy_conv4.0.gate.fc2.weight/Output_0/Data_4410_const2134_const" type="Const" version="opset1">
			<data element_type="f16" offset="959866" shape="128,8,1,1" size="2048"/>
			<output>
				<port id="0" names="conv4.0.gate.fc2.weight" precision="FP16">
					<dim>128</dim>
					<dim>8</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2659" name="1008/WithoutBiases" type="Convolution" version="opset1">
			<data auto_pad="explicit" dilations="1,1" pads_begin="0,0" pads_end="0,0" strides="1,1"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>8</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="1">
					<dim>128</dim>
					<dim>8</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>1</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2660" name="1008/Dims1291622688/EltwiseUnsqueeze23106_const2136_const" type="Const" version="opset1">
			<data element_type="f16" offset="961914" shape="1,128,1,1" size="256"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2661" name="1008" type="Add" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="1">
					<dim>1</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" names="1008" precision="FP16">
					<dim>1</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2662" name="1009" type="Sigmoid" version="opset1">
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="1" names="1009" precision="FP16">
					<dim>1</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2663" name="77577761_const" type="Const" version="opset1">
			<data element_type="f16" offset="10108" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="2664" name="77587762_const" type="Const" version="opset1">
			<data element_type="f16" offset="1136156" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="2665" name="77597763_const" type="Const" version="opset1">
			<data element_type="f16" offset="10108" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="2666" name="77607764_const" type="Const" version="opset1">
			<data element_type="f16" offset="1136156" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="2667" name="1010/fq_input_1" type="FakeQuantize" version="opset1">
			<data auto_broadcast="numpy" levels="256"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="1"/>
				<port id="2"/>
				<port id="3"/>
				<port id="4"/>
			</input>
			<output>
				<port id="5" precision="FP16">
					<dim>1</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2668" name="1010" type="Multiply" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>128</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
				<port id="1">
					<dim>1</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" names="1010" precision="FP16">
					<dim>1</dim>
					<dim>128</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
			</output>
		</layer>
		<layer id="2669" name="80778081_const" type="Const" version="opset1">
			<data element_type="f16" offset="10108" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="2670" name="80788082_const" type="Const" version="opset1">
			<data element_type="f16" offset="1136158" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="2671" name="80798083_const" type="Const" version="opset1">
			<data element_type="f16" offset="10108" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="2672" name="80808084_const" type="Const" version="opset1">
			<data element_type="f16" offset="1136158" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="2673" name="1011/fq_input_1" type="FakeQuantize" version="opset1">
			<data auto_broadcast="numpy" levels="256"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>128</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
				<port id="1"/>
				<port id="2"/>
				<port id="3"/>
				<port id="4"/>
			</input>
			<output>
				<port id="5" precision="FP16">
					<dim>1</dim>
					<dim>128</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
			</output>
		</layer>
		<layer id="2674" name="1011" type="Add" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>128</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
				<port id="1">
					<dim>1</dim>
					<dim>128</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
			</input>
			<output>
				<port id="2" names="1011" precision="FP16">
					<dim>1</dim>
					<dim>128</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
			</output>
		</layer>
		<layer id="2675" name="76277631_const" type="Const" version="opset1">
			<data element_type="f16" offset="10108" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="2676" name="76287632_const" type="Const" version="opset1">
			<data element_type="f16" offset="653594" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="2677" name="76297633_const" type="Const" version="opset1">
			<data element_type="f16" offset="10108" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="2678" name="76307634_const" type="Const" version="opset1">
			<data element_type="f16" offset="653594" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="2679" name="1012/fq_input_0" type="FakeQuantize" version="opset1">
			<data auto_broadcast="numpy" levels="256"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>128</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
				<port id="1"/>
				<port id="2"/>
				<port id="3"/>
				<port id="4"/>
			</input>
			<output>
				<port id="5" precision="FP16">
					<dim>1</dim>
					<dim>128</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
			</output>
		</layer>
		<layer id="2680" name="1013/mean/Fused_Mul_2461124613_const214115675/quantized20115_const" type="Const" version="opset1">
			<data element_type="i8" offset="1136160" shape="512,128,1,1" size="65536"/>
			<output>
				<port id="0" precision="I8">
					<dim>512</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2681" name="1013/mean/Fused_Mul_2461124613_const214115675/quantized/to_f16" type="Convert" version="opset1">
			<data destination_type="f16"/>
			<input>
				<port id="0">
					<dim>512</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="1" precision="FP16">
					<dim>512</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2682" name="1012/fq_weights_1/zero_point20128_const" type="Const" version="opset1">
			<data element_type="f16" offset="1201696" shape="512,1,1,1" size="1024"/>
			<output>
				<port id="0" precision="FP16">
					<dim>512</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2683" name="1012/fq_weights_1/minus_zp" type="Subtract" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>512</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="1">
					<dim>512</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>512</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2684" name="1012/fq_weights_1/scale20123_const" type="Const" version="opset1">
			<data element_type="f16" offset="1202720" shape="512,1,1,1" size="1024"/>
			<output>
				<port id="0" precision="FP16">
					<dim>512</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2685" name="1012/fq_weights_1/mulpiply_by_scale" type="Multiply" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>512</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="1">
					<dim>512</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>512</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2686" name="1012" type="Convolution" version="opset1">
			<data auto_pad="explicit" dilations="1,1" pads_begin="0,0" pads_end="0,0" strides="1,1"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>128</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
				<port id="1">
					<dim>512</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>1</dim>
					<dim>512</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
			</output>
		</layer>
		<layer id="2687" name="data_add_222052221022838/EltwiseUnsqueeze23698_const2143_const" type="Const" version="opset1">
			<data element_type="f16" offset="1203744" shape="1,512,1,1" size="1024"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>512</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2688" name="1013/variance/Fused_Add_" type="Add" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>512</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
				<port id="1">
					<dim>1</dim>
					<dim>512</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" names="1013" precision="FP16">
					<dim>1</dim>
					<dim>512</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
			</output>
		</layer>
		<layer id="2689" name="58775881_const" type="Const" version="opset1">
			<data element_type="f16" offset="1204768" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="2690" name="58785882_const" type="Const" version="opset1">
			<data element_type="f16" offset="1204770" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="2691" name="58795883_const" type="Const" version="opset1">
			<data element_type="f16" offset="1204768" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="2692" name="58805884_const" type="Const" version="opset1">
			<data element_type="f16" offset="1204770" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="2693" name="1016/fq_input_0" type="FakeQuantize" version="opset1">
			<data auto_broadcast="numpy" levels="256"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>512</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
				<port id="1"/>
				<port id="2"/>
				<port id="3"/>
				<port id="4"/>
			</input>
			<output>
				<port id="5" precision="FP16">
					<dim>1</dim>
					<dim>512</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
			</output>
		</layer>
		<layer id="2694" name="1015/mean/Fused_Mul_2456324565_const214515677/quantized17787_const" type="Const" version="opset1">
			<data element_type="i8" offset="1204772" shape="512,384,1,1" size="196608"/>
			<output>
				<port id="0" precision="I8">
					<dim>512</dim>
					<dim>384</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2695" name="1015/mean/Fused_Mul_2456324565_const214515677/quantized/to_f16" type="Convert" version="opset1">
			<data destination_type="f16"/>
			<input>
				<port id="0">
					<dim>512</dim>
					<dim>384</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="1" precision="FP16">
					<dim>512</dim>
					<dim>384</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2696" name="1014/fq_weights_1/zero_point17800_const" type="Const" version="opset1">
			<data element_type="f16" offset="1401380" shape="512,1,1,1" size="1024"/>
			<output>
				<port id="0" precision="FP16">
					<dim>512</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2697" name="1014/fq_weights_1/minus_zp" type="Subtract" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>512</dim>
					<dim>384</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="1">
					<dim>512</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>512</dim>
					<dim>384</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2698" name="1014/fq_weights_1/scale17795_const" type="Const" version="opset1">
			<data element_type="f16" offset="1402404" shape="512,1,1,1" size="1024"/>
			<output>
				<port id="0" precision="FP16">
					<dim>512</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2699" name="1014/fq_weights_1/mulpiply_by_scale" type="Multiply" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>512</dim>
					<dim>384</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="1">
					<dim>512</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>512</dim>
					<dim>384</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2700" name="1014" type="Convolution" version="opset1">
			<data auto_pad="explicit" dilations="1,1" pads_begin="0,0" pads_end="0,0" strides="1,1"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>384</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
				<port id="1">
					<dim>512</dim>
					<dim>384</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>1</dim>
					<dim>512</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
			</output>
		</layer>
		<layer id="2701" name="data_add_221092211422814/EltwiseUnsqueeze23602_const2147_const" type="Const" version="opset1">
			<data element_type="f16" offset="1403428" shape="1,512,1,1" size="1024"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>512</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2702" name="1015/variance/Fused_Add_" type="Add" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>512</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
				<port id="1">
					<dim>1</dim>
					<dim>512</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" names="1015" precision="FP16">
					<dim>1</dim>
					<dim>512</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
			</output>
		</layer>
		<layer id="2703" name="58875891_const" type="Const" version="opset1">
			<data element_type="f16" offset="1404452" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="2704" name="58885892_const" type="Const" version="opset1">
			<data element_type="f16" offset="1404454" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="2705" name="58895893_const" type="Const" version="opset1">
			<data element_type="f16" offset="1404452" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="2706" name="58905894_const" type="Const" version="opset1">
			<data element_type="f16" offset="1404454" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="2707" name="1016/fq_input_1" type="FakeQuantize" version="opset1">
			<data auto_broadcast="numpy" levels="256"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>512</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
				<port id="1"/>
				<port id="2"/>
				<port id="3"/>
				<port id="4"/>
			</input>
			<output>
				<port id="5" precision="FP16">
					<dim>1</dim>
					<dim>512</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
			</output>
		</layer>
		<layer id="2708" name="1016" type="Add" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>512</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
				<port id="1">
					<dim>1</dim>
					<dim>512</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
			</input>
			<output>
				<port id="2" names="1016" precision="FP16">
					<dim>1</dim>
					<dim>512</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
			</output>
		</layer>
		<layer id="2709" name="1017" type="ReLU" version="opset1">
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>512</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
			</input>
			<output>
				<port id="1" names="1017" precision="FP16">
					<dim>1</dim>
					<dim>512</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
			</output>
		</layer>
		<layer id="2710" name="53675371_const" type="Const" version="opset1">
			<data element_type="f16" offset="10108" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="2711" name="53685372_const" type="Const" version="opset1">
			<data element_type="f16" offset="1404456" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="2712" name="53695373_const" type="Const" version="opset1">
			<data element_type="f16" offset="10108" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="2713" name="53705374_const" type="Const" version="opset1">
			<data element_type="f16" offset="1404456" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="2714" name="1018/fq_input_0" type="FakeQuantize" version="opset1">
			<data auto_broadcast="numpy" levels="256"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>512</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
				<port id="1"/>
				<port id="2"/>
				<port id="3"/>
				<port id="4"/>
			</input>
			<output>
				<port id="5" precision="FP16">
					<dim>1</dim>
					<dim>512</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
			</output>
		</layer>
		<layer id="2715" name="1019/mean/Fused_Mul_2461524617_const215115679/quantized19515_const" type="Const" version="opset1">
			<data element_type="i8" offset="1404458" shape="128,512,1,1" size="65536"/>
			<output>
				<port id="0" precision="I8">
					<dim>128</dim>
					<dim>512</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2716" name="1019/mean/Fused_Mul_2461524617_const215115679/quantized/to_f16" type="Convert" version="opset1">
			<data destination_type="f16"/>
			<input>
				<port id="0">
					<dim>128</dim>
					<dim>512</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="1" precision="FP16">
					<dim>128</dim>
					<dim>512</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2717" name="1018/fq_weights_1/zero_point19528_const" type="Const" version="opset1">
			<data element_type="f16" offset="1469994" shape="128,1,1,1" size="256"/>
			<output>
				<port id="0" precision="FP16">
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2718" name="1018/fq_weights_1/minus_zp" type="Subtract" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>128</dim>
					<dim>512</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="1">
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>128</dim>
					<dim>512</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2719" name="1018/fq_weights_1/scale19523_const" type="Const" version="opset1">
			<data element_type="f16" offset="1470250" shape="128,1,1,1" size="256"/>
			<output>
				<port id="0" precision="FP16">
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2720" name="1018/fq_weights_1/mulpiply_by_scale" type="Multiply" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>128</dim>
					<dim>512</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="1">
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>128</dim>
					<dim>512</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2721" name="1018" type="Convolution" version="opset1">
			<data auto_pad="explicit" dilations="1,1" pads_begin="0,0" pads_end="0,0" strides="1,1"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>512</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
				<port id="1">
					<dim>128</dim>
					<dim>512</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>1</dim>
					<dim>128</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
			</output>
		</layer>
		<layer id="2722" name="data_add_222132221822840/EltwiseUnsqueeze23706_const2153_const" type="Const" version="opset1">
			<data element_type="f16" offset="1470506" shape="1,128,1,1" size="256"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2723" name="1019/variance/Fused_Add_" type="Add" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>128</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
				<port id="1">
					<dim>1</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" names="1019" precision="FP16">
					<dim>1</dim>
					<dim>128</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
			</output>
		</layer>
		<layer id="2724" name="1020" type="ReLU" version="opset1">
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>128</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
			</input>
			<output>
				<port id="1" names="1020" precision="FP16">
					<dim>1</dim>
					<dim>128</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
			</output>
		</layer>
		<layer id="2725" name="49374941_const" type="Const" version="opset1">
			<data element_type="f16" offset="10108" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="2726" name="49384942_const" type="Const" version="opset1">
			<data element_type="f16" offset="1470762" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="2727" name="49394943_const" type="Const" version="opset1">
			<data element_type="f16" offset="10108" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="2728" name="49404944_const" type="Const" version="opset1">
			<data element_type="f16" offset="1470762" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="2729" name="1021/fq_input_0" type="FakeQuantize" version="opset1">
			<data auto_broadcast="numpy" levels="256"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>128</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
				<port id="1"/>
				<port id="2"/>
				<port id="3"/>
				<port id="4"/>
			</input>
			<output>
				<port id="5" precision="FP16">
					<dim>1</dim>
					<dim>128</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
			</output>
		</layer>
		<layer id="2730" name="conv4.1.conv2a.conv1.weight/quantized19371_const" type="Const" version="opset1">
			<data element_type="i8" offset="1470764" shape="128,128,1,1" size="16384"/>
			<output>
				<port id="0" precision="I8">
					<dim>128</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2731" name="conv4.1.conv2a.conv1.weight/quantized/to_f16" type="Convert" version="opset1">
			<data destination_type="f16"/>
			<input>
				<port id="0">
					<dim>128</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="1" precision="FP16">
					<dim>128</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2732" name="1021/fq_weights_1/zero_point19384_const" type="Const" version="opset1">
			<data element_type="f16" offset="1487148" shape="128,1,1,1" size="256"/>
			<output>
				<port id="0" precision="FP16">
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2733" name="1021/fq_weights_1/minus_zp" type="Subtract" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>128</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="1">
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>128</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2734" name="1021/fq_weights_1/scale19379_const" type="Const" version="opset1">
			<data element_type="f16" offset="1487404" shape="128,1,1,1" size="256"/>
			<output>
				<port id="0" precision="FP16">
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2735" name="1021/fq_weights_1/mulpiply_by_scale" type="Multiply" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>128</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="1">
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>128</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2736" name="1021" type="Convolution" version="opset1">
			<data auto_pad="explicit" dilations="1,1" pads_begin="0,0" pads_end="0,0" strides="1,1"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>128</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
				<port id="1">
					<dim>128</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" names="1021" precision="FP16">
					<dim>1</dim>
					<dim>128</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
			</output>
		</layer>
		<layer id="2737" name="30723074_const" type="Const" version="opset1">
			<data element_type="f16" offset="955072" shape="1,128,1,1" size="256"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2738" name="1021/add_" type="Add" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>128</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
				<port id="1">
					<dim>1</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>1</dim>
					<dim>128</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
			</output>
		</layer>
		<layer id="2739" name="62176221_const" type="Const" version="opset1">
			<data element_type="f16" offset="1487660" shape="1,128,1,1" size="256"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2740" name="62186222_const" type="Const" version="opset1">
			<data element_type="f16" offset="1487916" shape="1,128,1,1" size="256"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2741" name="62196223_const" type="Const" version="opset1">
			<data element_type="f16" offset="1487660" shape="1,128,1,1" size="256"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2742" name="62206224_const" type="Const" version="opset1">
			<data element_type="f16" offset="1487916" shape="1,128,1,1" size="256"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2743" name="1022/fq_input_0" type="FakeQuantize" version="opset1">
			<data auto_broadcast="numpy" levels="256"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>128</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
				<port id="1">
					<dim>1</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="2">
					<dim>1</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="3">
					<dim>1</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="4">
					<dim>1</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="5" precision="FP16">
					<dim>1</dim>
					<dim>128</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
			</output>
		</layer>
		<layer id="2744" name="4223142234_const215815682/quantized18003_const" type="Const" version="opset1">
			<data element_type="i8" offset="1488172" shape="128,1,3,3" size="1152"/>
			<output>
				<port id="0" precision="I8">
					<dim>128</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</output>
		</layer>
		<layer id="2745" name="4223142234_const215815682/quantized/to_f16" type="Convert" version="opset1">
			<data destination_type="f16"/>
			<input>
				<port id="0">
					<dim>128</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</input>
			<output>
				<port id="1" precision="FP16">
					<dim>128</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</output>
		</layer>
		<layer id="2746" name="1022/fq_weights_1/zero_point18016_const" type="Const" version="opset1">
			<data element_type="f16" offset="1489324" shape="128,1,1,1" size="256"/>
			<output>
				<port id="0" precision="FP16">
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2747" name="1022/fq_weights_1/minus_zp" type="Subtract" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>128</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
				<port id="1">
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>128</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</output>
		</layer>
		<layer id="2748" name="1022/fq_weights_1/scale18011_const" type="Const" version="opset1">
			<data element_type="f16" offset="1489580" shape="128,1,1,1" size="256"/>
			<output>
				<port id="0" precision="FP16">
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2749" name="1022/fq_weights_1/mulpiply_by_scale" type="Multiply" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>128</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
				<port id="1">
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>128</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</output>
		</layer>
		<layer id="2750" name="24536/value24538_const" type="Const" version="opset1">
			<data element_type="i64" offset="957504" shape="5" size="40"/>
			<output>
				<port id="0" precision="I64">
					<dim>5</dim>
				</port>
			</output>
		</layer>
		<layer id="2751" name="24536" type="Reshape" version="opset1">
			<data special_zero="true"/>
			<input>
				<port id="0">
					<dim>128</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
				<port id="1">
					<dim>5</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</output>
		</layer>
		<layer id="2752" name="1022" type="GroupConvolution" version="opset1">
			<data auto_pad="explicit" dilations="1,1" pads_begin="1,1" pads_end="1,1" strides="1,1"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>128</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
				<port id="1">
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>1</dim>
					<dim>128</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
			</output>
		</layer>
		<layer id="2753" name="data_add_222932229822860/EltwiseUnsqueeze23786_const2160_const" type="Const" version="opset1">
			<data element_type="f16" offset="1489836" shape="1,128,1,1" size="256"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2754" name="1023/variance/Fused_Add_" type="Add" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>128</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
				<port id="1">
					<dim>1</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" names="1023" precision="FP16">
					<dim>1</dim>
					<dim>128</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
			</output>
		</layer>
		<layer id="2755" name="1024" type="ReLU" version="opset1">
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>128</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
			</input>
			<output>
				<port id="1" names="1024" precision="FP16">
					<dim>1</dim>
					<dim>128</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
			</output>
		</layer>
		<layer id="2756" name="63476351_const" type="Const" version="opset1">
			<data element_type="f16" offset="10108" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="2757" name="63486352_const" type="Const" version="opset1">
			<data element_type="f16" offset="1490092" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="2758" name="63496353_const" type="Const" version="opset1">
			<data element_type="f16" offset="10108" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="2759" name="63506354_const" type="Const" version="opset1">
			<data element_type="f16" offset="1490092" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="2760" name="1061/reduce/fq_input_0" type="FakeQuantize" version="opset1">
			<data auto_broadcast="numpy" levels="256"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>128</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
				<port id="1"/>
				<port id="2"/>
				<port id="3"/>
				<port id="4"/>
			</input>
			<output>
				<port id="5" precision="FP16">
					<dim>1</dim>
					<dim>128</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
			</output>
		</layer>
		<layer id="2761" name="1424/Output_0/Data__const2163_const" type="Const" version="opset1">
			<data element_type="i64" offset="24" shape="" size="8"/>
			<output>
				<port id="0" precision="I64"/>
			</output>
		</layer>
		<layer id="2762" name="1061/input_rank/shape_of" type="ShapeOf" version="opset3">
			<data output_type="i64"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>128</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
			</input>
			<output>
				<port id="1" precision="I64">
					<dim>4</dim>
				</port>
			</output>
		</layer>
		<layer id="2763" name="1061/input_rank/rank_of" type="ShapeOf" version="opset3">
			<data output_type="i64"/>
			<input>
				<port id="0">
					<dim>4</dim>
				</port>
			</input>
			<output>
				<port id="1" precision="I64">
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2764" name="1061/input_rank/0d_rank_of/value/Output_0/Data__const2166_const" type="Const" version="opset1">
			<data element_type="i64" offset="32" shape="1" size="8"/>
			<output>
				<port id="0" precision="I64">
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2765" name="1061/input_rank" type="Squeeze" version="opset1">
			<input>
				<port id="0">
					<dim>1</dim>
				</port>
				<port id="1">
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="I64"/>
			</output>
		</layer>
		<layer id="2766" name="1426/Output_0/Data__const2168_const" type="Const" version="opset1">
			<data element_type="i64" offset="0" shape="" size="8"/>
			<output>
				<port id="0" precision="I64"/>
			</output>
		</layer>
		<layer id="2767" name="1061/global_pooling_reduce_axis" type="Range" version="opset4">
			<data output_type="i64"/>
			<input>
				<port id="0"/>
				<port id="1"/>
				<port id="2"/>
			</input>
			<output>
				<port id="3" precision="I64">
					<dim>2</dim>
				</port>
			</output>
		</layer>
		<layer id="2768" name="1061/reduce" type="ReduceMean" version="opset1">
			<data keep_dims="true"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>128</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
				<port id="1">
					<dim>2</dim>
				</port>
			</input>
			<output>
				<port id="2" names="1061" precision="FP16">
					<dim>1</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2769" name="1072810732_const" type="Const" version="opset1">
			<data element_type="f16" offset="10108" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="2770" name="1072910733_const" type="Const" version="opset1">
			<data element_type="f16" offset="1490094" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="2771" name="1073010734_const" type="Const" version="opset1">
			<data element_type="f16" offset="10108" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="2772" name="1073110735_const" type="Const" version="opset1">
			<data element_type="f16" offset="1490094" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="2773" name="1063/fq_input_0" type="FakeQuantize" version="opset1">
			<data auto_broadcast="numpy" levels="256"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="1"/>
				<port id="2"/>
				<port id="3"/>
				<port id="4"/>
			</input>
			<output>
				<port id="5" precision="FP16">
					<dim>1</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2774" name="1063/Cast_143326_const2171_const" type="Const" version="opset1">
			<data element_type="i64" offset="129708" shape="3" size="24"/>
			<output>
				<port id="0" names="1062" precision="I64">
					<dim>3</dim>
				</port>
			</output>
		</layer>
		<layer id="2775" name="1063" type="Reshape" version="opset1">
			<data special_zero="true"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="1">
					<dim>3</dim>
				</port>
			</input>
			<output>
				<port id="2" names="1063" precision="FP16">
					<dim>1</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
			</output>
		</layer>
		<layer id="2776" name="1066/Range_input_port_0/value/Output_0/Data__const2173_const" type="Const" version="opset1">
			<data element_type="i64" offset="24" shape="" size="8"/>
			<output>
				<port id="0" precision="I64"/>
			</output>
		</layer>
		<layer id="2777" name="1066/Rank/shape_of" type="ShapeOf" version="opset3">
			<data output_type="i64"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
			</input>
			<output>
				<port id="1" precision="I64">
					<dim>3</dim>
				</port>
			</output>
		</layer>
		<layer id="2778" name="1066/Rank/rank_of" type="ShapeOf" version="opset3">
			<data output_type="i64"/>
			<input>
				<port id="0">
					<dim>3</dim>
				</port>
			</input>
			<output>
				<port id="1" precision="I64">
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2779" name="1066/Rank/0d_rank_of/value/Output_0/Data__const2176_const" type="Const" version="opset1">
			<data element_type="i64" offset="32" shape="1" size="8"/>
			<output>
				<port id="0" precision="I64">
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2780" name="1066/Rank" type="Squeeze" version="opset1">
			<input>
				<port id="0">
					<dim>1</dim>
				</port>
				<port id="1">
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="I64"/>
			</output>
		</layer>
		<layer id="2781" name="1066/Range_input_port_2/value/Output_0/Data__const2178_const" type="Const" version="opset1">
			<data element_type="i64" offset="0" shape="" size="8"/>
			<output>
				<port id="0" precision="I64"/>
			</output>
		</layer>
		<layer id="2782" name="1066/Range" type="Range" version="opset4">
			<data output_type="i64"/>
			<input>
				<port id="0"/>
				<port id="1"/>
				<port id="2"/>
			</input>
			<output>
				<port id="3" precision="I64">
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2783" name="1066/Ins_Norm/MVN_" type="MVN" version="opset6">
			<data eps="9.999999747378752e-06" eps_mode="inside_sqrt" normalize_variance="true"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
				<port id="1">
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>1</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
			</output>
		</layer>
		<layer id="2784" name="1064/EltwiseUnsqueeze22966_const2181_const" type="Const" version="opset1">
			<data element_type="f16" offset="129732" shape="1,16,1" size="32"/>
			<output>
				<port id="0" names="1064" precision="FP16">
					<dim>1</dim>
					<dim>16</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2785" name="1066/Ins_Norm/mul_" type="Multiply" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
				<port id="1">
					<dim>1</dim>
					<dim>16</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>1</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
			</output>
		</layer>
		<layer id="2786" name="1065/EltwiseUnsqueeze22970_const2183_const" type="Const" version="opset1">
			<data element_type="f16" offset="129764" shape="1,16,1" size="32"/>
			<output>
				<port id="0" names="1065" precision="FP16">
					<dim>1</dim>
					<dim>16</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2787" name="1066" type="Add" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
				<port id="1">
					<dim>1</dim>
					<dim>16</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" names="1066" precision="FP16">
					<dim>1</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
			</output>
		</layer>
		<layer id="2788" name="1073810742_const" type="Const" version="opset1">
			<data element_type="f16" offset="1490096" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="2789" name="1073910743_const" type="Const" version="opset1">
			<data element_type="f16" offset="1490098" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="2790" name="1074010744_const" type="Const" version="opset1">
			<data element_type="f16" offset="1490096" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="2791" name="1074110745_const" type="Const" version="opset1">
			<data element_type="f16" offset="1490098" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="2792" name="1068/fq_input_0" type="FakeQuantize" version="opset1">
			<data auto_broadcast="numpy" levels="256"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
				<port id="1"/>
				<port id="2"/>
				<port id="3"/>
				<port id="4"/>
			</input>
			<output>
				<port id="5" precision="FP16">
					<dim>1</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
			</output>
		</layer>
		<layer id="2793" name="1067" type="ShapeOf" version="opset3">
			<data output_type="i64"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="1" names="1067" precision="I64">
					<dim>4</dim>
				</port>
			</output>
		</layer>
		<layer id="2794" name="1068" type="Reshape" version="opset1">
			<data special_zero="true"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
				<port id="1">
					<dim>4</dim>
				</port>
			</input>
			<output>
				<port id="2" names="1068" precision="FP16">
					<dim>1</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2795" name="1069/Unsqueeze/EltwiseUnsqueeze22934_const2187_const" type="Const" version="opset1">
			<data element_type="f16" offset="1490100" shape="1,128,1,1" size="256"/>
			<output>
				<port id="0" names="1069" precision="FP16">
					<dim>1</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2796" name="1070" type="Multiply" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="1">
					<dim>1</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" names="1070" precision="FP16">
					<dim>1</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2797" name="1071/Unsqueeze/EltwiseUnsqueeze22938_const2189_const" type="Const" version="opset1">
			<data element_type="f16" offset="1490356" shape="1,128,1,1" size="256"/>
			<output>
				<port id="0" names="1071" precision="FP16">
					<dim>1</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2798" name="1072" type="Add" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="1">
					<dim>1</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" names="1072" precision="FP16">
					<dim>1</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2799" name="1073" type="Sigmoid" version="opset1">
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="1" names="1073" precision="FP16">
					<dim>1</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2800" name="68176821_const" type="Const" version="opset1">
			<data element_type="f16" offset="10108" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="2801" name="68186822_const" type="Const" version="opset1">
			<data element_type="f16" offset="1490612" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="2802" name="68196823_const" type="Const" version="opset1">
			<data element_type="f16" offset="10108" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="2803" name="68206824_const" type="Const" version="opset1">
			<data element_type="f16" offset="1490612" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="2804" name="1074/fq_input_1" type="FakeQuantize" version="opset1">
			<data auto_broadcast="numpy" levels="256"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="1"/>
				<port id="2"/>
				<port id="3"/>
				<port id="4"/>
			</input>
			<output>
				<port id="5" precision="FP16">
					<dim>1</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2805" name="1074" type="Multiply" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>128</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
				<port id="1">
					<dim>1</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" names="1074" precision="FP16">
					<dim>1</dim>
					<dim>128</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
			</output>
		</layer>
		<layer id="2806" name="47474751_const" type="Const" version="opset1">
			<data element_type="f16" offset="10108" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="2807" name="47484752_const" type="Const" version="opset1">
			<data element_type="f16" offset="1490614" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="2808" name="47494753_const" type="Const" version="opset1">
			<data element_type="f16" offset="10108" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="2809" name="47504754_const" type="Const" version="opset1">
			<data element_type="f16" offset="1490614" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="2810" name="1089/fq_input_0" type="FakeQuantize" version="opset1">
			<data auto_broadcast="numpy" levels="256"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>128</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
				<port id="1"/>
				<port id="2"/>
				<port id="3"/>
				<port id="4"/>
			</input>
			<output>
				<port id="5" precision="FP16">
					<dim>1</dim>
					<dim>128</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
			</output>
		</layer>
		<layer id="2811" name="conv4.1.conv2b.0.conv1.weight/quantized18435_const" type="Const" version="opset1">
			<data element_type="i8" offset="1490616" shape="128,128,1,1" size="16384"/>
			<output>
				<port id="0" precision="I8">
					<dim>128</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2812" name="conv4.1.conv2b.0.conv1.weight/quantized/to_f16" type="Convert" version="opset1">
			<data destination_type="f16"/>
			<input>
				<port id="0">
					<dim>128</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="1" precision="FP16">
					<dim>128</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2813" name="1025/fq_weights_1/zero_point18448_const" type="Const" version="opset1">
			<data element_type="f16" offset="1507000" shape="128,1,1,1" size="256"/>
			<output>
				<port id="0" precision="FP16">
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2814" name="1025/fq_weights_1/minus_zp" type="Subtract" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>128</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="1">
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>128</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2815" name="1025/fq_weights_1/scale18443_const" type="Const" version="opset1">
			<data element_type="f16" offset="1507256" shape="128,1,1,1" size="256"/>
			<output>
				<port id="0" precision="FP16">
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2816" name="1025/fq_weights_1/mulpiply_by_scale" type="Multiply" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>128</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="1">
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>128</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2817" name="1025" type="Convolution" version="opset1">
			<data auto_pad="explicit" dilations="1,1" pads_begin="0,0" pads_end="0,0" strides="1,1"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>128</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
				<port id="1">
					<dim>128</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" names="1025" precision="FP16">
					<dim>1</dim>
					<dim>128</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
			</output>
		</layer>
		<layer id="2818" name="30763078_const" type="Const" version="opset1">
			<data element_type="f16" offset="955072" shape="1,128,1,1" size="256"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2819" name="1025/add_" type="Add" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>128</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
				<port id="1">
					<dim>1</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>1</dim>
					<dim>128</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
			</output>
		</layer>
		<layer id="2820" name="76777681_const" type="Const" version="opset1">
			<data element_type="f16" offset="1507512" shape="1,128,1,1" size="256"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2821" name="76787682_const" type="Const" version="opset1">
			<data element_type="f16" offset="1507768" shape="1,128,1,1" size="256"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2822" name="76797683_const" type="Const" version="opset1">
			<data element_type="f16" offset="1507512" shape="1,128,1,1" size="256"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2823" name="76807684_const" type="Const" version="opset1">
			<data element_type="f16" offset="1507768" shape="1,128,1,1" size="256"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2824" name="1026/fq_input_0" type="FakeQuantize" version="opset1">
			<data auto_broadcast="numpy" levels="256"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>128</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
				<port id="1">
					<dim>1</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="2">
					<dim>1</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="3">
					<dim>1</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="4">
					<dim>1</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="5" precision="FP16">
					<dim>1</dim>
					<dim>128</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
			</output>
		</layer>
		<layer id="2825" name="4208342086_const219515696/quantized19443_const" type="Const" version="opset1">
			<data element_type="i8" offset="1508024" shape="128,1,3,3" size="1152"/>
			<output>
				<port id="0" precision="I8">
					<dim>128</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</output>
		</layer>
		<layer id="2826" name="4208342086_const219515696/quantized/to_f16" type="Convert" version="opset1">
			<data destination_type="f16"/>
			<input>
				<port id="0">
					<dim>128</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</input>
			<output>
				<port id="1" precision="FP16">
					<dim>128</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</output>
		</layer>
		<layer id="2827" name="1026/fq_weights_1/zero_point19456_const" type="Const" version="opset1">
			<data element_type="f16" offset="1509176" shape="128,1,1,1" size="256"/>
			<output>
				<port id="0" precision="FP16">
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2828" name="1026/fq_weights_1/minus_zp" type="Subtract" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>128</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
				<port id="1">
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>128</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</output>
		</layer>
		<layer id="2829" name="1026/fq_weights_1/scale19451_const" type="Const" version="opset1">
			<data element_type="f16" offset="1509432" shape="128,1,1,1" size="256"/>
			<output>
				<port id="0" precision="FP16">
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2830" name="1026/fq_weights_1/mulpiply_by_scale" type="Multiply" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>128</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
				<port id="1">
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>128</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</output>
		</layer>
		<layer id="2831" name="24448/value24450_const" type="Const" version="opset1">
			<data element_type="i64" offset="957504" shape="5" size="40"/>
			<output>
				<port id="0" precision="I64">
					<dim>5</dim>
				</port>
			</output>
		</layer>
		<layer id="2832" name="24448" type="Reshape" version="opset1">
			<data special_zero="true"/>
			<input>
				<port id="0">
					<dim>128</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
				<port id="1">
					<dim>5</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</output>
		</layer>
		<layer id="2833" name="1026" type="GroupConvolution" version="opset1">
			<data auto_pad="explicit" dilations="1,1" pads_begin="1,1" pads_end="1,1" strides="1,1"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>128</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
				<port id="1">
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>1</dim>
					<dim>128</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
			</output>
		</layer>
		<layer id="2834" name="data_add_222772228222856/EltwiseUnsqueeze23770_const2197_const" type="Const" version="opset1">
			<data element_type="f16" offset="1509688" shape="1,128,1,1" size="256"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2835" name="1027/variance/Fused_Add_" type="Add" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>128</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
				<port id="1">
					<dim>1</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" names="1027" precision="FP16">
					<dim>1</dim>
					<dim>128</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
			</output>
		</layer>
		<layer id="2836" name="1028" type="ReLU" version="opset1">
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>128</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
			</input>
			<output>
				<port id="1" names="1028" precision="FP16">
					<dim>1</dim>
					<dim>128</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
			</output>
		</layer>
		<layer id="2837" name="62776281_const" type="Const" version="opset1">
			<data element_type="f16" offset="10108" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="2838" name="62786282_const" type="Const" version="opset1">
			<data element_type="f16" offset="1509944" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="2839" name="62796283_const" type="Const" version="opset1">
			<data element_type="f16" offset="10108" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="2840" name="62806284_const" type="Const" version="opset1">
			<data element_type="f16" offset="1509944" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="2841" name="1029/fq_input_0" type="FakeQuantize" version="opset1">
			<data auto_broadcast="numpy" levels="256"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>128</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
				<port id="1"/>
				<port id="2"/>
				<port id="3"/>
				<port id="4"/>
			</input>
			<output>
				<port id="5" precision="FP16">
					<dim>1</dim>
					<dim>128</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
			</output>
		</layer>
		<layer id="2842" name="conv4.1.conv2b.1.conv1.weight/quantized20019_const" type="Const" version="opset1">
			<data element_type="i8" offset="1509946" shape="128,128,1,1" size="16384"/>
			<output>
				<port id="0" precision="I8">
					<dim>128</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2843" name="conv4.1.conv2b.1.conv1.weight/quantized/to_f16" type="Convert" version="opset1">
			<data destination_type="f16"/>
			<input>
				<port id="0">
					<dim>128</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="1" precision="FP16">
					<dim>128</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2844" name="1029/fq_weights_1/zero_point20032_const" type="Const" version="opset1">
			<data element_type="f16" offset="1526330" shape="128,1,1,1" size="256"/>
			<output>
				<port id="0" precision="FP16">
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2845" name="1029/fq_weights_1/minus_zp" type="Subtract" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>128</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="1">
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>128</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2846" name="1029/fq_weights_1/scale20027_const" type="Const" version="opset1">
			<data element_type="f16" offset="1526586" shape="128,1,1,1" size="256"/>
			<output>
				<port id="0" precision="FP16">
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2847" name="1029/fq_weights_1/mulpiply_by_scale" type="Multiply" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>128</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="1">
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>128</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2848" name="1029" type="Convolution" version="opset1">
			<data auto_pad="explicit" dilations="1,1" pads_begin="0,0" pads_end="0,0" strides="1,1"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>128</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
				<port id="1">
					<dim>128</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" names="1029" precision="FP16">
					<dim>1</dim>
					<dim>128</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
			</output>
		</layer>
		<layer id="2849" name="30803082_const" type="Const" version="opset1">
			<data element_type="f16" offset="955072" shape="1,128,1,1" size="256"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2850" name="1029/add_" type="Add" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>128</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
				<port id="1">
					<dim>1</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>1</dim>
					<dim>128</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
			</output>
		</layer>
		<layer id="2851" name="41874191_const" type="Const" version="opset1">
			<data element_type="f16" offset="1526842" shape="1,128,1,1" size="256"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2852" name="41884192_const" type="Const" version="opset1">
			<data element_type="f16" offset="1527098" shape="1,128,1,1" size="256"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2853" name="41894193_const" type="Const" version="opset1">
			<data element_type="f16" offset="1526842" shape="1,128,1,1" size="256"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2854" name="41904194_const" type="Const" version="opset1">
			<data element_type="f16" offset="1527098" shape="1,128,1,1" size="256"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2855" name="1030/fq_input_0" type="FakeQuantize" version="opset1">
			<data auto_broadcast="numpy" levels="256"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>128</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
				<port id="1">
					<dim>1</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="2">
					<dim>1</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="3">
					<dim>1</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="4">
					<dim>1</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="5" precision="FP16">
					<dim>1</dim>
					<dim>128</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
			</output>
		</layer>
		<layer id="2856" name="4221142214_const220215699/quantized20667_const" type="Const" version="opset1">
			<data element_type="i8" offset="1527354" shape="128,1,3,3" size="1152"/>
			<output>
				<port id="0" precision="I8">
					<dim>128</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</output>
		</layer>
		<layer id="2857" name="4221142214_const220215699/quantized/to_f16" type="Convert" version="opset1">
			<data destination_type="f16"/>
			<input>
				<port id="0">
					<dim>128</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</input>
			<output>
				<port id="1" precision="FP16">
					<dim>128</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</output>
		</layer>
		<layer id="2858" name="1030/fq_weights_1/zero_point20680_const" type="Const" version="opset1">
			<data element_type="f16" offset="1528506" shape="128,1,1,1" size="256"/>
			<output>
				<port id="0" precision="FP16">
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2859" name="1030/fq_weights_1/minus_zp" type="Subtract" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>128</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
				<port id="1">
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>128</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</output>
		</layer>
		<layer id="2860" name="1030/fq_weights_1/scale20675_const" type="Const" version="opset1">
			<data element_type="f16" offset="1528762" shape="128,1,1,1" size="256"/>
			<output>
				<port id="0" precision="FP16">
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2861" name="1030/fq_weights_1/mulpiply_by_scale" type="Multiply" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>128</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
				<port id="1">
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>128</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</output>
		</layer>
		<layer id="2862" name="24568/value24570_const" type="Const" version="opset1">
			<data element_type="i64" offset="957504" shape="5" size="40"/>
			<output>
				<port id="0" precision="I64">
					<dim>5</dim>
				</port>
			</output>
		</layer>
		<layer id="2863" name="24568" type="Reshape" version="opset1">
			<data special_zero="true"/>
			<input>
				<port id="0">
					<dim>128</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
				<port id="1">
					<dim>5</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</output>
		</layer>
		<layer id="2864" name="1030" type="GroupConvolution" version="opset1">
			<data auto_pad="explicit" dilations="1,1" pads_begin="1,1" pads_end="1,1" strides="1,1"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>128</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
				<port id="1">
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>1</dim>
					<dim>128</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
			</output>
		</layer>
		<layer id="2865" name="data_add_222852229022858/EltwiseUnsqueeze23778_const2204_const" type="Const" version="opset1">
			<data element_type="f16" offset="1529018" shape="1,128,1,1" size="256"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2866" name="1031/variance/Fused_Add_" type="Add" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>128</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
				<port id="1">
					<dim>1</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" names="1031" precision="FP16">
					<dim>1</dim>
					<dim>128</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
			</output>
		</layer>
		<layer id="2867" name="1032" type="ReLU" version="opset1">
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>128</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
			</input>
			<output>
				<port id="1" names="1032" precision="FP16">
					<dim>1</dim>
					<dim>128</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
			</output>
		</layer>
		<layer id="2868" name="51175121_const" type="Const" version="opset1">
			<data element_type="f16" offset="10108" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="2869" name="51185122_const" type="Const" version="opset1">
			<data element_type="f16" offset="1529274" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="2870" name="51195123_const" type="Const" version="opset1">
			<data element_type="f16" offset="10108" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="2871" name="51205124_const" type="Const" version="opset1">
			<data element_type="f16" offset="1529274" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="2872" name="1075/reduce/fq_input_0" type="FakeQuantize" version="opset1">
			<data auto_broadcast="numpy" levels="256"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>128</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
				<port id="1"/>
				<port id="2"/>
				<port id="3"/>
				<port id="4"/>
			</input>
			<output>
				<port id="5" precision="FP16">
					<dim>1</dim>
					<dim>128</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
			</output>
		</layer>
		<layer id="2873" name="1429/Output_0/Data__const2207_const" type="Const" version="opset1">
			<data element_type="i64" offset="24" shape="" size="8"/>
			<output>
				<port id="0" precision="I64"/>
			</output>
		</layer>
		<layer id="2874" name="1075/input_rank/shape_of" type="ShapeOf" version="opset3">
			<data output_type="i64"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>128</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
			</input>
			<output>
				<port id="1" precision="I64">
					<dim>4</dim>
				</port>
			</output>
		</layer>
		<layer id="2875" name="1075/input_rank/rank_of" type="ShapeOf" version="opset3">
			<data output_type="i64"/>
			<input>
				<port id="0">
					<dim>4</dim>
				</port>
			</input>
			<output>
				<port id="1" precision="I64">
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2876" name="1075/input_rank/0d_rank_of/value/Output_0/Data__const2210_const" type="Const" version="opset1">
			<data element_type="i64" offset="32" shape="1" size="8"/>
			<output>
				<port id="0" precision="I64">
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2877" name="1075/input_rank" type="Squeeze" version="opset1">
			<input>
				<port id="0">
					<dim>1</dim>
				</port>
				<port id="1">
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="I64"/>
			</output>
		</layer>
		<layer id="2878" name="1431/Output_0/Data__const2212_const" type="Const" version="opset1">
			<data element_type="i64" offset="0" shape="" size="8"/>
			<output>
				<port id="0" precision="I64"/>
			</output>
		</layer>
		<layer id="2879" name="1075/global_pooling_reduce_axis" type="Range" version="opset4">
			<data output_type="i64"/>
			<input>
				<port id="0"/>
				<port id="1"/>
				<port id="2"/>
			</input>
			<output>
				<port id="3" precision="I64">
					<dim>2</dim>
				</port>
			</output>
		</layer>
		<layer id="2880" name="1075/reduce" type="ReduceMean" version="opset1">
			<data keep_dims="true"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>128</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
				<port id="1">
					<dim>2</dim>
				</port>
			</input>
			<output>
				<port id="2" names="1075" precision="FP16">
					<dim>1</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2881" name="1074810752_const" type="Const" version="opset1">
			<data element_type="f16" offset="10108" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="2882" name="1074910753_const" type="Const" version="opset1">
			<data element_type="f16" offset="1529276" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="2883" name="1075010754_const" type="Const" version="opset1">
			<data element_type="f16" offset="10108" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="2884" name="1075110755_const" type="Const" version="opset1">
			<data element_type="f16" offset="1529276" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="2885" name="1077/fq_input_0" type="FakeQuantize" version="opset1">
			<data auto_broadcast="numpy" levels="256"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="1"/>
				<port id="2"/>
				<port id="3"/>
				<port id="4"/>
			</input>
			<output>
				<port id="5" precision="FP16">
					<dim>1</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2886" name="1077/Cast_143256_const2215_const" type="Const" version="opset1">
			<data element_type="i64" offset="129708" shape="3" size="24"/>
			<output>
				<port id="0" names="1076" precision="I64">
					<dim>3</dim>
				</port>
			</output>
		</layer>
		<layer id="2887" name="1077" type="Reshape" version="opset1">
			<data special_zero="true"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="1">
					<dim>3</dim>
				</port>
			</input>
			<output>
				<port id="2" names="1077" precision="FP16">
					<dim>1</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
			</output>
		</layer>
		<layer id="2888" name="1080/Range_input_port_0/value/Output_0/Data__const2217_const" type="Const" version="opset1">
			<data element_type="i64" offset="24" shape="" size="8"/>
			<output>
				<port id="0" precision="I64"/>
			</output>
		</layer>
		<layer id="2889" name="1080/Rank/shape_of" type="ShapeOf" version="opset3">
			<data output_type="i64"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
			</input>
			<output>
				<port id="1" precision="I64">
					<dim>3</dim>
				</port>
			</output>
		</layer>
		<layer id="2890" name="1080/Rank/rank_of" type="ShapeOf" version="opset3">
			<data output_type="i64"/>
			<input>
				<port id="0">
					<dim>3</dim>
				</port>
			</input>
			<output>
				<port id="1" precision="I64">
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2891" name="1080/Rank/0d_rank_of/value/Output_0/Data__const2220_const" type="Const" version="opset1">
			<data element_type="i64" offset="32" shape="1" size="8"/>
			<output>
				<port id="0" precision="I64">
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2892" name="1080/Rank" type="Squeeze" version="opset1">
			<input>
				<port id="0">
					<dim>1</dim>
				</port>
				<port id="1">
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="I64"/>
			</output>
		</layer>
		<layer id="2893" name="1080/Range_input_port_2/value/Output_0/Data__const2222_const" type="Const" version="opset1">
			<data element_type="i64" offset="0" shape="" size="8"/>
			<output>
				<port id="0" precision="I64"/>
			</output>
		</layer>
		<layer id="2894" name="1080/Range" type="Range" version="opset4">
			<data output_type="i64"/>
			<input>
				<port id="0"/>
				<port id="1"/>
				<port id="2"/>
			</input>
			<output>
				<port id="3" precision="I64">
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2895" name="1080/Ins_Norm/MVN_" type="MVN" version="opset6">
			<data eps="9.999999747378752e-06" eps_mode="inside_sqrt" normalize_variance="true"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
				<port id="1">
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>1</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
			</output>
		</layer>
		<layer id="2896" name="1078/EltwiseUnsqueeze23054_const2225_const" type="Const" version="opset1">
			<data element_type="f16" offset="129732" shape="1,16,1" size="32"/>
			<output>
				<port id="0" names="1078" precision="FP16">
					<dim>1</dim>
					<dim>16</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2897" name="1080/Ins_Norm/mul_" type="Multiply" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
				<port id="1">
					<dim>1</dim>
					<dim>16</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>1</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
			</output>
		</layer>
		<layer id="2898" name="1079/EltwiseUnsqueeze23058_const2227_const" type="Const" version="opset1">
			<data element_type="f16" offset="129764" shape="1,16,1" size="32"/>
			<output>
				<port id="0" names="1079" precision="FP16">
					<dim>1</dim>
					<dim>16</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2899" name="1080" type="Add" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
				<port id="1">
					<dim>1</dim>
					<dim>16</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" names="1080" precision="FP16">
					<dim>1</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
			</output>
		</layer>
		<layer id="2900" name="1075810762_const" type="Const" version="opset1">
			<data element_type="f16" offset="1529278" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="2901" name="1075910763_const" type="Const" version="opset1">
			<data element_type="f16" offset="1529280" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="2902" name="1076010764_const" type="Const" version="opset1">
			<data element_type="f16" offset="1529278" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="2903" name="1076110765_const" type="Const" version="opset1">
			<data element_type="f16" offset="1529280" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="2904" name="1082/fq_input_0" type="FakeQuantize" version="opset1">
			<data auto_broadcast="numpy" levels="256"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
				<port id="1"/>
				<port id="2"/>
				<port id="3"/>
				<port id="4"/>
			</input>
			<output>
				<port id="5" precision="FP16">
					<dim>1</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
			</output>
		</layer>
		<layer id="2905" name="1081" type="ShapeOf" version="opset3">
			<data output_type="i64"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="1" names="1081" precision="I64">
					<dim>4</dim>
				</port>
			</output>
		</layer>
		<layer id="2906" name="1082" type="Reshape" version="opset1">
			<data special_zero="true"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
				<port id="1">
					<dim>4</dim>
				</port>
			</input>
			<output>
				<port id="2" names="1082" precision="FP16">
					<dim>1</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2907" name="1083/Unsqueeze/EltwiseUnsqueeze22942_const2231_const" type="Const" version="opset1">
			<data element_type="f16" offset="1490100" shape="1,128,1,1" size="256"/>
			<output>
				<port id="0" names="1083" precision="FP16">
					<dim>1</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2908" name="1084" type="Multiply" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="1">
					<dim>1</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" names="1084" precision="FP16">
					<dim>1</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2909" name="1085/Unsqueeze/EltwiseUnsqueeze22946_const2233_const" type="Const" version="opset1">
			<data element_type="f16" offset="1490356" shape="1,128,1,1" size="256"/>
			<output>
				<port id="0" names="1085" precision="FP16">
					<dim>1</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2910" name="1086" type="Add" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="1">
					<dim>1</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" names="1086" precision="FP16">
					<dim>1</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2911" name="1087" type="Sigmoid" version="opset1">
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="1" names="1087" precision="FP16">
					<dim>1</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2912" name="43974401_const" type="Const" version="opset1">
			<data element_type="f16" offset="10108" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="2913" name="43984402_const" type="Const" version="opset1">
			<data element_type="f16" offset="1529282" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="2914" name="43994403_const" type="Const" version="opset1">
			<data element_type="f16" offset="10108" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="2915" name="44004404_const" type="Const" version="opset1">
			<data element_type="f16" offset="1529282" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="2916" name="1088/fq_input_1" type="FakeQuantize" version="opset1">
			<data auto_broadcast="numpy" levels="256"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="1"/>
				<port id="2"/>
				<port id="3"/>
				<port id="4"/>
			</input>
			<output>
				<port id="5" precision="FP16">
					<dim>1</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2917" name="1088" type="Multiply" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>128</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
				<port id="1">
					<dim>1</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" names="1088" precision="FP16">
					<dim>1</dim>
					<dim>128</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
			</output>
		</layer>
		<layer id="2918" name="47574761_const" type="Const" version="opset1">
			<data element_type="f16" offset="10108" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="2919" name="47584762_const" type="Const" version="opset1">
			<data element_type="f16" offset="1529284" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="2920" name="47594763_const" type="Const" version="opset1">
			<data element_type="f16" offset="10108" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="2921" name="47604764_const" type="Const" version="opset1">
			<data element_type="f16" offset="1529284" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="2922" name="1089/fq_input_1" type="FakeQuantize" version="opset1">
			<data auto_broadcast="numpy" levels="256"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>128</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
				<port id="1"/>
				<port id="2"/>
				<port id="3"/>
				<port id="4"/>
			</input>
			<output>
				<port id="5" precision="FP16">
					<dim>1</dim>
					<dim>128</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
			</output>
		</layer>
		<layer id="2923" name="1089" type="Add" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>128</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
				<port id="1">
					<dim>1</dim>
					<dim>128</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
			</input>
			<output>
				<port id="2" names="1089" precision="FP16">
					<dim>1</dim>
					<dim>128</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
			</output>
		</layer>
		<layer id="2924" name="66876691_const" type="Const" version="opset1">
			<data element_type="f16" offset="10108" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="2925" name="66886692_const" type="Const" version="opset1">
			<data element_type="f16" offset="1529286" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="2926" name="66896693_const" type="Const" version="opset1">
			<data element_type="f16" offset="10108" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="2927" name="66906694_const" type="Const" version="opset1">
			<data element_type="f16" offset="1529286" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="2928" name="1104/fq_input_0" type="FakeQuantize" version="opset1">
			<data auto_broadcast="numpy" levels="256"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>128</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
				<port id="1"/>
				<port id="2"/>
				<port id="3"/>
				<port id="4"/>
			</input>
			<output>
				<port id="5" precision="FP16">
					<dim>1</dim>
					<dim>128</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
			</output>
		</layer>
		<layer id="2929" name="conv4.1.conv2c.0.conv1.weight/quantized17451_const" type="Const" version="opset1">
			<data element_type="i8" offset="1529288" shape="128,128,1,1" size="16384"/>
			<output>
				<port id="0" precision="I8">
					<dim>128</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2930" name="conv4.1.conv2c.0.conv1.weight/quantized/to_f16" type="Convert" version="opset1">
			<data destination_type="f16"/>
			<input>
				<port id="0">
					<dim>128</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="1" precision="FP16">
					<dim>128</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2931" name="1033/fq_weights_1/zero_point17464_const" type="Const" version="opset1">
			<data element_type="f16" offset="1545672" shape="128,1,1,1" size="256"/>
			<output>
				<port id="0" precision="FP16">
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2932" name="1033/fq_weights_1/minus_zp" type="Subtract" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>128</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="1">
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>128</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2933" name="1033/fq_weights_1/scale17459_const" type="Const" version="opset1">
			<data element_type="f16" offset="1545928" shape="128,1,1,1" size="256"/>
			<output>
				<port id="0" precision="FP16">
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2934" name="1033/fq_weights_1/mulpiply_by_scale" type="Multiply" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>128</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="1">
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>128</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2935" name="1033" type="Convolution" version="opset1">
			<data auto_pad="explicit" dilations="1,1" pads_begin="0,0" pads_end="0,0" strides="1,1"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>128</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
				<port id="1">
					<dim>128</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" names="1033" precision="FP16">
					<dim>1</dim>
					<dim>128</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
			</output>
		</layer>
		<layer id="2936" name="30843086_const" type="Const" version="opset1">
			<data element_type="f16" offset="955072" shape="1,128,1,1" size="256"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2937" name="1033/add_" type="Add" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>128</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
				<port id="1">
					<dim>1</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>1</dim>
					<dim>128</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
			</output>
		</layer>
		<layer id="2938" name="78477851_const" type="Const" version="opset1">
			<data element_type="f16" offset="1546184" shape="1,128,1,1" size="256"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2939" name="78487852_const" type="Const" version="opset1">
			<data element_type="f16" offset="1546440" shape="1,128,1,1" size="256"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2940" name="78497853_const" type="Const" version="opset1">
			<data element_type="f16" offset="1546184" shape="1,128,1,1" size="256"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2941" name="78507854_const" type="Const" version="opset1">
			<data element_type="f16" offset="1546440" shape="1,128,1,1" size="256"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2942" name="1034/fq_input_0" type="FakeQuantize" version="opset1">
			<data auto_broadcast="numpy" levels="256"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>128</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
				<port id="1">
					<dim>1</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="2">
					<dim>1</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="3">
					<dim>1</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="4">
					<dim>1</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="5" precision="FP16">
					<dim>1</dim>
					<dim>128</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
			</output>
		</layer>
		<layer id="2943" name="4220342206_const224015713/quantized17667_const" type="Const" version="opset1">
			<data element_type="i8" offset="1546696" shape="128,1,3,3" size="1152"/>
			<output>
				<port id="0" precision="I8">
					<dim>128</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</output>
		</layer>
		<layer id="2944" name="4220342206_const224015713/quantized/to_f16" type="Convert" version="opset1">
			<data destination_type="f16"/>
			<input>
				<port id="0">
					<dim>128</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</input>
			<output>
				<port id="1" precision="FP16">
					<dim>128</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</output>
		</layer>
		<layer id="2945" name="1034/fq_weights_1/zero_point17680_const" type="Const" version="opset1">
			<data element_type="f16" offset="1547848" shape="128,1,1,1" size="256"/>
			<output>
				<port id="0" precision="FP16">
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2946" name="1034/fq_weights_1/minus_zp" type="Subtract" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>128</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
				<port id="1">
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>128</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</output>
		</layer>
		<layer id="2947" name="1034/fq_weights_1/scale17675_const" type="Const" version="opset1">
			<data element_type="f16" offset="1548104" shape="128,1,1,1" size="256"/>
			<output>
				<port id="0" precision="FP16">
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2948" name="1034/fq_weights_1/mulpiply_by_scale" type="Multiply" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>128</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
				<port id="1">
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>128</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</output>
		</layer>
		<layer id="2949" name="24608/value24610_const" type="Const" version="opset1">
			<data element_type="i64" offset="957504" shape="5" size="40"/>
			<output>
				<port id="0" precision="I64">
					<dim>5</dim>
				</port>
			</output>
		</layer>
		<layer id="2950" name="24608" type="Reshape" version="opset1">
			<data special_zero="true"/>
			<input>
				<port id="0">
					<dim>128</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
				<port id="1">
					<dim>5</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</output>
		</layer>
		<layer id="2951" name="1034" type="GroupConvolution" version="opset1">
			<data auto_pad="explicit" dilations="1,1" pads_begin="1,1" pads_end="1,1" strides="1,1"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>128</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
				<port id="1">
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>1</dim>
					<dim>128</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
			</output>
		</layer>
		<layer id="2952" name="data_add_222532225822850/EltwiseUnsqueeze23746_const2242_const" type="Const" version="opset1">
			<data element_type="f16" offset="1548360" shape="1,128,1,1" size="256"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2953" name="1035/variance/Fused_Add_" type="Add" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>128</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
				<port id="1">
					<dim>1</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" names="1035" precision="FP16">
					<dim>1</dim>
					<dim>128</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
			</output>
		</layer>
		<layer id="2954" name="1036" type="ReLU" version="opset1">
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>128</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
			</input>
			<output>
				<port id="1" names="1036" precision="FP16">
					<dim>1</dim>
					<dim>128</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
			</output>
		</layer>
		<layer id="2955" name="56075611_const" type="Const" version="opset1">
			<data element_type="f16" offset="10108" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="2956" name="56085612_const" type="Const" version="opset1">
			<data element_type="f16" offset="1548616" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="2957" name="56095613_const" type="Const" version="opset1">
			<data element_type="f16" offset="10108" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="2958" name="56105614_const" type="Const" version="opset1">
			<data element_type="f16" offset="1548616" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="2959" name="1037/fq_input_0" type="FakeQuantize" version="opset1">
			<data auto_broadcast="numpy" levels="256"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>128</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
				<port id="1"/>
				<port id="2"/>
				<port id="3"/>
				<port id="4"/>
			</input>
			<output>
				<port id="5" precision="FP16">
					<dim>1</dim>
					<dim>128</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
			</output>
		</layer>
		<layer id="2960" name="conv4.1.conv2c.1.conv1.weight/quantized20691_const" type="Const" version="opset1">
			<data element_type="i8" offset="1548618" shape="128,128,1,1" size="16384"/>
			<output>
				<port id="0" precision="I8">
					<dim>128</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2961" name="conv4.1.conv2c.1.conv1.weight/quantized/to_f16" type="Convert" version="opset1">
			<data destination_type="f16"/>
			<input>
				<port id="0">
					<dim>128</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="1" precision="FP16">
					<dim>128</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2962" name="1037/fq_weights_1/zero_point20704_const" type="Const" version="opset1">
			<data element_type="f16" offset="1565002" shape="128,1,1,1" size="256"/>
			<output>
				<port id="0" precision="FP16">
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2963" name="1037/fq_weights_1/minus_zp" type="Subtract" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>128</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="1">
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>128</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2964" name="1037/fq_weights_1/scale20699_const" type="Const" version="opset1">
			<data element_type="f16" offset="1565258" shape="128,1,1,1" size="256"/>
			<output>
				<port id="0" precision="FP16">
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2965" name="1037/fq_weights_1/mulpiply_by_scale" type="Multiply" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>128</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="1">
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>128</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2966" name="1037" type="Convolution" version="opset1">
			<data auto_pad="explicit" dilations="1,1" pads_begin="0,0" pads_end="0,0" strides="1,1"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>128</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
				<port id="1">
					<dim>128</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" names="1037" precision="FP16">
					<dim>1</dim>
					<dim>128</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
			</output>
		</layer>
		<layer id="2967" name="30883090_const" type="Const" version="opset1">
			<data element_type="f16" offset="955072" shape="1,128,1,1" size="256"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2968" name="1037/add_" type="Add" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>128</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
				<port id="1">
					<dim>1</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>1</dim>
					<dim>128</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
			</output>
		</layer>
		<layer id="2969" name="61976201_const" type="Const" version="opset1">
			<data element_type="f16" offset="1565514" shape="1,128,1,1" size="256"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2970" name="61986202_const" type="Const" version="opset1">
			<data element_type="f16" offset="1565770" shape="1,128,1,1" size="256"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2971" name="61996203_const" type="Const" version="opset1">
			<data element_type="f16" offset="1565514" shape="1,128,1,1" size="256"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2972" name="62006204_const" type="Const" version="opset1">
			<data element_type="f16" offset="1565770" shape="1,128,1,1" size="256"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2973" name="1038/fq_input_0" type="FakeQuantize" version="opset1">
			<data auto_broadcast="numpy" levels="256"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>128</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
				<port id="1">
					<dim>1</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="2">
					<dim>1</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="3">
					<dim>1</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="4">
					<dim>1</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="5" precision="FP16">
					<dim>1</dim>
					<dim>128</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
			</output>
		</layer>
		<layer id="2974" name="4227942282_const224715716/quantized19467_const" type="Const" version="opset1">
			<data element_type="i8" offset="1566026" shape="128,1,3,3" size="1152"/>
			<output>
				<port id="0" precision="I8">
					<dim>128</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</output>
		</layer>
		<layer id="2975" name="4227942282_const224715716/quantized/to_f16" type="Convert" version="opset1">
			<data destination_type="f16"/>
			<input>
				<port id="0">
					<dim>128</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</input>
			<output>
				<port id="1" precision="FP16">
					<dim>128</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</output>
		</layer>
		<layer id="2976" name="1038/fq_weights_1/zero_point19480_const" type="Const" version="opset1">
			<data element_type="f16" offset="1567178" shape="128,1,1,1" size="256"/>
			<output>
				<port id="0" precision="FP16">
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2977" name="1038/fq_weights_1/minus_zp" type="Subtract" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>128</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
				<port id="1">
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>128</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</output>
		</layer>
		<layer id="2978" name="1038/fq_weights_1/scale19475_const" type="Const" version="opset1">
			<data element_type="f16" offset="1567434" shape="128,1,1,1" size="256"/>
			<output>
				<port id="0" precision="FP16">
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2979" name="1038/fq_weights_1/mulpiply_by_scale" type="Multiply" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>128</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
				<port id="1">
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>128</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</output>
		</layer>
		<layer id="2980" name="24532/value24534_const" type="Const" version="opset1">
			<data element_type="i64" offset="957504" shape="5" size="40"/>
			<output>
				<port id="0" precision="I64">
					<dim>5</dim>
				</port>
			</output>
		</layer>
		<layer id="2981" name="24532" type="Reshape" version="opset1">
			<data special_zero="true"/>
			<input>
				<port id="0">
					<dim>128</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
				<port id="1">
					<dim>5</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</output>
		</layer>
		<layer id="2982" name="1038" type="GroupConvolution" version="opset1">
			<data auto_pad="explicit" dilations="1,1" pads_begin="1,1" pads_end="1,1" strides="1,1"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>128</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
				<port id="1">
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>1</dim>
					<dim>128</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
			</output>
		</layer>
		<layer id="2983" name="data_add_222612226622852/EltwiseUnsqueeze23754_const2249_const" type="Const" version="opset1">
			<data element_type="f16" offset="1567690" shape="1,128,1,1" size="256"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2984" name="1039/variance/Fused_Add_" type="Add" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>128</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
				<port id="1">
					<dim>1</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" names="1039" precision="FP16">
					<dim>1</dim>
					<dim>128</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
			</output>
		</layer>
		<layer id="2985" name="1040" type="ReLU" version="opset1">
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>128</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
			</input>
			<output>
				<port id="1" names="1040" precision="FP16">
					<dim>1</dim>
					<dim>128</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
			</output>
		</layer>
		<layer id="2986" name="83778381_const" type="Const" version="opset1">
			<data element_type="f16" offset="10108" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="2987" name="83788382_const" type="Const" version="opset1">
			<data element_type="f16" offset="1567946" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="2988" name="83798383_const" type="Const" version="opset1">
			<data element_type="f16" offset="10108" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="2989" name="83808384_const" type="Const" version="opset1">
			<data element_type="f16" offset="1567946" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="2990" name="1041/fq_input_0" type="FakeQuantize" version="opset1">
			<data auto_broadcast="numpy" levels="256"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>128</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
				<port id="1"/>
				<port id="2"/>
				<port id="3"/>
				<port id="4"/>
			</input>
			<output>
				<port id="5" precision="FP16">
					<dim>1</dim>
					<dim>128</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
			</output>
		</layer>
		<layer id="2991" name="conv4.1.conv2c.2.conv1.weight/quantized20427_const" type="Const" version="opset1">
			<data element_type="i8" offset="1567948" shape="128,128,1,1" size="16384"/>
			<output>
				<port id="0" precision="I8">
					<dim>128</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2992" name="conv4.1.conv2c.2.conv1.weight/quantized/to_f16" type="Convert" version="opset1">
			<data destination_type="f16"/>
			<input>
				<port id="0">
					<dim>128</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="1" precision="FP16">
					<dim>128</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2993" name="1041/fq_weights_1/zero_point20440_const" type="Const" version="opset1">
			<data element_type="f16" offset="1584332" shape="128,1,1,1" size="256"/>
			<output>
				<port id="0" precision="FP16">
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2994" name="1041/fq_weights_1/minus_zp" type="Subtract" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>128</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="1">
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>128</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2995" name="1041/fq_weights_1/scale20435_const" type="Const" version="opset1">
			<data element_type="f16" offset="1584588" shape="128,1,1,1" size="256"/>
			<output>
				<port id="0" precision="FP16">
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2996" name="1041/fq_weights_1/mulpiply_by_scale" type="Multiply" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>128</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="1">
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>128</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2997" name="1041" type="Convolution" version="opset1">
			<data auto_pad="explicit" dilations="1,1" pads_begin="0,0" pads_end="0,0" strides="1,1"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>128</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
				<port id="1">
					<dim>128</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" names="1041" precision="FP16">
					<dim>1</dim>
					<dim>128</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
			</output>
		</layer>
		<layer id="2998" name="30923094_const" type="Const" version="opset1">
			<data element_type="f16" offset="955072" shape="1,128,1,1" size="256"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="2999" name="1041/add_" type="Add" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>128</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
				<port id="1">
					<dim>1</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>1</dim>
					<dim>128</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
			</output>
		</layer>
		<layer id="3000" name="49574961_const" type="Const" version="opset1">
			<data element_type="f16" offset="1584844" shape="1,128,1,1" size="256"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="3001" name="49584962_const" type="Const" version="opset1">
			<data element_type="f16" offset="1585100" shape="1,128,1,1" size="256"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="3002" name="49594963_const" type="Const" version="opset1">
			<data element_type="f16" offset="1584844" shape="1,128,1,1" size="256"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="3003" name="49604964_const" type="Const" version="opset1">
			<data element_type="f16" offset="1585100" shape="1,128,1,1" size="256"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="3004" name="1042/fq_input_0" type="FakeQuantize" version="opset1">
			<data auto_broadcast="numpy" levels="256"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>128</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
				<port id="1">
					<dim>1</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="2">
					<dim>1</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="3">
					<dim>1</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="4">
					<dim>1</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="5" precision="FP16">
					<dim>1</dim>
					<dim>128</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
			</output>
		</layer>
		<layer id="3005" name="4228342286_const225415719/quantized19059_const" type="Const" version="opset1">
			<data element_type="i8" offset="1585356" shape="128,1,3,3" size="1152"/>
			<output>
				<port id="0" precision="I8">
					<dim>128</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</output>
		</layer>
		<layer id="3006" name="4228342286_const225415719/quantized/to_f16" type="Convert" version="opset1">
			<data destination_type="f16"/>
			<input>
				<port id="0">
					<dim>128</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</input>
			<output>
				<port id="1" precision="FP16">
					<dim>128</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</output>
		</layer>
		<layer id="3007" name="1042/fq_weights_1/zero_point19072_const" type="Const" version="opset1">
			<data element_type="f16" offset="1586508" shape="128,1,1,1" size="256"/>
			<output>
				<port id="0" precision="FP16">
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="3008" name="1042/fq_weights_1/minus_zp" type="Subtract" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>128</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
				<port id="1">
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>128</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</output>
		</layer>
		<layer id="3009" name="1042/fq_weights_1/scale19067_const" type="Const" version="opset1">
			<data element_type="f16" offset="1586764" shape="128,1,1,1" size="256"/>
			<output>
				<port id="0" precision="FP16">
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="3010" name="1042/fq_weights_1/mulpiply_by_scale" type="Multiply" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>128</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
				<port id="1">
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>128</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</output>
		</layer>
		<layer id="3011" name="24384/value24386_const" type="Const" version="opset1">
			<data element_type="i64" offset="957504" shape="5" size="40"/>
			<output>
				<port id="0" precision="I64">
					<dim>5</dim>
				</port>
			</output>
		</layer>
		<layer id="3012" name="24384" type="Reshape" version="opset1">
			<data special_zero="true"/>
			<input>
				<port id="0">
					<dim>128</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
				<port id="1">
					<dim>5</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</output>
		</layer>
		<layer id="3013" name="1042" type="GroupConvolution" version="opset1">
			<data auto_pad="explicit" dilations="1,1" pads_begin="1,1" pads_end="1,1" strides="1,1"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>128</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
				<port id="1">
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>1</dim>
					<dim>128</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
			</output>
		</layer>
		<layer id="3014" name="data_add_222692227422854/EltwiseUnsqueeze23762_const2256_const" type="Const" version="opset1">
			<data element_type="f16" offset="1587020" shape="1,128,1,1" size="256"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="3015" name="1043/variance/Fused_Add_" type="Add" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>128</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
				<port id="1">
					<dim>1</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" names="1043" precision="FP16">
					<dim>1</dim>
					<dim>128</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
			</output>
		</layer>
		<layer id="3016" name="1044" type="ReLU" version="opset1">
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>128</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
			</input>
			<output>
				<port id="1" names="1044" precision="FP16">
					<dim>1</dim>
					<dim>128</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
			</output>
		</layer>
		<layer id="3017" name="53275331_const" type="Const" version="opset1">
			<data element_type="f16" offset="10108" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="3018" name="53285332_const" type="Const" version="opset1">
			<data element_type="f16" offset="1587276" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="3019" name="53295333_const" type="Const" version="opset1">
			<data element_type="f16" offset="10108" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="3020" name="53305334_const" type="Const" version="opset1">
			<data element_type="f16" offset="1587276" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="3021" name="1090/reduce/fq_input_0" type="FakeQuantize" version="opset1">
			<data auto_broadcast="numpy" levels="256"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>128</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
				<port id="1"/>
				<port id="2"/>
				<port id="3"/>
				<port id="4"/>
			</input>
			<output>
				<port id="5" precision="FP16">
					<dim>1</dim>
					<dim>128</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
			</output>
		</layer>
		<layer id="3022" name="1434/Output_0/Data__const2259_const" type="Const" version="opset1">
			<data element_type="i64" offset="24" shape="" size="8"/>
			<output>
				<port id="0" precision="I64"/>
			</output>
		</layer>
		<layer id="3023" name="1090/input_rank/shape_of" type="ShapeOf" version="opset3">
			<data output_type="i64"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>128</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
			</input>
			<output>
				<port id="1" precision="I64">
					<dim>4</dim>
				</port>
			</output>
		</layer>
		<layer id="3024" name="1090/input_rank/rank_of" type="ShapeOf" version="opset3">
			<data output_type="i64"/>
			<input>
				<port id="0">
					<dim>4</dim>
				</port>
			</input>
			<output>
				<port id="1" precision="I64">
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="3025" name="1090/input_rank/0d_rank_of/value/Output_0/Data__const2262_const" type="Const" version="opset1">
			<data element_type="i64" offset="32" shape="1" size="8"/>
			<output>
				<port id="0" precision="I64">
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="3026" name="1090/input_rank" type="Squeeze" version="opset1">
			<input>
				<port id="0">
					<dim>1</dim>
				</port>
				<port id="1">
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="I64"/>
			</output>
		</layer>
		<layer id="3027" name="1436/Output_0/Data__const2264_const" type="Const" version="opset1">
			<data element_type="i64" offset="0" shape="" size="8"/>
			<output>
				<port id="0" precision="I64"/>
			</output>
		</layer>
		<layer id="3028" name="1090/global_pooling_reduce_axis" type="Range" version="opset4">
			<data output_type="i64"/>
			<input>
				<port id="0"/>
				<port id="1"/>
				<port id="2"/>
			</input>
			<output>
				<port id="3" precision="I64">
					<dim>2</dim>
				</port>
			</output>
		</layer>
		<layer id="3029" name="1090/reduce" type="ReduceMean" version="opset1">
			<data keep_dims="true"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>128</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
				<port id="1">
					<dim>2</dim>
				</port>
			</input>
			<output>
				<port id="2" names="1090" precision="FP16">
					<dim>1</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="3030" name="1076810772_const" type="Const" version="opset1">
			<data element_type="f16" offset="10108" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="3031" name="1076910773_const" type="Const" version="opset1">
			<data element_type="f16" offset="1587278" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="3032" name="1077010774_const" type="Const" version="opset1">
			<data element_type="f16" offset="10108" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="3033" name="1077110775_const" type="Const" version="opset1">
			<data element_type="f16" offset="1587278" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="3034" name="1092/fq_input_0" type="FakeQuantize" version="opset1">
			<data auto_broadcast="numpy" levels="256"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="1"/>
				<port id="2"/>
				<port id="3"/>
				<port id="4"/>
			</input>
			<output>
				<port id="5" precision="FP16">
					<dim>1</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="3035" name="1092/Cast_143260_const2267_const" type="Const" version="opset1">
			<data element_type="i64" offset="129708" shape="3" size="24"/>
			<output>
				<port id="0" names="1091" precision="I64">
					<dim>3</dim>
				</port>
			</output>
		</layer>
		<layer id="3036" name="1092" type="Reshape" version="opset1">
			<data special_zero="true"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="1">
					<dim>3</dim>
				</port>
			</input>
			<output>
				<port id="2" names="1092" precision="FP16">
					<dim>1</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
			</output>
		</layer>
		<layer id="3037" name="1095/Range_input_port_0/value/Output_0/Data__const2269_const" type="Const" version="opset1">
			<data element_type="i64" offset="24" shape="" size="8"/>
			<output>
				<port id="0" precision="I64"/>
			</output>
		</layer>
		<layer id="3038" name="1095/Rank/shape_of" type="ShapeOf" version="opset3">
			<data output_type="i64"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
			</input>
			<output>
				<port id="1" precision="I64">
					<dim>3</dim>
				</port>
			</output>
		</layer>
		<layer id="3039" name="1095/Rank/rank_of" type="ShapeOf" version="opset3">
			<data output_type="i64"/>
			<input>
				<port id="0">
					<dim>3</dim>
				</port>
			</input>
			<output>
				<port id="1" precision="I64">
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="3040" name="1095/Rank/0d_rank_of/value/Output_0/Data__const2272_const" type="Const" version="opset1">
			<data element_type="i64" offset="32" shape="1" size="8"/>
			<output>
				<port id="0" precision="I64">
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="3041" name="1095/Rank" type="Squeeze" version="opset1">
			<input>
				<port id="0">
					<dim>1</dim>
				</port>
				<port id="1">
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="I64"/>
			</output>
		</layer>
		<layer id="3042" name="1095/Range_input_port_2/value/Output_0/Data__const2274_const" type="Const" version="opset1">
			<data element_type="i64" offset="0" shape="" size="8"/>
			<output>
				<port id="0" precision="I64"/>
			</output>
		</layer>
		<layer id="3043" name="1095/Range" type="Range" version="opset4">
			<data output_type="i64"/>
			<input>
				<port id="0"/>
				<port id="1"/>
				<port id="2"/>
			</input>
			<output>
				<port id="3" precision="I64">
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="3044" name="1095/Ins_Norm/MVN_" type="MVN" version="opset6">
			<data eps="9.999999747378752e-06" eps_mode="inside_sqrt" normalize_variance="true"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
				<port id="1">
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>1</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
			</output>
		</layer>
		<layer id="3045" name="1093/EltwiseUnsqueeze22982_const2277_const" type="Const" version="opset1">
			<data element_type="f16" offset="129732" shape="1,16,1" size="32"/>
			<output>
				<port id="0" names="1093" precision="FP16">
					<dim>1</dim>
					<dim>16</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="3046" name="1095/Ins_Norm/mul_" type="Multiply" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
				<port id="1">
					<dim>1</dim>
					<dim>16</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>1</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
			</output>
		</layer>
		<layer id="3047" name="1094/EltwiseUnsqueeze22986_const2279_const" type="Const" version="opset1">
			<data element_type="f16" offset="129764" shape="1,16,1" size="32"/>
			<output>
				<port id="0" names="1094" precision="FP16">
					<dim>1</dim>
					<dim>16</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="3048" name="1095" type="Add" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
				<port id="1">
					<dim>1</dim>
					<dim>16</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" names="1095" precision="FP16">
					<dim>1</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
			</output>
		</layer>
		<layer id="3049" name="1077810782_const" type="Const" version="opset1">
			<data element_type="f16" offset="1587280" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="3050" name="1077910783_const" type="Const" version="opset1">
			<data element_type="f16" offset="1587282" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="3051" name="1078010784_const" type="Const" version="opset1">
			<data element_type="f16" offset="1587280" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="3052" name="1078110785_const" type="Const" version="opset1">
			<data element_type="f16" offset="1587282" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="3053" name="1097/fq_input_0" type="FakeQuantize" version="opset1">
			<data auto_broadcast="numpy" levels="256"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
				<port id="1"/>
				<port id="2"/>
				<port id="3"/>
				<port id="4"/>
			</input>
			<output>
				<port id="5" precision="FP16">
					<dim>1</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
			</output>
		</layer>
		<layer id="3054" name="1096" type="ShapeOf" version="opset3">
			<data output_type="i64"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="1" names="1096" precision="I64">
					<dim>4</dim>
				</port>
			</output>
		</layer>
		<layer id="3055" name="1097" type="Reshape" version="opset1">
			<data special_zero="true"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
				<port id="1">
					<dim>4</dim>
				</port>
			</input>
			<output>
				<port id="2" names="1097" precision="FP16">
					<dim>1</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="3056" name="1098/Unsqueeze/EltwiseUnsqueeze22950_const2283_const" type="Const" version="opset1">
			<data element_type="f16" offset="1490100" shape="1,128,1,1" size="256"/>
			<output>
				<port id="0" names="1098" precision="FP16">
					<dim>1</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="3057" name="1099" type="Multiply" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="1">
					<dim>1</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" names="1099" precision="FP16">
					<dim>1</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="3058" name="1100/Unsqueeze/EltwiseUnsqueeze22954_const2285_const" type="Const" version="opset1">
			<data element_type="f16" offset="1490356" shape="1,128,1,1" size="256"/>
			<output>
				<port id="0" names="1100" precision="FP16">
					<dim>1</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="3059" name="1101" type="Add" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="1">
					<dim>1</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" names="1101" precision="FP16">
					<dim>1</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="3060" name="1102" type="Sigmoid" version="opset1">
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="1" names="1102" precision="FP16">
					<dim>1</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="3061" name="44774481_const" type="Const" version="opset1">
			<data element_type="f16" offset="10108" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="3062" name="44784482_const" type="Const" version="opset1">
			<data element_type="f16" offset="1587284" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="3063" name="44794483_const" type="Const" version="opset1">
			<data element_type="f16" offset="10108" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="3064" name="44804484_const" type="Const" version="opset1">
			<data element_type="f16" offset="1587284" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="3065" name="1103/fq_input_1" type="FakeQuantize" version="opset1">
			<data auto_broadcast="numpy" levels="256"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="1"/>
				<port id="2"/>
				<port id="3"/>
				<port id="4"/>
			</input>
			<output>
				<port id="5" precision="FP16">
					<dim>1</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="3066" name="1103" type="Multiply" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>128</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
				<port id="1">
					<dim>1</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" names="1103" precision="FP16">
					<dim>1</dim>
					<dim>128</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
			</output>
		</layer>
		<layer id="3067" name="66976701_const" type="Const" version="opset1">
			<data element_type="f16" offset="10108" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="3068" name="66986702_const" type="Const" version="opset1">
			<data element_type="f16" offset="1587286" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="3069" name="66996703_const" type="Const" version="opset1">
			<data element_type="f16" offset="10108" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="3070" name="67006704_const" type="Const" version="opset1">
			<data element_type="f16" offset="1587286" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="3071" name="1104/fq_input_1" type="FakeQuantize" version="opset1">
			<data auto_broadcast="numpy" levels="256"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>128</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
				<port id="1"/>
				<port id="2"/>
				<port id="3"/>
				<port id="4"/>
			</input>
			<output>
				<port id="5" precision="FP16">
					<dim>1</dim>
					<dim>128</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
			</output>
		</layer>
		<layer id="3072" name="1104" type="Add" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>128</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
				<port id="1">
					<dim>1</dim>
					<dim>128</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
			</input>
			<output>
				<port id="2" names="1104" precision="FP16">
					<dim>1</dim>
					<dim>128</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
			</output>
		</layer>
		<layer id="3073" name="57075711_const" type="Const" version="opset1">
			<data element_type="f16" offset="10108" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="3074" name="57085712_const" type="Const" version="opset1">
			<data element_type="f16" offset="1587286" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="3075" name="57095713_const" type="Const" version="opset1">
			<data element_type="f16" offset="10108" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="3076" name="57105714_const" type="Const" version="opset1">
			<data element_type="f16" offset="1587286" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="3077" name="1119/fq_input_0" type="FakeQuantize" version="opset1">
			<data auto_broadcast="numpy" levels="256"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>128</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
				<port id="1"/>
				<port id="2"/>
				<port id="3"/>
				<port id="4"/>
			</input>
			<output>
				<port id="5" precision="FP16">
					<dim>1</dim>
					<dim>128</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
			</output>
		</layer>
		<layer id="3078" name="conv4.1.conv2d.0.conv1.weight/quantized19035_const" type="Const" version="opset1">
			<data element_type="i8" offset="1587288" shape="128,128,1,1" size="16384"/>
			<output>
				<port id="0" precision="I8">
					<dim>128</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="3079" name="conv4.1.conv2d.0.conv1.weight/quantized/to_f16" type="Convert" version="opset1">
			<data destination_type="f16"/>
			<input>
				<port id="0">
					<dim>128</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="1" precision="FP16">
					<dim>128</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="3080" name="1045/fq_weights_1/zero_point19048_const" type="Const" version="opset1">
			<data element_type="f16" offset="1603672" shape="128,1,1,1" size="256"/>
			<output>
				<port id="0" precision="FP16">
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="3081" name="1045/fq_weights_1/minus_zp" type="Subtract" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>128</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="1">
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>128</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="3082" name="1045/fq_weights_1/scale19043_const" type="Const" version="opset1">
			<data element_type="f16" offset="1603928" shape="128,1,1,1" size="256"/>
			<output>
				<port id="0" precision="FP16">
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="3083" name="1045/fq_weights_1/mulpiply_by_scale" type="Multiply" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>128</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="1">
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>128</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="3084" name="1045" type="Convolution" version="opset1">
			<data auto_pad="explicit" dilations="1,1" pads_begin="0,0" pads_end="0,0" strides="1,1"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>128</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
				<port id="1">
					<dim>128</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" names="1045" precision="FP16">
					<dim>1</dim>
					<dim>128</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
			</output>
		</layer>
		<layer id="3085" name="30963098_const" type="Const" version="opset1">
			<data element_type="f16" offset="955072" shape="1,128,1,1" size="256"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="3086" name="1045/add_" type="Add" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>128</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
				<port id="1">
					<dim>1</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>1</dim>
					<dim>128</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
			</output>
		</layer>
		<layer id="3087" name="52775281_const" type="Const" version="opset1">
			<data element_type="f16" offset="1604184" shape="1,128,1,1" size="256"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="3088" name="52785282_const" type="Const" version="opset1">
			<data element_type="f16" offset="1604440" shape="1,128,1,1" size="256"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="3089" name="52795283_const" type="Const" version="opset1">
			<data element_type="f16" offset="1604184" shape="1,128,1,1" size="256"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="3090" name="52805284_const" type="Const" version="opset1">
			<data element_type="f16" offset="1604440" shape="1,128,1,1" size="256"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="3091" name="1046/fq_input_0" type="FakeQuantize" version="opset1">
			<data auto_broadcast="numpy" levels="256"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>128</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
				<port id="1">
					<dim>1</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="2">
					<dim>1</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="3">
					<dim>1</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="4">
					<dim>1</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="5" precision="FP16">
					<dim>1</dim>
					<dim>128</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
			</output>
		</layer>
		<layer id="3092" name="4215142154_const229215733/quantized18291_const" type="Const" version="opset1">
			<data element_type="i8" offset="1604696" shape="128,1,3,3" size="1152"/>
			<output>
				<port id="0" precision="I8">
					<dim>128</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</output>
		</layer>
		<layer id="3093" name="4215142154_const229215733/quantized/to_f16" type="Convert" version="opset1">
			<data destination_type="f16"/>
			<input>
				<port id="0">
					<dim>128</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</input>
			<output>
				<port id="1" precision="FP16">
					<dim>128</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</output>
		</layer>
		<layer id="3094" name="1046/fq_weights_1/zero_point18304_const" type="Const" version="opset1">
			<data element_type="f16" offset="1605848" shape="128,1,1,1" size="256"/>
			<output>
				<port id="0" precision="FP16">
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="3095" name="1046/fq_weights_1/minus_zp" type="Subtract" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>128</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
				<port id="1">
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>128</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</output>
		</layer>
		<layer id="3096" name="1046/fq_weights_1/scale18299_const" type="Const" version="opset1">
			<data element_type="f16" offset="1606104" shape="128,1,1,1" size="256"/>
			<output>
				<port id="0" precision="FP16">
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="3097" name="1046/fq_weights_1/mulpiply_by_scale" type="Multiply" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>128</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
				<port id="1">
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>128</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</output>
		</layer>
		<layer id="3098" name="24576/value24578_const" type="Const" version="opset1">
			<data element_type="i64" offset="957504" shape="5" size="40"/>
			<output>
				<port id="0" precision="I64">
					<dim>5</dim>
				</port>
			</output>
		</layer>
		<layer id="3099" name="24576" type="Reshape" version="opset1">
			<data special_zero="true"/>
			<input>
				<port id="0">
					<dim>128</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
				<port id="1">
					<dim>5</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</output>
		</layer>
		<layer id="3100" name="1046" type="GroupConvolution" version="opset1">
			<data auto_pad="explicit" dilations="1,1" pads_begin="1,1" pads_end="1,1" strides="1,1"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>128</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
				<port id="1">
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>1</dim>
					<dim>128</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
			</output>
		</layer>
		<layer id="3101" name="data_add_222212222622842/EltwiseUnsqueeze23714_const2294_const" type="Const" version="opset1">
			<data element_type="f16" offset="1606360" shape="1,128,1,1" size="256"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="3102" name="1047/variance/Fused_Add_" type="Add" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>128</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
				<port id="1">
					<dim>1</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" names="1047" precision="FP16">
					<dim>1</dim>
					<dim>128</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
			</output>
		</layer>
		<layer id="3103" name="1048" type="ReLU" version="opset1">
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>128</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
			</input>
			<output>
				<port id="1" names="1048" precision="FP16">
					<dim>1</dim>
					<dim>128</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
			</output>
		</layer>
		<layer id="3104" name="47274731_const" type="Const" version="opset1">
			<data element_type="f16" offset="10108" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="3105" name="47284732_const" type="Const" version="opset1">
			<data element_type="f16" offset="1606616" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="3106" name="47294733_const" type="Const" version="opset1">
			<data element_type="f16" offset="10108" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="3107" name="47304734_const" type="Const" version="opset1">
			<data element_type="f16" offset="1606616" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="3108" name="1049/fq_input_0" type="FakeQuantize" version="opset1">
			<data auto_broadcast="numpy" levels="256"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>128</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
				<port id="1"/>
				<port id="2"/>
				<port id="3"/>
				<port id="4"/>
			</input>
			<output>
				<port id="5" precision="FP16">
					<dim>1</dim>
					<dim>128</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
			</output>
		</layer>
		<layer id="3109" name="conv4.1.conv2d.1.conv1.weight/quantized18915_const" type="Const" version="opset1">
			<data element_type="i8" offset="1606618" shape="128,128,1,1" size="16384"/>
			<output>
				<port id="0" precision="I8">
					<dim>128</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="3110" name="conv4.1.conv2d.1.conv1.weight/quantized/to_f16" type="Convert" version="opset1">
			<data destination_type="f16"/>
			<input>
				<port id="0">
					<dim>128</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="1" precision="FP16">
					<dim>128</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="3111" name="1049/fq_weights_1/zero_point18928_const" type="Const" version="opset1">
			<data element_type="f16" offset="1623002" shape="128,1,1,1" size="256"/>
			<output>
				<port id="0" precision="FP16">
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="3112" name="1049/fq_weights_1/minus_zp" type="Subtract" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>128</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="1">
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>128</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="3113" name="1049/fq_weights_1/scale18923_const" type="Const" version="opset1">
			<data element_type="f16" offset="1623258" shape="128,1,1,1" size="256"/>
			<output>
				<port id="0" precision="FP16">
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="3114" name="1049/fq_weights_1/mulpiply_by_scale" type="Multiply" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>128</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="1">
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>128</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="3115" name="1049" type="Convolution" version="opset1">
			<data auto_pad="explicit" dilations="1,1" pads_begin="0,0" pads_end="0,0" strides="1,1"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>128</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
				<port id="1">
					<dim>128</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" names="1049" precision="FP16">
					<dim>1</dim>
					<dim>128</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
			</output>
		</layer>
		<layer id="3116" name="31003102_const" type="Const" version="opset1">
			<data element_type="f16" offset="955072" shape="1,128,1,1" size="256"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="3117" name="1049/add_" type="Add" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>128</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
				<port id="1">
					<dim>1</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>1</dim>
					<dim>128</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
			</output>
		</layer>
		<layer id="3118" name="60376041_const" type="Const" version="opset1">
			<data element_type="f16" offset="1623514" shape="1,128,1,1" size="256"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="3119" name="60386042_const" type="Const" version="opset1">
			<data element_type="f16" offset="1623770" shape="1,128,1,1" size="256"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="3120" name="60396043_const" type="Const" version="opset1">
			<data element_type="f16" offset="1623514" shape="1,128,1,1" size="256"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="3121" name="60406044_const" type="Const" version="opset1">
			<data element_type="f16" offset="1623770" shape="1,128,1,1" size="256"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="3122" name="1050/fq_input_0" type="FakeQuantize" version="opset1">
			<data auto_broadcast="numpy" levels="256"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>128</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
				<port id="1">
					<dim>1</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="2">
					<dim>1</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="3">
					<dim>1</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="4">
					<dim>1</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="5" precision="FP16">
					<dim>1</dim>
					<dim>128</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
			</output>
		</layer>
		<layer id="3123" name="4227542278_const229915736/quantized20067_const" type="Const" version="opset1">
			<data element_type="i8" offset="1624026" shape="128,1,3,3" size="1152"/>
			<output>
				<port id="0" precision="I8">
					<dim>128</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</output>
		</layer>
		<layer id="3124" name="4227542278_const229915736/quantized/to_f16" type="Convert" version="opset1">
			<data destination_type="f16"/>
			<input>
				<port id="0">
					<dim>128</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</input>
			<output>
				<port id="1" precision="FP16">
					<dim>128</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</output>
		</layer>
		<layer id="3125" name="1050/fq_weights_1/zero_point20080_const" type="Const" version="opset1">
			<data element_type="f16" offset="1625178" shape="128,1,1,1" size="256"/>
			<output>
				<port id="0" precision="FP16">
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="3126" name="1050/fq_weights_1/minus_zp" type="Subtract" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>128</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
				<port id="1">
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>128</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</output>
		</layer>
		<layer id="3127" name="1050/fq_weights_1/scale20075_const" type="Const" version="opset1">
			<data element_type="f16" offset="1625434" shape="128,1,1,1" size="256"/>
			<output>
				<port id="0" precision="FP16">
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="3128" name="1050/fq_weights_1/mulpiply_by_scale" type="Multiply" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>128</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
				<port id="1">
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>128</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</output>
		</layer>
		<layer id="3129" name="24524/value24526_const" type="Const" version="opset1">
			<data element_type="i64" offset="957504" shape="5" size="40"/>
			<output>
				<port id="0" precision="I64">
					<dim>5</dim>
				</port>
			</output>
		</layer>
		<layer id="3130" name="24524" type="Reshape" version="opset1">
			<data special_zero="true"/>
			<input>
				<port id="0">
					<dim>128</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
				<port id="1">
					<dim>5</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</output>
		</layer>
		<layer id="3131" name="1050" type="GroupConvolution" version="opset1">
			<data auto_pad="explicit" dilations="1,1" pads_begin="1,1" pads_end="1,1" strides="1,1"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>128</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
				<port id="1">
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>1</dim>
					<dim>128</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
			</output>
		</layer>
		<layer id="3132" name="data_add_222292223422844/EltwiseUnsqueeze23722_const2301_const" type="Const" version="opset1">
			<data element_type="f16" offset="1625690" shape="1,128,1,1" size="256"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="3133" name="1051/variance/Fused_Add_" type="Add" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>128</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
				<port id="1">
					<dim>1</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" names="1051" precision="FP16">
					<dim>1</dim>
					<dim>128</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
			</output>
		</layer>
		<layer id="3134" name="1052" type="ReLU" version="opset1">
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>128</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
			</input>
			<output>
				<port id="1" names="1052" precision="FP16">
					<dim>1</dim>
					<dim>128</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
			</output>
		</layer>
		<layer id="3135" name="54275431_const" type="Const" version="opset1">
			<data element_type="f16" offset="10108" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="3136" name="54285432_const" type="Const" version="opset1">
			<data element_type="f16" offset="1625946" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="3137" name="54295433_const" type="Const" version="opset1">
			<data element_type="f16" offset="10108" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="3138" name="54305434_const" type="Const" version="opset1">
			<data element_type="f16" offset="1625946" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="3139" name="1053/fq_input_0" type="FakeQuantize" version="opset1">
			<data auto_broadcast="numpy" levels="256"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>128</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
				<port id="1"/>
				<port id="2"/>
				<port id="3"/>
				<port id="4"/>
			</input>
			<output>
				<port id="5" precision="FP16">
					<dim>1</dim>
					<dim>128</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
			</output>
		</layer>
		<layer id="3140" name="conv4.1.conv2d.2.conv1.weight/quantized17499_const" type="Const" version="opset1">
			<data element_type="i8" offset="1625948" shape="128,128,1,1" size="16384"/>
			<output>
				<port id="0" precision="I8">
					<dim>128</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="3141" name="conv4.1.conv2d.2.conv1.weight/quantized/to_f16" type="Convert" version="opset1">
			<data destination_type="f16"/>
			<input>
				<port id="0">
					<dim>128</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="1" precision="FP16">
					<dim>128</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="3142" name="1053/fq_weights_1/zero_point17512_const" type="Const" version="opset1">
			<data element_type="f16" offset="1642332" shape="128,1,1,1" size="256"/>
			<output>
				<port id="0" precision="FP16">
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="3143" name="1053/fq_weights_1/minus_zp" type="Subtract" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>128</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="1">
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>128</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="3144" name="1053/fq_weights_1/scale17507_const" type="Const" version="opset1">
			<data element_type="f16" offset="1642588" shape="128,1,1,1" size="256"/>
			<output>
				<port id="0" precision="FP16">
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="3145" name="1053/fq_weights_1/mulpiply_by_scale" type="Multiply" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>128</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="1">
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>128</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="3146" name="1053" type="Convolution" version="opset1">
			<data auto_pad="explicit" dilations="1,1" pads_begin="0,0" pads_end="0,0" strides="1,1"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>128</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
				<port id="1">
					<dim>128</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" names="1053" precision="FP16">
					<dim>1</dim>
					<dim>128</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
			</output>
		</layer>
		<layer id="3147" name="31043106_const" type="Const" version="opset1">
			<data element_type="f16" offset="955072" shape="1,128,1,1" size="256"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="3148" name="1053/add_" type="Add" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>128</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
				<port id="1">
					<dim>1</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>1</dim>
					<dim>128</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
			</output>
		</layer>
		<layer id="3149" name="81778181_const" type="Const" version="opset1">
			<data element_type="f16" offset="1642844" shape="1,128,1,1" size="256"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="3150" name="81788182_const" type="Const" version="opset1">
			<data element_type="f16" offset="1643100" shape="1,128,1,1" size="256"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="3151" name="81798183_const" type="Const" version="opset1">
			<data element_type="f16" offset="1642844" shape="1,128,1,1" size="256"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="3152" name="81808184_const" type="Const" version="opset1">
			<data element_type="f16" offset="1643100" shape="1,128,1,1" size="256"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="3153" name="1054/fq_input_0" type="FakeQuantize" version="opset1">
			<data auto_broadcast="numpy" levels="256"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>128</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
				<port id="1">
					<dim>1</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="2">
					<dim>1</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="3">
					<dim>1</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="4">
					<dim>1</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="5" precision="FP16">
					<dim>1</dim>
					<dim>128</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
			</output>
		</layer>
		<layer id="3154" name="4214342146_const230615739/quantized18603_const" type="Const" version="opset1">
			<data element_type="i8" offset="1643356" shape="128,1,3,3" size="1152"/>
			<output>
				<port id="0" precision="I8">
					<dim>128</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</output>
		</layer>
		<layer id="3155" name="4214342146_const230615739/quantized/to_f16" type="Convert" version="opset1">
			<data destination_type="f16"/>
			<input>
				<port id="0">
					<dim>128</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</input>
			<output>
				<port id="1" precision="FP16">
					<dim>128</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</output>
		</layer>
		<layer id="3156" name="1054/fq_weights_1/zero_point18616_const" type="Const" version="opset1">
			<data element_type="f16" offset="1644508" shape="128,1,1,1" size="256"/>
			<output>
				<port id="0" precision="FP16">
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="3157" name="1054/fq_weights_1/minus_zp" type="Subtract" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>128</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
				<port id="1">
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>128</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</output>
		</layer>
		<layer id="3158" name="1054/fq_weights_1/scale18611_const" type="Const" version="opset1">
			<data element_type="f16" offset="1644764" shape="128,1,1,1" size="256"/>
			<output>
				<port id="0" precision="FP16">
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="3159" name="1054/fq_weights_1/mulpiply_by_scale" type="Multiply" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>128</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
				<port id="1">
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>128</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</output>
		</layer>
		<layer id="3160" name="24460/value24462_const" type="Const" version="opset1">
			<data element_type="i64" offset="957504" shape="5" size="40"/>
			<output>
				<port id="0" precision="I64">
					<dim>5</dim>
				</port>
			</output>
		</layer>
		<layer id="3161" name="24460" type="Reshape" version="opset1">
			<data special_zero="true"/>
			<input>
				<port id="0">
					<dim>128</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
				<port id="1">
					<dim>5</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</output>
		</layer>
		<layer id="3162" name="1054" type="GroupConvolution" version="opset1">
			<data auto_pad="explicit" dilations="1,1" pads_begin="1,1" pads_end="1,1" strides="1,1"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>128</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
				<port id="1">
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>1</dim>
					<dim>128</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
			</output>
		</layer>
		<layer id="3163" name="data_add_222372224222846/EltwiseUnsqueeze23730_const2308_const" type="Const" version="opset1">
			<data element_type="f16" offset="1645020" shape="1,128,1,1" size="256"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="3164" name="1055/variance/Fused_Add_" type="Add" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>128</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
				<port id="1">
					<dim>1</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" names="1055" precision="FP16">
					<dim>1</dim>
					<dim>128</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
			</output>
		</layer>
		<layer id="3165" name="1056" type="ReLU" version="opset1">
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>128</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
			</input>
			<output>
				<port id="1" names="1056" precision="FP16">
					<dim>1</dim>
					<dim>128</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
			</output>
		</layer>
		<layer id="3166" name="57575761_const" type="Const" version="opset1">
			<data element_type="f16" offset="10108" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="3167" name="57585762_const" type="Const" version="opset1">
			<data element_type="f16" offset="1645276" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="3168" name="57595763_const" type="Const" version="opset1">
			<data element_type="f16" offset="10108" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="3169" name="57605764_const" type="Const" version="opset1">
			<data element_type="f16" offset="1645276" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="3170" name="1057/fq_input_0" type="FakeQuantize" version="opset1">
			<data auto_broadcast="numpy" levels="256"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>128</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
				<port id="1"/>
				<port id="2"/>
				<port id="3"/>
				<port id="4"/>
			</input>
			<output>
				<port id="5" precision="FP16">
					<dim>1</dim>
					<dim>128</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
			</output>
		</layer>
		<layer id="3171" name="conv4.1.conv2d.3.conv1.weight/quantized19803_const" type="Const" version="opset1">
			<data element_type="i8" offset="1645278" shape="128,128,1,1" size="16384"/>
			<output>
				<port id="0" precision="I8">
					<dim>128</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="3172" name="conv4.1.conv2d.3.conv1.weight/quantized/to_f16" type="Convert" version="opset1">
			<data destination_type="f16"/>
			<input>
				<port id="0">
					<dim>128</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="1" precision="FP16">
					<dim>128</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="3173" name="1057/fq_weights_1/zero_point19816_const" type="Const" version="opset1">
			<data element_type="f16" offset="1661662" shape="128,1,1,1" size="256"/>
			<output>
				<port id="0" precision="FP16">
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="3174" name="1057/fq_weights_1/minus_zp" type="Subtract" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>128</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="1">
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>128</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="3175" name="1057/fq_weights_1/scale19811_const" type="Const" version="opset1">
			<data element_type="f16" offset="1661918" shape="128,1,1,1" size="256"/>
			<output>
				<port id="0" precision="FP16">
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="3176" name="1057/fq_weights_1/mulpiply_by_scale" type="Multiply" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>128</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="1">
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>128</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="3177" name="1057" type="Convolution" version="opset1">
			<data auto_pad="explicit" dilations="1,1" pads_begin="0,0" pads_end="0,0" strides="1,1"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>128</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
				<port id="1">
					<dim>128</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" names="1057" precision="FP16">
					<dim>1</dim>
					<dim>128</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
			</output>
		</layer>
		<layer id="3178" name="31083110_const" type="Const" version="opset1">
			<data element_type="f16" offset="955072" shape="1,128,1,1" size="256"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="3179" name="1057/add_" type="Add" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>128</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
				<port id="1">
					<dim>1</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>1</dim>
					<dim>128</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
			</output>
		</layer>
		<layer id="3180" name="66276631_const" type="Const" version="opset1">
			<data element_type="f16" offset="1662174" shape="1,128,1,1" size="256"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="3181" name="66286632_const" type="Const" version="opset1">
			<data element_type="f16" offset="1662430" shape="1,128,1,1" size="256"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="3182" name="66296633_const" type="Const" version="opset1">
			<data element_type="f16" offset="1662174" shape="1,128,1,1" size="256"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="3183" name="66306634_const" type="Const" version="opset1">
			<data element_type="f16" offset="1662430" shape="1,128,1,1" size="256"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="3184" name="1058/fq_input_0" type="FakeQuantize" version="opset1">
			<data auto_broadcast="numpy" levels="256"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>128</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
				<port id="1">
					<dim>1</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="2">
					<dim>1</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="3">
					<dim>1</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="4">
					<dim>1</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="5" precision="FP16">
					<dim>1</dim>
					<dim>128</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
			</output>
		</layer>
		<layer id="3185" name="4221542218_const231315742/quantized17571_const" type="Const" version="opset1">
			<data element_type="i8" offset="1662686" shape="128,1,3,3" size="1152"/>
			<output>
				<port id="0" precision="I8">
					<dim>128</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</output>
		</layer>
		<layer id="3186" name="4221542218_const231315742/quantized/to_f16" type="Convert" version="opset1">
			<data destination_type="f16"/>
			<input>
				<port id="0">
					<dim>128</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</input>
			<output>
				<port id="1" precision="FP16">
					<dim>128</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</output>
		</layer>
		<layer id="3187" name="1058/fq_weights_1/zero_point17584_const" type="Const" version="opset1">
			<data element_type="f16" offset="1663838" shape="128,1,1,1" size="256"/>
			<output>
				<port id="0" precision="FP16">
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="3188" name="1058/fq_weights_1/minus_zp" type="Subtract" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>128</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
				<port id="1">
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>128</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</output>
		</layer>
		<layer id="3189" name="1058/fq_weights_1/scale17579_const" type="Const" version="opset1">
			<data element_type="f16" offset="1664094" shape="128,1,1,1" size="256"/>
			<output>
				<port id="0" precision="FP16">
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="3190" name="1058/fq_weights_1/mulpiply_by_scale" type="Multiply" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>128</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
				<port id="1">
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>128</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</output>
		</layer>
		<layer id="3191" name="24480/value24482_const" type="Const" version="opset1">
			<data element_type="i64" offset="957504" shape="5" size="40"/>
			<output>
				<port id="0" precision="I64">
					<dim>5</dim>
				</port>
			</output>
		</layer>
		<layer id="3192" name="24480" type="Reshape" version="opset1">
			<data special_zero="true"/>
			<input>
				<port id="0">
					<dim>128</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
				<port id="1">
					<dim>5</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</output>
		</layer>
		<layer id="3193" name="1058" type="GroupConvolution" version="opset1">
			<data auto_pad="explicit" dilations="1,1" pads_begin="1,1" pads_end="1,1" strides="1,1"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>128</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
				<port id="1">
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>3</dim>
					<dim>3</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>1</dim>
					<dim>128</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
			</output>
		</layer>
		<layer id="3194" name="data_add_222452225022848/EltwiseUnsqueeze23738_const2315_const" type="Const" version="opset1">
			<data element_type="f16" offset="1664350" shape="1,128,1,1" size="256"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="3195" name="1059/variance/Fused_Add_" type="Add" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>128</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
				<port id="1">
					<dim>1</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" names="1059" precision="FP16">
					<dim>1</dim>
					<dim>128</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
			</output>
		</layer>
		<layer id="3196" name="1060" type="ReLU" version="opset1">
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>128</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
			</input>
			<output>
				<port id="1" names="1060" precision="FP16">
					<dim>1</dim>
					<dim>128</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
			</output>
		</layer>
		<layer id="3197" name="50475051_const" type="Const" version="opset1">
			<data element_type="f16" offset="10108" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="3198" name="50485052_const" type="Const" version="opset1">
			<data element_type="f16" offset="1664606" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="3199" name="50495053_const" type="Const" version="opset1">
			<data element_type="f16" offset="10108" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="3200" name="50505054_const" type="Const" version="opset1">
			<data element_type="f16" offset="1664606" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="3201" name="1105/reduce/fq_input_0" type="FakeQuantize" version="opset1">
			<data auto_broadcast="numpy" levels="256"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>128</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
				<port id="1"/>
				<port id="2"/>
				<port id="3"/>
				<port id="4"/>
			</input>
			<output>
				<port id="5" precision="FP16">
					<dim>1</dim>
					<dim>128</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
			</output>
		</layer>
		<layer id="3202" name="1439/Output_0/Data__const2318_const" type="Const" version="opset1">
			<data element_type="i64" offset="24" shape="" size="8"/>
			<output>
				<port id="0" precision="I64"/>
			</output>
		</layer>
		<layer id="3203" name="1105/input_rank/shape_of" type="ShapeOf" version="opset3">
			<data output_type="i64"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>128</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
			</input>
			<output>
				<port id="1" precision="I64">
					<dim>4</dim>
				</port>
			</output>
		</layer>
		<layer id="3204" name="1105/input_rank/rank_of" type="ShapeOf" version="opset3">
			<data output_type="i64"/>
			<input>
				<port id="0">
					<dim>4</dim>
				</port>
			</input>
			<output>
				<port id="1" precision="I64">
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="3205" name="1105/input_rank/0d_rank_of/value/Output_0/Data__const2321_const" type="Const" version="opset1">
			<data element_type="i64" offset="32" shape="1" size="8"/>
			<output>
				<port id="0" precision="I64">
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="3206" name="1105/input_rank" type="Squeeze" version="opset1">
			<input>
				<port id="0">
					<dim>1</dim>
				</port>
				<port id="1">
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="I64"/>
			</output>
		</layer>
		<layer id="3207" name="1441/Output_0/Data__const2323_const" type="Const" version="opset1">
			<data element_type="i64" offset="0" shape="" size="8"/>
			<output>
				<port id="0" precision="I64"/>
			</output>
		</layer>
		<layer id="3208" name="1105/global_pooling_reduce_axis" type="Range" version="opset4">
			<data output_type="i64"/>
			<input>
				<port id="0"/>
				<port id="1"/>
				<port id="2"/>
			</input>
			<output>
				<port id="3" precision="I64">
					<dim>2</dim>
				</port>
			</output>
		</layer>
		<layer id="3209" name="1105/reduce" type="ReduceMean" version="opset1">
			<data keep_dims="true"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>128</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
				<port id="1">
					<dim>2</dim>
				</port>
			</input>
			<output>
				<port id="2" names="1105" precision="FP16">
					<dim>1</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="3210" name="1078810792_const" type="Const" version="opset1">
			<data element_type="f16" offset="10108" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="3211" name="1078910793_const" type="Const" version="opset1">
			<data element_type="f16" offset="1664608" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="3212" name="1079010794_const" type="Const" version="opset1">
			<data element_type="f16" offset="10108" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="3213" name="1079110795_const" type="Const" version="opset1">
			<data element_type="f16" offset="1664608" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="3214" name="1107/fq_input_0" type="FakeQuantize" version="opset1">
			<data auto_broadcast="numpy" levels="256"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="1"/>
				<port id="2"/>
				<port id="3"/>
				<port id="4"/>
			</input>
			<output>
				<port id="5" precision="FP16">
					<dim>1</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="3215" name="1107/Cast_143252_const2326_const" type="Const" version="opset1">
			<data element_type="i64" offset="129708" shape="3" size="24"/>
			<output>
				<port id="0" names="1106" precision="I64">
					<dim>3</dim>
				</port>
			</output>
		</layer>
		<layer id="3216" name="1107" type="Reshape" version="opset1">
			<data special_zero="true"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="1">
					<dim>3</dim>
				</port>
			</input>
			<output>
				<port id="2" names="1107" precision="FP16">
					<dim>1</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
			</output>
		</layer>
		<layer id="3217" name="1110/Range_input_port_0/value/Output_0/Data__const2328_const" type="Const" version="opset1">
			<data element_type="i64" offset="24" shape="" size="8"/>
			<output>
				<port id="0" precision="I64"/>
			</output>
		</layer>
		<layer id="3218" name="1110/Rank/shape_of" type="ShapeOf" version="opset3">
			<data output_type="i64"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
			</input>
			<output>
				<port id="1" precision="I64">
					<dim>3</dim>
				</port>
			</output>
		</layer>
		<layer id="3219" name="1110/Rank/rank_of" type="ShapeOf" version="opset3">
			<data output_type="i64"/>
			<input>
				<port id="0">
					<dim>3</dim>
				</port>
			</input>
			<output>
				<port id="1" precision="I64">
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="3220" name="1110/Rank/0d_rank_of/value/Output_0/Data__const2331_const" type="Const" version="opset1">
			<data element_type="i64" offset="32" shape="1" size="8"/>
			<output>
				<port id="0" precision="I64">
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="3221" name="1110/Rank" type="Squeeze" version="opset1">
			<input>
				<port id="0">
					<dim>1</dim>
				</port>
				<port id="1">
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="I64"/>
			</output>
		</layer>
		<layer id="3222" name="1110/Range_input_port_2/value/Output_0/Data__const2333_const" type="Const" version="opset1">
			<data element_type="i64" offset="0" shape="" size="8"/>
			<output>
				<port id="0" precision="I64"/>
			</output>
		</layer>
		<layer id="3223" name="1110/Range" type="Range" version="opset4">
			<data output_type="i64"/>
			<input>
				<port id="0"/>
				<port id="1"/>
				<port id="2"/>
			</input>
			<output>
				<port id="3" precision="I64">
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="3224" name="1110/Ins_Norm/MVN_" type="MVN" version="opset6">
			<data eps="9.999999747378752e-06" eps_mode="inside_sqrt" normalize_variance="true"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
				<port id="1">
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>1</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
			</output>
		</layer>
		<layer id="3225" name="1108/EltwiseUnsqueeze22990_const2336_const" type="Const" version="opset1">
			<data element_type="f16" offset="129732" shape="1,16,1" size="32"/>
			<output>
				<port id="0" names="1108" precision="FP16">
					<dim>1</dim>
					<dim>16</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="3226" name="1110/Ins_Norm/mul_" type="Multiply" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
				<port id="1">
					<dim>1</dim>
					<dim>16</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>1</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
			</output>
		</layer>
		<layer id="3227" name="1109/EltwiseUnsqueeze22994_const2338_const" type="Const" version="opset1">
			<data element_type="f16" offset="129764" shape="1,16,1" size="32"/>
			<output>
				<port id="0" names="1109" precision="FP16">
					<dim>1</dim>
					<dim>16</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="3228" name="1110" type="Add" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
				<port id="1">
					<dim>1</dim>
					<dim>16</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" names="1110" precision="FP16">
					<dim>1</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
			</output>
		</layer>
		<layer id="3229" name="1079810802_const" type="Const" version="opset1">
			<data element_type="f16" offset="1664610" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="3230" name="1079910803_const" type="Const" version="opset1">
			<data element_type="f16" offset="1664612" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="3231" name="1080010804_const" type="Const" version="opset1">
			<data element_type="f16" offset="1664610" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="3232" name="1080110805_const" type="Const" version="opset1">
			<data element_type="f16" offset="1664612" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="3233" name="1112/fq_input_0" type="FakeQuantize" version="opset1">
			<data auto_broadcast="numpy" levels="256"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
				<port id="1"/>
				<port id="2"/>
				<port id="3"/>
				<port id="4"/>
			</input>
			<output>
				<port id="5" precision="FP16">
					<dim>1</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
			</output>
		</layer>
		<layer id="3234" name="1111" type="ShapeOf" version="opset3">
			<data output_type="i64"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="1" names="1111" precision="I64">
					<dim>4</dim>
				</port>
			</output>
		</layer>
		<layer id="3235" name="1112" type="Reshape" version="opset1">
			<data special_zero="true"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
				<port id="1">
					<dim>4</dim>
				</port>
			</input>
			<output>
				<port id="2" names="1112" precision="FP16">
					<dim>1</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="3236" name="1113/Unsqueeze/EltwiseUnsqueeze22958_const2342_const" type="Const" version="opset1">
			<data element_type="f16" offset="1490100" shape="1,128,1,1" size="256"/>
			<output>
				<port id="0" names="1113" precision="FP16">
					<dim>1</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="3237" name="1114" type="Multiply" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="1">
					<dim>1</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" names="1114" precision="FP16">
					<dim>1</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="3238" name="1115/Unsqueeze/EltwiseUnsqueeze22962_const2344_const" type="Const" version="opset1">
			<data element_type="f16" offset="1490356" shape="1,128,1,1" size="256"/>
			<output>
				<port id="0" names="1115" precision="FP16">
					<dim>1</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="3239" name="1116" type="Add" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="1">
					<dim>1</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" names="1116" precision="FP16">
					<dim>1</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="3240" name="1117" type="Sigmoid" version="opset1">
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="1" names="1117" precision="FP16">
					<dim>1</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="3241" name="66776681_const" type="Const" version="opset1">
			<data element_type="f16" offset="10108" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="3242" name="66786682_const" type="Const" version="opset1">
			<data element_type="f16" offset="1664614" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="3243" name="66796683_const" type="Const" version="opset1">
			<data element_type="f16" offset="10108" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="3244" name="66806684_const" type="Const" version="opset1">
			<data element_type="f16" offset="1664614" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="3245" name="1118/fq_input_1" type="FakeQuantize" version="opset1">
			<data auto_broadcast="numpy" levels="256"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="1"/>
				<port id="2"/>
				<port id="3"/>
				<port id="4"/>
			</input>
			<output>
				<port id="5" precision="FP16">
					<dim>1</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="3246" name="1118" type="Multiply" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>128</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
				<port id="1">
					<dim>1</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" names="1118" precision="FP16">
					<dim>1</dim>
					<dim>128</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
			</output>
		</layer>
		<layer id="3247" name="57175721_const" type="Const" version="opset1">
			<data element_type="f16" offset="10108" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="3248" name="57185722_const" type="Const" version="opset1">
			<data element_type="f16" offset="1664616" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="3249" name="57195723_const" type="Const" version="opset1">
			<data element_type="f16" offset="10108" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="3250" name="57205724_const" type="Const" version="opset1">
			<data element_type="f16" offset="1664616" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="3251" name="1119/fq_input_1" type="FakeQuantize" version="opset1">
			<data auto_broadcast="numpy" levels="256"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>128</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
				<port id="1"/>
				<port id="2"/>
				<port id="3"/>
				<port id="4"/>
			</input>
			<output>
				<port id="5" precision="FP16">
					<dim>1</dim>
					<dim>128</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
			</output>
		</layer>
		<layer id="3252" name="1119" type="Add" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>128</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
				<port id="1">
					<dim>1</dim>
					<dim>128</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
			</input>
			<output>
				<port id="2" names="1119" precision="FP16">
					<dim>1</dim>
					<dim>128</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
			</output>
		</layer>
		<layer id="3253" name="49174921_const" type="Const" version="opset1">
			<data element_type="f16" offset="10108" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="3254" name="49184922_const" type="Const" version="opset1">
			<data element_type="f16" offset="1664618" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="3255" name="49194923_const" type="Const" version="opset1">
			<data element_type="f16" offset="10108" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="3256" name="49204924_const" type="Const" version="opset1">
			<data element_type="f16" offset="1664618" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="3257" name="1120/fq_input_0" type="FakeQuantize" version="opset1">
			<data auto_broadcast="numpy" levels="256"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>128</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
				<port id="1"/>
				<port id="2"/>
				<port id="3"/>
				<port id="4"/>
			</input>
			<output>
				<port id="5" precision="FP16">
					<dim>1</dim>
					<dim>128</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
			</output>
		</layer>
		<layer id="3258" name="1121/mean/Fused_Mul_2465924661_const234915755/quantized17907_const" type="Const" version="opset1">
			<data element_type="i8" offset="1664620" shape="512,128,1,1" size="65536"/>
			<output>
				<port id="0" precision="I8">
					<dim>512</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="3259" name="1121/mean/Fused_Mul_2465924661_const234915755/quantized/to_f16" type="Convert" version="opset1">
			<data destination_type="f16"/>
			<input>
				<port id="0">
					<dim>512</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="1" precision="FP16">
					<dim>512</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="3260" name="1120/fq_weights_1/zero_point17920_const" type="Const" version="opset1">
			<data element_type="f16" offset="1730156" shape="512,1,1,1" size="1024"/>
			<output>
				<port id="0" precision="FP16">
					<dim>512</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="3261" name="1120/fq_weights_1/minus_zp" type="Subtract" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>512</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="1">
					<dim>512</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>512</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="3262" name="1120/fq_weights_1/scale17915_const" type="Const" version="opset1">
			<data element_type="f16" offset="1731180" shape="512,1,1,1" size="1024"/>
			<output>
				<port id="0" precision="FP16">
					<dim>512</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="3263" name="1120/fq_weights_1/mulpiply_by_scale" type="Multiply" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>512</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="1">
					<dim>512</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>512</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="3264" name="1120" type="Convolution" version="opset1">
			<data auto_pad="explicit" dilations="1,1" pads_begin="0,0" pads_end="0,0" strides="1,1"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>128</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
				<port id="1">
					<dim>512</dim>
					<dim>128</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>1</dim>
					<dim>512</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
			</output>
		</layer>
		<layer id="3265" name="data_add_223012230622862/EltwiseUnsqueeze23794_const2351_const" type="Const" version="opset1">
			<data element_type="f16" offset="1732204" shape="1,512,1,1" size="1024"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>512</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="3266" name="1121/variance/Fused_Add_" type="Add" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>512</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
				<port id="1">
					<dim>1</dim>
					<dim>512</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" names="1121" precision="FP16">
					<dim>1</dim>
					<dim>512</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
			</output>
		</layer>
		<layer id="3267" name="80278031_const" type="Const" version="opset1">
			<data element_type="f16" offset="1733228" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="3268" name="80288032_const" type="Const" version="opset1">
			<data element_type="f16" offset="1733230" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="3269" name="80298033_const" type="Const" version="opset1">
			<data element_type="f16" offset="1733228" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="3270" name="80308034_const" type="Const" version="opset1">
			<data element_type="f16" offset="1733230" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="3271" name="1122/fq_input_0" type="FakeQuantize" version="opset1">
			<data auto_broadcast="numpy" levels="256"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>512</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
				<port id="1"/>
				<port id="2"/>
				<port id="3"/>
				<port id="4"/>
			</input>
			<output>
				<port id="5" precision="FP16">
					<dim>1</dim>
					<dim>512</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
			</output>
		</layer>
		<layer id="3272" name="1122" type="Add" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>512</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
				<port id="1">
					<dim>1</dim>
					<dim>512</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
			</input>
			<output>
				<port id="2" names="1122" precision="FP16">
					<dim>1</dim>
					<dim>512</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
			</output>
		</layer>
		<layer id="3273" name="1123" type="ReLU" version="opset1">
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>512</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
			</input>
			<output>
				<port id="1" names="1123" precision="FP16">
					<dim>1</dim>
					<dim>512</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
			</output>
		</layer>
		<layer id="3274" name="73877391_const" type="Const" version="opset1">
			<data element_type="f16" offset="10108" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="3275" name="73887392_const" type="Const" version="opset1">
			<data element_type="f16" offset="1733232" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="3276" name="73897393_const" type="Const" version="opset1">
			<data element_type="f16" offset="10108" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="3277" name="73907394_const" type="Const" version="opset1">
			<data element_type="f16" offset="1733232" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="3278" name="1124/fq_input_0" type="FakeQuantize" version="opset1">
			<data auto_broadcast="numpy" levels="256"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>512</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
				<port id="1"/>
				<port id="2"/>
				<port id="3"/>
				<port id="4"/>
			</input>
			<output>
				<port id="5" precision="FP16">
					<dim>1</dim>
					<dim>512</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
			</output>
		</layer>
		<layer id="3279" name="1125/mean/Fused_Mul_2466324665_const235515757/quantized20307_const" type="Const" version="opset1">
			<data element_type="i8" offset="1733234" shape="512,512,1,1" size="262144"/>
			<output>
				<port id="0" precision="I8">
					<dim>512</dim>
					<dim>512</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="3280" name="1125/mean/Fused_Mul_2466324665_const235515757/quantized/to_f16" type="Convert" version="opset1">
			<data destination_type="f16"/>
			<input>
				<port id="0">
					<dim>512</dim>
					<dim>512</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="1" precision="FP16">
					<dim>512</dim>
					<dim>512</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="3281" name="1124/fq_weights_1/zero_point20320_const" type="Const" version="opset1">
			<data element_type="f16" offset="1995378" shape="512,1,1,1" size="1024"/>
			<output>
				<port id="0" precision="FP16">
					<dim>512</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="3282" name="1124/fq_weights_1/minus_zp" type="Subtract" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>512</dim>
					<dim>512</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="1">
					<dim>512</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>512</dim>
					<dim>512</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="3283" name="1124/fq_weights_1/scale20315_const" type="Const" version="opset1">
			<data element_type="f16" offset="1996402" shape="512,1,1,1" size="1024"/>
			<output>
				<port id="0" precision="FP16">
					<dim>512</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="3284" name="1124/fq_weights_1/mulpiply_by_scale" type="Multiply" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>512</dim>
					<dim>512</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="1">
					<dim>512</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>512</dim>
					<dim>512</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="3285" name="1124" type="Convolution" version="opset1">
			<data auto_pad="explicit" dilations="1,1" pads_begin="0,0" pads_end="0,0" strides="1,1"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>512</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
				<port id="1">
					<dim>512</dim>
					<dim>512</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>1</dim>
					<dim>512</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
			</output>
		</layer>
		<layer id="3286" name="data_add_223092231422864/EltwiseUnsqueeze23802_const2357_const" type="Const" version="opset1">
			<data element_type="f16" offset="1997426" shape="1,512,1,1" size="1024"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>512</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="3287" name="1125/variance/Fused_Add_" type="Add" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>512</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
				<port id="1">
					<dim>1</dim>
					<dim>512</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" names="1125" precision="FP16">
					<dim>1</dim>
					<dim>512</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
			</output>
		</layer>
		<layer id="3288" name="1126" type="ReLU" version="opset1">
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>512</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
			</input>
			<output>
				<port id="1" names="1126" precision="FP16">
					<dim>1</dim>
					<dim>512</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
			</output>
		</layer>
		<layer id="3289" name="42874291_const" type="Const" version="opset1">
			<data element_type="f16" offset="1998450" shape="1,512,1,1" size="1024"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>512</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="3290" name="42884292_const" type="Const" version="opset1">
			<data element_type="f16" offset="1999474" shape="1,512,1,1" size="1024"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>512</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="3291" name="42894293_const" type="Const" version="opset1">
			<data element_type="f16" offset="1998450" shape="1,512,1,1" size="1024"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>512</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="3292" name="42904294_const" type="Const" version="opset1">
			<data element_type="f16" offset="1999474" shape="1,512,1,1" size="1024"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>512</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="3293" name="1127/WithoutBiases/fq_input_0" type="FakeQuantize" version="opset1">
			<data auto_broadcast="numpy" levels="256"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>512</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
				<port id="1">
					<dim>1</dim>
					<dim>512</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="2">
					<dim>1</dim>
					<dim>512</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="3">
					<dim>1</dim>
					<dim>512</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="4">
					<dim>1</dim>
					<dim>512</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="5" precision="FP16">
					<dim>1</dim>
					<dim>512</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
			</output>
		</layer>
		<layer id="3294" name="4206742070_const236015759/quantized19947_const" type="Const" version="opset1">
			<data element_type="i8" offset="2000498" shape="512,1,16,8" size="65536"/>
			<output>
				<port id="0" precision="I8">
					<dim>512</dim>
					<dim>1</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
			</output>
		</layer>
		<layer id="3295" name="4206742070_const236015759/quantized/to_f16" type="Convert" version="opset1">
			<data destination_type="f16"/>
			<input>
				<port id="0">
					<dim>512</dim>
					<dim>1</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
			</input>
			<output>
				<port id="1" precision="FP16">
					<dim>512</dim>
					<dim>1</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
			</output>
		</layer>
		<layer id="3296" name="1127/WithoutBiases/fq_weights_1/zero_point19960_const" type="Const" version="opset1">
			<data element_type="f16" offset="2066034" shape="512,1,1,1" size="1024"/>
			<output>
				<port id="0" precision="FP16">
					<dim>512</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="3297" name="1127/WithoutBiases/fq_weights_1/minus_zp" type="Subtract" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>512</dim>
					<dim>1</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
				<port id="1">
					<dim>512</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>512</dim>
					<dim>1</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
			</output>
		</layer>
		<layer id="3298" name="1127/WithoutBiases/fq_weights_1/scale19955_const" type="Const" version="opset1">
			<data element_type="f16" offset="2067058" shape="512,1,1,1" size="1024"/>
			<output>
				<port id="0" precision="FP16">
					<dim>512</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="3299" name="1127/WithoutBiases/fq_weights_1/mulpiply_by_scale" type="Multiply" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>512</dim>
					<dim>1</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
				<port id="1">
					<dim>512</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>512</dim>
					<dim>1</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
			</output>
		</layer>
		<layer id="3300" name="24372/value24374_const" type="Const" version="opset1">
			<data element_type="i64" offset="2068082" shape="5" size="40"/>
			<output>
				<port id="0" precision="I64">
					<dim>5</dim>
				</port>
			</output>
		</layer>
		<layer id="3301" name="24372" type="Reshape" version="opset1">
			<data special_zero="true"/>
			<input>
				<port id="0">
					<dim>512</dim>
					<dim>1</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
				<port id="1">
					<dim>5</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>512</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
			</output>
		</layer>
		<layer id="3302" name="1127/WithoutBiases" type="GroupConvolution" version="opset1">
			<data auto_pad="explicit" dilations="1,1" pads_begin="0,0" pads_end="0,0" strides="1,1"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>512</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
				<port id="1">
					<dim>512</dim>
					<dim>1</dim>
					<dim>1</dim>
					<dim>16</dim>
					<dim>8</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>1</dim>
					<dim>512</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="3303" name="1127/Dims1289222684/EltwiseUnsqueeze23090_const2362_const" type="Const" version="opset1">
			<data element_type="f16" offset="2068122" shape="1,512,1,1" size="1024"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>512</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="3304" name="1127" type="Add" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>512</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="1">
					<dim>1</dim>
					<dim>512</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" names="1127" precision="FP16">
					<dim>1</dim>
					<dim>512</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="3305" name="1080810812_const" type="Const" version="opset1">
			<data element_type="f16" offset="2069146" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="3306" name="1080910813_const" type="Const" version="opset1">
			<data element_type="f16" offset="2069148" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="3307" name="1081010814_const" type="Const" version="opset1">
			<data element_type="f16" offset="2069146" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="3308" name="1081110815_const" type="Const" version="opset1">
			<data element_type="f16" offset="2069148" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="3309" name="1135/fq_input_0" type="FakeQuantize" version="opset1">
			<data auto_broadcast="numpy" levels="256"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>512</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="1"/>
				<port id="2"/>
				<port id="3"/>
				<port id="4"/>
			</input>
			<output>
				<port id="5" precision="FP16">
					<dim>1</dim>
					<dim>512</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="3310" name="1128" type="ShapeOf" version="opset3">
			<data output_type="i64"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>512</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="1" names="1128" precision="I64">
					<dim>4</dim>
				</port>
			</output>
		</layer>
		<layer id="3311" name="11301607/Cast_122548_const" type="Const" version="opset1">
			<data element_type="i32" offset="2069150" shape="" size="4"/>
			<output>
				<port id="0" names="1129" precision="I32"/>
			</output>
		</layer>
		<layer id="3312" name="11301607/Cast_222550_const" type="Const" version="opset1">
			<data element_type="i64" offset="32" shape="" size="8"/>
			<output>
				<port id="0" precision="I64"/>
			</output>
		</layer>
		<layer id="3313" name="11301607" type="Gather" version="opset1">
			<input>
				<port id="0">
					<dim>4</dim>
				</port>
				<port id="1"/>
				<port id="2"/>
			</input>
			<output>
				<port id="3" names="1130" precision="I64"/>
			</output>
		</layer>
		<layer id="3314" name="1132/Dims/Output_0/Data__const2368_const" type="Const" version="opset1">
			<data element_type="i64" offset="32" shape="1" size="8"/>
			<output>
				<port id="0" precision="I64">
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="3315" name="1132/Unsqueeze" type="Unsqueeze" version="opset1">
			<input>
				<port id="0"/>
				<port id="1">
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" names="1132" precision="I64">
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="3316" name="1133/Unsqueeze/Output_0/Data__const2370_const" type="Const" version="opset1">
			<data element_type="i64" offset="2069154" shape="1" size="8"/>
			<output>
				<port id="0" names="1133" precision="I64">
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="3317" name="1134" type="Concat" version="opset1">
			<data axis="0"/>
			<input>
				<port id="0">
					<dim>1</dim>
				</port>
				<port id="1">
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" names="1134" precision="I64">
					<dim>2</dim>
				</port>
			</output>
		</layer>
		<layer id="3318" name="1135" type="Reshape" version="opset1">
			<data special_zero="true"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>512</dim>
					<dim>1</dim>
					<dim>1</dim>
				</port>
				<port id="1">
					<dim>2</dim>
				</port>
			</input>
			<output>
				<port id="2" names="1135" precision="FP16">
					<dim>1</dim>
					<dim>512</dim>
				</port>
			</output>
		</layer>
		<layer id="3319" name="fc.0.weight/quantized18531_const" type="Const" version="opset1">
			<data element_type="i8" offset="2069162" shape="256,512" size="131072"/>
			<output>
				<port id="0" precision="I8">
					<dim>256</dim>
					<dim>512</dim>
				</port>
			</output>
		</layer>
		<layer id="3320" name="fc.0.weight/quantized/to_f16" type="Convert" version="opset1">
			<data destination_type="f16"/>
			<input>
				<port id="0">
					<dim>256</dim>
					<dim>512</dim>
				</port>
			</input>
			<output>
				<port id="1" precision="FP16">
					<dim>256</dim>
					<dim>512</dim>
				</port>
			</output>
		</layer>
		<layer id="3321" name="1136/WithoutBiases/fq_weights_1/zero_point18544_const" type="Const" version="opset1">
			<data element_type="f16" offset="2200234" shape="256,1" size="512"/>
			<output>
				<port id="0" precision="FP16">
					<dim>256</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="3322" name="1136/WithoutBiases/fq_weights_1/minus_zp" type="Subtract" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>256</dim>
					<dim>512</dim>
				</port>
				<port id="1">
					<dim>256</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>256</dim>
					<dim>512</dim>
				</port>
			</output>
		</layer>
		<layer id="3323" name="1136/WithoutBiases/fq_weights_1/scale18539_const" type="Const" version="opset1">
			<data element_type="f16" offset="2200746" shape="256,1" size="512"/>
			<output>
				<port id="0" precision="FP16">
					<dim>256</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="3324" name="1136/WithoutBiases/fq_weights_1/mulpiply_by_scale" type="Multiply" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>256</dim>
					<dim>512</dim>
				</port>
				<port id="1">
					<dim>256</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>256</dim>
					<dim>512</dim>
				</port>
			</output>
		</layer>
		<layer id="3325" name="1136/WithoutBiases" type="MatMul" version="opset1">
			<data transpose_a="false" transpose_b="true"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>512</dim>
				</port>
				<port id="1">
					<dim>256</dim>
					<dim>512</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>1</dim>
					<dim>256</dim>
				</port>
			</output>
		</layer>
		<layer id="3326" name="fc.0.bias/EltwiseUnsqueeze23078_const2375_const" type="Const" version="opset1">
			<data element_type="f16" offset="2201258" shape="1,256" size="512"/>
			<output>
				<port id="0" names="fc.0.bias" precision="FP16">
					<dim>1</dim>
					<dim>256</dim>
				</port>
			</output>
		</layer>
		<layer id="3327" name="1136" type="Add" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>256</dim>
				</port>
				<port id="1">
					<dim>1</dim>
					<dim>256</dim>
				</port>
			</input>
			<output>
				<port id="2" names="1136" precision="FP16">
					<dim>1</dim>
					<dim>256</dim>
				</port>
			</output>
		</layer>
		<layer id="3328" name="1081810822_const" type="Const" version="opset1">
			<data element_type="f16" offset="2201770" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="3329" name="1081910823_const" type="Const" version="opset1">
			<data element_type="f16" offset="2201772" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="3330" name="1082010824_const" type="Const" version="opset1">
			<data element_type="f16" offset="2201770" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="3331" name="1082110825_const" type="Const" version="opset1">
			<data element_type="f16" offset="2201772" shape="" size="2"/>
			<output>
				<port id="0" precision="FP16"/>
			</output>
		</layer>
		<layer id="3332" name="1146/fq_input_0" type="FakeQuantize" version="opset1">
			<data auto_broadcast="numpy" levels="256"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>256</dim>
				</port>
				<port id="1"/>
				<port id="2"/>
				<port id="3"/>
				<port id="4"/>
			</input>
			<output>
				<port id="5" precision="FP16">
					<dim>1</dim>
					<dim>256</dim>
				</port>
			</output>
		</layer>
		<layer id="3333" name="1137" type="ShapeOf" version="opset3">
			<data output_type="i64"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>512</dim>
				</port>
			</input>
			<output>
				<port id="1" names="1137" precision="I64">
					<dim>2</dim>
				</port>
			</output>
		</layer>
		<layer id="3334" name="11391609/Cast_122580_const" type="Const" version="opset1">
			<data element_type="i32" offset="2069150" shape="" size="4"/>
			<output>
				<port id="0" names="1138" precision="I32"/>
			</output>
		</layer>
		<layer id="3335" name="11391609/Cast_222582_const" type="Const" version="opset1">
			<data element_type="i64" offset="32" shape="" size="8"/>
			<output>
				<port id="0" precision="I64"/>
			</output>
		</layer>
		<layer id="3336" name="11391609" type="Gather" version="opset1">
			<input>
				<port id="0">
					<dim>2</dim>
				</port>
				<port id="1"/>
				<port id="2"/>
			</input>
			<output>
				<port id="3" names="1139" precision="I64"/>
			</output>
		</layer>
		<layer id="3337" name="1142/Dims/Output_0/Data__const2381_const" type="Const" version="opset1">
			<data element_type="i64" offset="32" shape="1" size="8"/>
			<output>
				<port id="0" precision="I64">
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="3338" name="1142/Unsqueeze" type="Unsqueeze" version="opset1">
			<input>
				<port id="0"/>
				<port id="1">
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" names="1142" precision="I64">
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="3339" name="1143/Unsqueeze/Output_0/Data__const2383_const" type="Const" version="opset1">
			<data element_type="i64" offset="2069154" shape="1" size="8"/>
			<output>
				<port id="0" names="1143" precision="I64">
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="3340" name="1144/Unsqueeze/Output_0/Data__const2384_const" type="Const" version="opset1">
			<data element_type="i64" offset="0" shape="1" size="8"/>
			<output>
				<port id="0" names="1144" precision="I64">
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="3341" name="1145" type="Concat" version="opset1">
			<data axis="0"/>
			<input>
				<port id="0">
					<dim>1</dim>
				</port>
				<port id="1">
					<dim>1</dim>
				</port>
				<port id="2">
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="3" names="1145" precision="I64">
					<dim>3</dim>
				</port>
			</output>
		</layer>
		<layer id="3342" name="1146" type="Reshape" version="opset1">
			<data special_zero="true"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>256</dim>
				</port>
				<port id="1">
					<dim>3</dim>
				</port>
			</input>
			<output>
				<port id="2" names="1146" precision="FP16">
					<dim>1</dim>
					<dim>256</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="3343" name="data_mul_223162232022865/EltwiseUnsqueeze23806_const2387_const" type="Const" version="opset1">
			<data element_type="f16" offset="2201774" shape="1,256,1" size="512"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>256</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="3344" name="1147/mean/Fused_Mul_" type="Multiply" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>256</dim>
					<dim>1</dim>
				</port>
				<port id="1">
					<dim>1</dim>
					<dim>256</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP16">
					<dim>1</dim>
					<dim>256</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="3345" name="data_add_223172232222866/EltwiseUnsqueeze23810_const2389_const" type="Const" version="opset1">
			<data element_type="f16" offset="2202286" shape="1,256,1" size="512"/>
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>256</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="3346" name="1147/variance/Fused_Add_" type="Add" version="opset1">
			<data auto_broadcast="numpy"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>256</dim>
					<dim>1</dim>
				</port>
				<port id="1">
					<dim>1</dim>
					<dim>256</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" names="1147" precision="FP16">
					<dim>1</dim>
					<dim>256</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="3347" name="1149/Cast_122562_const" type="Const" version="opset1">
			<data element_type="f32" offset="2202798" shape="1,1" size="4"/>
			<output>
				<port id="0" names="1148" precision="FP32">
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="3348" name="1149" type="PReLU" version="opset1">
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>256</dim>
					<dim>1</dim>
				</port>
				<port id="1">
					<dim>1</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" names="1149" precision="FP16">
					<dim>1</dim>
					<dim>256</dim>
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="3349" name="1150" type="ShapeOf" version="opset3">
			<data output_type="i64"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>256</dim>
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="1" names="1150" precision="I64">
					<dim>3</dim>
				</port>
			</output>
		</layer>
		<layer id="3350" name="11521605/Cast_122540_const" type="Const" version="opset1">
			<data element_type="i32" offset="2069150" shape="" size="4"/>
			<output>
				<port id="0" names="1151" precision="I32"/>
			</output>
		</layer>
		<layer id="3351" name="11521605/Cast_222542_const" type="Const" version="opset1">
			<data element_type="i64" offset="32" shape="" size="8"/>
			<output>
				<port id="0" precision="I64"/>
			</output>
		</layer>
		<layer id="3352" name="11521605" type="Gather" version="opset1">
			<input>
				<port id="0">
					<dim>3</dim>
				</port>
				<port id="1"/>
				<port id="2"/>
			</input>
			<output>
				<port id="3" names="1152" precision="I64"/>
			</output>
		</layer>
		<layer id="3353" name="1154/Dims/Output_0/Data__const2397_const" type="Const" version="opset1">
			<data element_type="i64" offset="32" shape="1" size="8"/>
			<output>
				<port id="0" precision="I64">
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="3354" name="1154/Unsqueeze" type="Unsqueeze" version="opset1">
			<input>
				<port id="0"/>
				<port id="1">
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" names="1154" precision="I64">
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="3355" name="1155/Unsqueeze/Output_0/Data__const2399_const" type="Const" version="opset1">
			<data element_type="i64" offset="2069154" shape="1" size="8"/>
			<output>
				<port id="0" names="1155" precision="I64">
					<dim>1</dim>
				</port>
			</output>
		</layer>
		<layer id="3356" name="1156" type="Concat" version="opset1">
			<data axis="0"/>
			<input>
				<port id="0">
					<dim>1</dim>
				</port>
				<port id="1">
					<dim>1</dim>
				</port>
			</input>
			<output>
				<port id="2" names="1156" precision="I64">
					<dim>2</dim>
				</port>
			</output>
		</layer>
		<layer id="3357" name="reid_embedding" type="Reshape" version="opset1">
			<data special_zero="true"/>
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>256</dim>
					<dim>1</dim>
				</port>
				<port id="1">
					<dim>2</dim>
				</port>
			</input>
			<output>
				<port id="2" names="reid_embedding" precision="FP16">
					<dim>1</dim>
					<dim>256</dim>
				</port>
			</output>
		</layer>
		<layer id="3358" name="reid_embedding/sink_port_0" type="Result" version="opset1">
			<input>
				<port id="0">
					<dim>1</dim>
					<dim>256</dim>
				</port>
			</input>
		</layer>
	</layers>
	<edges>
		<edge from-layer="0" from-port="0" to-layer="2" to-port="0"/>
		<edge from-layer="1" from-port="0" to-layer="2" to-port="1"/>
		<edge from-layer="2" from-port="4" to-layer="3" to-port="0"/>
		<edge from-layer="2" from-port="3" to-layer="3" to-port="1"/>
		<edge from-layer="2" from-port="2" to-layer="3" to-port="2"/>
		<edge from-layer="3" from-port="3" to-layer="5" to-port="0"/>
		<edge from-layer="4" from-port="0" to-layer="5" to-port="1"/>
		<edge from-layer="5" from-port="2" to-layer="7" to-port="0"/>
		<edge from-layer="6" from-port="0" to-layer="7" to-port="1"/>
		<edge from-layer="7" from-port="2" to-layer="12" to-port="0"/>
		<edge from-layer="8" from-port="0" to-layer="12" to-port="1"/>
		<edge from-layer="9" from-port="0" to-layer="12" to-port="2"/>
		<edge from-layer="10" from-port="0" to-layer="12" to-port="3"/>
		<edge from-layer="11" from-port="0" to-layer="12" to-port="4"/>
		<edge from-layer="0" from-port="0" to-layer="14" to-port="0"/>
		<edge from-layer="14" from-port="1" to-layer="15" to-port="0"/>
		<edge from-layer="15" from-port="1" to-layer="17" to-port="0"/>
		<edge from-layer="16" from-port="0" to-layer="17" to-port="1"/>
		<edge from-layer="13" from-port="0" to-layer="19" to-port="0"/>
		<edge from-layer="17" from-port="2" to-layer="19" to-port="1"/>
		<edge from-layer="18" from-port="0" to-layer="19" to-port="2"/>
		<edge from-layer="12" from-port="5" to-layer="20" to-port="0"/>
		<edge from-layer="19" from-port="3" to-layer="20" to-port="1"/>
		<edge from-layer="20" from-port="2" to-layer="22" to-port="0"/>
		<edge from-layer="21" from-port="0" to-layer="22" to-port="1"/>
		<edge from-layer="22" from-port="2" to-layer="24" to-port="0"/>
		<edge from-layer="23" from-port="0" to-layer="24" to-port="1"/>
		<edge from-layer="24" from-port="2" to-layer="29" to-port="0"/>
		<edge from-layer="25" from-port="0" to-layer="29" to-port="1"/>
		<edge from-layer="26" from-port="0" to-layer="29" to-port="2"/>
		<edge from-layer="27" from-port="0" to-layer="29" to-port="3"/>
		<edge from-layer="28" from-port="0" to-layer="29" to-port="4"/>
		<edge from-layer="30" from-port="0" to-layer="31" to-port="0"/>
		<edge from-layer="31" from-port="1" to-layer="33" to-port="0"/>
		<edge from-layer="32" from-port="0" to-layer="33" to-port="1"/>
		<edge from-layer="33" from-port="2" to-layer="35" to-port="0"/>
		<edge from-layer="34" from-port="0" to-layer="35" to-port="1"/>
		<edge from-layer="29" from-port="5" to-layer="36" to-port="0"/>
		<edge from-layer="35" from-port="2" to-layer="36" to-port="1"/>
		<edge from-layer="36" from-port="2" to-layer="38" to-port="0"/>
		<edge from-layer="37" from-port="0" to-layer="38" to-port="1"/>
		<edge from-layer="38" from-port="2" to-layer="43" to-port="0"/>
		<edge from-layer="39" from-port="0" to-layer="43" to-port="1"/>
		<edge from-layer="40" from-port="0" to-layer="43" to-port="2"/>
		<edge from-layer="41" from-port="0" to-layer="43" to-port="3"/>
		<edge from-layer="42" from-port="0" to-layer="43" to-port="4"/>
		<edge from-layer="38" from-port="2" to-layer="45" to-port="0"/>
		<edge from-layer="45" from-port="1" to-layer="46" to-port="0"/>
		<edge from-layer="46" from-port="1" to-layer="48" to-port="0"/>
		<edge from-layer="47" from-port="0" to-layer="48" to-port="1"/>
		<edge from-layer="44" from-port="0" to-layer="50" to-port="0"/>
		<edge from-layer="48" from-port="2" to-layer="50" to-port="1"/>
		<edge from-layer="49" from-port="0" to-layer="50" to-port="2"/>
		<edge from-layer="43" from-port="5" to-layer="51" to-port="0"/>
		<edge from-layer="50" from-port="3" to-layer="51" to-port="1"/>
		<edge from-layer="51" from-port="2" to-layer="53" to-port="0"/>
		<edge from-layer="52" from-port="0" to-layer="53" to-port="1"/>
		<edge from-layer="53" from-port="2" to-layer="55" to-port="0"/>
		<edge from-layer="54" from-port="0" to-layer="55" to-port="1"/>
		<edge from-layer="55" from-port="2" to-layer="56" to-port="0"/>
		<edge from-layer="56" from-port="1" to-layer="61" to-port="0"/>
		<edge from-layer="57" from-port="0" to-layer="61" to-port="1"/>
		<edge from-layer="58" from-port="0" to-layer="61" to-port="2"/>
		<edge from-layer="59" from-port="0" to-layer="61" to-port="3"/>
		<edge from-layer="60" from-port="0" to-layer="61" to-port="4"/>
		<edge from-layer="61" from-port="5" to-layer="62" to-port="0"/>
		<edge from-layer="63" from-port="0" to-layer="64" to-port="0"/>
		<edge from-layer="64" from-port="1" to-layer="66" to-port="0"/>
		<edge from-layer="65" from-port="0" to-layer="66" to-port="1"/>
		<edge from-layer="66" from-port="2" to-layer="68" to-port="0"/>
		<edge from-layer="67" from-port="0" to-layer="68" to-port="1"/>
		<edge from-layer="62" from-port="1" to-layer="69" to-port="0"/>
		<edge from-layer="68" from-port="2" to-layer="69" to-port="1"/>
		<edge from-layer="69" from-port="2" to-layer="71" to-port="0"/>
		<edge from-layer="70" from-port="0" to-layer="71" to-port="1"/>
		<edge from-layer="71" from-port="2" to-layer="72" to-port="0"/>
		<edge from-layer="72" from-port="1" to-layer="77" to-port="0"/>
		<edge from-layer="73" from-port="0" to-layer="77" to-port="1"/>
		<edge from-layer="74" from-port="0" to-layer="77" to-port="2"/>
		<edge from-layer="75" from-port="0" to-layer="77" to-port="3"/>
		<edge from-layer="76" from-port="0" to-layer="77" to-port="4"/>
		<edge from-layer="78" from-port="0" to-layer="79" to-port="0"/>
		<edge from-layer="79" from-port="1" to-layer="81" to-port="0"/>
		<edge from-layer="80" from-port="0" to-layer="81" to-port="1"/>
		<edge from-layer="81" from-port="2" to-layer="83" to-port="0"/>
		<edge from-layer="82" from-port="0" to-layer="83" to-port="1"/>
		<edge from-layer="77" from-port="5" to-layer="84" to-port="0"/>
		<edge from-layer="83" from-port="2" to-layer="84" to-port="1"/>
		<edge from-layer="84" from-port="2" to-layer="86" to-port="0"/>
		<edge from-layer="85" from-port="0" to-layer="86" to-port="1"/>
		<edge from-layer="86" from-port="2" to-layer="91" to-port="0"/>
		<edge from-layer="87" from-port="0" to-layer="91" to-port="1"/>
		<edge from-layer="88" from-port="0" to-layer="91" to-port="2"/>
		<edge from-layer="89" from-port="0" to-layer="91" to-port="3"/>
		<edge from-layer="90" from-port="0" to-layer="91" to-port="4"/>
		<edge from-layer="92" from-port="0" to-layer="93" to-port="0"/>
		<edge from-layer="93" from-port="1" to-layer="95" to-port="0"/>
		<edge from-layer="94" from-port="0" to-layer="95" to-port="1"/>
		<edge from-layer="95" from-port="2" to-layer="97" to-port="0"/>
		<edge from-layer="96" from-port="0" to-layer="97" to-port="1"/>
		<edge from-layer="97" from-port="2" to-layer="99" to-port="0"/>
		<edge from-layer="98" from-port="0" to-layer="99" to-port="1"/>
		<edge from-layer="91" from-port="5" to-layer="100" to-port="0"/>
		<edge from-layer="99" from-port="2" to-layer="100" to-port="1"/>
		<edge from-layer="100" from-port="2" to-layer="102" to-port="0"/>
		<edge from-layer="101" from-port="0" to-layer="102" to-port="1"/>
		<edge from-layer="102" from-port="2" to-layer="103" to-port="0"/>
		<edge from-layer="103" from-port="1" to-layer="108" to-port="0"/>
		<edge from-layer="104" from-port="0" to-layer="108" to-port="1"/>
		<edge from-layer="105" from-port="0" to-layer="108" to-port="2"/>
		<edge from-layer="106" from-port="0" to-layer="108" to-port="3"/>
		<edge from-layer="107" from-port="0" to-layer="108" to-port="4"/>
		<edge from-layer="103" from-port="1" to-layer="110" to-port="0"/>
		<edge from-layer="110" from-port="1" to-layer="111" to-port="0"/>
		<edge from-layer="111" from-port="1" to-layer="113" to-port="0"/>
		<edge from-layer="112" from-port="0" to-layer="113" to-port="1"/>
		<edge from-layer="109" from-port="0" to-layer="115" to-port="0"/>
		<edge from-layer="113" from-port="2" to-layer="115" to-port="1"/>
		<edge from-layer="114" from-port="0" to-layer="115" to-port="2"/>
		<edge from-layer="108" from-port="5" to-layer="116" to-port="0"/>
		<edge from-layer="115" from-port="3" to-layer="116" to-port="1"/>
		<edge from-layer="116" from-port="2" to-layer="118" to-port="0"/>
		<edge from-layer="117" from-port="0" to-layer="118" to-port="1"/>
		<edge from-layer="118" from-port="2" to-layer="120" to-port="0"/>
		<edge from-layer="119" from-port="0" to-layer="120" to-port="1"/>
		<edge from-layer="120" from-port="2" to-layer="121" to-port="0"/>
		<edge from-layer="121" from-port="1" to-layer="123" to-port="0"/>
		<edge from-layer="122" from-port="0" to-layer="123" to-port="1"/>
		<edge from-layer="123" from-port="2" to-layer="125" to-port="0"/>
		<edge from-layer="124" from-port="0" to-layer="125" to-port="1"/>
		<edge from-layer="125" from-port="2" to-layer="126" to-port="0"/>
		<edge from-layer="126" from-port="1" to-layer="131" to-port="0"/>
		<edge from-layer="127" from-port="0" to-layer="131" to-port="1"/>
		<edge from-layer="128" from-port="0" to-layer="131" to-port="2"/>
		<edge from-layer="129" from-port="0" to-layer="131" to-port="3"/>
		<edge from-layer="130" from-port="0" to-layer="131" to-port="4"/>
		<edge from-layer="108" from-port="5" to-layer="132" to-port="0"/>
		<edge from-layer="131" from-port="5" to-layer="132" to-port="1"/>
		<edge from-layer="132" from-port="2" to-layer="137" to-port="0"/>
		<edge from-layer="133" from-port="0" to-layer="137" to-port="1"/>
		<edge from-layer="134" from-port="0" to-layer="137" to-port="2"/>
		<edge from-layer="135" from-port="0" to-layer="137" to-port="3"/>
		<edge from-layer="136" from-port="0" to-layer="137" to-port="4"/>
		<edge from-layer="138" from-port="0" to-layer="139" to-port="0"/>
		<edge from-layer="139" from-port="1" to-layer="141" to-port="0"/>
		<edge from-layer="140" from-port="0" to-layer="141" to-port="1"/>
		<edge from-layer="141" from-port="2" to-layer="143" to-port="0"/>
		<edge from-layer="142" from-port="0" to-layer="143" to-port="1"/>
		<edge from-layer="77" from-port="5" to-layer="144" to-port="0"/>
		<edge from-layer="143" from-port="2" to-layer="144" to-port="1"/>
		<edge from-layer="144" from-port="2" to-layer="146" to-port="0"/>
		<edge from-layer="145" from-port="0" to-layer="146" to-port="1"/>
		<edge from-layer="146" from-port="2" to-layer="151" to-port="0"/>
		<edge from-layer="147" from-port="0" to-layer="151" to-port="1"/>
		<edge from-layer="148" from-port="0" to-layer="151" to-port="2"/>
		<edge from-layer="149" from-port="0" to-layer="151" to-port="3"/>
		<edge from-layer="150" from-port="0" to-layer="151" to-port="4"/>
		<edge from-layer="152" from-port="0" to-layer="153" to-port="0"/>
		<edge from-layer="153" from-port="1" to-layer="155" to-port="0"/>
		<edge from-layer="154" from-port="0" to-layer="155" to-port="1"/>
		<edge from-layer="155" from-port="2" to-layer="157" to-port="0"/>
		<edge from-layer="156" from-port="0" to-layer="157" to-port="1"/>
		<edge from-layer="157" from-port="2" to-layer="159" to-port="0"/>
		<edge from-layer="158" from-port="0" to-layer="159" to-port="1"/>
		<edge from-layer="151" from-port="5" to-layer="160" to-port="0"/>
		<edge from-layer="159" from-port="2" to-layer="160" to-port="1"/>
		<edge from-layer="160" from-port="2" to-layer="162" to-port="0"/>
		<edge from-layer="161" from-port="0" to-layer="162" to-port="1"/>
		<edge from-layer="162" from-port="2" to-layer="163" to-port="0"/>
		<edge from-layer="163" from-port="1" to-layer="168" to-port="0"/>
		<edge from-layer="164" from-port="0" to-layer="168" to-port="1"/>
		<edge from-layer="165" from-port="0" to-layer="168" to-port="2"/>
		<edge from-layer="166" from-port="0" to-layer="168" to-port="3"/>
		<edge from-layer="167" from-port="0" to-layer="168" to-port="4"/>
		<edge from-layer="169" from-port="0" to-layer="170" to-port="0"/>
		<edge from-layer="170" from-port="1" to-layer="172" to-port="0"/>
		<edge from-layer="171" from-port="0" to-layer="172" to-port="1"/>
		<edge from-layer="172" from-port="2" to-layer="174" to-port="0"/>
		<edge from-layer="173" from-port="0" to-layer="174" to-port="1"/>
		<edge from-layer="168" from-port="5" to-layer="175" to-port="0"/>
		<edge from-layer="174" from-port="2" to-layer="175" to-port="1"/>
		<edge from-layer="175" from-port="2" to-layer="177" to-port="0"/>
		<edge from-layer="176" from-port="0" to-layer="177" to-port="1"/>
		<edge from-layer="177" from-port="2" to-layer="182" to-port="0"/>
		<edge from-layer="178" from-port="0" to-layer="182" to-port="1"/>
		<edge from-layer="179" from-port="0" to-layer="182" to-port="2"/>
		<edge from-layer="180" from-port="0" to-layer="182" to-port="3"/>
		<edge from-layer="181" from-port="0" to-layer="182" to-port="4"/>
		<edge from-layer="183" from-port="0" to-layer="184" to-port="0"/>
		<edge from-layer="184" from-port="1" to-layer="186" to-port="0"/>
		<edge from-layer="185" from-port="0" to-layer="186" to-port="1"/>
		<edge from-layer="186" from-port="2" to-layer="188" to-port="0"/>
		<edge from-layer="187" from-port="0" to-layer="188" to-port="1"/>
		<edge from-layer="188" from-port="2" to-layer="190" to-port="0"/>
		<edge from-layer="189" from-port="0" to-layer="190" to-port="1"/>
		<edge from-layer="182" from-port="5" to-layer="191" to-port="0"/>
		<edge from-layer="190" from-port="2" to-layer="191" to-port="1"/>
		<edge from-layer="191" from-port="2" to-layer="193" to-port="0"/>
		<edge from-layer="192" from-port="0" to-layer="193" to-port="1"/>
		<edge from-layer="193" from-port="2" to-layer="194" to-port="0"/>
		<edge from-layer="194" from-port="1" to-layer="199" to-port="0"/>
		<edge from-layer="195" from-port="0" to-layer="199" to-port="1"/>
		<edge from-layer="196" from-port="0" to-layer="199" to-port="2"/>
		<edge from-layer="197" from-port="0" to-layer="199" to-port="3"/>
		<edge from-layer="198" from-port="0" to-layer="199" to-port="4"/>
		<edge from-layer="194" from-port="1" to-layer="201" to-port="0"/>
		<edge from-layer="201" from-port="1" to-layer="202" to-port="0"/>
		<edge from-layer="202" from-port="1" to-layer="204" to-port="0"/>
		<edge from-layer="203" from-port="0" to-layer="204" to-port="1"/>
		<edge from-layer="200" from-port="0" to-layer="206" to-port="0"/>
		<edge from-layer="204" from-port="2" to-layer="206" to-port="1"/>
		<edge from-layer="205" from-port="0" to-layer="206" to-port="2"/>
		<edge from-layer="199" from-port="5" to-layer="207" to-port="0"/>
		<edge from-layer="206" from-port="3" to-layer="207" to-port="1"/>
		<edge from-layer="207" from-port="2" to-layer="209" to-port="0"/>
		<edge from-layer="208" from-port="0" to-layer="209" to-port="1"/>
		<edge from-layer="209" from-port="2" to-layer="211" to-port="0"/>
		<edge from-layer="210" from-port="0" to-layer="211" to-port="1"/>
		<edge from-layer="211" from-port="2" to-layer="212" to-port="0"/>
		<edge from-layer="212" from-port="1" to-layer="214" to-port="0"/>
		<edge from-layer="213" from-port="0" to-layer="214" to-port="1"/>
		<edge from-layer="214" from-port="2" to-layer="216" to-port="0"/>
		<edge from-layer="215" from-port="0" to-layer="216" to-port="1"/>
		<edge from-layer="216" from-port="2" to-layer="217" to-port="0"/>
		<edge from-layer="217" from-port="1" to-layer="222" to-port="0"/>
		<edge from-layer="218" from-port="0" to-layer="222" to-port="1"/>
		<edge from-layer="219" from-port="0" to-layer="222" to-port="2"/>
		<edge from-layer="220" from-port="0" to-layer="222" to-port="3"/>
		<edge from-layer="221" from-port="0" to-layer="222" to-port="4"/>
		<edge from-layer="199" from-port="5" to-layer="223" to-port="0"/>
		<edge from-layer="222" from-port="5" to-layer="223" to-port="1"/>
		<edge from-layer="223" from-port="2" to-layer="228" to-port="0"/>
		<edge from-layer="224" from-port="0" to-layer="228" to-port="1"/>
		<edge from-layer="225" from-port="0" to-layer="228" to-port="2"/>
		<edge from-layer="226" from-port="0" to-layer="228" to-port="3"/>
		<edge from-layer="227" from-port="0" to-layer="228" to-port="4"/>
		<edge from-layer="137" from-port="5" to-layer="229" to-port="0"/>
		<edge from-layer="228" from-port="5" to-layer="229" to-port="1"/>
		<edge from-layer="229" from-port="2" to-layer="234" to-port="0"/>
		<edge from-layer="230" from-port="0" to-layer="234" to-port="1"/>
		<edge from-layer="231" from-port="0" to-layer="234" to-port="2"/>
		<edge from-layer="232" from-port="0" to-layer="234" to-port="3"/>
		<edge from-layer="233" from-port="0" to-layer="234" to-port="4"/>
		<edge from-layer="235" from-port="0" to-layer="236" to-port="0"/>
		<edge from-layer="236" from-port="1" to-layer="238" to-port="0"/>
		<edge from-layer="237" from-port="0" to-layer="238" to-port="1"/>
		<edge from-layer="238" from-port="2" to-layer="240" to-port="0"/>
		<edge from-layer="239" from-port="0" to-layer="240" to-port="1"/>
		<edge from-layer="77" from-port="5" to-layer="241" to-port="0"/>
		<edge from-layer="240" from-port="2" to-layer="241" to-port="1"/>
		<edge from-layer="241" from-port="2" to-layer="243" to-port="0"/>
		<edge from-layer="242" from-port="0" to-layer="243" to-port="1"/>
		<edge from-layer="243" from-port="2" to-layer="248" to-port="0"/>
		<edge from-layer="244" from-port="0" to-layer="248" to-port="1"/>
		<edge from-layer="245" from-port="0" to-layer="248" to-port="2"/>
		<edge from-layer="246" from-port="0" to-layer="248" to-port="3"/>
		<edge from-layer="247" from-port="0" to-layer="248" to-port="4"/>
		<edge from-layer="249" from-port="0" to-layer="250" to-port="0"/>
		<edge from-layer="250" from-port="1" to-layer="252" to-port="0"/>
		<edge from-layer="251" from-port="0" to-layer="252" to-port="1"/>
		<edge from-layer="252" from-port="2" to-layer="254" to-port="0"/>
		<edge from-layer="253" from-port="0" to-layer="254" to-port="1"/>
		<edge from-layer="254" from-port="2" to-layer="256" to-port="0"/>
		<edge from-layer="255" from-port="0" to-layer="256" to-port="1"/>
		<edge from-layer="248" from-port="5" to-layer="257" to-port="0"/>
		<edge from-layer="256" from-port="2" to-layer="257" to-port="1"/>
		<edge from-layer="257" from-port="2" to-layer="259" to-port="0"/>
		<edge from-layer="258" from-port="0" to-layer="259" to-port="1"/>
		<edge from-layer="259" from-port="2" to-layer="260" to-port="0"/>
		<edge from-layer="260" from-port="1" to-layer="265" to-port="0"/>
		<edge from-layer="261" from-port="0" to-layer="265" to-port="1"/>
		<edge from-layer="262" from-port="0" to-layer="265" to-port="2"/>
		<edge from-layer="263" from-port="0" to-layer="265" to-port="3"/>
		<edge from-layer="264" from-port="0" to-layer="265" to-port="4"/>
		<edge from-layer="266" from-port="0" to-layer="267" to-port="0"/>
		<edge from-layer="267" from-port="1" to-layer="269" to-port="0"/>
		<edge from-layer="268" from-port="0" to-layer="269" to-port="1"/>
		<edge from-layer="269" from-port="2" to-layer="271" to-port="0"/>
		<edge from-layer="270" from-port="0" to-layer="271" to-port="1"/>
		<edge from-layer="265" from-port="5" to-layer="272" to-port="0"/>
		<edge from-layer="271" from-port="2" to-layer="272" to-port="1"/>
		<edge from-layer="272" from-port="2" to-layer="274" to-port="0"/>
		<edge from-layer="273" from-port="0" to-layer="274" to-port="1"/>
		<edge from-layer="274" from-port="2" to-layer="279" to-port="0"/>
		<edge from-layer="275" from-port="0" to-layer="279" to-port="1"/>
		<edge from-layer="276" from-port="0" to-layer="279" to-port="2"/>
		<edge from-layer="277" from-port="0" to-layer="279" to-port="3"/>
		<edge from-layer="278" from-port="0" to-layer="279" to-port="4"/>
		<edge from-layer="280" from-port="0" to-layer="281" to-port="0"/>
		<edge from-layer="281" from-port="1" to-layer="283" to-port="0"/>
		<edge from-layer="282" from-port="0" to-layer="283" to-port="1"/>
		<edge from-layer="283" from-port="2" to-layer="285" to-port="0"/>
		<edge from-layer="284" from-port="0" to-layer="285" to-port="1"/>
		<edge from-layer="285" from-port="2" to-layer="287" to-port="0"/>
		<edge from-layer="286" from-port="0" to-layer="287" to-port="1"/>
		<edge from-layer="279" from-port="5" to-layer="288" to-port="0"/>
		<edge from-layer="287" from-port="2" to-layer="288" to-port="1"/>
		<edge from-layer="288" from-port="2" to-layer="290" to-port="0"/>
		<edge from-layer="289" from-port="0" to-layer="290" to-port="1"/>
		<edge from-layer="290" from-port="2" to-layer="291" to-port="0"/>
		<edge from-layer="291" from-port="1" to-layer="296" to-port="0"/>
		<edge from-layer="292" from-port="0" to-layer="296" to-port="1"/>
		<edge from-layer="293" from-port="0" to-layer="296" to-port="2"/>
		<edge from-layer="294" from-port="0" to-layer="296" to-port="3"/>
		<edge from-layer="295" from-port="0" to-layer="296" to-port="4"/>
		<edge from-layer="297" from-port="0" to-layer="298" to-port="0"/>
		<edge from-layer="298" from-port="1" to-layer="300" to-port="0"/>
		<edge from-layer="299" from-port="0" to-layer="300" to-port="1"/>
		<edge from-layer="300" from-port="2" to-layer="302" to-port="0"/>
		<edge from-layer="301" from-port="0" to-layer="302" to-port="1"/>
		<edge from-layer="296" from-port="5" to-layer="303" to-port="0"/>
		<edge from-layer="302" from-port="2" to-layer="303" to-port="1"/>
		<edge from-layer="303" from-port="2" to-layer="305" to-port="0"/>
		<edge from-layer="304" from-port="0" to-layer="305" to-port="1"/>
		<edge from-layer="305" from-port="2" to-layer="310" to-port="0"/>
		<edge from-layer="306" from-port="0" to-layer="310" to-port="1"/>
		<edge from-layer="307" from-port="0" to-layer="310" to-port="2"/>
		<edge from-layer="308" from-port="0" to-layer="310" to-port="3"/>
		<edge from-layer="309" from-port="0" to-layer="310" to-port="4"/>
		<edge from-layer="311" from-port="0" to-layer="312" to-port="0"/>
		<edge from-layer="312" from-port="1" to-layer="314" to-port="0"/>
		<edge from-layer="313" from-port="0" to-layer="314" to-port="1"/>
		<edge from-layer="314" from-port="2" to-layer="316" to-port="0"/>
		<edge from-layer="315" from-port="0" to-layer="316" to-port="1"/>
		<edge from-layer="316" from-port="2" to-layer="318" to-port="0"/>
		<edge from-layer="317" from-port="0" to-layer="318" to-port="1"/>
		<edge from-layer="310" from-port="5" to-layer="319" to-port="0"/>
		<edge from-layer="318" from-port="2" to-layer="319" to-port="1"/>
		<edge from-layer="319" from-port="2" to-layer="321" to-port="0"/>
		<edge from-layer="320" from-port="0" to-layer="321" to-port="1"/>
		<edge from-layer="321" from-port="2" to-layer="322" to-port="0"/>
		<edge from-layer="322" from-port="1" to-layer="327" to-port="0"/>
		<edge from-layer="323" from-port="0" to-layer="327" to-port="1"/>
		<edge from-layer="324" from-port="0" to-layer="327" to-port="2"/>
		<edge from-layer="325" from-port="0" to-layer="327" to-port="3"/>
		<edge from-layer="326" from-port="0" to-layer="327" to-port="4"/>
		<edge from-layer="322" from-port="1" to-layer="329" to-port="0"/>
		<edge from-layer="329" from-port="1" to-layer="330" to-port="0"/>
		<edge from-layer="330" from-port="1" to-layer="332" to-port="0"/>
		<edge from-layer="331" from-port="0" to-layer="332" to-port="1"/>
		<edge from-layer="328" from-port="0" to-layer="334" to-port="0"/>
		<edge from-layer="332" from-port="2" to-layer="334" to-port="1"/>
		<edge from-layer="333" from-port="0" to-layer="334" to-port="2"/>
		<edge from-layer="327" from-port="5" to-layer="335" to-port="0"/>
		<edge from-layer="334" from-port="3" to-layer="335" to-port="1"/>
		<edge from-layer="335" from-port="2" to-layer="337" to-port="0"/>
		<edge from-layer="336" from-port="0" to-layer="337" to-port="1"/>
		<edge from-layer="337" from-port="2" to-layer="339" to-port="0"/>
		<edge from-layer="338" from-port="0" to-layer="339" to-port="1"/>
		<edge from-layer="339" from-port="2" to-layer="340" to-port="0"/>
		<edge from-layer="340" from-port="1" to-layer="342" to-port="0"/>
		<edge from-layer="341" from-port="0" to-layer="342" to-port="1"/>
		<edge from-layer="342" from-port="2" to-layer="344" to-port="0"/>
		<edge from-layer="343" from-port="0" to-layer="344" to-port="1"/>
		<edge from-layer="344" from-port="2" to-layer="345" to-port="0"/>
		<edge from-layer="345" from-port="1" to-layer="350" to-port="0"/>
		<edge from-layer="346" from-port="0" to-layer="350" to-port="1"/>
		<edge from-layer="347" from-port="0" to-layer="350" to-port="2"/>
		<edge from-layer="348" from-port="0" to-layer="350" to-port="3"/>
		<edge from-layer="349" from-port="0" to-layer="350" to-port="4"/>
		<edge from-layer="327" from-port="5" to-layer="351" to-port="0"/>
		<edge from-layer="350" from-port="5" to-layer="351" to-port="1"/>
		<edge from-layer="351" from-port="2" to-layer="356" to-port="0"/>
		<edge from-layer="352" from-port="0" to-layer="356" to-port="1"/>
		<edge from-layer="353" from-port="0" to-layer="356" to-port="2"/>
		<edge from-layer="354" from-port="0" to-layer="356" to-port="3"/>
		<edge from-layer="355" from-port="0" to-layer="356" to-port="4"/>
		<edge from-layer="234" from-port="5" to-layer="357" to-port="0"/>
		<edge from-layer="356" from-port="5" to-layer="357" to-port="1"/>
		<edge from-layer="357" from-port="2" to-layer="362" to-port="0"/>
		<edge from-layer="358" from-port="0" to-layer="362" to-port="1"/>
		<edge from-layer="359" from-port="0" to-layer="362" to-port="2"/>
		<edge from-layer="360" from-port="0" to-layer="362" to-port="3"/>
		<edge from-layer="361" from-port="0" to-layer="362" to-port="4"/>
		<edge from-layer="363" from-port="0" to-layer="364" to-port="0"/>
		<edge from-layer="364" from-port="1" to-layer="366" to-port="0"/>
		<edge from-layer="365" from-port="0" to-layer="366" to-port="1"/>
		<edge from-layer="366" from-port="2" to-layer="368" to-port="0"/>
		<edge from-layer="367" from-port="0" to-layer="368" to-port="1"/>
		<edge from-layer="77" from-port="5" to-layer="369" to-port="0"/>
		<edge from-layer="368" from-port="2" to-layer="369" to-port="1"/>
		<edge from-layer="369" from-port="2" to-layer="371" to-port="0"/>
		<edge from-layer="370" from-port="0" to-layer="371" to-port="1"/>
		<edge from-layer="371" from-port="2" to-layer="376" to-port="0"/>
		<edge from-layer="372" from-port="0" to-layer="376" to-port="1"/>
		<edge from-layer="373" from-port="0" to-layer="376" to-port="2"/>
		<edge from-layer="374" from-port="0" to-layer="376" to-port="3"/>
		<edge from-layer="375" from-port="0" to-layer="376" to-port="4"/>
		<edge from-layer="377" from-port="0" to-layer="378" to-port="0"/>
		<edge from-layer="378" from-port="1" to-layer="380" to-port="0"/>
		<edge from-layer="379" from-port="0" to-layer="380" to-port="1"/>
		<edge from-layer="380" from-port="2" to-layer="382" to-port="0"/>
		<edge from-layer="381" from-port="0" to-layer="382" to-port="1"/>
		<edge from-layer="382" from-port="2" to-layer="384" to-port="0"/>
		<edge from-layer="383" from-port="0" to-layer="384" to-port="1"/>
		<edge from-layer="376" from-port="5" to-layer="385" to-port="0"/>
		<edge from-layer="384" from-port="2" to-layer="385" to-port="1"/>
		<edge from-layer="385" from-port="2" to-layer="387" to-port="0"/>
		<edge from-layer="386" from-port="0" to-layer="387" to-port="1"/>
		<edge from-layer="387" from-port="2" to-layer="388" to-port="0"/>
		<edge from-layer="388" from-port="1" to-layer="393" to-port="0"/>
		<edge from-layer="389" from-port="0" to-layer="393" to-port="1"/>
		<edge from-layer="390" from-port="0" to-layer="393" to-port="2"/>
		<edge from-layer="391" from-port="0" to-layer="393" to-port="3"/>
		<edge from-layer="392" from-port="0" to-layer="393" to-port="4"/>
		<edge from-layer="394" from-port="0" to-layer="395" to-port="0"/>
		<edge from-layer="395" from-port="1" to-layer="397" to-port="0"/>
		<edge from-layer="396" from-port="0" to-layer="397" to-port="1"/>
		<edge from-layer="397" from-port="2" to-layer="399" to-port="0"/>
		<edge from-layer="398" from-port="0" to-layer="399" to-port="1"/>
		<edge from-layer="393" from-port="5" to-layer="400" to-port="0"/>
		<edge from-layer="399" from-port="2" to-layer="400" to-port="1"/>
		<edge from-layer="400" from-port="2" to-layer="402" to-port="0"/>
		<edge from-layer="401" from-port="0" to-layer="402" to-port="1"/>
		<edge from-layer="402" from-port="2" to-layer="407" to-port="0"/>
		<edge from-layer="403" from-port="0" to-layer="407" to-port="1"/>
		<edge from-layer="404" from-port="0" to-layer="407" to-port="2"/>
		<edge from-layer="405" from-port="0" to-layer="407" to-port="3"/>
		<edge from-layer="406" from-port="0" to-layer="407" to-port="4"/>
		<edge from-layer="408" from-port="0" to-layer="409" to-port="0"/>
		<edge from-layer="409" from-port="1" to-layer="411" to-port="0"/>
		<edge from-layer="410" from-port="0" to-layer="411" to-port="1"/>
		<edge from-layer="411" from-port="2" to-layer="413" to-port="0"/>
		<edge from-layer="412" from-port="0" to-layer="413" to-port="1"/>
		<edge from-layer="413" from-port="2" to-layer="415" to-port="0"/>
		<edge from-layer="414" from-port="0" to-layer="415" to-port="1"/>
		<edge from-layer="407" from-port="5" to-layer="416" to-port="0"/>
		<edge from-layer="415" from-port="2" to-layer="416" to-port="1"/>
		<edge from-layer="416" from-port="2" to-layer="418" to-port="0"/>
		<edge from-layer="417" from-port="0" to-layer="418" to-port="1"/>
		<edge from-layer="418" from-port="2" to-layer="419" to-port="0"/>
		<edge from-layer="419" from-port="1" to-layer="424" to-port="0"/>
		<edge from-layer="420" from-port="0" to-layer="424" to-port="1"/>
		<edge from-layer="421" from-port="0" to-layer="424" to-port="2"/>
		<edge from-layer="422" from-port="0" to-layer="424" to-port="3"/>
		<edge from-layer="423" from-port="0" to-layer="424" to-port="4"/>
		<edge from-layer="425" from-port="0" to-layer="426" to-port="0"/>
		<edge from-layer="426" from-port="1" to-layer="428" to-port="0"/>
		<edge from-layer="427" from-port="0" to-layer="428" to-port="1"/>
		<edge from-layer="428" from-port="2" to-layer="430" to-port="0"/>
		<edge from-layer="429" from-port="0" to-layer="430" to-port="1"/>
		<edge from-layer="424" from-port="5" to-layer="431" to-port="0"/>
		<edge from-layer="430" from-port="2" to-layer="431" to-port="1"/>
		<edge from-layer="431" from-port="2" to-layer="433" to-port="0"/>
		<edge from-layer="432" from-port="0" to-layer="433" to-port="1"/>
		<edge from-layer="433" from-port="2" to-layer="438" to-port="0"/>
		<edge from-layer="434" from-port="0" to-layer="438" to-port="1"/>
		<edge from-layer="435" from-port="0" to-layer="438" to-port="2"/>
		<edge from-layer="436" from-port="0" to-layer="438" to-port="3"/>
		<edge from-layer="437" from-port="0" to-layer="438" to-port="4"/>
		<edge from-layer="439" from-port="0" to-layer="440" to-port="0"/>
		<edge from-layer="440" from-port="1" to-layer="442" to-port="0"/>
		<edge from-layer="441" from-port="0" to-layer="442" to-port="1"/>
		<edge from-layer="442" from-port="2" to-layer="444" to-port="0"/>
		<edge from-layer="443" from-port="0" to-layer="444" to-port="1"/>
		<edge from-layer="444" from-port="2" to-layer="446" to-port="0"/>
		<edge from-layer="445" from-port="0" to-layer="446" to-port="1"/>
		<edge from-layer="438" from-port="5" to-layer="447" to-port="0"/>
		<edge from-layer="446" from-port="2" to-layer="447" to-port="1"/>
		<edge from-layer="447" from-port="2" to-layer="449" to-port="0"/>
		<edge from-layer="448" from-port="0" to-layer="449" to-port="1"/>
		<edge from-layer="449" from-port="2" to-layer="450" to-port="0"/>
		<edge from-layer="450" from-port="1" to-layer="455" to-port="0"/>
		<edge from-layer="451" from-port="0" to-layer="455" to-port="1"/>
		<edge from-layer="452" from-port="0" to-layer="455" to-port="2"/>
		<edge from-layer="453" from-port="0" to-layer="455" to-port="3"/>
		<edge from-layer="454" from-port="0" to-layer="455" to-port="4"/>
		<edge from-layer="456" from-port="0" to-layer="457" to-port="0"/>
		<edge from-layer="457" from-port="1" to-layer="459" to-port="0"/>
		<edge from-layer="458" from-port="0" to-layer="459" to-port="1"/>
		<edge from-layer="459" from-port="2" to-layer="461" to-port="0"/>
		<edge from-layer="460" from-port="0" to-layer="461" to-port="1"/>
		<edge from-layer="455" from-port="5" to-layer="462" to-port="0"/>
		<edge from-layer="461" from-port="2" to-layer="462" to-port="1"/>
		<edge from-layer="462" from-port="2" to-layer="464" to-port="0"/>
		<edge from-layer="463" from-port="0" to-layer="464" to-port="1"/>
		<edge from-layer="464" from-port="2" to-layer="469" to-port="0"/>
		<edge from-layer="465" from-port="0" to-layer="469" to-port="1"/>
		<edge from-layer="466" from-port="0" to-layer="469" to-port="2"/>
		<edge from-layer="467" from-port="0" to-layer="469" to-port="3"/>
		<edge from-layer="468" from-port="0" to-layer="469" to-port="4"/>
		<edge from-layer="470" from-port="0" to-layer="471" to-port="0"/>
		<edge from-layer="471" from-port="1" to-layer="473" to-port="0"/>
		<edge from-layer="472" from-port="0" to-layer="473" to-port="1"/>
		<edge from-layer="473" from-port="2" to-layer="475" to-port="0"/>
		<edge from-layer="474" from-port="0" to-layer="475" to-port="1"/>
		<edge from-layer="475" from-port="2" to-layer="477" to-port="0"/>
		<edge from-layer="476" from-port="0" to-layer="477" to-port="1"/>
		<edge from-layer="469" from-port="5" to-layer="478" to-port="0"/>
		<edge from-layer="477" from-port="2" to-layer="478" to-port="1"/>
		<edge from-layer="478" from-port="2" to-layer="480" to-port="0"/>
		<edge from-layer="479" from-port="0" to-layer="480" to-port="1"/>
		<edge from-layer="480" from-port="2" to-layer="481" to-port="0"/>
		<edge from-layer="481" from-port="1" to-layer="486" to-port="0"/>
		<edge from-layer="482" from-port="0" to-layer="486" to-port="1"/>
		<edge from-layer="483" from-port="0" to-layer="486" to-port="2"/>
		<edge from-layer="484" from-port="0" to-layer="486" to-port="3"/>
		<edge from-layer="485" from-port="0" to-layer="486" to-port="4"/>
		<edge from-layer="481" from-port="1" to-layer="488" to-port="0"/>
		<edge from-layer="488" from-port="1" to-layer="489" to-port="0"/>
		<edge from-layer="489" from-port="1" to-layer="491" to-port="0"/>
		<edge from-layer="490" from-port="0" to-layer="491" to-port="1"/>
		<edge from-layer="487" from-port="0" to-layer="493" to-port="0"/>
		<edge from-layer="491" from-port="2" to-layer="493" to-port="1"/>
		<edge from-layer="492" from-port="0" to-layer="493" to-port="2"/>
		<edge from-layer="486" from-port="5" to-layer="494" to-port="0"/>
		<edge from-layer="493" from-port="3" to-layer="494" to-port="1"/>
		<edge from-layer="494" from-port="2" to-layer="496" to-port="0"/>
		<edge from-layer="495" from-port="0" to-layer="496" to-port="1"/>
		<edge from-layer="496" from-port="2" to-layer="498" to-port="0"/>
		<edge from-layer="497" from-port="0" to-layer="498" to-port="1"/>
		<edge from-layer="498" from-port="2" to-layer="499" to-port="0"/>
		<edge from-layer="499" from-port="1" to-layer="501" to-port="0"/>
		<edge from-layer="500" from-port="0" to-layer="501" to-port="1"/>
		<edge from-layer="501" from-port="2" to-layer="503" to-port="0"/>
		<edge from-layer="502" from-port="0" to-layer="503" to-port="1"/>
		<edge from-layer="503" from-port="2" to-layer="504" to-port="0"/>
		<edge from-layer="504" from-port="1" to-layer="509" to-port="0"/>
		<edge from-layer="505" from-port="0" to-layer="509" to-port="1"/>
		<edge from-layer="506" from-port="0" to-layer="509" to-port="2"/>
		<edge from-layer="507" from-port="0" to-layer="509" to-port="3"/>
		<edge from-layer="508" from-port="0" to-layer="509" to-port="4"/>
		<edge from-layer="486" from-port="5" to-layer="510" to-port="0"/>
		<edge from-layer="509" from-port="5" to-layer="510" to-port="1"/>
		<edge from-layer="510" from-port="2" to-layer="515" to-port="0"/>
		<edge from-layer="511" from-port="0" to-layer="515" to-port="1"/>
		<edge from-layer="512" from-port="0" to-layer="515" to-port="2"/>
		<edge from-layer="513" from-port="0" to-layer="515" to-port="3"/>
		<edge from-layer="514" from-port="0" to-layer="515" to-port="4"/>
		<edge from-layer="362" from-port="5" to-layer="516" to-port="0"/>
		<edge from-layer="515" from-port="5" to-layer="516" to-port="1"/>
		<edge from-layer="516" from-port="2" to-layer="521" to-port="0"/>
		<edge from-layer="517" from-port="0" to-layer="521" to-port="1"/>
		<edge from-layer="518" from-port="0" to-layer="521" to-port="2"/>
		<edge from-layer="519" from-port="0" to-layer="521" to-port="3"/>
		<edge from-layer="520" from-port="0" to-layer="521" to-port="4"/>
		<edge from-layer="522" from-port="0" to-layer="523" to-port="0"/>
		<edge from-layer="523" from-port="1" to-layer="525" to-port="0"/>
		<edge from-layer="524" from-port="0" to-layer="525" to-port="1"/>
		<edge from-layer="525" from-port="2" to-layer="527" to-port="0"/>
		<edge from-layer="526" from-port="0" to-layer="527" to-port="1"/>
		<edge from-layer="521" from-port="5" to-layer="528" to-port="0"/>
		<edge from-layer="527" from-port="2" to-layer="528" to-port="1"/>
		<edge from-layer="528" from-port="2" to-layer="530" to-port="0"/>
		<edge from-layer="529" from-port="0" to-layer="530" to-port="1"/>
		<edge from-layer="530" from-port="2" to-layer="535" to-port="0"/>
		<edge from-layer="531" from-port="0" to-layer="535" to-port="1"/>
		<edge from-layer="532" from-port="0" to-layer="535" to-port="2"/>
		<edge from-layer="533" from-port="0" to-layer="535" to-port="3"/>
		<edge from-layer="534" from-port="0" to-layer="535" to-port="4"/>
		<edge from-layer="536" from-port="0" to-layer="537" to-port="0"/>
		<edge from-layer="537" from-port="1" to-layer="539" to-port="0"/>
		<edge from-layer="538" from-port="0" to-layer="539" to-port="1"/>
		<edge from-layer="539" from-port="2" to-layer="541" to-port="0"/>
		<edge from-layer="540" from-port="0" to-layer="541" to-port="1"/>
		<edge from-layer="62" from-port="1" to-layer="542" to-port="0"/>
		<edge from-layer="541" from-port="2" to-layer="542" to-port="1"/>
		<edge from-layer="542" from-port="2" to-layer="544" to-port="0"/>
		<edge from-layer="543" from-port="0" to-layer="544" to-port="1"/>
		<edge from-layer="544" from-port="2" to-layer="549" to-port="0"/>
		<edge from-layer="545" from-port="0" to-layer="549" to-port="1"/>
		<edge from-layer="546" from-port="0" to-layer="549" to-port="2"/>
		<edge from-layer="547" from-port="0" to-layer="549" to-port="3"/>
		<edge from-layer="548" from-port="0" to-layer="549" to-port="4"/>
		<edge from-layer="535" from-port="5" to-layer="550" to-port="0"/>
		<edge from-layer="549" from-port="5" to-layer="550" to-port="1"/>
		<edge from-layer="550" from-port="2" to-layer="551" to-port="0"/>
		<edge from-layer="551" from-port="1" to-layer="556" to-port="0"/>
		<edge from-layer="552" from-port="0" to-layer="556" to-port="1"/>
		<edge from-layer="553" from-port="0" to-layer="556" to-port="2"/>
		<edge from-layer="554" from-port="0" to-layer="556" to-port="3"/>
		<edge from-layer="555" from-port="0" to-layer="556" to-port="4"/>
		<edge from-layer="557" from-port="0" to-layer="558" to-port="0"/>
		<edge from-layer="558" from-port="1" to-layer="560" to-port="0"/>
		<edge from-layer="559" from-port="0" to-layer="560" to-port="1"/>
		<edge from-layer="560" from-port="2" to-layer="562" to-port="0"/>
		<edge from-layer="561" from-port="0" to-layer="562" to-port="1"/>
		<edge from-layer="556" from-port="5" to-layer="563" to-port="0"/>
		<edge from-layer="562" from-port="2" to-layer="563" to-port="1"/>
		<edge from-layer="563" from-port="2" to-layer="565" to-port="0"/>
		<edge from-layer="564" from-port="0" to-layer="565" to-port="1"/>
		<edge from-layer="565" from-port="2" to-layer="566" to-port="0"/>
		<edge from-layer="566" from-port="1" to-layer="571" to-port="0"/>
		<edge from-layer="567" from-port="0" to-layer="571" to-port="1"/>
		<edge from-layer="568" from-port="0" to-layer="571" to-port="2"/>
		<edge from-layer="569" from-port="0" to-layer="571" to-port="3"/>
		<edge from-layer="570" from-port="0" to-layer="571" to-port="4"/>
		<edge from-layer="572" from-port="0" to-layer="573" to-port="0"/>
		<edge from-layer="573" from-port="1" to-layer="575" to-port="0"/>
		<edge from-layer="574" from-port="0" to-layer="575" to-port="1"/>
		<edge from-layer="575" from-port="2" to-layer="577" to-port="0"/>
		<edge from-layer="576" from-port="0" to-layer="577" to-port="1"/>
		<edge from-layer="571" from-port="5" to-layer="578" to-port="0"/>
		<edge from-layer="577" from-port="2" to-layer="578" to-port="1"/>
		<edge from-layer="578" from-port="2" to-layer="580" to-port="0"/>
		<edge from-layer="579" from-port="0" to-layer="580" to-port="1"/>
		<edge from-layer="580" from-port="2" to-layer="585" to-port="0"/>
		<edge from-layer="581" from-port="0" to-layer="585" to-port="1"/>
		<edge from-layer="582" from-port="0" to-layer="585" to-port="2"/>
		<edge from-layer="583" from-port="0" to-layer="585" to-port="3"/>
		<edge from-layer="584" from-port="0" to-layer="585" to-port="4"/>
		<edge from-layer="586" from-port="0" to-layer="587" to-port="0"/>
		<edge from-layer="587" from-port="1" to-layer="589" to-port="0"/>
		<edge from-layer="588" from-port="0" to-layer="589" to-port="1"/>
		<edge from-layer="589" from-port="2" to-layer="591" to-port="0"/>
		<edge from-layer="590" from-port="0" to-layer="591" to-port="1"/>
		<edge from-layer="591" from-port="2" to-layer="593" to-port="0"/>
		<edge from-layer="592" from-port="0" to-layer="593" to-port="1"/>
		<edge from-layer="585" from-port="5" to-layer="594" to-port="0"/>
		<edge from-layer="593" from-port="2" to-layer="594" to-port="1"/>
		<edge from-layer="594" from-port="2" to-layer="596" to-port="0"/>
		<edge from-layer="595" from-port="0" to-layer="596" to-port="1"/>
		<edge from-layer="596" from-port="2" to-layer="597" to-port="0"/>
		<edge from-layer="597" from-port="1" to-layer="602" to-port="0"/>
		<edge from-layer="598" from-port="0" to-layer="602" to-port="1"/>
		<edge from-layer="599" from-port="0" to-layer="602" to-port="2"/>
		<edge from-layer="600" from-port="0" to-layer="602" to-port="3"/>
		<edge from-layer="601" from-port="0" to-layer="602" to-port="4"/>
		<edge from-layer="597" from-port="1" to-layer="604" to-port="0"/>
		<edge from-layer="604" from-port="1" to-layer="605" to-port="0"/>
		<edge from-layer="605" from-port="1" to-layer="607" to-port="0"/>
		<edge from-layer="606" from-port="0" to-layer="607" to-port="1"/>
		<edge from-layer="603" from-port="0" to-layer="609" to-port="0"/>
		<edge from-layer="607" from-port="2" to-layer="609" to-port="1"/>
		<edge from-layer="608" from-port="0" to-layer="609" to-port="2"/>
		<edge from-layer="602" from-port="5" to-layer="610" to-port="0"/>
		<edge from-layer="609" from-port="3" to-layer="610" to-port="1"/>
		<edge from-layer="610" from-port="2" to-layer="615" to-port="0"/>
		<edge from-layer="611" from-port="0" to-layer="615" to-port="1"/>
		<edge from-layer="612" from-port="0" to-layer="615" to-port="2"/>
		<edge from-layer="613" from-port="0" to-layer="615" to-port="3"/>
		<edge from-layer="614" from-port="0" to-layer="615" to-port="4"/>
		<edge from-layer="615" from-port="5" to-layer="617" to-port="0"/>
		<edge from-layer="616" from-port="0" to-layer="617" to-port="1"/>
		<edge from-layer="617" from-port="2" to-layer="619" to-port="0"/>
		<edge from-layer="619" from-port="1" to-layer="620" to-port="0"/>
		<edge from-layer="620" from-port="1" to-layer="622" to-port="0"/>
		<edge from-layer="621" from-port="0" to-layer="622" to-port="1"/>
		<edge from-layer="618" from-port="0" to-layer="624" to-port="0"/>
		<edge from-layer="622" from-port="2" to-layer="624" to-port="1"/>
		<edge from-layer="623" from-port="0" to-layer="624" to-port="2"/>
		<edge from-layer="617" from-port="2" to-layer="625" to-port="0"/>
		<edge from-layer="624" from-port="3" to-layer="625" to-port="1"/>
		<edge from-layer="625" from-port="2" to-layer="627" to-port="0"/>
		<edge from-layer="626" from-port="0" to-layer="627" to-port="1"/>
		<edge from-layer="627" from-port="2" to-layer="629" to-port="0"/>
		<edge from-layer="628" from-port="0" to-layer="629" to-port="1"/>
		<edge from-layer="629" from-port="2" to-layer="634" to-port="0"/>
		<edge from-layer="630" from-port="0" to-layer="634" to-port="1"/>
		<edge from-layer="631" from-port="0" to-layer="634" to-port="2"/>
		<edge from-layer="632" from-port="0" to-layer="634" to-port="3"/>
		<edge from-layer="633" from-port="0" to-layer="634" to-port="4"/>
		<edge from-layer="610" from-port="2" to-layer="635" to-port="0"/>
		<edge from-layer="634" from-port="5" to-layer="636" to-port="0"/>
		<edge from-layer="635" from-port="1" to-layer="636" to-port="1"/>
		<edge from-layer="636" from-port="2" to-layer="638" to-port="0"/>
		<edge from-layer="637" from-port="0" to-layer="638" to-port="1"/>
		<edge from-layer="638" from-port="2" to-layer="640" to-port="0"/>
		<edge from-layer="639" from-port="0" to-layer="640" to-port="1"/>
		<edge from-layer="640" from-port="2" to-layer="641" to-port="0"/>
		<edge from-layer="641" from-port="1" to-layer="646" to-port="0"/>
		<edge from-layer="642" from-port="0" to-layer="646" to-port="1"/>
		<edge from-layer="643" from-port="0" to-layer="646" to-port="2"/>
		<edge from-layer="644" from-port="0" to-layer="646" to-port="3"/>
		<edge from-layer="645" from-port="0" to-layer="646" to-port="4"/>
		<edge from-layer="602" from-port="5" to-layer="647" to-port="0"/>
		<edge from-layer="646" from-port="5" to-layer="647" to-port="1"/>
		<edge from-layer="647" from-port="2" to-layer="652" to-port="0"/>
		<edge from-layer="648" from-port="0" to-layer="652" to-port="1"/>
		<edge from-layer="649" from-port="0" to-layer="652" to-port="2"/>
		<edge from-layer="650" from-port="0" to-layer="652" to-port="3"/>
		<edge from-layer="651" from-port="0" to-layer="652" to-port="4"/>
		<edge from-layer="653" from-port="0" to-layer="654" to-port="0"/>
		<edge from-layer="654" from-port="1" to-layer="656" to-port="0"/>
		<edge from-layer="655" from-port="0" to-layer="656" to-port="1"/>
		<edge from-layer="656" from-port="2" to-layer="658" to-port="0"/>
		<edge from-layer="657" from-port="0" to-layer="658" to-port="1"/>
		<edge from-layer="571" from-port="5" to-layer="659" to-port="0"/>
		<edge from-layer="658" from-port="2" to-layer="659" to-port="1"/>
		<edge from-layer="659" from-port="2" to-layer="661" to-port="0"/>
		<edge from-layer="660" from-port="0" to-layer="661" to-port="1"/>
		<edge from-layer="661" from-port="2" to-layer="666" to-port="0"/>
		<edge from-layer="662" from-port="0" to-layer="666" to-port="1"/>
		<edge from-layer="663" from-port="0" to-layer="666" to-port="2"/>
		<edge from-layer="664" from-port="0" to-layer="666" to-port="3"/>
		<edge from-layer="665" from-port="0" to-layer="666" to-port="4"/>
		<edge from-layer="667" from-port="0" to-layer="668" to-port="0"/>
		<edge from-layer="668" from-port="1" to-layer="670" to-port="0"/>
		<edge from-layer="669" from-port="0" to-layer="670" to-port="1"/>
		<edge from-layer="670" from-port="2" to-layer="672" to-port="0"/>
		<edge from-layer="671" from-port="0" to-layer="672" to-port="1"/>
		<edge from-layer="672" from-port="2" to-layer="674" to-port="0"/>
		<edge from-layer="673" from-port="0" to-layer="674" to-port="1"/>
		<edge from-layer="666" from-port="5" to-layer="675" to-port="0"/>
		<edge from-layer="674" from-port="2" to-layer="675" to-port="1"/>
		<edge from-layer="675" from-port="2" to-layer="677" to-port="0"/>
		<edge from-layer="676" from-port="0" to-layer="677" to-port="1"/>
		<edge from-layer="677" from-port="2" to-layer="678" to-port="0"/>
		<edge from-layer="678" from-port="1" to-layer="683" to-port="0"/>
		<edge from-layer="679" from-port="0" to-layer="683" to-port="1"/>
		<edge from-layer="680" from-port="0" to-layer="683" to-port="2"/>
		<edge from-layer="681" from-port="0" to-layer="683" to-port="3"/>
		<edge from-layer="682" from-port="0" to-layer="683" to-port="4"/>
		<edge from-layer="684" from-port="0" to-layer="685" to-port="0"/>
		<edge from-layer="685" from-port="1" to-layer="687" to-port="0"/>
		<edge from-layer="686" from-port="0" to-layer="687" to-port="1"/>
		<edge from-layer="687" from-port="2" to-layer="689" to-port="0"/>
		<edge from-layer="688" from-port="0" to-layer="689" to-port="1"/>
		<edge from-layer="683" from-port="5" to-layer="690" to-port="0"/>
		<edge from-layer="689" from-port="2" to-layer="690" to-port="1"/>
		<edge from-layer="690" from-port="2" to-layer="692" to-port="0"/>
		<edge from-layer="691" from-port="0" to-layer="692" to-port="1"/>
		<edge from-layer="692" from-port="2" to-layer="697" to-port="0"/>
		<edge from-layer="693" from-port="0" to-layer="697" to-port="1"/>
		<edge from-layer="694" from-port="0" to-layer="697" to-port="2"/>
		<edge from-layer="695" from-port="0" to-layer="697" to-port="3"/>
		<edge from-layer="696" from-port="0" to-layer="697" to-port="4"/>
		<edge from-layer="698" from-port="0" to-layer="699" to-port="0"/>
		<edge from-layer="699" from-port="1" to-layer="701" to-port="0"/>
		<edge from-layer="700" from-port="0" to-layer="701" to-port="1"/>
		<edge from-layer="701" from-port="2" to-layer="703" to-port="0"/>
		<edge from-layer="702" from-port="0" to-layer="703" to-port="1"/>
		<edge from-layer="703" from-port="2" to-layer="705" to-port="0"/>
		<edge from-layer="704" from-port="0" to-layer="705" to-port="1"/>
		<edge from-layer="697" from-port="5" to-layer="706" to-port="0"/>
		<edge from-layer="705" from-port="2" to-layer="706" to-port="1"/>
		<edge from-layer="706" from-port="2" to-layer="708" to-port="0"/>
		<edge from-layer="707" from-port="0" to-layer="708" to-port="1"/>
		<edge from-layer="708" from-port="2" to-layer="709" to-port="0"/>
		<edge from-layer="709" from-port="1" to-layer="714" to-port="0"/>
		<edge from-layer="710" from-port="0" to-layer="714" to-port="1"/>
		<edge from-layer="711" from-port="0" to-layer="714" to-port="2"/>
		<edge from-layer="712" from-port="0" to-layer="714" to-port="3"/>
		<edge from-layer="713" from-port="0" to-layer="714" to-port="4"/>
		<edge from-layer="709" from-port="1" to-layer="716" to-port="0"/>
		<edge from-layer="716" from-port="1" to-layer="717" to-port="0"/>
		<edge from-layer="717" from-port="1" to-layer="719" to-port="0"/>
		<edge from-layer="718" from-port="0" to-layer="719" to-port="1"/>
		<edge from-layer="715" from-port="0" to-layer="721" to-port="0"/>
		<edge from-layer="719" from-port="2" to-layer="721" to-port="1"/>
		<edge from-layer="720" from-port="0" to-layer="721" to-port="2"/>
		<edge from-layer="714" from-port="5" to-layer="722" to-port="0"/>
		<edge from-layer="721" from-port="3" to-layer="722" to-port="1"/>
		<edge from-layer="722" from-port="2" to-layer="727" to-port="0"/>
		<edge from-layer="723" from-port="0" to-layer="727" to-port="1"/>
		<edge from-layer="724" from-port="0" to-layer="727" to-port="2"/>
		<edge from-layer="725" from-port="0" to-layer="727" to-port="3"/>
		<edge from-layer="726" from-port="0" to-layer="727" to-port="4"/>
		<edge from-layer="727" from-port="5" to-layer="729" to-port="0"/>
		<edge from-layer="728" from-port="0" to-layer="729" to-port="1"/>
		<edge from-layer="729" from-port="2" to-layer="731" to-port="0"/>
		<edge from-layer="731" from-port="1" to-layer="732" to-port="0"/>
		<edge from-layer="732" from-port="1" to-layer="734" to-port="0"/>
		<edge from-layer="733" from-port="0" to-layer="734" to-port="1"/>
		<edge from-layer="730" from-port="0" to-layer="736" to-port="0"/>
		<edge from-layer="734" from-port="2" to-layer="736" to-port="1"/>
		<edge from-layer="735" from-port="0" to-layer="736" to-port="2"/>
		<edge from-layer="729" from-port="2" to-layer="737" to-port="0"/>
		<edge from-layer="736" from-port="3" to-layer="737" to-port="1"/>
		<edge from-layer="737" from-port="2" to-layer="739" to-port="0"/>
		<edge from-layer="738" from-port="0" to-layer="739" to-port="1"/>
		<edge from-layer="739" from-port="2" to-layer="741" to-port="0"/>
		<edge from-layer="740" from-port="0" to-layer="741" to-port="1"/>
		<edge from-layer="741" from-port="2" to-layer="746" to-port="0"/>
		<edge from-layer="742" from-port="0" to-layer="746" to-port="1"/>
		<edge from-layer="743" from-port="0" to-layer="746" to-port="2"/>
		<edge from-layer="744" from-port="0" to-layer="746" to-port="3"/>
		<edge from-layer="745" from-port="0" to-layer="746" to-port="4"/>
		<edge from-layer="722" from-port="2" to-layer="747" to-port="0"/>
		<edge from-layer="746" from-port="5" to-layer="748" to-port="0"/>
		<edge from-layer="747" from-port="1" to-layer="748" to-port="1"/>
		<edge from-layer="748" from-port="2" to-layer="750" to-port="0"/>
		<edge from-layer="749" from-port="0" to-layer="750" to-port="1"/>
		<edge from-layer="750" from-port="2" to-layer="752" to-port="0"/>
		<edge from-layer="751" from-port="0" to-layer="752" to-port="1"/>
		<edge from-layer="752" from-port="2" to-layer="753" to-port="0"/>
		<edge from-layer="753" from-port="1" to-layer="758" to-port="0"/>
		<edge from-layer="754" from-port="0" to-layer="758" to-port="1"/>
		<edge from-layer="755" from-port="0" to-layer="758" to-port="2"/>
		<edge from-layer="756" from-port="0" to-layer="758" to-port="3"/>
		<edge from-layer="757" from-port="0" to-layer="758" to-port="4"/>
		<edge from-layer="714" from-port="5" to-layer="759" to-port="0"/>
		<edge from-layer="758" from-port="5" to-layer="759" to-port="1"/>
		<edge from-layer="759" from-port="2" to-layer="764" to-port="0"/>
		<edge from-layer="760" from-port="0" to-layer="764" to-port="1"/>
		<edge from-layer="761" from-port="0" to-layer="764" to-port="2"/>
		<edge from-layer="762" from-port="0" to-layer="764" to-port="3"/>
		<edge from-layer="763" from-port="0" to-layer="764" to-port="4"/>
		<edge from-layer="652" from-port="5" to-layer="765" to-port="0"/>
		<edge from-layer="764" from-port="5" to-layer="765" to-port="1"/>
		<edge from-layer="765" from-port="2" to-layer="770" to-port="0"/>
		<edge from-layer="766" from-port="0" to-layer="770" to-port="1"/>
		<edge from-layer="767" from-port="0" to-layer="770" to-port="2"/>
		<edge from-layer="768" from-port="0" to-layer="770" to-port="3"/>
		<edge from-layer="769" from-port="0" to-layer="770" to-port="4"/>
		<edge from-layer="771" from-port="0" to-layer="772" to-port="0"/>
		<edge from-layer="772" from-port="1" to-layer="774" to-port="0"/>
		<edge from-layer="773" from-port="0" to-layer="774" to-port="1"/>
		<edge from-layer="774" from-port="2" to-layer="776" to-port="0"/>
		<edge from-layer="775" from-port="0" to-layer="776" to-port="1"/>
		<edge from-layer="571" from-port="5" to-layer="777" to-port="0"/>
		<edge from-layer="776" from-port="2" to-layer="777" to-port="1"/>
		<edge from-layer="777" from-port="2" to-layer="779" to-port="0"/>
		<edge from-layer="778" from-port="0" to-layer="779" to-port="1"/>
		<edge from-layer="779" from-port="2" to-layer="784" to-port="0"/>
		<edge from-layer="780" from-port="0" to-layer="784" to-port="1"/>
		<edge from-layer="781" from-port="0" to-layer="784" to-port="2"/>
		<edge from-layer="782" from-port="0" to-layer="784" to-port="3"/>
		<edge from-layer="783" from-port="0" to-layer="784" to-port="4"/>
		<edge from-layer="785" from-port="0" to-layer="786" to-port="0"/>
		<edge from-layer="786" from-port="1" to-layer="788" to-port="0"/>
		<edge from-layer="787" from-port="0" to-layer="788" to-port="1"/>
		<edge from-layer="788" from-port="2" to-layer="790" to-port="0"/>
		<edge from-layer="789" from-port="0" to-layer="790" to-port="1"/>
		<edge from-layer="790" from-port="2" to-layer="792" to-port="0"/>
		<edge from-layer="791" from-port="0" to-layer="792" to-port="1"/>
		<edge from-layer="784" from-port="5" to-layer="793" to-port="0"/>
		<edge from-layer="792" from-port="2" to-layer="793" to-port="1"/>
		<edge from-layer="793" from-port="2" to-layer="795" to-port="0"/>
		<edge from-layer="794" from-port="0" to-layer="795" to-port="1"/>
		<edge from-layer="795" from-port="2" to-layer="796" to-port="0"/>
		<edge from-layer="796" from-port="1" to-layer="801" to-port="0"/>
		<edge from-layer="797" from-port="0" to-layer="801" to-port="1"/>
		<edge from-layer="798" from-port="0" to-layer="801" to-port="2"/>
		<edge from-layer="799" from-port="0" to-layer="801" to-port="3"/>
		<edge from-layer="800" from-port="0" to-layer="801" to-port="4"/>
		<edge from-layer="802" from-port="0" to-layer="803" to-port="0"/>
		<edge from-layer="803" from-port="1" to-layer="805" to-port="0"/>
		<edge from-layer="804" from-port="0" to-layer="805" to-port="1"/>
		<edge from-layer="805" from-port="2" to-layer="807" to-port="0"/>
		<edge from-layer="806" from-port="0" to-layer="807" to-port="1"/>
		<edge from-layer="801" from-port="5" to-layer="808" to-port="0"/>
		<edge from-layer="807" from-port="2" to-layer="808" to-port="1"/>
		<edge from-layer="808" from-port="2" to-layer="810" to-port="0"/>
		<edge from-layer="809" from-port="0" to-layer="810" to-port="1"/>
		<edge from-layer="810" from-port="2" to-layer="815" to-port="0"/>
		<edge from-layer="811" from-port="0" to-layer="815" to-port="1"/>
		<edge from-layer="812" from-port="0" to-layer="815" to-port="2"/>
		<edge from-layer="813" from-port="0" to-layer="815" to-port="3"/>
		<edge from-layer="814" from-port="0" to-layer="815" to-port="4"/>
		<edge from-layer="816" from-port="0" to-layer="817" to-port="0"/>
		<edge from-layer="817" from-port="1" to-layer="819" to-port="0"/>
		<edge from-layer="818" from-port="0" to-layer="819" to-port="1"/>
		<edge from-layer="819" from-port="2" to-layer="821" to-port="0"/>
		<edge from-layer="820" from-port="0" to-layer="821" to-port="1"/>
		<edge from-layer="821" from-port="2" to-layer="823" to-port="0"/>
		<edge from-layer="822" from-port="0" to-layer="823" to-port="1"/>
		<edge from-layer="815" from-port="5" to-layer="824" to-port="0"/>
		<edge from-layer="823" from-port="2" to-layer="824" to-port="1"/>
		<edge from-layer="824" from-port="2" to-layer="826" to-port="0"/>
		<edge from-layer="825" from-port="0" to-layer="826" to-port="1"/>
		<edge from-layer="826" from-port="2" to-layer="827" to-port="0"/>
		<edge from-layer="827" from-port="1" to-layer="832" to-port="0"/>
		<edge from-layer="828" from-port="0" to-layer="832" to-port="1"/>
		<edge from-layer="829" from-port="0" to-layer="832" to-port="2"/>
		<edge from-layer="830" from-port="0" to-layer="832" to-port="3"/>
		<edge from-layer="831" from-port="0" to-layer="832" to-port="4"/>
		<edge from-layer="833" from-port="0" to-layer="834" to-port="0"/>
		<edge from-layer="834" from-port="1" to-layer="836" to-port="0"/>
		<edge from-layer="835" from-port="0" to-layer="836" to-port="1"/>
		<edge from-layer="836" from-port="2" to-layer="838" to-port="0"/>
		<edge from-layer="837" from-port="0" to-layer="838" to-port="1"/>
		<edge from-layer="832" from-port="5" to-layer="839" to-port="0"/>
		<edge from-layer="838" from-port="2" to-layer="839" to-port="1"/>
		<edge from-layer="839" from-port="2" to-layer="841" to-port="0"/>
		<edge from-layer="840" from-port="0" to-layer="841" to-port="1"/>
		<edge from-layer="841" from-port="2" to-layer="846" to-port="0"/>
		<edge from-layer="842" from-port="0" to-layer="846" to-port="1"/>
		<edge from-layer="843" from-port="0" to-layer="846" to-port="2"/>
		<edge from-layer="844" from-port="0" to-layer="846" to-port="3"/>
		<edge from-layer="845" from-port="0" to-layer="846" to-port="4"/>
		<edge from-layer="847" from-port="0" to-layer="848" to-port="0"/>
		<edge from-layer="848" from-port="1" to-layer="850" to-port="0"/>
		<edge from-layer="849" from-port="0" to-layer="850" to-port="1"/>
		<edge from-layer="850" from-port="2" to-layer="852" to-port="0"/>
		<edge from-layer="851" from-port="0" to-layer="852" to-port="1"/>
		<edge from-layer="852" from-port="2" to-layer="854" to-port="0"/>
		<edge from-layer="853" from-port="0" to-layer="854" to-port="1"/>
		<edge from-layer="846" from-port="5" to-layer="855" to-port="0"/>
		<edge from-layer="854" from-port="2" to-layer="855" to-port="1"/>
		<edge from-layer="855" from-port="2" to-layer="857" to-port="0"/>
		<edge from-layer="856" from-port="0" to-layer="857" to-port="1"/>
		<edge from-layer="857" from-port="2" to-layer="858" to-port="0"/>
		<edge from-layer="858" from-port="1" to-layer="863" to-port="0"/>
		<edge from-layer="859" from-port="0" to-layer="863" to-port="1"/>
		<edge from-layer="860" from-port="0" to-layer="863" to-port="2"/>
		<edge from-layer="861" from-port="0" to-layer="863" to-port="3"/>
		<edge from-layer="862" from-port="0" to-layer="863" to-port="4"/>
		<edge from-layer="858" from-port="1" to-layer="865" to-port="0"/>
		<edge from-layer="865" from-port="1" to-layer="866" to-port="0"/>
		<edge from-layer="866" from-port="1" to-layer="868" to-port="0"/>
		<edge from-layer="867" from-port="0" to-layer="868" to-port="1"/>
		<edge from-layer="864" from-port="0" to-layer="870" to-port="0"/>
		<edge from-layer="868" from-port="2" to-layer="870" to-port="1"/>
		<edge from-layer="869" from-port="0" to-layer="870" to-port="2"/>
		<edge from-layer="863" from-port="5" to-layer="871" to-port="0"/>
		<edge from-layer="870" from-port="3" to-layer="871" to-port="1"/>
		<edge from-layer="871" from-port="2" to-layer="876" to-port="0"/>
		<edge from-layer="872" from-port="0" to-layer="876" to-port="1"/>
		<edge from-layer="873" from-port="0" to-layer="876" to-port="2"/>
		<edge from-layer="874" from-port="0" to-layer="876" to-port="3"/>
		<edge from-layer="875" from-port="0" to-layer="876" to-port="4"/>
		<edge from-layer="876" from-port="5" to-layer="878" to-port="0"/>
		<edge from-layer="877" from-port="0" to-layer="878" to-port="1"/>
		<edge from-layer="878" from-port="2" to-layer="880" to-port="0"/>
		<edge from-layer="880" from-port="1" to-layer="881" to-port="0"/>
		<edge from-layer="881" from-port="1" to-layer="883" to-port="0"/>
		<edge from-layer="882" from-port="0" to-layer="883" to-port="1"/>
		<edge from-layer="879" from-port="0" to-layer="885" to-port="0"/>
		<edge from-layer="883" from-port="2" to-layer="885" to-port="1"/>
		<edge from-layer="884" from-port="0" to-layer="885" to-port="2"/>
		<edge from-layer="878" from-port="2" to-layer="886" to-port="0"/>
		<edge from-layer="885" from-port="3" to-layer="886" to-port="1"/>
		<edge from-layer="886" from-port="2" to-layer="888" to-port="0"/>
		<edge from-layer="887" from-port="0" to-layer="888" to-port="1"/>
		<edge from-layer="888" from-port="2" to-layer="890" to-port="0"/>
		<edge from-layer="889" from-port="0" to-layer="890" to-port="1"/>
		<edge from-layer="890" from-port="2" to-layer="895" to-port="0"/>
		<edge from-layer="891" from-port="0" to-layer="895" to-port="1"/>
		<edge from-layer="892" from-port="0" to-layer="895" to-port="2"/>
		<edge from-layer="893" from-port="0" to-layer="895" to-port="3"/>
		<edge from-layer="894" from-port="0" to-layer="895" to-port="4"/>
		<edge from-layer="871" from-port="2" to-layer="896" to-port="0"/>
		<edge from-layer="895" from-port="5" to-layer="897" to-port="0"/>
		<edge from-layer="896" from-port="1" to-layer="897" to-port="1"/>
		<edge from-layer="897" from-port="2" to-layer="899" to-port="0"/>
		<edge from-layer="898" from-port="0" to-layer="899" to-port="1"/>
		<edge from-layer="899" from-port="2" to-layer="901" to-port="0"/>
		<edge from-layer="900" from-port="0" to-layer="901" to-port="1"/>
		<edge from-layer="901" from-port="2" to-layer="902" to-port="0"/>
		<edge from-layer="902" from-port="1" to-layer="907" to-port="0"/>
		<edge from-layer="903" from-port="0" to-layer="907" to-port="1"/>
		<edge from-layer="904" from-port="0" to-layer="907" to-port="2"/>
		<edge from-layer="905" from-port="0" to-layer="907" to-port="3"/>
		<edge from-layer="906" from-port="0" to-layer="907" to-port="4"/>
		<edge from-layer="863" from-port="5" to-layer="908" to-port="0"/>
		<edge from-layer="907" from-port="5" to-layer="908" to-port="1"/>
		<edge from-layer="908" from-port="2" to-layer="913" to-port="0"/>
		<edge from-layer="909" from-port="0" to-layer="913" to-port="1"/>
		<edge from-layer="910" from-port="0" to-layer="913" to-port="2"/>
		<edge from-layer="911" from-port="0" to-layer="913" to-port="3"/>
		<edge from-layer="912" from-port="0" to-layer="913" to-port="4"/>
		<edge from-layer="770" from-port="5" to-layer="914" to-port="0"/>
		<edge from-layer="913" from-port="5" to-layer="914" to-port="1"/>
		<edge from-layer="914" from-port="2" to-layer="919" to-port="0"/>
		<edge from-layer="915" from-port="0" to-layer="919" to-port="1"/>
		<edge from-layer="916" from-port="0" to-layer="919" to-port="2"/>
		<edge from-layer="917" from-port="0" to-layer="919" to-port="3"/>
		<edge from-layer="918" from-port="0" to-layer="919" to-port="4"/>
		<edge from-layer="920" from-port="0" to-layer="921" to-port="0"/>
		<edge from-layer="921" from-port="1" to-layer="923" to-port="0"/>
		<edge from-layer="922" from-port="0" to-layer="923" to-port="1"/>
		<edge from-layer="923" from-port="2" to-layer="925" to-port="0"/>
		<edge from-layer="924" from-port="0" to-layer="925" to-port="1"/>
		<edge from-layer="571" from-port="5" to-layer="926" to-port="0"/>
		<edge from-layer="925" from-port="2" to-layer="926" to-port="1"/>
		<edge from-layer="926" from-port="2" to-layer="928" to-port="0"/>
		<edge from-layer="927" from-port="0" to-layer="928" to-port="1"/>
		<edge from-layer="928" from-port="2" to-layer="933" to-port="0"/>
		<edge from-layer="929" from-port="0" to-layer="933" to-port="1"/>
		<edge from-layer="930" from-port="0" to-layer="933" to-port="2"/>
		<edge from-layer="931" from-port="0" to-layer="933" to-port="3"/>
		<edge from-layer="932" from-port="0" to-layer="933" to-port="4"/>
		<edge from-layer="934" from-port="0" to-layer="935" to-port="0"/>
		<edge from-layer="935" from-port="1" to-layer="937" to-port="0"/>
		<edge from-layer="936" from-port="0" to-layer="937" to-port="1"/>
		<edge from-layer="937" from-port="2" to-layer="939" to-port="0"/>
		<edge from-layer="938" from-port="0" to-layer="939" to-port="1"/>
		<edge from-layer="939" from-port="2" to-layer="941" to-port="0"/>
		<edge from-layer="940" from-port="0" to-layer="941" to-port="1"/>
		<edge from-layer="933" from-port="5" to-layer="942" to-port="0"/>
		<edge from-layer="941" from-port="2" to-layer="942" to-port="1"/>
		<edge from-layer="942" from-port="2" to-layer="944" to-port="0"/>
		<edge from-layer="943" from-port="0" to-layer="944" to-port="1"/>
		<edge from-layer="944" from-port="2" to-layer="945" to-port="0"/>
		<edge from-layer="945" from-port="1" to-layer="950" to-port="0"/>
		<edge from-layer="946" from-port="0" to-layer="950" to-port="1"/>
		<edge from-layer="947" from-port="0" to-layer="950" to-port="2"/>
		<edge from-layer="948" from-port="0" to-layer="950" to-port="3"/>
		<edge from-layer="949" from-port="0" to-layer="950" to-port="4"/>
		<edge from-layer="951" from-port="0" to-layer="952" to-port="0"/>
		<edge from-layer="952" from-port="1" to-layer="954" to-port="0"/>
		<edge from-layer="953" from-port="0" to-layer="954" to-port="1"/>
		<edge from-layer="954" from-port="2" to-layer="956" to-port="0"/>
		<edge from-layer="955" from-port="0" to-layer="956" to-port="1"/>
		<edge from-layer="950" from-port="5" to-layer="957" to-port="0"/>
		<edge from-layer="956" from-port="2" to-layer="957" to-port="1"/>
		<edge from-layer="957" from-port="2" to-layer="959" to-port="0"/>
		<edge from-layer="958" from-port="0" to-layer="959" to-port="1"/>
		<edge from-layer="959" from-port="2" to-layer="964" to-port="0"/>
		<edge from-layer="960" from-port="0" to-layer="964" to-port="1"/>
		<edge from-layer="961" from-port="0" to-layer="964" to-port="2"/>
		<edge from-layer="962" from-port="0" to-layer="964" to-port="3"/>
		<edge from-layer="963" from-port="0" to-layer="964" to-port="4"/>
		<edge from-layer="965" from-port="0" to-layer="966" to-port="0"/>
		<edge from-layer="966" from-port="1" to-layer="968" to-port="0"/>
		<edge from-layer="967" from-port="0" to-layer="968" to-port="1"/>
		<edge from-layer="968" from-port="2" to-layer="970" to-port="0"/>
		<edge from-layer="969" from-port="0" to-layer="970" to-port="1"/>
		<edge from-layer="970" from-port="2" to-layer="972" to-port="0"/>
		<edge from-layer="971" from-port="0" to-layer="972" to-port="1"/>
		<edge from-layer="964" from-port="5" to-layer="973" to-port="0"/>
		<edge from-layer="972" from-port="2" to-layer="973" to-port="1"/>
		<edge from-layer="973" from-port="2" to-layer="975" to-port="0"/>
		<edge from-layer="974" from-port="0" to-layer="975" to-port="1"/>
		<edge from-layer="975" from-port="2" to-layer="976" to-port="0"/>
		<edge from-layer="976" from-port="1" to-layer="981" to-port="0"/>
		<edge from-layer="977" from-port="0" to-layer="981" to-port="1"/>
		<edge from-layer="978" from-port="0" to-layer="981" to-port="2"/>
		<edge from-layer="979" from-port="0" to-layer="981" to-port="3"/>
		<edge from-layer="980" from-port="0" to-layer="981" to-port="4"/>
		<edge from-layer="982" from-port="0" to-layer="983" to-port="0"/>
		<edge from-layer="983" from-port="1" to-layer="985" to-port="0"/>
		<edge from-layer="984" from-port="0" to-layer="985" to-port="1"/>
		<edge from-layer="985" from-port="2" to-layer="987" to-port="0"/>
		<edge from-layer="986" from-port="0" to-layer="987" to-port="1"/>
		<edge from-layer="981" from-port="5" to-layer="988" to-port="0"/>
		<edge from-layer="987" from-port="2" to-layer="988" to-port="1"/>
		<edge from-layer="988" from-port="2" to-layer="990" to-port="0"/>
		<edge from-layer="989" from-port="0" to-layer="990" to-port="1"/>
		<edge from-layer="990" from-port="2" to-layer="995" to-port="0"/>
		<edge from-layer="991" from-port="0" to-layer="995" to-port="1"/>
		<edge from-layer="992" from-port="0" to-layer="995" to-port="2"/>
		<edge from-layer="993" from-port="0" to-layer="995" to-port="3"/>
		<edge from-layer="994" from-port="0" to-layer="995" to-port="4"/>
		<edge from-layer="996" from-port="0" to-layer="997" to-port="0"/>
		<edge from-layer="997" from-port="1" to-layer="999" to-port="0"/>
		<edge from-layer="998" from-port="0" to-layer="999" to-port="1"/>
		<edge from-layer="999" from-port="2" to-layer="1001" to-port="0"/>
		<edge from-layer="1000" from-port="0" to-layer="1001" to-port="1"/>
		<edge from-layer="1001" from-port="2" to-layer="1003" to-port="0"/>
		<edge from-layer="1002" from-port="0" to-layer="1003" to-port="1"/>
		<edge from-layer="995" from-port="5" to-layer="1004" to-port="0"/>
		<edge from-layer="1003" from-port="2" to-layer="1004" to-port="1"/>
		<edge from-layer="1004" from-port="2" to-layer="1006" to-port="0"/>
		<edge from-layer="1005" from-port="0" to-layer="1006" to-port="1"/>
		<edge from-layer="1006" from-port="2" to-layer="1007" to-port="0"/>
		<edge from-layer="1007" from-port="1" to-layer="1012" to-port="0"/>
		<edge from-layer="1008" from-port="0" to-layer="1012" to-port="1"/>
		<edge from-layer="1009" from-port="0" to-layer="1012" to-port="2"/>
		<edge from-layer="1010" from-port="0" to-layer="1012" to-port="3"/>
		<edge from-layer="1011" from-port="0" to-layer="1012" to-port="4"/>
		<edge from-layer="1013" from-port="0" to-layer="1014" to-port="0"/>
		<edge from-layer="1014" from-port="1" to-layer="1016" to-port="0"/>
		<edge from-layer="1015" from-port="0" to-layer="1016" to-port="1"/>
		<edge from-layer="1016" from-port="2" to-layer="1018" to-port="0"/>
		<edge from-layer="1017" from-port="0" to-layer="1018" to-port="1"/>
		<edge from-layer="1012" from-port="5" to-layer="1019" to-port="0"/>
		<edge from-layer="1018" from-port="2" to-layer="1019" to-port="1"/>
		<edge from-layer="1019" from-port="2" to-layer="1021" to-port="0"/>
		<edge from-layer="1020" from-port="0" to-layer="1021" to-port="1"/>
		<edge from-layer="1021" from-port="2" to-layer="1026" to-port="0"/>
		<edge from-layer="1022" from-port="0" to-layer="1026" to-port="1"/>
		<edge from-layer="1023" from-port="0" to-layer="1026" to-port="2"/>
		<edge from-layer="1024" from-port="0" to-layer="1026" to-port="3"/>
		<edge from-layer="1025" from-port="0" to-layer="1026" to-port="4"/>
		<edge from-layer="1027" from-port="0" to-layer="1028" to-port="0"/>
		<edge from-layer="1028" from-port="1" to-layer="1030" to-port="0"/>
		<edge from-layer="1029" from-port="0" to-layer="1030" to-port="1"/>
		<edge from-layer="1030" from-port="2" to-layer="1032" to-port="0"/>
		<edge from-layer="1031" from-port="0" to-layer="1032" to-port="1"/>
		<edge from-layer="1032" from-port="2" to-layer="1034" to-port="0"/>
		<edge from-layer="1033" from-port="0" to-layer="1034" to-port="1"/>
		<edge from-layer="1026" from-port="5" to-layer="1035" to-port="0"/>
		<edge from-layer="1034" from-port="2" to-layer="1035" to-port="1"/>
		<edge from-layer="1035" from-port="2" to-layer="1037" to-port="0"/>
		<edge from-layer="1036" from-port="0" to-layer="1037" to-port="1"/>
		<edge from-layer="1037" from-port="2" to-layer="1038" to-port="0"/>
		<edge from-layer="1038" from-port="1" to-layer="1043" to-port="0"/>
		<edge from-layer="1039" from-port="0" to-layer="1043" to-port="1"/>
		<edge from-layer="1040" from-port="0" to-layer="1043" to-port="2"/>
		<edge from-layer="1041" from-port="0" to-layer="1043" to-port="3"/>
		<edge from-layer="1042" from-port="0" to-layer="1043" to-port="4"/>
		<edge from-layer="1038" from-port="1" to-layer="1045" to-port="0"/>
		<edge from-layer="1045" from-port="1" to-layer="1046" to-port="0"/>
		<edge from-layer="1046" from-port="1" to-layer="1048" to-port="0"/>
		<edge from-layer="1047" from-port="0" to-layer="1048" to-port="1"/>
		<edge from-layer="1044" from-port="0" to-layer="1050" to-port="0"/>
		<edge from-layer="1048" from-port="2" to-layer="1050" to-port="1"/>
		<edge from-layer="1049" from-port="0" to-layer="1050" to-port="2"/>
		<edge from-layer="1043" from-port="5" to-layer="1051" to-port="0"/>
		<edge from-layer="1050" from-port="3" to-layer="1051" to-port="1"/>
		<edge from-layer="1051" from-port="2" to-layer="1056" to-port="0"/>
		<edge from-layer="1052" from-port="0" to-layer="1056" to-port="1"/>
		<edge from-layer="1053" from-port="0" to-layer="1056" to-port="2"/>
		<edge from-layer="1054" from-port="0" to-layer="1056" to-port="3"/>
		<edge from-layer="1055" from-port="0" to-layer="1056" to-port="4"/>
		<edge from-layer="1056" from-port="5" to-layer="1058" to-port="0"/>
		<edge from-layer="1057" from-port="0" to-layer="1058" to-port="1"/>
		<edge from-layer="1058" from-port="2" to-layer="1060" to-port="0"/>
		<edge from-layer="1060" from-port="1" to-layer="1061" to-port="0"/>
		<edge from-layer="1061" from-port="1" to-layer="1063" to-port="0"/>
		<edge from-layer="1062" from-port="0" to-layer="1063" to-port="1"/>
		<edge from-layer="1059" from-port="0" to-layer="1065" to-port="0"/>
		<edge from-layer="1063" from-port="2" to-layer="1065" to-port="1"/>
		<edge from-layer="1064" from-port="0" to-layer="1065" to-port="2"/>
		<edge from-layer="1058" from-port="2" to-layer="1066" to-port="0"/>
		<edge from-layer="1065" from-port="3" to-layer="1066" to-port="1"/>
		<edge from-layer="1066" from-port="2" to-layer="1068" to-port="0"/>
		<edge from-layer="1067" from-port="0" to-layer="1068" to-port="1"/>
		<edge from-layer="1068" from-port="2" to-layer="1070" to-port="0"/>
		<edge from-layer="1069" from-port="0" to-layer="1070" to-port="1"/>
		<edge from-layer="1070" from-port="2" to-layer="1075" to-port="0"/>
		<edge from-layer="1071" from-port="0" to-layer="1075" to-port="1"/>
		<edge from-layer="1072" from-port="0" to-layer="1075" to-port="2"/>
		<edge from-layer="1073" from-port="0" to-layer="1075" to-port="3"/>
		<edge from-layer="1074" from-port="0" to-layer="1075" to-port="4"/>
		<edge from-layer="1051" from-port="2" to-layer="1076" to-port="0"/>
		<edge from-layer="1075" from-port="5" to-layer="1077" to-port="0"/>
		<edge from-layer="1076" from-port="1" to-layer="1077" to-port="1"/>
		<edge from-layer="1077" from-port="2" to-layer="1079" to-port="0"/>
		<edge from-layer="1078" from-port="0" to-layer="1079" to-port="1"/>
		<edge from-layer="1079" from-port="2" to-layer="1081" to-port="0"/>
		<edge from-layer="1080" from-port="0" to-layer="1081" to-port="1"/>
		<edge from-layer="1081" from-port="2" to-layer="1082" to-port="0"/>
		<edge from-layer="1082" from-port="1" to-layer="1087" to-port="0"/>
		<edge from-layer="1083" from-port="0" to-layer="1087" to-port="1"/>
		<edge from-layer="1084" from-port="0" to-layer="1087" to-port="2"/>
		<edge from-layer="1085" from-port="0" to-layer="1087" to-port="3"/>
		<edge from-layer="1086" from-port="0" to-layer="1087" to-port="4"/>
		<edge from-layer="1043" from-port="5" to-layer="1088" to-port="0"/>
		<edge from-layer="1087" from-port="5" to-layer="1088" to-port="1"/>
		<edge from-layer="1088" from-port="2" to-layer="1093" to-port="0"/>
		<edge from-layer="1089" from-port="0" to-layer="1093" to-port="1"/>
		<edge from-layer="1090" from-port="0" to-layer="1093" to-port="2"/>
		<edge from-layer="1091" from-port="0" to-layer="1093" to-port="3"/>
		<edge from-layer="1092" from-port="0" to-layer="1093" to-port="4"/>
		<edge from-layer="919" from-port="5" to-layer="1094" to-port="0"/>
		<edge from-layer="1093" from-port="5" to-layer="1094" to-port="1"/>
		<edge from-layer="1094" from-port="2" to-layer="1099" to-port="0"/>
		<edge from-layer="1095" from-port="0" to-layer="1099" to-port="1"/>
		<edge from-layer="1096" from-port="0" to-layer="1099" to-port="2"/>
		<edge from-layer="1097" from-port="0" to-layer="1099" to-port="3"/>
		<edge from-layer="1098" from-port="0" to-layer="1099" to-port="4"/>
		<edge from-layer="1100" from-port="0" to-layer="1101" to-port="0"/>
		<edge from-layer="1101" from-port="1" to-layer="1103" to-port="0"/>
		<edge from-layer="1102" from-port="0" to-layer="1103" to-port="1"/>
		<edge from-layer="1103" from-port="2" to-layer="1105" to-port="0"/>
		<edge from-layer="1104" from-port="0" to-layer="1105" to-port="1"/>
		<edge from-layer="1099" from-port="5" to-layer="1106" to-port="0"/>
		<edge from-layer="1105" from-port="2" to-layer="1106" to-port="1"/>
		<edge from-layer="1106" from-port="2" to-layer="1108" to-port="0"/>
		<edge from-layer="1107" from-port="0" to-layer="1108" to-port="1"/>
		<edge from-layer="1108" from-port="2" to-layer="1113" to-port="0"/>
		<edge from-layer="1109" from-port="0" to-layer="1113" to-port="1"/>
		<edge from-layer="1110" from-port="0" to-layer="1113" to-port="2"/>
		<edge from-layer="1111" from-port="0" to-layer="1113" to-port="3"/>
		<edge from-layer="1112" from-port="0" to-layer="1113" to-port="4"/>
		<edge from-layer="1113" from-port="5" to-layer="1114" to-port="0"/>
		<edge from-layer="556" from-port="5" to-layer="1114" to-port="1"/>
		<edge from-layer="1114" from-port="2" to-layer="1115" to-port="0"/>
		<edge from-layer="1115" from-port="1" to-layer="1120" to-port="0"/>
		<edge from-layer="1116" from-port="0" to-layer="1120" to-port="1"/>
		<edge from-layer="1117" from-port="0" to-layer="1120" to-port="2"/>
		<edge from-layer="1118" from-port="0" to-layer="1120" to-port="3"/>
		<edge from-layer="1119" from-port="0" to-layer="1120" to-port="4"/>
		<edge from-layer="1121" from-port="0" to-layer="1122" to-port="0"/>
		<edge from-layer="1122" from-port="1" to-layer="1124" to-port="0"/>
		<edge from-layer="1123" from-port="0" to-layer="1124" to-port="1"/>
		<edge from-layer="1124" from-port="2" to-layer="1126" to-port="0"/>
		<edge from-layer="1125" from-port="0" to-layer="1126" to-port="1"/>
		<edge from-layer="1120" from-port="5" to-layer="1127" to-port="0"/>
		<edge from-layer="1126" from-port="2" to-layer="1127" to-port="1"/>
		<edge from-layer="1127" from-port="2" to-layer="1129" to-port="0"/>
		<edge from-layer="1128" from-port="0" to-layer="1129" to-port="1"/>
		<edge from-layer="1129" from-port="2" to-layer="1130" to-port="0"/>
		<edge from-layer="1130" from-port="1" to-layer="1135" to-port="0"/>
		<edge from-layer="1131" from-port="0" to-layer="1135" to-port="1"/>
		<edge from-layer="1132" from-port="0" to-layer="1135" to-port="2"/>
		<edge from-layer="1133" from-port="0" to-layer="1135" to-port="3"/>
		<edge from-layer="1134" from-port="0" to-layer="1135" to-port="4"/>
		<edge from-layer="1135" from-port="5" to-layer="1136" to-port="0"/>
		<edge from-layer="1136" from-port="1" to-layer="1141" to-port="0"/>
		<edge from-layer="1137" from-port="0" to-layer="1141" to-port="1"/>
		<edge from-layer="1138" from-port="0" to-layer="1141" to-port="2"/>
		<edge from-layer="1139" from-port="0" to-layer="1141" to-port="3"/>
		<edge from-layer="1140" from-port="0" to-layer="1141" to-port="4"/>
		<edge from-layer="1142" from-port="0" to-layer="1143" to-port="0"/>
		<edge from-layer="1143" from-port="1" to-layer="1145" to-port="0"/>
		<edge from-layer="1144" from-port="0" to-layer="1145" to-port="1"/>
		<edge from-layer="1145" from-port="2" to-layer="1147" to-port="0"/>
		<edge from-layer="1146" from-port="0" to-layer="1147" to-port="1"/>
		<edge from-layer="1141" from-port="5" to-layer="1148" to-port="0"/>
		<edge from-layer="1147" from-port="2" to-layer="1148" to-port="1"/>
		<edge from-layer="1148" from-port="2" to-layer="1150" to-port="0"/>
		<edge from-layer="1149" from-port="0" to-layer="1150" to-port="1"/>
		<edge from-layer="1150" from-port="2" to-layer="1151" to-port="0"/>
		<edge from-layer="1151" from-port="1" to-layer="1156" to-port="0"/>
		<edge from-layer="1152" from-port="0" to-layer="1156" to-port="1"/>
		<edge from-layer="1153" from-port="0" to-layer="1156" to-port="2"/>
		<edge from-layer="1154" from-port="0" to-layer="1156" to-port="3"/>
		<edge from-layer="1155" from-port="0" to-layer="1156" to-port="4"/>
		<edge from-layer="1157" from-port="0" to-layer="1158" to-port="0"/>
		<edge from-layer="1158" from-port="1" to-layer="1160" to-port="0"/>
		<edge from-layer="1159" from-port="0" to-layer="1160" to-port="1"/>
		<edge from-layer="1160" from-port="2" to-layer="1162" to-port="0"/>
		<edge from-layer="1161" from-port="0" to-layer="1162" to-port="1"/>
		<edge from-layer="1156" from-port="5" to-layer="1163" to-port="0"/>
		<edge from-layer="1162" from-port="2" to-layer="1163" to-port="1"/>
		<edge from-layer="1163" from-port="2" to-layer="1165" to-port="0"/>
		<edge from-layer="1164" from-port="0" to-layer="1165" to-port="1"/>
		<edge from-layer="1165" from-port="2" to-layer="1170" to-port="0"/>
		<edge from-layer="1166" from-port="0" to-layer="1170" to-port="1"/>
		<edge from-layer="1167" from-port="0" to-layer="1170" to-port="2"/>
		<edge from-layer="1168" from-port="0" to-layer="1170" to-port="3"/>
		<edge from-layer="1169" from-port="0" to-layer="1170" to-port="4"/>
		<edge from-layer="1171" from-port="0" to-layer="1172" to-port="0"/>
		<edge from-layer="1172" from-port="1" to-layer="1174" to-port="0"/>
		<edge from-layer="1173" from-port="0" to-layer="1174" to-port="1"/>
		<edge from-layer="1174" from-port="2" to-layer="1176" to-port="0"/>
		<edge from-layer="1175" from-port="0" to-layer="1176" to-port="1"/>
		<edge from-layer="1176" from-port="2" to-layer="1178" to-port="0"/>
		<edge from-layer="1177" from-port="0" to-layer="1178" to-port="1"/>
		<edge from-layer="1170" from-port="5" to-layer="1179" to-port="0"/>
		<edge from-layer="1178" from-port="2" to-layer="1179" to-port="1"/>
		<edge from-layer="1179" from-port="2" to-layer="1181" to-port="0"/>
		<edge from-layer="1180" from-port="0" to-layer="1181" to-port="1"/>
		<edge from-layer="1181" from-port="2" to-layer="1182" to-port="0"/>
		<edge from-layer="1182" from-port="1" to-layer="1187" to-port="0"/>
		<edge from-layer="1183" from-port="0" to-layer="1187" to-port="1"/>
		<edge from-layer="1184" from-port="0" to-layer="1187" to-port="2"/>
		<edge from-layer="1185" from-port="0" to-layer="1187" to-port="3"/>
		<edge from-layer="1186" from-port="0" to-layer="1187" to-port="4"/>
		<edge from-layer="1182" from-port="1" to-layer="1189" to-port="0"/>
		<edge from-layer="1189" from-port="1" to-layer="1190" to-port="0"/>
		<edge from-layer="1190" from-port="1" to-layer="1192" to-port="0"/>
		<edge from-layer="1191" from-port="0" to-layer="1192" to-port="1"/>
		<edge from-layer="1188" from-port="0" to-layer="1194" to-port="0"/>
		<edge from-layer="1192" from-port="2" to-layer="1194" to-port="1"/>
		<edge from-layer="1193" from-port="0" to-layer="1194" to-port="2"/>
		<edge from-layer="1187" from-port="5" to-layer="1195" to-port="0"/>
		<edge from-layer="1194" from-port="3" to-layer="1195" to-port="1"/>
		<edge from-layer="1195" from-port="2" to-layer="1197" to-port="0"/>
		<edge from-layer="1196" from-port="0" to-layer="1197" to-port="1"/>
		<edge from-layer="1197" from-port="2" to-layer="1199" to-port="0"/>
		<edge from-layer="1198" from-port="0" to-layer="1199" to-port="1"/>
		<edge from-layer="1199" from-port="2" to-layer="1200" to-port="0"/>
		<edge from-layer="1200" from-port="1" to-layer="1202" to-port="0"/>
		<edge from-layer="1201" from-port="0" to-layer="1202" to-port="1"/>
		<edge from-layer="1202" from-port="2" to-layer="1204" to-port="0"/>
		<edge from-layer="1203" from-port="0" to-layer="1204" to-port="1"/>
		<edge from-layer="1204" from-port="2" to-layer="1205" to-port="0"/>
		<edge from-layer="1205" from-port="1" to-layer="1210" to-port="0"/>
		<edge from-layer="1206" from-port="0" to-layer="1210" to-port="1"/>
		<edge from-layer="1207" from-port="0" to-layer="1210" to-port="2"/>
		<edge from-layer="1208" from-port="0" to-layer="1210" to-port="3"/>
		<edge from-layer="1209" from-port="0" to-layer="1210" to-port="4"/>
		<edge from-layer="1187" from-port="5" to-layer="1211" to-port="0"/>
		<edge from-layer="1210" from-port="5" to-layer="1211" to-port="1"/>
		<edge from-layer="1211" from-port="2" to-layer="1216" to-port="0"/>
		<edge from-layer="1212" from-port="0" to-layer="1216" to-port="1"/>
		<edge from-layer="1213" from-port="0" to-layer="1216" to-port="2"/>
		<edge from-layer="1214" from-port="0" to-layer="1216" to-port="3"/>
		<edge from-layer="1215" from-port="0" to-layer="1216" to-port="4"/>
		<edge from-layer="1217" from-port="0" to-layer="1218" to-port="0"/>
		<edge from-layer="1218" from-port="1" to-layer="1220" to-port="0"/>
		<edge from-layer="1219" from-port="0" to-layer="1220" to-port="1"/>
		<edge from-layer="1220" from-port="2" to-layer="1222" to-port="0"/>
		<edge from-layer="1221" from-port="0" to-layer="1222" to-port="1"/>
		<edge from-layer="1156" from-port="5" to-layer="1223" to-port="0"/>
		<edge from-layer="1222" from-port="2" to-layer="1223" to-port="1"/>
		<edge from-layer="1223" from-port="2" to-layer="1225" to-port="0"/>
		<edge from-layer="1224" from-port="0" to-layer="1225" to-port="1"/>
		<edge from-layer="1225" from-port="2" to-layer="1230" to-port="0"/>
		<edge from-layer="1226" from-port="0" to-layer="1230" to-port="1"/>
		<edge from-layer="1227" from-port="0" to-layer="1230" to-port="2"/>
		<edge from-layer="1228" from-port="0" to-layer="1230" to-port="3"/>
		<edge from-layer="1229" from-port="0" to-layer="1230" to-port="4"/>
		<edge from-layer="1231" from-port="0" to-layer="1232" to-port="0"/>
		<edge from-layer="1232" from-port="1" to-layer="1234" to-port="0"/>
		<edge from-layer="1233" from-port="0" to-layer="1234" to-port="1"/>
		<edge from-layer="1234" from-port="2" to-layer="1236" to-port="0"/>
		<edge from-layer="1235" from-port="0" to-layer="1236" to-port="1"/>
		<edge from-layer="1236" from-port="2" to-layer="1238" to-port="0"/>
		<edge from-layer="1237" from-port="0" to-layer="1238" to-port="1"/>
		<edge from-layer="1230" from-port="5" to-layer="1239" to-port="0"/>
		<edge from-layer="1238" from-port="2" to-layer="1239" to-port="1"/>
		<edge from-layer="1239" from-port="2" to-layer="1241" to-port="0"/>
		<edge from-layer="1240" from-port="0" to-layer="1241" to-port="1"/>
		<edge from-layer="1241" from-port="2" to-layer="1242" to-port="0"/>
		<edge from-layer="1242" from-port="1" to-layer="1247" to-port="0"/>
		<edge from-layer="1243" from-port="0" to-layer="1247" to-port="1"/>
		<edge from-layer="1244" from-port="0" to-layer="1247" to-port="2"/>
		<edge from-layer="1245" from-port="0" to-layer="1247" to-port="3"/>
		<edge from-layer="1246" from-port="0" to-layer="1247" to-port="4"/>
		<edge from-layer="1248" from-port="0" to-layer="1249" to-port="0"/>
		<edge from-layer="1249" from-port="1" to-layer="1251" to-port="0"/>
		<edge from-layer="1250" from-port="0" to-layer="1251" to-port="1"/>
		<edge from-layer="1251" from-port="2" to-layer="1253" to-port="0"/>
		<edge from-layer="1252" from-port="0" to-layer="1253" to-port="1"/>
		<edge from-layer="1247" from-port="5" to-layer="1254" to-port="0"/>
		<edge from-layer="1253" from-port="2" to-layer="1254" to-port="1"/>
		<edge from-layer="1254" from-port="2" to-layer="1256" to-port="0"/>
		<edge from-layer="1255" from-port="0" to-layer="1256" to-port="1"/>
		<edge from-layer="1256" from-port="2" to-layer="1261" to-port="0"/>
		<edge from-layer="1257" from-port="0" to-layer="1261" to-port="1"/>
		<edge from-layer="1258" from-port="0" to-layer="1261" to-port="2"/>
		<edge from-layer="1259" from-port="0" to-layer="1261" to-port="3"/>
		<edge from-layer="1260" from-port="0" to-layer="1261" to-port="4"/>
		<edge from-layer="1262" from-port="0" to-layer="1263" to-port="0"/>
		<edge from-layer="1263" from-port="1" to-layer="1265" to-port="0"/>
		<edge from-layer="1264" from-port="0" to-layer="1265" to-port="1"/>
		<edge from-layer="1265" from-port="2" to-layer="1267" to-port="0"/>
		<edge from-layer="1266" from-port="0" to-layer="1267" to-port="1"/>
		<edge from-layer="1267" from-port="2" to-layer="1269" to-port="0"/>
		<edge from-layer="1268" from-port="0" to-layer="1269" to-port="1"/>
		<edge from-layer="1261" from-port="5" to-layer="1270" to-port="0"/>
		<edge from-layer="1269" from-port="2" to-layer="1270" to-port="1"/>
		<edge from-layer="1270" from-port="2" to-layer="1272" to-port="0"/>
		<edge from-layer="1271" from-port="0" to-layer="1272" to-port="1"/>
		<edge from-layer="1272" from-port="2" to-layer="1273" to-port="0"/>
		<edge from-layer="1273" from-port="1" to-layer="1278" to-port="0"/>
		<edge from-layer="1274" from-port="0" to-layer="1278" to-port="1"/>
		<edge from-layer="1275" from-port="0" to-layer="1278" to-port="2"/>
		<edge from-layer="1276" from-port="0" to-layer="1278" to-port="3"/>
		<edge from-layer="1277" from-port="0" to-layer="1278" to-port="4"/>
		<edge from-layer="1273" from-port="1" to-layer="1280" to-port="0"/>
		<edge from-layer="1280" from-port="1" to-layer="1281" to-port="0"/>
		<edge from-layer="1281" from-port="1" to-layer="1283" to-port="0"/>
		<edge from-layer="1282" from-port="0" to-layer="1283" to-port="1"/>
		<edge from-layer="1279" from-port="0" to-layer="1285" to-port="0"/>
		<edge from-layer="1283" from-port="2" to-layer="1285" to-port="1"/>
		<edge from-layer="1284" from-port="0" to-layer="1285" to-port="2"/>
		<edge from-layer="1278" from-port="5" to-layer="1286" to-port="0"/>
		<edge from-layer="1285" from-port="3" to-layer="1286" to-port="1"/>
		<edge from-layer="1286" from-port="2" to-layer="1288" to-port="0"/>
		<edge from-layer="1287" from-port="0" to-layer="1288" to-port="1"/>
		<edge from-layer="1288" from-port="2" to-layer="1290" to-port="0"/>
		<edge from-layer="1289" from-port="0" to-layer="1290" to-port="1"/>
		<edge from-layer="1290" from-port="2" to-layer="1291" to-port="0"/>
		<edge from-layer="1291" from-port="1" to-layer="1293" to-port="0"/>
		<edge from-layer="1292" from-port="0" to-layer="1293" to-port="1"/>
		<edge from-layer="1293" from-port="2" to-layer="1295" to-port="0"/>
		<edge from-layer="1294" from-port="0" to-layer="1295" to-port="1"/>
		<edge from-layer="1295" from-port="2" to-layer="1296" to-port="0"/>
		<edge from-layer="1296" from-port="1" to-layer="1301" to-port="0"/>
		<edge from-layer="1297" from-port="0" to-layer="1301" to-port="1"/>
		<edge from-layer="1298" from-port="0" to-layer="1301" to-port="2"/>
		<edge from-layer="1299" from-port="0" to-layer="1301" to-port="3"/>
		<edge from-layer="1300" from-port="0" to-layer="1301" to-port="4"/>
		<edge from-layer="1278" from-port="5" to-layer="1302" to-port="0"/>
		<edge from-layer="1301" from-port="5" to-layer="1302" to-port="1"/>
		<edge from-layer="1302" from-port="2" to-layer="1307" to-port="0"/>
		<edge from-layer="1303" from-port="0" to-layer="1307" to-port="1"/>
		<edge from-layer="1304" from-port="0" to-layer="1307" to-port="2"/>
		<edge from-layer="1305" from-port="0" to-layer="1307" to-port="3"/>
		<edge from-layer="1306" from-port="0" to-layer="1307" to-port="4"/>
		<edge from-layer="1216" from-port="5" to-layer="1308" to-port="0"/>
		<edge from-layer="1307" from-port="5" to-layer="1308" to-port="1"/>
		<edge from-layer="1308" from-port="2" to-layer="1313" to-port="0"/>
		<edge from-layer="1309" from-port="0" to-layer="1313" to-port="1"/>
		<edge from-layer="1310" from-port="0" to-layer="1313" to-port="2"/>
		<edge from-layer="1311" from-port="0" to-layer="1313" to-port="3"/>
		<edge from-layer="1312" from-port="0" to-layer="1313" to-port="4"/>
		<edge from-layer="1314" from-port="0" to-layer="1315" to-port="0"/>
		<edge from-layer="1315" from-port="1" to-layer="1317" to-port="0"/>
		<edge from-layer="1316" from-port="0" to-layer="1317" to-port="1"/>
		<edge from-layer="1317" from-port="2" to-layer="1319" to-port="0"/>
		<edge from-layer="1318" from-port="0" to-layer="1319" to-port="1"/>
		<edge from-layer="1156" from-port="5" to-layer="1320" to-port="0"/>
		<edge from-layer="1319" from-port="2" to-layer="1320" to-port="1"/>
		<edge from-layer="1320" from-port="2" to-layer="1322" to-port="0"/>
		<edge from-layer="1321" from-port="0" to-layer="1322" to-port="1"/>
		<edge from-layer="1322" from-port="2" to-layer="1327" to-port="0"/>
		<edge from-layer="1323" from-port="0" to-layer="1327" to-port="1"/>
		<edge from-layer="1324" from-port="0" to-layer="1327" to-port="2"/>
		<edge from-layer="1325" from-port="0" to-layer="1327" to-port="3"/>
		<edge from-layer="1326" from-port="0" to-layer="1327" to-port="4"/>
		<edge from-layer="1328" from-port="0" to-layer="1329" to-port="0"/>
		<edge from-layer="1329" from-port="1" to-layer="1331" to-port="0"/>
		<edge from-layer="1330" from-port="0" to-layer="1331" to-port="1"/>
		<edge from-layer="1331" from-port="2" to-layer="1333" to-port="0"/>
		<edge from-layer="1332" from-port="0" to-layer="1333" to-port="1"/>
		<edge from-layer="1333" from-port="2" to-layer="1335" to-port="0"/>
		<edge from-layer="1334" from-port="0" to-layer="1335" to-port="1"/>
		<edge from-layer="1327" from-port="5" to-layer="1336" to-port="0"/>
		<edge from-layer="1335" from-port="2" to-layer="1336" to-port="1"/>
		<edge from-layer="1336" from-port="2" to-layer="1338" to-port="0"/>
		<edge from-layer="1337" from-port="0" to-layer="1338" to-port="1"/>
		<edge from-layer="1338" from-port="2" to-layer="1339" to-port="0"/>
		<edge from-layer="1339" from-port="1" to-layer="1344" to-port="0"/>
		<edge from-layer="1340" from-port="0" to-layer="1344" to-port="1"/>
		<edge from-layer="1341" from-port="0" to-layer="1344" to-port="2"/>
		<edge from-layer="1342" from-port="0" to-layer="1344" to-port="3"/>
		<edge from-layer="1343" from-port="0" to-layer="1344" to-port="4"/>
		<edge from-layer="1345" from-port="0" to-layer="1346" to-port="0"/>
		<edge from-layer="1346" from-port="1" to-layer="1348" to-port="0"/>
		<edge from-layer="1347" from-port="0" to-layer="1348" to-port="1"/>
		<edge from-layer="1348" from-port="2" to-layer="1350" to-port="0"/>
		<edge from-layer="1349" from-port="0" to-layer="1350" to-port="1"/>
		<edge from-layer="1344" from-port="5" to-layer="1351" to-port="0"/>
		<edge from-layer="1350" from-port="2" to-layer="1351" to-port="1"/>
		<edge from-layer="1351" from-port="2" to-layer="1353" to-port="0"/>
		<edge from-layer="1352" from-port="0" to-layer="1353" to-port="1"/>
		<edge from-layer="1353" from-port="2" to-layer="1358" to-port="0"/>
		<edge from-layer="1354" from-port="0" to-layer="1358" to-port="1"/>
		<edge from-layer="1355" from-port="0" to-layer="1358" to-port="2"/>
		<edge from-layer="1356" from-port="0" to-layer="1358" to-port="3"/>
		<edge from-layer="1357" from-port="0" to-layer="1358" to-port="4"/>
		<edge from-layer="1359" from-port="0" to-layer="1360" to-port="0"/>
		<edge from-layer="1360" from-port="1" to-layer="1362" to-port="0"/>
		<edge from-layer="1361" from-port="0" to-layer="1362" to-port="1"/>
		<edge from-layer="1362" from-port="2" to-layer="1364" to-port="0"/>
		<edge from-layer="1363" from-port="0" to-layer="1364" to-port="1"/>
		<edge from-layer="1364" from-port="2" to-layer="1366" to-port="0"/>
		<edge from-layer="1365" from-port="0" to-layer="1366" to-port="1"/>
		<edge from-layer="1358" from-port="5" to-layer="1367" to-port="0"/>
		<edge from-layer="1366" from-port="2" to-layer="1367" to-port="1"/>
		<edge from-layer="1367" from-port="2" to-layer="1369" to-port="0"/>
		<edge from-layer="1368" from-port="0" to-layer="1369" to-port="1"/>
		<edge from-layer="1369" from-port="2" to-layer="1370" to-port="0"/>
		<edge from-layer="1370" from-port="1" to-layer="1375" to-port="0"/>
		<edge from-layer="1371" from-port="0" to-layer="1375" to-port="1"/>
		<edge from-layer="1372" from-port="0" to-layer="1375" to-port="2"/>
		<edge from-layer="1373" from-port="0" to-layer="1375" to-port="3"/>
		<edge from-layer="1374" from-port="0" to-layer="1375" to-port="4"/>
		<edge from-layer="1376" from-port="0" to-layer="1377" to-port="0"/>
		<edge from-layer="1377" from-port="1" to-layer="1379" to-port="0"/>
		<edge from-layer="1378" from-port="0" to-layer="1379" to-port="1"/>
		<edge from-layer="1379" from-port="2" to-layer="1381" to-port="0"/>
		<edge from-layer="1380" from-port="0" to-layer="1381" to-port="1"/>
		<edge from-layer="1375" from-port="5" to-layer="1382" to-port="0"/>
		<edge from-layer="1381" from-port="2" to-layer="1382" to-port="1"/>
		<edge from-layer="1382" from-port="2" to-layer="1384" to-port="0"/>
		<edge from-layer="1383" from-port="0" to-layer="1384" to-port="1"/>
		<edge from-layer="1384" from-port="2" to-layer="1389" to-port="0"/>
		<edge from-layer="1385" from-port="0" to-layer="1389" to-port="1"/>
		<edge from-layer="1386" from-port="0" to-layer="1389" to-port="2"/>
		<edge from-layer="1387" from-port="0" to-layer="1389" to-port="3"/>
		<edge from-layer="1388" from-port="0" to-layer="1389" to-port="4"/>
		<edge from-layer="1390" from-port="0" to-layer="1391" to-port="0"/>
		<edge from-layer="1391" from-port="1" to-layer="1393" to-port="0"/>
		<edge from-layer="1392" from-port="0" to-layer="1393" to-port="1"/>
		<edge from-layer="1393" from-port="2" to-layer="1395" to-port="0"/>
		<edge from-layer="1394" from-port="0" to-layer="1395" to-port="1"/>
		<edge from-layer="1395" from-port="2" to-layer="1397" to-port="0"/>
		<edge from-layer="1396" from-port="0" to-layer="1397" to-port="1"/>
		<edge from-layer="1389" from-port="5" to-layer="1398" to-port="0"/>
		<edge from-layer="1397" from-port="2" to-layer="1398" to-port="1"/>
		<edge from-layer="1398" from-port="2" to-layer="1400" to-port="0"/>
		<edge from-layer="1399" from-port="0" to-layer="1400" to-port="1"/>
		<edge from-layer="1400" from-port="2" to-layer="1401" to-port="0"/>
		<edge from-layer="1401" from-port="1" to-layer="1406" to-port="0"/>
		<edge from-layer="1402" from-port="0" to-layer="1406" to-port="1"/>
		<edge from-layer="1403" from-port="0" to-layer="1406" to-port="2"/>
		<edge from-layer="1404" from-port="0" to-layer="1406" to-port="3"/>
		<edge from-layer="1405" from-port="0" to-layer="1406" to-port="4"/>
		<edge from-layer="1401" from-port="1" to-layer="1408" to-port="0"/>
		<edge from-layer="1408" from-port="1" to-layer="1409" to-port="0"/>
		<edge from-layer="1409" from-port="1" to-layer="1411" to-port="0"/>
		<edge from-layer="1410" from-port="0" to-layer="1411" to-port="1"/>
		<edge from-layer="1407" from-port="0" to-layer="1413" to-port="0"/>
		<edge from-layer="1411" from-port="2" to-layer="1413" to-port="1"/>
		<edge from-layer="1412" from-port="0" to-layer="1413" to-port="2"/>
		<edge from-layer="1406" from-port="5" to-layer="1414" to-port="0"/>
		<edge from-layer="1413" from-port="3" to-layer="1414" to-port="1"/>
		<edge from-layer="1414" from-port="2" to-layer="1416" to-port="0"/>
		<edge from-layer="1415" from-port="0" to-layer="1416" to-port="1"/>
		<edge from-layer="1416" from-port="2" to-layer="1418" to-port="0"/>
		<edge from-layer="1417" from-port="0" to-layer="1418" to-port="1"/>
		<edge from-layer="1418" from-port="2" to-layer="1419" to-port="0"/>
		<edge from-layer="1419" from-port="1" to-layer="1421" to-port="0"/>
		<edge from-layer="1420" from-port="0" to-layer="1421" to-port="1"/>
		<edge from-layer="1421" from-port="2" to-layer="1423" to-port="0"/>
		<edge from-layer="1422" from-port="0" to-layer="1423" to-port="1"/>
		<edge from-layer="1423" from-port="2" to-layer="1424" to-port="0"/>
		<edge from-layer="1424" from-port="1" to-layer="1429" to-port="0"/>
		<edge from-layer="1425" from-port="0" to-layer="1429" to-port="1"/>
		<edge from-layer="1426" from-port="0" to-layer="1429" to-port="2"/>
		<edge from-layer="1427" from-port="0" to-layer="1429" to-port="3"/>
		<edge from-layer="1428" from-port="0" to-layer="1429" to-port="4"/>
		<edge from-layer="1406" from-port="5" to-layer="1430" to-port="0"/>
		<edge from-layer="1429" from-port="5" to-layer="1430" to-port="1"/>
		<edge from-layer="1430" from-port="2" to-layer="1435" to-port="0"/>
		<edge from-layer="1431" from-port="0" to-layer="1435" to-port="1"/>
		<edge from-layer="1432" from-port="0" to-layer="1435" to-port="2"/>
		<edge from-layer="1433" from-port="0" to-layer="1435" to-port="3"/>
		<edge from-layer="1434" from-port="0" to-layer="1435" to-port="4"/>
		<edge from-layer="1313" from-port="5" to-layer="1436" to-port="0"/>
		<edge from-layer="1435" from-port="5" to-layer="1436" to-port="1"/>
		<edge from-layer="1436" from-port="2" to-layer="1441" to-port="0"/>
		<edge from-layer="1437" from-port="0" to-layer="1441" to-port="1"/>
		<edge from-layer="1438" from-port="0" to-layer="1441" to-port="2"/>
		<edge from-layer="1439" from-port="0" to-layer="1441" to-port="3"/>
		<edge from-layer="1440" from-port="0" to-layer="1441" to-port="4"/>
		<edge from-layer="1442" from-port="0" to-layer="1443" to-port="0"/>
		<edge from-layer="1443" from-port="1" to-layer="1445" to-port="0"/>
		<edge from-layer="1444" from-port="0" to-layer="1445" to-port="1"/>
		<edge from-layer="1445" from-port="2" to-layer="1447" to-port="0"/>
		<edge from-layer="1446" from-port="0" to-layer="1447" to-port="1"/>
		<edge from-layer="1156" from-port="5" to-layer="1448" to-port="0"/>
		<edge from-layer="1447" from-port="2" to-layer="1448" to-port="1"/>
		<edge from-layer="1448" from-port="2" to-layer="1450" to-port="0"/>
		<edge from-layer="1449" from-port="0" to-layer="1450" to-port="1"/>
		<edge from-layer="1450" from-port="2" to-layer="1455" to-port="0"/>
		<edge from-layer="1451" from-port="0" to-layer="1455" to-port="1"/>
		<edge from-layer="1452" from-port="0" to-layer="1455" to-port="2"/>
		<edge from-layer="1453" from-port="0" to-layer="1455" to-port="3"/>
		<edge from-layer="1454" from-port="0" to-layer="1455" to-port="4"/>
		<edge from-layer="1456" from-port="0" to-layer="1457" to-port="0"/>
		<edge from-layer="1457" from-port="1" to-layer="1459" to-port="0"/>
		<edge from-layer="1458" from-port="0" to-layer="1459" to-port="1"/>
		<edge from-layer="1459" from-port="2" to-layer="1461" to-port="0"/>
		<edge from-layer="1460" from-port="0" to-layer="1461" to-port="1"/>
		<edge from-layer="1461" from-port="2" to-layer="1463" to-port="0"/>
		<edge from-layer="1462" from-port="0" to-layer="1463" to-port="1"/>
		<edge from-layer="1455" from-port="5" to-layer="1464" to-port="0"/>
		<edge from-layer="1463" from-port="2" to-layer="1464" to-port="1"/>
		<edge from-layer="1464" from-port="2" to-layer="1466" to-port="0"/>
		<edge from-layer="1465" from-port="0" to-layer="1466" to-port="1"/>
		<edge from-layer="1466" from-port="2" to-layer="1467" to-port="0"/>
		<edge from-layer="1467" from-port="1" to-layer="1472" to-port="0"/>
		<edge from-layer="1468" from-port="0" to-layer="1472" to-port="1"/>
		<edge from-layer="1469" from-port="0" to-layer="1472" to-port="2"/>
		<edge from-layer="1470" from-port="0" to-layer="1472" to-port="3"/>
		<edge from-layer="1471" from-port="0" to-layer="1472" to-port="4"/>
		<edge from-layer="1473" from-port="0" to-layer="1474" to-port="0"/>
		<edge from-layer="1474" from-port="1" to-layer="1476" to-port="0"/>
		<edge from-layer="1475" from-port="0" to-layer="1476" to-port="1"/>
		<edge from-layer="1476" from-port="2" to-layer="1478" to-port="0"/>
		<edge from-layer="1477" from-port="0" to-layer="1478" to-port="1"/>
		<edge from-layer="1472" from-port="5" to-layer="1479" to-port="0"/>
		<edge from-layer="1478" from-port="2" to-layer="1479" to-port="1"/>
		<edge from-layer="1479" from-port="2" to-layer="1481" to-port="0"/>
		<edge from-layer="1480" from-port="0" to-layer="1481" to-port="1"/>
		<edge from-layer="1481" from-port="2" to-layer="1486" to-port="0"/>
		<edge from-layer="1482" from-port="0" to-layer="1486" to-port="1"/>
		<edge from-layer="1483" from-port="0" to-layer="1486" to-port="2"/>
		<edge from-layer="1484" from-port="0" to-layer="1486" to-port="3"/>
		<edge from-layer="1485" from-port="0" to-layer="1486" to-port="4"/>
		<edge from-layer="1487" from-port="0" to-layer="1488" to-port="0"/>
		<edge from-layer="1488" from-port="1" to-layer="1490" to-port="0"/>
		<edge from-layer="1489" from-port="0" to-layer="1490" to-port="1"/>
		<edge from-layer="1490" from-port="2" to-layer="1492" to-port="0"/>
		<edge from-layer="1491" from-port="0" to-layer="1492" to-port="1"/>
		<edge from-layer="1492" from-port="2" to-layer="1494" to-port="0"/>
		<edge from-layer="1493" from-port="0" to-layer="1494" to-port="1"/>
		<edge from-layer="1486" from-port="5" to-layer="1495" to-port="0"/>
		<edge from-layer="1494" from-port="2" to-layer="1495" to-port="1"/>
		<edge from-layer="1495" from-port="2" to-layer="1497" to-port="0"/>
		<edge from-layer="1496" from-port="0" to-layer="1497" to-port="1"/>
		<edge from-layer="1497" from-port="2" to-layer="1498" to-port="0"/>
		<edge from-layer="1498" from-port="1" to-layer="1503" to-port="0"/>
		<edge from-layer="1499" from-port="0" to-layer="1503" to-port="1"/>
		<edge from-layer="1500" from-port="0" to-layer="1503" to-port="2"/>
		<edge from-layer="1501" from-port="0" to-layer="1503" to-port="3"/>
		<edge from-layer="1502" from-port="0" to-layer="1503" to-port="4"/>
		<edge from-layer="1504" from-port="0" to-layer="1505" to-port="0"/>
		<edge from-layer="1505" from-port="1" to-layer="1507" to-port="0"/>
		<edge from-layer="1506" from-port="0" to-layer="1507" to-port="1"/>
		<edge from-layer="1507" from-port="2" to-layer="1509" to-port="0"/>
		<edge from-layer="1508" from-port="0" to-layer="1509" to-port="1"/>
		<edge from-layer="1503" from-port="5" to-layer="1510" to-port="0"/>
		<edge from-layer="1509" from-port="2" to-layer="1510" to-port="1"/>
		<edge from-layer="1510" from-port="2" to-layer="1512" to-port="0"/>
		<edge from-layer="1511" from-port="0" to-layer="1512" to-port="1"/>
		<edge from-layer="1512" from-port="2" to-layer="1517" to-port="0"/>
		<edge from-layer="1513" from-port="0" to-layer="1517" to-port="1"/>
		<edge from-layer="1514" from-port="0" to-layer="1517" to-port="2"/>
		<edge from-layer="1515" from-port="0" to-layer="1517" to-port="3"/>
		<edge from-layer="1516" from-port="0" to-layer="1517" to-port="4"/>
		<edge from-layer="1518" from-port="0" to-layer="1519" to-port="0"/>
		<edge from-layer="1519" from-port="1" to-layer="1521" to-port="0"/>
		<edge from-layer="1520" from-port="0" to-layer="1521" to-port="1"/>
		<edge from-layer="1521" from-port="2" to-layer="1523" to-port="0"/>
		<edge from-layer="1522" from-port="0" to-layer="1523" to-port="1"/>
		<edge from-layer="1523" from-port="2" to-layer="1525" to-port="0"/>
		<edge from-layer="1524" from-port="0" to-layer="1525" to-port="1"/>
		<edge from-layer="1517" from-port="5" to-layer="1526" to-port="0"/>
		<edge from-layer="1525" from-port="2" to-layer="1526" to-port="1"/>
		<edge from-layer="1526" from-port="2" to-layer="1528" to-port="0"/>
		<edge from-layer="1527" from-port="0" to-layer="1528" to-port="1"/>
		<edge from-layer="1528" from-port="2" to-layer="1529" to-port="0"/>
		<edge from-layer="1529" from-port="1" to-layer="1534" to-port="0"/>
		<edge from-layer="1530" from-port="0" to-layer="1534" to-port="1"/>
		<edge from-layer="1531" from-port="0" to-layer="1534" to-port="2"/>
		<edge from-layer="1532" from-port="0" to-layer="1534" to-port="3"/>
		<edge from-layer="1533" from-port="0" to-layer="1534" to-port="4"/>
		<edge from-layer="1535" from-port="0" to-layer="1536" to-port="0"/>
		<edge from-layer="1536" from-port="1" to-layer="1538" to-port="0"/>
		<edge from-layer="1537" from-port="0" to-layer="1538" to-port="1"/>
		<edge from-layer="1538" from-port="2" to-layer="1540" to-port="0"/>
		<edge from-layer="1539" from-port="0" to-layer="1540" to-port="1"/>
		<edge from-layer="1534" from-port="5" to-layer="1541" to-port="0"/>
		<edge from-layer="1540" from-port="2" to-layer="1541" to-port="1"/>
		<edge from-layer="1541" from-port="2" to-layer="1543" to-port="0"/>
		<edge from-layer="1542" from-port="0" to-layer="1543" to-port="1"/>
		<edge from-layer="1543" from-port="2" to-layer="1548" to-port="0"/>
		<edge from-layer="1544" from-port="0" to-layer="1548" to-port="1"/>
		<edge from-layer="1545" from-port="0" to-layer="1548" to-port="2"/>
		<edge from-layer="1546" from-port="0" to-layer="1548" to-port="3"/>
		<edge from-layer="1547" from-port="0" to-layer="1548" to-port="4"/>
		<edge from-layer="1549" from-port="0" to-layer="1550" to-port="0"/>
		<edge from-layer="1550" from-port="1" to-layer="1552" to-port="0"/>
		<edge from-layer="1551" from-port="0" to-layer="1552" to-port="1"/>
		<edge from-layer="1552" from-port="2" to-layer="1554" to-port="0"/>
		<edge from-layer="1553" from-port="0" to-layer="1554" to-port="1"/>
		<edge from-layer="1554" from-port="2" to-layer="1556" to-port="0"/>
		<edge from-layer="1555" from-port="0" to-layer="1556" to-port="1"/>
		<edge from-layer="1548" from-port="5" to-layer="1557" to-port="0"/>
		<edge from-layer="1556" from-port="2" to-layer="1557" to-port="1"/>
		<edge from-layer="1557" from-port="2" to-layer="1559" to-port="0"/>
		<edge from-layer="1558" from-port="0" to-layer="1559" to-port="1"/>
		<edge from-layer="1559" from-port="2" to-layer="1560" to-port="0"/>
		<edge from-layer="1560" from-port="1" to-layer="1565" to-port="0"/>
		<edge from-layer="1561" from-port="0" to-layer="1565" to-port="1"/>
		<edge from-layer="1562" from-port="0" to-layer="1565" to-port="2"/>
		<edge from-layer="1563" from-port="0" to-layer="1565" to-port="3"/>
		<edge from-layer="1564" from-port="0" to-layer="1565" to-port="4"/>
		<edge from-layer="1560" from-port="1" to-layer="1567" to-port="0"/>
		<edge from-layer="1567" from-port="1" to-layer="1568" to-port="0"/>
		<edge from-layer="1568" from-port="1" to-layer="1570" to-port="0"/>
		<edge from-layer="1569" from-port="0" to-layer="1570" to-port="1"/>
		<edge from-layer="1566" from-port="0" to-layer="1572" to-port="0"/>
		<edge from-layer="1570" from-port="2" to-layer="1572" to-port="1"/>
		<edge from-layer="1571" from-port="0" to-layer="1572" to-port="2"/>
		<edge from-layer="1565" from-port="5" to-layer="1573" to-port="0"/>
		<edge from-layer="1572" from-port="3" to-layer="1573" to-port="1"/>
		<edge from-layer="1573" from-port="2" to-layer="1575" to-port="0"/>
		<edge from-layer="1574" from-port="0" to-layer="1575" to-port="1"/>
		<edge from-layer="1575" from-port="2" to-layer="1577" to-port="0"/>
		<edge from-layer="1576" from-port="0" to-layer="1577" to-port="1"/>
		<edge from-layer="1577" from-port="2" to-layer="1578" to-port="0"/>
		<edge from-layer="1578" from-port="1" to-layer="1580" to-port="0"/>
		<edge from-layer="1579" from-port="0" to-layer="1580" to-port="1"/>
		<edge from-layer="1580" from-port="2" to-layer="1582" to-port="0"/>
		<edge from-layer="1581" from-port="0" to-layer="1582" to-port="1"/>
		<edge from-layer="1582" from-port="2" to-layer="1583" to-port="0"/>
		<edge from-layer="1583" from-port="1" to-layer="1588" to-port="0"/>
		<edge from-layer="1584" from-port="0" to-layer="1588" to-port="1"/>
		<edge from-layer="1585" from-port="0" to-layer="1588" to-port="2"/>
		<edge from-layer="1586" from-port="0" to-layer="1588" to-port="3"/>
		<edge from-layer="1587" from-port="0" to-layer="1588" to-port="4"/>
		<edge from-layer="1565" from-port="5" to-layer="1589" to-port="0"/>
		<edge from-layer="1588" from-port="5" to-layer="1589" to-port="1"/>
		<edge from-layer="1589" from-port="2" to-layer="1594" to-port="0"/>
		<edge from-layer="1590" from-port="0" to-layer="1594" to-port="1"/>
		<edge from-layer="1591" from-port="0" to-layer="1594" to-port="2"/>
		<edge from-layer="1592" from-port="0" to-layer="1594" to-port="3"/>
		<edge from-layer="1593" from-port="0" to-layer="1594" to-port="4"/>
		<edge from-layer="1441" from-port="5" to-layer="1595" to-port="0"/>
		<edge from-layer="1594" from-port="5" to-layer="1595" to-port="1"/>
		<edge from-layer="1595" from-port="2" to-layer="1600" to-port="0"/>
		<edge from-layer="1596" from-port="0" to-layer="1600" to-port="1"/>
		<edge from-layer="1597" from-port="0" to-layer="1600" to-port="2"/>
		<edge from-layer="1598" from-port="0" to-layer="1600" to-port="3"/>
		<edge from-layer="1599" from-port="0" to-layer="1600" to-port="4"/>
		<edge from-layer="1601" from-port="0" to-layer="1602" to-port="0"/>
		<edge from-layer="1602" from-port="1" to-layer="1604" to-port="0"/>
		<edge from-layer="1603" from-port="0" to-layer="1604" to-port="1"/>
		<edge from-layer="1604" from-port="2" to-layer="1606" to-port="0"/>
		<edge from-layer="1605" from-port="0" to-layer="1606" to-port="1"/>
		<edge from-layer="1600" from-port="5" to-layer="1607" to-port="0"/>
		<edge from-layer="1606" from-port="2" to-layer="1607" to-port="1"/>
		<edge from-layer="1607" from-port="2" to-layer="1609" to-port="0"/>
		<edge from-layer="1608" from-port="0" to-layer="1609" to-port="1"/>
		<edge from-layer="1609" from-port="2" to-layer="1614" to-port="0"/>
		<edge from-layer="1610" from-port="0" to-layer="1614" to-port="1"/>
		<edge from-layer="1611" from-port="0" to-layer="1614" to-port="2"/>
		<edge from-layer="1612" from-port="0" to-layer="1614" to-port="3"/>
		<edge from-layer="1613" from-port="0" to-layer="1614" to-port="4"/>
		<edge from-layer="1615" from-port="0" to-layer="1616" to-port="0"/>
		<edge from-layer="1616" from-port="1" to-layer="1618" to-port="0"/>
		<edge from-layer="1617" from-port="0" to-layer="1618" to-port="1"/>
		<edge from-layer="1618" from-port="2" to-layer="1620" to-port="0"/>
		<edge from-layer="1619" from-port="0" to-layer="1620" to-port="1"/>
		<edge from-layer="1141" from-port="5" to-layer="1621" to-port="0"/>
		<edge from-layer="1620" from-port="2" to-layer="1621" to-port="1"/>
		<edge from-layer="1621" from-port="2" to-layer="1623" to-port="0"/>
		<edge from-layer="1622" from-port="0" to-layer="1623" to-port="1"/>
		<edge from-layer="1623" from-port="2" to-layer="1628" to-port="0"/>
		<edge from-layer="1624" from-port="0" to-layer="1628" to-port="1"/>
		<edge from-layer="1625" from-port="0" to-layer="1628" to-port="2"/>
		<edge from-layer="1626" from-port="0" to-layer="1628" to-port="3"/>
		<edge from-layer="1627" from-port="0" to-layer="1628" to-port="4"/>
		<edge from-layer="1614" from-port="5" to-layer="1629" to-port="0"/>
		<edge from-layer="1628" from-port="5" to-layer="1629" to-port="1"/>
		<edge from-layer="1629" from-port="2" to-layer="1630" to-port="0"/>
		<edge from-layer="1630" from-port="1" to-layer="1635" to-port="0"/>
		<edge from-layer="1631" from-port="0" to-layer="1635" to-port="1"/>
		<edge from-layer="1632" from-port="0" to-layer="1635" to-port="2"/>
		<edge from-layer="1633" from-port="0" to-layer="1635" to-port="3"/>
		<edge from-layer="1634" from-port="0" to-layer="1635" to-port="4"/>
		<edge from-layer="1636" from-port="0" to-layer="1637" to-port="0"/>
		<edge from-layer="1637" from-port="1" to-layer="1639" to-port="0"/>
		<edge from-layer="1638" from-port="0" to-layer="1639" to-port="1"/>
		<edge from-layer="1639" from-port="2" to-layer="1641" to-port="0"/>
		<edge from-layer="1640" from-port="0" to-layer="1641" to-port="1"/>
		<edge from-layer="1635" from-port="5" to-layer="1642" to-port="0"/>
		<edge from-layer="1641" from-port="2" to-layer="1642" to-port="1"/>
		<edge from-layer="1642" from-port="2" to-layer="1644" to-port="0"/>
		<edge from-layer="1643" from-port="0" to-layer="1644" to-port="1"/>
		<edge from-layer="1644" from-port="2" to-layer="1645" to-port="0"/>
		<edge from-layer="1645" from-port="1" to-layer="1650" to-port="0"/>
		<edge from-layer="1646" from-port="0" to-layer="1650" to-port="1"/>
		<edge from-layer="1647" from-port="0" to-layer="1650" to-port="2"/>
		<edge from-layer="1648" from-port="0" to-layer="1650" to-port="3"/>
		<edge from-layer="1649" from-port="0" to-layer="1650" to-port="4"/>
		<edge from-layer="1651" from-port="0" to-layer="1652" to-port="0"/>
		<edge from-layer="1652" from-port="1" to-layer="1654" to-port="0"/>
		<edge from-layer="1653" from-port="0" to-layer="1654" to-port="1"/>
		<edge from-layer="1654" from-port="2" to-layer="1656" to-port="0"/>
		<edge from-layer="1655" from-port="0" to-layer="1656" to-port="1"/>
		<edge from-layer="1650" from-port="5" to-layer="1657" to-port="0"/>
		<edge from-layer="1656" from-port="2" to-layer="1657" to-port="1"/>
		<edge from-layer="1657" from-port="2" to-layer="1659" to-port="0"/>
		<edge from-layer="1658" from-port="0" to-layer="1659" to-port="1"/>
		<edge from-layer="1659" from-port="2" to-layer="1664" to-port="0"/>
		<edge from-layer="1660" from-port="0" to-layer="1664" to-port="1"/>
		<edge from-layer="1661" from-port="0" to-layer="1664" to-port="2"/>
		<edge from-layer="1662" from-port="0" to-layer="1664" to-port="3"/>
		<edge from-layer="1663" from-port="0" to-layer="1664" to-port="4"/>
		<edge from-layer="1665" from-port="0" to-layer="1666" to-port="0"/>
		<edge from-layer="1666" from-port="1" to-layer="1668" to-port="0"/>
		<edge from-layer="1667" from-port="0" to-layer="1668" to-port="1"/>
		<edge from-layer="1668" from-port="2" to-layer="1670" to-port="0"/>
		<edge from-layer="1669" from-port="0" to-layer="1670" to-port="1"/>
		<edge from-layer="1670" from-port="2" to-layer="1672" to-port="0"/>
		<edge from-layer="1671" from-port="0" to-layer="1672" to-port="1"/>
		<edge from-layer="1664" from-port="5" to-layer="1673" to-port="0"/>
		<edge from-layer="1672" from-port="2" to-layer="1673" to-port="1"/>
		<edge from-layer="1673" from-port="2" to-layer="1675" to-port="0"/>
		<edge from-layer="1674" from-port="0" to-layer="1675" to-port="1"/>
		<edge from-layer="1675" from-port="2" to-layer="1676" to-port="0"/>
		<edge from-layer="1676" from-port="1" to-layer="1681" to-port="0"/>
		<edge from-layer="1677" from-port="0" to-layer="1681" to-port="1"/>
		<edge from-layer="1678" from-port="0" to-layer="1681" to-port="2"/>
		<edge from-layer="1679" from-port="0" to-layer="1681" to-port="3"/>
		<edge from-layer="1680" from-port="0" to-layer="1681" to-port="4"/>
		<edge from-layer="1676" from-port="1" to-layer="1683" to-port="0"/>
		<edge from-layer="1683" from-port="1" to-layer="1684" to-port="0"/>
		<edge from-layer="1684" from-port="1" to-layer="1686" to-port="0"/>
		<edge from-layer="1685" from-port="0" to-layer="1686" to-port="1"/>
		<edge from-layer="1682" from-port="0" to-layer="1688" to-port="0"/>
		<edge from-layer="1686" from-port="2" to-layer="1688" to-port="1"/>
		<edge from-layer="1687" from-port="0" to-layer="1688" to-port="2"/>
		<edge from-layer="1681" from-port="5" to-layer="1689" to-port="0"/>
		<edge from-layer="1688" from-port="3" to-layer="1689" to-port="1"/>
		<edge from-layer="1689" from-port="2" to-layer="1694" to-port="0"/>
		<edge from-layer="1690" from-port="0" to-layer="1694" to-port="1"/>
		<edge from-layer="1691" from-port="0" to-layer="1694" to-port="2"/>
		<edge from-layer="1692" from-port="0" to-layer="1694" to-port="3"/>
		<edge from-layer="1693" from-port="0" to-layer="1694" to-port="4"/>
		<edge from-layer="1694" from-port="5" to-layer="1696" to-port="0"/>
		<edge from-layer="1695" from-port="0" to-layer="1696" to-port="1"/>
		<edge from-layer="1696" from-port="2" to-layer="1698" to-port="0"/>
		<edge from-layer="1698" from-port="1" to-layer="1699" to-port="0"/>
		<edge from-layer="1699" from-port="1" to-layer="1701" to-port="0"/>
		<edge from-layer="1700" from-port="0" to-layer="1701" to-port="1"/>
		<edge from-layer="1697" from-port="0" to-layer="1703" to-port="0"/>
		<edge from-layer="1701" from-port="2" to-layer="1703" to-port="1"/>
		<edge from-layer="1702" from-port="0" to-layer="1703" to-port="2"/>
		<edge from-layer="1696" from-port="2" to-layer="1704" to-port="0"/>
		<edge from-layer="1703" from-port="3" to-layer="1704" to-port="1"/>
		<edge from-layer="1704" from-port="2" to-layer="1706" to-port="0"/>
		<edge from-layer="1705" from-port="0" to-layer="1706" to-port="1"/>
		<edge from-layer="1706" from-port="2" to-layer="1708" to-port="0"/>
		<edge from-layer="1707" from-port="0" to-layer="1708" to-port="1"/>
		<edge from-layer="1708" from-port="2" to-layer="1713" to-port="0"/>
		<edge from-layer="1709" from-port="0" to-layer="1713" to-port="1"/>
		<edge from-layer="1710" from-port="0" to-layer="1713" to-port="2"/>
		<edge from-layer="1711" from-port="0" to-layer="1713" to-port="3"/>
		<edge from-layer="1712" from-port="0" to-layer="1713" to-port="4"/>
		<edge from-layer="1689" from-port="2" to-layer="1714" to-port="0"/>
		<edge from-layer="1713" from-port="5" to-layer="1715" to-port="0"/>
		<edge from-layer="1714" from-port="1" to-layer="1715" to-port="1"/>
		<edge from-layer="1715" from-port="2" to-layer="1717" to-port="0"/>
		<edge from-layer="1716" from-port="0" to-layer="1717" to-port="1"/>
		<edge from-layer="1717" from-port="2" to-layer="1719" to-port="0"/>
		<edge from-layer="1718" from-port="0" to-layer="1719" to-port="1"/>
		<edge from-layer="1719" from-port="2" to-layer="1720" to-port="0"/>
		<edge from-layer="1720" from-port="1" to-layer="1725" to-port="0"/>
		<edge from-layer="1721" from-port="0" to-layer="1725" to-port="1"/>
		<edge from-layer="1722" from-port="0" to-layer="1725" to-port="2"/>
		<edge from-layer="1723" from-port="0" to-layer="1725" to-port="3"/>
		<edge from-layer="1724" from-port="0" to-layer="1725" to-port="4"/>
		<edge from-layer="1681" from-port="5" to-layer="1726" to-port="0"/>
		<edge from-layer="1725" from-port="5" to-layer="1726" to-port="1"/>
		<edge from-layer="1726" from-port="2" to-layer="1731" to-port="0"/>
		<edge from-layer="1727" from-port="0" to-layer="1731" to-port="1"/>
		<edge from-layer="1728" from-port="0" to-layer="1731" to-port="2"/>
		<edge from-layer="1729" from-port="0" to-layer="1731" to-port="3"/>
		<edge from-layer="1730" from-port="0" to-layer="1731" to-port="4"/>
		<edge from-layer="1732" from-port="0" to-layer="1733" to-port="0"/>
		<edge from-layer="1733" from-port="1" to-layer="1735" to-port="0"/>
		<edge from-layer="1734" from-port="0" to-layer="1735" to-port="1"/>
		<edge from-layer="1735" from-port="2" to-layer="1737" to-port="0"/>
		<edge from-layer="1736" from-port="0" to-layer="1737" to-port="1"/>
		<edge from-layer="1650" from-port="5" to-layer="1738" to-port="0"/>
		<edge from-layer="1737" from-port="2" to-layer="1738" to-port="1"/>
		<edge from-layer="1738" from-port="2" to-layer="1740" to-port="0"/>
		<edge from-layer="1739" from-port="0" to-layer="1740" to-port="1"/>
		<edge from-layer="1740" from-port="2" to-layer="1745" to-port="0"/>
		<edge from-layer="1741" from-port="0" to-layer="1745" to-port="1"/>
		<edge from-layer="1742" from-port="0" to-layer="1745" to-port="2"/>
		<edge from-layer="1743" from-port="0" to-layer="1745" to-port="3"/>
		<edge from-layer="1744" from-port="0" to-layer="1745" to-port="4"/>
		<edge from-layer="1746" from-port="0" to-layer="1747" to-port="0"/>
		<edge from-layer="1747" from-port="1" to-layer="1749" to-port="0"/>
		<edge from-layer="1748" from-port="0" to-layer="1749" to-port="1"/>
		<edge from-layer="1749" from-port="2" to-layer="1751" to-port="0"/>
		<edge from-layer="1750" from-port="0" to-layer="1751" to-port="1"/>
		<edge from-layer="1751" from-port="2" to-layer="1753" to-port="0"/>
		<edge from-layer="1752" from-port="0" to-layer="1753" to-port="1"/>
		<edge from-layer="1745" from-port="5" to-layer="1754" to-port="0"/>
		<edge from-layer="1753" from-port="2" to-layer="1754" to-port="1"/>
		<edge from-layer="1754" from-port="2" to-layer="1756" to-port="0"/>
		<edge from-layer="1755" from-port="0" to-layer="1756" to-port="1"/>
		<edge from-layer="1756" from-port="2" to-layer="1757" to-port="0"/>
		<edge from-layer="1757" from-port="1" to-layer="1762" to-port="0"/>
		<edge from-layer="1758" from-port="0" to-layer="1762" to-port="1"/>
		<edge from-layer="1759" from-port="0" to-layer="1762" to-port="2"/>
		<edge from-layer="1760" from-port="0" to-layer="1762" to-port="3"/>
		<edge from-layer="1761" from-port="0" to-layer="1762" to-port="4"/>
		<edge from-layer="1763" from-port="0" to-layer="1764" to-port="0"/>
		<edge from-layer="1764" from-port="1" to-layer="1766" to-port="0"/>
		<edge from-layer="1765" from-port="0" to-layer="1766" to-port="1"/>
		<edge from-layer="1766" from-port="2" to-layer="1768" to-port="0"/>
		<edge from-layer="1767" from-port="0" to-layer="1768" to-port="1"/>
		<edge from-layer="1762" from-port="5" to-layer="1769" to-port="0"/>
		<edge from-layer="1768" from-port="2" to-layer="1769" to-port="1"/>
		<edge from-layer="1769" from-port="2" to-layer="1771" to-port="0"/>
		<edge from-layer="1770" from-port="0" to-layer="1771" to-port="1"/>
		<edge from-layer="1771" from-port="2" to-layer="1776" to-port="0"/>
		<edge from-layer="1772" from-port="0" to-layer="1776" to-port="1"/>
		<edge from-layer="1773" from-port="0" to-layer="1776" to-port="2"/>
		<edge from-layer="1774" from-port="0" to-layer="1776" to-port="3"/>
		<edge from-layer="1775" from-port="0" to-layer="1776" to-port="4"/>
		<edge from-layer="1777" from-port="0" to-layer="1778" to-port="0"/>
		<edge from-layer="1778" from-port="1" to-layer="1780" to-port="0"/>
		<edge from-layer="1779" from-port="0" to-layer="1780" to-port="1"/>
		<edge from-layer="1780" from-port="2" to-layer="1782" to-port="0"/>
		<edge from-layer="1781" from-port="0" to-layer="1782" to-port="1"/>
		<edge from-layer="1782" from-port="2" to-layer="1784" to-port="0"/>
		<edge from-layer="1783" from-port="0" to-layer="1784" to-port="1"/>
		<edge from-layer="1776" from-port="5" to-layer="1785" to-port="0"/>
		<edge from-layer="1784" from-port="2" to-layer="1785" to-port="1"/>
		<edge from-layer="1785" from-port="2" to-layer="1787" to-port="0"/>
		<edge from-layer="1786" from-port="0" to-layer="1787" to-port="1"/>
		<edge from-layer="1787" from-port="2" to-layer="1788" to-port="0"/>
		<edge from-layer="1788" from-port="1" to-layer="1793" to-port="0"/>
		<edge from-layer="1789" from-port="0" to-layer="1793" to-port="1"/>
		<edge from-layer="1790" from-port="0" to-layer="1793" to-port="2"/>
		<edge from-layer="1791" from-port="0" to-layer="1793" to-port="3"/>
		<edge from-layer="1792" from-port="0" to-layer="1793" to-port="4"/>
		<edge from-layer="1788" from-port="1" to-layer="1795" to-port="0"/>
		<edge from-layer="1795" from-port="1" to-layer="1796" to-port="0"/>
		<edge from-layer="1796" from-port="1" to-layer="1798" to-port="0"/>
		<edge from-layer="1797" from-port="0" to-layer="1798" to-port="1"/>
		<edge from-layer="1794" from-port="0" to-layer="1800" to-port="0"/>
		<edge from-layer="1798" from-port="2" to-layer="1800" to-port="1"/>
		<edge from-layer="1799" from-port="0" to-layer="1800" to-port="2"/>
		<edge from-layer="1793" from-port="5" to-layer="1801" to-port="0"/>
		<edge from-layer="1800" from-port="3" to-layer="1801" to-port="1"/>
		<edge from-layer="1801" from-port="2" to-layer="1806" to-port="0"/>
		<edge from-layer="1802" from-port="0" to-layer="1806" to-port="1"/>
		<edge from-layer="1803" from-port="0" to-layer="1806" to-port="2"/>
		<edge from-layer="1804" from-port="0" to-layer="1806" to-port="3"/>
		<edge from-layer="1805" from-port="0" to-layer="1806" to-port="4"/>
		<edge from-layer="1806" from-port="5" to-layer="1808" to-port="0"/>
		<edge from-layer="1807" from-port="0" to-layer="1808" to-port="1"/>
		<edge from-layer="1808" from-port="2" to-layer="1810" to-port="0"/>
		<edge from-layer="1810" from-port="1" to-layer="1811" to-port="0"/>
		<edge from-layer="1811" from-port="1" to-layer="1813" to-port="0"/>
		<edge from-layer="1812" from-port="0" to-layer="1813" to-port="1"/>
		<edge from-layer="1809" from-port="0" to-layer="1815" to-port="0"/>
		<edge from-layer="1813" from-port="2" to-layer="1815" to-port="1"/>
		<edge from-layer="1814" from-port="0" to-layer="1815" to-port="2"/>
		<edge from-layer="1808" from-port="2" to-layer="1816" to-port="0"/>
		<edge from-layer="1815" from-port="3" to-layer="1816" to-port="1"/>
		<edge from-layer="1816" from-port="2" to-layer="1818" to-port="0"/>
		<edge from-layer="1817" from-port="0" to-layer="1818" to-port="1"/>
		<edge from-layer="1818" from-port="2" to-layer="1820" to-port="0"/>
		<edge from-layer="1819" from-port="0" to-layer="1820" to-port="1"/>
		<edge from-layer="1820" from-port="2" to-layer="1825" to-port="0"/>
		<edge from-layer="1821" from-port="0" to-layer="1825" to-port="1"/>
		<edge from-layer="1822" from-port="0" to-layer="1825" to-port="2"/>
		<edge from-layer="1823" from-port="0" to-layer="1825" to-port="3"/>
		<edge from-layer="1824" from-port="0" to-layer="1825" to-port="4"/>
		<edge from-layer="1801" from-port="2" to-layer="1826" to-port="0"/>
		<edge from-layer="1825" from-port="5" to-layer="1827" to-port="0"/>
		<edge from-layer="1826" from-port="1" to-layer="1827" to-port="1"/>
		<edge from-layer="1827" from-port="2" to-layer="1829" to-port="0"/>
		<edge from-layer="1828" from-port="0" to-layer="1829" to-port="1"/>
		<edge from-layer="1829" from-port="2" to-layer="1831" to-port="0"/>
		<edge from-layer="1830" from-port="0" to-layer="1831" to-port="1"/>
		<edge from-layer="1831" from-port="2" to-layer="1832" to-port="0"/>
		<edge from-layer="1832" from-port="1" to-layer="1837" to-port="0"/>
		<edge from-layer="1833" from-port="0" to-layer="1837" to-port="1"/>
		<edge from-layer="1834" from-port="0" to-layer="1837" to-port="2"/>
		<edge from-layer="1835" from-port="0" to-layer="1837" to-port="3"/>
		<edge from-layer="1836" from-port="0" to-layer="1837" to-port="4"/>
		<edge from-layer="1793" from-port="5" to-layer="1838" to-port="0"/>
		<edge from-layer="1837" from-port="5" to-layer="1838" to-port="1"/>
		<edge from-layer="1838" from-port="2" to-layer="1843" to-port="0"/>
		<edge from-layer="1839" from-port="0" to-layer="1843" to-port="1"/>
		<edge from-layer="1840" from-port="0" to-layer="1843" to-port="2"/>
		<edge from-layer="1841" from-port="0" to-layer="1843" to-port="3"/>
		<edge from-layer="1842" from-port="0" to-layer="1843" to-port="4"/>
		<edge from-layer="1731" from-port="5" to-layer="1844" to-port="0"/>
		<edge from-layer="1843" from-port="5" to-layer="1844" to-port="1"/>
		<edge from-layer="1844" from-port="2" to-layer="1849" to-port="0"/>
		<edge from-layer="1845" from-port="0" to-layer="1849" to-port="1"/>
		<edge from-layer="1846" from-port="0" to-layer="1849" to-port="2"/>
		<edge from-layer="1847" from-port="0" to-layer="1849" to-port="3"/>
		<edge from-layer="1848" from-port="0" to-layer="1849" to-port="4"/>
		<edge from-layer="1850" from-port="0" to-layer="1851" to-port="0"/>
		<edge from-layer="1851" from-port="1" to-layer="1853" to-port="0"/>
		<edge from-layer="1852" from-port="0" to-layer="1853" to-port="1"/>
		<edge from-layer="1853" from-port="2" to-layer="1855" to-port="0"/>
		<edge from-layer="1854" from-port="0" to-layer="1855" to-port="1"/>
		<edge from-layer="1650" from-port="5" to-layer="1856" to-port="0"/>
		<edge from-layer="1855" from-port="2" to-layer="1856" to-port="1"/>
		<edge from-layer="1856" from-port="2" to-layer="1858" to-port="0"/>
		<edge from-layer="1857" from-port="0" to-layer="1858" to-port="1"/>
		<edge from-layer="1858" from-port="2" to-layer="1863" to-port="0"/>
		<edge from-layer="1859" from-port="0" to-layer="1863" to-port="1"/>
		<edge from-layer="1860" from-port="0" to-layer="1863" to-port="2"/>
		<edge from-layer="1861" from-port="0" to-layer="1863" to-port="3"/>
		<edge from-layer="1862" from-port="0" to-layer="1863" to-port="4"/>
		<edge from-layer="1864" from-port="0" to-layer="1865" to-port="0"/>
		<edge from-layer="1865" from-port="1" to-layer="1867" to-port="0"/>
		<edge from-layer="1866" from-port="0" to-layer="1867" to-port="1"/>
		<edge from-layer="1867" from-port="2" to-layer="1869" to-port="0"/>
		<edge from-layer="1868" from-port="0" to-layer="1869" to-port="1"/>
		<edge from-layer="1869" from-port="2" to-layer="1871" to-port="0"/>
		<edge from-layer="1870" from-port="0" to-layer="1871" to-port="1"/>
		<edge from-layer="1863" from-port="5" to-layer="1872" to-port="0"/>
		<edge from-layer="1871" from-port="2" to-layer="1872" to-port="1"/>
		<edge from-layer="1872" from-port="2" to-layer="1874" to-port="0"/>
		<edge from-layer="1873" from-port="0" to-layer="1874" to-port="1"/>
		<edge from-layer="1874" from-port="2" to-layer="1875" to-port="0"/>
		<edge from-layer="1875" from-port="1" to-layer="1880" to-port="0"/>
		<edge from-layer="1876" from-port="0" to-layer="1880" to-port="1"/>
		<edge from-layer="1877" from-port="0" to-layer="1880" to-port="2"/>
		<edge from-layer="1878" from-port="0" to-layer="1880" to-port="3"/>
		<edge from-layer="1879" from-port="0" to-layer="1880" to-port="4"/>
		<edge from-layer="1881" from-port="0" to-layer="1882" to-port="0"/>
		<edge from-layer="1882" from-port="1" to-layer="1884" to-port="0"/>
		<edge from-layer="1883" from-port="0" to-layer="1884" to-port="1"/>
		<edge from-layer="1884" from-port="2" to-layer="1886" to-port="0"/>
		<edge from-layer="1885" from-port="0" to-layer="1886" to-port="1"/>
		<edge from-layer="1880" from-port="5" to-layer="1887" to-port="0"/>
		<edge from-layer="1886" from-port="2" to-layer="1887" to-port="1"/>
		<edge from-layer="1887" from-port="2" to-layer="1889" to-port="0"/>
		<edge from-layer="1888" from-port="0" to-layer="1889" to-port="1"/>
		<edge from-layer="1889" from-port="2" to-layer="1894" to-port="0"/>
		<edge from-layer="1890" from-port="0" to-layer="1894" to-port="1"/>
		<edge from-layer="1891" from-port="0" to-layer="1894" to-port="2"/>
		<edge from-layer="1892" from-port="0" to-layer="1894" to-port="3"/>
		<edge from-layer="1893" from-port="0" to-layer="1894" to-port="4"/>
		<edge from-layer="1895" from-port="0" to-layer="1896" to-port="0"/>
		<edge from-layer="1896" from-port="1" to-layer="1898" to-port="0"/>
		<edge from-layer="1897" from-port="0" to-layer="1898" to-port="1"/>
		<edge from-layer="1898" from-port="2" to-layer="1900" to-port="0"/>
		<edge from-layer="1899" from-port="0" to-layer="1900" to-port="1"/>
		<edge from-layer="1900" from-port="2" to-layer="1902" to-port="0"/>
		<edge from-layer="1901" from-port="0" to-layer="1902" to-port="1"/>
		<edge from-layer="1894" from-port="5" to-layer="1903" to-port="0"/>
		<edge from-layer="1902" from-port="2" to-layer="1903" to-port="1"/>
		<edge from-layer="1903" from-port="2" to-layer="1905" to-port="0"/>
		<edge from-layer="1904" from-port="0" to-layer="1905" to-port="1"/>
		<edge from-layer="1905" from-port="2" to-layer="1906" to-port="0"/>
		<edge from-layer="1906" from-port="1" to-layer="1911" to-port="0"/>
		<edge from-layer="1907" from-port="0" to-layer="1911" to-port="1"/>
		<edge from-layer="1908" from-port="0" to-layer="1911" to-port="2"/>
		<edge from-layer="1909" from-port="0" to-layer="1911" to-port="3"/>
		<edge from-layer="1910" from-port="0" to-layer="1911" to-port="4"/>
		<edge from-layer="1912" from-port="0" to-layer="1913" to-port="0"/>
		<edge from-layer="1913" from-port="1" to-layer="1915" to-port="0"/>
		<edge from-layer="1914" from-port="0" to-layer="1915" to-port="1"/>
		<edge from-layer="1915" from-port="2" to-layer="1917" to-port="0"/>
		<edge from-layer="1916" from-port="0" to-layer="1917" to-port="1"/>
		<edge from-layer="1911" from-port="5" to-layer="1918" to-port="0"/>
		<edge from-layer="1917" from-port="2" to-layer="1918" to-port="1"/>
		<edge from-layer="1918" from-port="2" to-layer="1920" to-port="0"/>
		<edge from-layer="1919" from-port="0" to-layer="1920" to-port="1"/>
		<edge from-layer="1920" from-port="2" to-layer="1925" to-port="0"/>
		<edge from-layer="1921" from-port="0" to-layer="1925" to-port="1"/>
		<edge from-layer="1922" from-port="0" to-layer="1925" to-port="2"/>
		<edge from-layer="1923" from-port="0" to-layer="1925" to-port="3"/>
		<edge from-layer="1924" from-port="0" to-layer="1925" to-port="4"/>
		<edge from-layer="1926" from-port="0" to-layer="1927" to-port="0"/>
		<edge from-layer="1927" from-port="1" to-layer="1929" to-port="0"/>
		<edge from-layer="1928" from-port="0" to-layer="1929" to-port="1"/>
		<edge from-layer="1929" from-port="2" to-layer="1931" to-port="0"/>
		<edge from-layer="1930" from-port="0" to-layer="1931" to-port="1"/>
		<edge from-layer="1931" from-port="2" to-layer="1933" to-port="0"/>
		<edge from-layer="1932" from-port="0" to-layer="1933" to-port="1"/>
		<edge from-layer="1925" from-port="5" to-layer="1934" to-port="0"/>
		<edge from-layer="1933" from-port="2" to-layer="1934" to-port="1"/>
		<edge from-layer="1934" from-port="2" to-layer="1936" to-port="0"/>
		<edge from-layer="1935" from-port="0" to-layer="1936" to-port="1"/>
		<edge from-layer="1936" from-port="2" to-layer="1937" to-port="0"/>
		<edge from-layer="1937" from-port="1" to-layer="1942" to-port="0"/>
		<edge from-layer="1938" from-port="0" to-layer="1942" to-port="1"/>
		<edge from-layer="1939" from-port="0" to-layer="1942" to-port="2"/>
		<edge from-layer="1940" from-port="0" to-layer="1942" to-port="3"/>
		<edge from-layer="1941" from-port="0" to-layer="1942" to-port="4"/>
		<edge from-layer="1937" from-port="1" to-layer="1944" to-port="0"/>
		<edge from-layer="1944" from-port="1" to-layer="1945" to-port="0"/>
		<edge from-layer="1945" from-port="1" to-layer="1947" to-port="0"/>
		<edge from-layer="1946" from-port="0" to-layer="1947" to-port="1"/>
		<edge from-layer="1943" from-port="0" to-layer="1949" to-port="0"/>
		<edge from-layer="1947" from-port="2" to-layer="1949" to-port="1"/>
		<edge from-layer="1948" from-port="0" to-layer="1949" to-port="2"/>
		<edge from-layer="1942" from-port="5" to-layer="1950" to-port="0"/>
		<edge from-layer="1949" from-port="3" to-layer="1950" to-port="1"/>
		<edge from-layer="1950" from-port="2" to-layer="1955" to-port="0"/>
		<edge from-layer="1951" from-port="0" to-layer="1955" to-port="1"/>
		<edge from-layer="1952" from-port="0" to-layer="1955" to-port="2"/>
		<edge from-layer="1953" from-port="0" to-layer="1955" to-port="3"/>
		<edge from-layer="1954" from-port="0" to-layer="1955" to-port="4"/>
		<edge from-layer="1955" from-port="5" to-layer="1957" to-port="0"/>
		<edge from-layer="1956" from-port="0" to-layer="1957" to-port="1"/>
		<edge from-layer="1957" from-port="2" to-layer="1959" to-port="0"/>
		<edge from-layer="1959" from-port="1" to-layer="1960" to-port="0"/>
		<edge from-layer="1960" from-port="1" to-layer="1962" to-port="0"/>
		<edge from-layer="1961" from-port="0" to-layer="1962" to-port="1"/>
		<edge from-layer="1958" from-port="0" to-layer="1964" to-port="0"/>
		<edge from-layer="1962" from-port="2" to-layer="1964" to-port="1"/>
		<edge from-layer="1963" from-port="0" to-layer="1964" to-port="2"/>
		<edge from-layer="1957" from-port="2" to-layer="1965" to-port="0"/>
		<edge from-layer="1964" from-port="3" to-layer="1965" to-port="1"/>
		<edge from-layer="1965" from-port="2" to-layer="1967" to-port="0"/>
		<edge from-layer="1966" from-port="0" to-layer="1967" to-port="1"/>
		<edge from-layer="1967" from-port="2" to-layer="1969" to-port="0"/>
		<edge from-layer="1968" from-port="0" to-layer="1969" to-port="1"/>
		<edge from-layer="1969" from-port="2" to-layer="1974" to-port="0"/>
		<edge from-layer="1970" from-port="0" to-layer="1974" to-port="1"/>
		<edge from-layer="1971" from-port="0" to-layer="1974" to-port="2"/>
		<edge from-layer="1972" from-port="0" to-layer="1974" to-port="3"/>
		<edge from-layer="1973" from-port="0" to-layer="1974" to-port="4"/>
		<edge from-layer="1950" from-port="2" to-layer="1975" to-port="0"/>
		<edge from-layer="1974" from-port="5" to-layer="1976" to-port="0"/>
		<edge from-layer="1975" from-port="1" to-layer="1976" to-port="1"/>
		<edge from-layer="1976" from-port="2" to-layer="1978" to-port="0"/>
		<edge from-layer="1977" from-port="0" to-layer="1978" to-port="1"/>
		<edge from-layer="1978" from-port="2" to-layer="1980" to-port="0"/>
		<edge from-layer="1979" from-port="0" to-layer="1980" to-port="1"/>
		<edge from-layer="1980" from-port="2" to-layer="1981" to-port="0"/>
		<edge from-layer="1981" from-port="1" to-layer="1986" to-port="0"/>
		<edge from-layer="1982" from-port="0" to-layer="1986" to-port="1"/>
		<edge from-layer="1983" from-port="0" to-layer="1986" to-port="2"/>
		<edge from-layer="1984" from-port="0" to-layer="1986" to-port="3"/>
		<edge from-layer="1985" from-port="0" to-layer="1986" to-port="4"/>
		<edge from-layer="1942" from-port="5" to-layer="1987" to-port="0"/>
		<edge from-layer="1986" from-port="5" to-layer="1987" to-port="1"/>
		<edge from-layer="1987" from-port="2" to-layer="1992" to-port="0"/>
		<edge from-layer="1988" from-port="0" to-layer="1992" to-port="1"/>
		<edge from-layer="1989" from-port="0" to-layer="1992" to-port="2"/>
		<edge from-layer="1990" from-port="0" to-layer="1992" to-port="3"/>
		<edge from-layer="1991" from-port="0" to-layer="1992" to-port="4"/>
		<edge from-layer="1849" from-port="5" to-layer="1993" to-port="0"/>
		<edge from-layer="1992" from-port="5" to-layer="1993" to-port="1"/>
		<edge from-layer="1993" from-port="2" to-layer="1998" to-port="0"/>
		<edge from-layer="1994" from-port="0" to-layer="1998" to-port="1"/>
		<edge from-layer="1995" from-port="0" to-layer="1998" to-port="2"/>
		<edge from-layer="1996" from-port="0" to-layer="1998" to-port="3"/>
		<edge from-layer="1997" from-port="0" to-layer="1998" to-port="4"/>
		<edge from-layer="1999" from-port="0" to-layer="2000" to-port="0"/>
		<edge from-layer="2000" from-port="1" to-layer="2002" to-port="0"/>
		<edge from-layer="2001" from-port="0" to-layer="2002" to-port="1"/>
		<edge from-layer="2002" from-port="2" to-layer="2004" to-port="0"/>
		<edge from-layer="2003" from-port="0" to-layer="2004" to-port="1"/>
		<edge from-layer="1650" from-port="5" to-layer="2005" to-port="0"/>
		<edge from-layer="2004" from-port="2" to-layer="2005" to-port="1"/>
		<edge from-layer="2005" from-port="2" to-layer="2007" to-port="0"/>
		<edge from-layer="2006" from-port="0" to-layer="2007" to-port="1"/>
		<edge from-layer="2007" from-port="2" to-layer="2012" to-port="0"/>
		<edge from-layer="2008" from-port="0" to-layer="2012" to-port="1"/>
		<edge from-layer="2009" from-port="0" to-layer="2012" to-port="2"/>
		<edge from-layer="2010" from-port="0" to-layer="2012" to-port="3"/>
		<edge from-layer="2011" from-port="0" to-layer="2012" to-port="4"/>
		<edge from-layer="2013" from-port="0" to-layer="2014" to-port="0"/>
		<edge from-layer="2014" from-port="1" to-layer="2016" to-port="0"/>
		<edge from-layer="2015" from-port="0" to-layer="2016" to-port="1"/>
		<edge from-layer="2016" from-port="2" to-layer="2018" to-port="0"/>
		<edge from-layer="2017" from-port="0" to-layer="2018" to-port="1"/>
		<edge from-layer="2018" from-port="2" to-layer="2020" to-port="0"/>
		<edge from-layer="2019" from-port="0" to-layer="2020" to-port="1"/>
		<edge from-layer="2012" from-port="5" to-layer="2021" to-port="0"/>
		<edge from-layer="2020" from-port="2" to-layer="2021" to-port="1"/>
		<edge from-layer="2021" from-port="2" to-layer="2023" to-port="0"/>
		<edge from-layer="2022" from-port="0" to-layer="2023" to-port="1"/>
		<edge from-layer="2023" from-port="2" to-layer="2024" to-port="0"/>
		<edge from-layer="2024" from-port="1" to-layer="2029" to-port="0"/>
		<edge from-layer="2025" from-port="0" to-layer="2029" to-port="1"/>
		<edge from-layer="2026" from-port="0" to-layer="2029" to-port="2"/>
		<edge from-layer="2027" from-port="0" to-layer="2029" to-port="3"/>
		<edge from-layer="2028" from-port="0" to-layer="2029" to-port="4"/>
		<edge from-layer="2030" from-port="0" to-layer="2031" to-port="0"/>
		<edge from-layer="2031" from-port="1" to-layer="2033" to-port="0"/>
		<edge from-layer="2032" from-port="0" to-layer="2033" to-port="1"/>
		<edge from-layer="2033" from-port="2" to-layer="2035" to-port="0"/>
		<edge from-layer="2034" from-port="0" to-layer="2035" to-port="1"/>
		<edge from-layer="2029" from-port="5" to-layer="2036" to-port="0"/>
		<edge from-layer="2035" from-port="2" to-layer="2036" to-port="1"/>
		<edge from-layer="2036" from-port="2" to-layer="2038" to-port="0"/>
		<edge from-layer="2037" from-port="0" to-layer="2038" to-port="1"/>
		<edge from-layer="2038" from-port="2" to-layer="2043" to-port="0"/>
		<edge from-layer="2039" from-port="0" to-layer="2043" to-port="1"/>
		<edge from-layer="2040" from-port="0" to-layer="2043" to-port="2"/>
		<edge from-layer="2041" from-port="0" to-layer="2043" to-port="3"/>
		<edge from-layer="2042" from-port="0" to-layer="2043" to-port="4"/>
		<edge from-layer="2044" from-port="0" to-layer="2045" to-port="0"/>
		<edge from-layer="2045" from-port="1" to-layer="2047" to-port="0"/>
		<edge from-layer="2046" from-port="0" to-layer="2047" to-port="1"/>
		<edge from-layer="2047" from-port="2" to-layer="2049" to-port="0"/>
		<edge from-layer="2048" from-port="0" to-layer="2049" to-port="1"/>
		<edge from-layer="2049" from-port="2" to-layer="2051" to-port="0"/>
		<edge from-layer="2050" from-port="0" to-layer="2051" to-port="1"/>
		<edge from-layer="2043" from-port="5" to-layer="2052" to-port="0"/>
		<edge from-layer="2051" from-port="2" to-layer="2052" to-port="1"/>
		<edge from-layer="2052" from-port="2" to-layer="2054" to-port="0"/>
		<edge from-layer="2053" from-port="0" to-layer="2054" to-port="1"/>
		<edge from-layer="2054" from-port="2" to-layer="2055" to-port="0"/>
		<edge from-layer="2055" from-port="1" to-layer="2060" to-port="0"/>
		<edge from-layer="2056" from-port="0" to-layer="2060" to-port="1"/>
		<edge from-layer="2057" from-port="0" to-layer="2060" to-port="2"/>
		<edge from-layer="2058" from-port="0" to-layer="2060" to-port="3"/>
		<edge from-layer="2059" from-port="0" to-layer="2060" to-port="4"/>
		<edge from-layer="2061" from-port="0" to-layer="2062" to-port="0"/>
		<edge from-layer="2062" from-port="1" to-layer="2064" to-port="0"/>
		<edge from-layer="2063" from-port="0" to-layer="2064" to-port="1"/>
		<edge from-layer="2064" from-port="2" to-layer="2066" to-port="0"/>
		<edge from-layer="2065" from-port="0" to-layer="2066" to-port="1"/>
		<edge from-layer="2060" from-port="5" to-layer="2067" to-port="0"/>
		<edge from-layer="2066" from-port="2" to-layer="2067" to-port="1"/>
		<edge from-layer="2067" from-port="2" to-layer="2069" to-port="0"/>
		<edge from-layer="2068" from-port="0" to-layer="2069" to-port="1"/>
		<edge from-layer="2069" from-port="2" to-layer="2074" to-port="0"/>
		<edge from-layer="2070" from-port="0" to-layer="2074" to-port="1"/>
		<edge from-layer="2071" from-port="0" to-layer="2074" to-port="2"/>
		<edge from-layer="2072" from-port="0" to-layer="2074" to-port="3"/>
		<edge from-layer="2073" from-port="0" to-layer="2074" to-port="4"/>
		<edge from-layer="2075" from-port="0" to-layer="2076" to-port="0"/>
		<edge from-layer="2076" from-port="1" to-layer="2078" to-port="0"/>
		<edge from-layer="2077" from-port="0" to-layer="2078" to-port="1"/>
		<edge from-layer="2078" from-port="2" to-layer="2080" to-port="0"/>
		<edge from-layer="2079" from-port="0" to-layer="2080" to-port="1"/>
		<edge from-layer="2080" from-port="2" to-layer="2082" to-port="0"/>
		<edge from-layer="2081" from-port="0" to-layer="2082" to-port="1"/>
		<edge from-layer="2074" from-port="5" to-layer="2083" to-port="0"/>
		<edge from-layer="2082" from-port="2" to-layer="2083" to-port="1"/>
		<edge from-layer="2083" from-port="2" to-layer="2085" to-port="0"/>
		<edge from-layer="2084" from-port="0" to-layer="2085" to-port="1"/>
		<edge from-layer="2085" from-port="2" to-layer="2086" to-port="0"/>
		<edge from-layer="2086" from-port="1" to-layer="2091" to-port="0"/>
		<edge from-layer="2087" from-port="0" to-layer="2091" to-port="1"/>
		<edge from-layer="2088" from-port="0" to-layer="2091" to-port="2"/>
		<edge from-layer="2089" from-port="0" to-layer="2091" to-port="3"/>
		<edge from-layer="2090" from-port="0" to-layer="2091" to-port="4"/>
		<edge from-layer="2092" from-port="0" to-layer="2093" to-port="0"/>
		<edge from-layer="2093" from-port="1" to-layer="2095" to-port="0"/>
		<edge from-layer="2094" from-port="0" to-layer="2095" to-port="1"/>
		<edge from-layer="2095" from-port="2" to-layer="2097" to-port="0"/>
		<edge from-layer="2096" from-port="0" to-layer="2097" to-port="1"/>
		<edge from-layer="2091" from-port="5" to-layer="2098" to-port="0"/>
		<edge from-layer="2097" from-port="2" to-layer="2098" to-port="1"/>
		<edge from-layer="2098" from-port="2" to-layer="2100" to-port="0"/>
		<edge from-layer="2099" from-port="0" to-layer="2100" to-port="1"/>
		<edge from-layer="2100" from-port="2" to-layer="2105" to-port="0"/>
		<edge from-layer="2101" from-port="0" to-layer="2105" to-port="1"/>
		<edge from-layer="2102" from-port="0" to-layer="2105" to-port="2"/>
		<edge from-layer="2103" from-port="0" to-layer="2105" to-port="3"/>
		<edge from-layer="2104" from-port="0" to-layer="2105" to-port="4"/>
		<edge from-layer="2106" from-port="0" to-layer="2107" to-port="0"/>
		<edge from-layer="2107" from-port="1" to-layer="2109" to-port="0"/>
		<edge from-layer="2108" from-port="0" to-layer="2109" to-port="1"/>
		<edge from-layer="2109" from-port="2" to-layer="2111" to-port="0"/>
		<edge from-layer="2110" from-port="0" to-layer="2111" to-port="1"/>
		<edge from-layer="2111" from-port="2" to-layer="2113" to-port="0"/>
		<edge from-layer="2112" from-port="0" to-layer="2113" to-port="1"/>
		<edge from-layer="2105" from-port="5" to-layer="2114" to-port="0"/>
		<edge from-layer="2113" from-port="2" to-layer="2114" to-port="1"/>
		<edge from-layer="2114" from-port="2" to-layer="2116" to-port="0"/>
		<edge from-layer="2115" from-port="0" to-layer="2116" to-port="1"/>
		<edge from-layer="2116" from-port="2" to-layer="2117" to-port="0"/>
		<edge from-layer="2117" from-port="1" to-layer="2122" to-port="0"/>
		<edge from-layer="2118" from-port="0" to-layer="2122" to-port="1"/>
		<edge from-layer="2119" from-port="0" to-layer="2122" to-port="2"/>
		<edge from-layer="2120" from-port="0" to-layer="2122" to-port="3"/>
		<edge from-layer="2121" from-port="0" to-layer="2122" to-port="4"/>
		<edge from-layer="2117" from-port="1" to-layer="2124" to-port="0"/>
		<edge from-layer="2124" from-port="1" to-layer="2125" to-port="0"/>
		<edge from-layer="2125" from-port="1" to-layer="2127" to-port="0"/>
		<edge from-layer="2126" from-port="0" to-layer="2127" to-port="1"/>
		<edge from-layer="2123" from-port="0" to-layer="2129" to-port="0"/>
		<edge from-layer="2127" from-port="2" to-layer="2129" to-port="1"/>
		<edge from-layer="2128" from-port="0" to-layer="2129" to-port="2"/>
		<edge from-layer="2122" from-port="5" to-layer="2130" to-port="0"/>
		<edge from-layer="2129" from-port="3" to-layer="2130" to-port="1"/>
		<edge from-layer="2130" from-port="2" to-layer="2135" to-port="0"/>
		<edge from-layer="2131" from-port="0" to-layer="2135" to-port="1"/>
		<edge from-layer="2132" from-port="0" to-layer="2135" to-port="2"/>
		<edge from-layer="2133" from-port="0" to-layer="2135" to-port="3"/>
		<edge from-layer="2134" from-port="0" to-layer="2135" to-port="4"/>
		<edge from-layer="2135" from-port="5" to-layer="2137" to-port="0"/>
		<edge from-layer="2136" from-port="0" to-layer="2137" to-port="1"/>
		<edge from-layer="2137" from-port="2" to-layer="2139" to-port="0"/>
		<edge from-layer="2139" from-port="1" to-layer="2140" to-port="0"/>
		<edge from-layer="2140" from-port="1" to-layer="2142" to-port="0"/>
		<edge from-layer="2141" from-port="0" to-layer="2142" to-port="1"/>
		<edge from-layer="2138" from-port="0" to-layer="2144" to-port="0"/>
		<edge from-layer="2142" from-port="2" to-layer="2144" to-port="1"/>
		<edge from-layer="2143" from-port="0" to-layer="2144" to-port="2"/>
		<edge from-layer="2137" from-port="2" to-layer="2145" to-port="0"/>
		<edge from-layer="2144" from-port="3" to-layer="2145" to-port="1"/>
		<edge from-layer="2145" from-port="2" to-layer="2147" to-port="0"/>
		<edge from-layer="2146" from-port="0" to-layer="2147" to-port="1"/>
		<edge from-layer="2147" from-port="2" to-layer="2149" to-port="0"/>
		<edge from-layer="2148" from-port="0" to-layer="2149" to-port="1"/>
		<edge from-layer="2149" from-port="2" to-layer="2154" to-port="0"/>
		<edge from-layer="2150" from-port="0" to-layer="2154" to-port="1"/>
		<edge from-layer="2151" from-port="0" to-layer="2154" to-port="2"/>
		<edge from-layer="2152" from-port="0" to-layer="2154" to-port="3"/>
		<edge from-layer="2153" from-port="0" to-layer="2154" to-port="4"/>
		<edge from-layer="2130" from-port="2" to-layer="2155" to-port="0"/>
		<edge from-layer="2154" from-port="5" to-layer="2156" to-port="0"/>
		<edge from-layer="2155" from-port="1" to-layer="2156" to-port="1"/>
		<edge from-layer="2156" from-port="2" to-layer="2158" to-port="0"/>
		<edge from-layer="2157" from-port="0" to-layer="2158" to-port="1"/>
		<edge from-layer="2158" from-port="2" to-layer="2160" to-port="0"/>
		<edge from-layer="2159" from-port="0" to-layer="2160" to-port="1"/>
		<edge from-layer="2160" from-port="2" to-layer="2161" to-port="0"/>
		<edge from-layer="2161" from-port="1" to-layer="2166" to-port="0"/>
		<edge from-layer="2162" from-port="0" to-layer="2166" to-port="1"/>
		<edge from-layer="2163" from-port="0" to-layer="2166" to-port="2"/>
		<edge from-layer="2164" from-port="0" to-layer="2166" to-port="3"/>
		<edge from-layer="2165" from-port="0" to-layer="2166" to-port="4"/>
		<edge from-layer="2122" from-port="5" to-layer="2167" to-port="0"/>
		<edge from-layer="2166" from-port="5" to-layer="2167" to-port="1"/>
		<edge from-layer="2167" from-port="2" to-layer="2172" to-port="0"/>
		<edge from-layer="2168" from-port="0" to-layer="2172" to-port="1"/>
		<edge from-layer="2169" from-port="0" to-layer="2172" to-port="2"/>
		<edge from-layer="2170" from-port="0" to-layer="2172" to-port="3"/>
		<edge from-layer="2171" from-port="0" to-layer="2172" to-port="4"/>
		<edge from-layer="1998" from-port="5" to-layer="2173" to-port="0"/>
		<edge from-layer="2172" from-port="5" to-layer="2173" to-port="1"/>
		<edge from-layer="2173" from-port="2" to-layer="2178" to-port="0"/>
		<edge from-layer="2174" from-port="0" to-layer="2178" to-port="1"/>
		<edge from-layer="2175" from-port="0" to-layer="2178" to-port="2"/>
		<edge from-layer="2176" from-port="0" to-layer="2178" to-port="3"/>
		<edge from-layer="2177" from-port="0" to-layer="2178" to-port="4"/>
		<edge from-layer="2179" from-port="0" to-layer="2180" to-port="0"/>
		<edge from-layer="2180" from-port="1" to-layer="2182" to-port="0"/>
		<edge from-layer="2181" from-port="0" to-layer="2182" to-port="1"/>
		<edge from-layer="2182" from-port="2" to-layer="2184" to-port="0"/>
		<edge from-layer="2183" from-port="0" to-layer="2184" to-port="1"/>
		<edge from-layer="2178" from-port="5" to-layer="2185" to-port="0"/>
		<edge from-layer="2184" from-port="2" to-layer="2185" to-port="1"/>
		<edge from-layer="2185" from-port="2" to-layer="2187" to-port="0"/>
		<edge from-layer="2186" from-port="0" to-layer="2187" to-port="1"/>
		<edge from-layer="2187" from-port="2" to-layer="2192" to-port="0"/>
		<edge from-layer="2188" from-port="0" to-layer="2192" to-port="1"/>
		<edge from-layer="2189" from-port="0" to-layer="2192" to-port="2"/>
		<edge from-layer="2190" from-port="0" to-layer="2192" to-port="3"/>
		<edge from-layer="2191" from-port="0" to-layer="2192" to-port="4"/>
		<edge from-layer="2192" from-port="5" to-layer="2193" to-port="0"/>
		<edge from-layer="1635" from-port="5" to-layer="2193" to-port="1"/>
		<edge from-layer="2193" from-port="2" to-layer="2194" to-port="0"/>
		<edge from-layer="2194" from-port="1" to-layer="2199" to-port="0"/>
		<edge from-layer="2195" from-port="0" to-layer="2199" to-port="1"/>
		<edge from-layer="2196" from-port="0" to-layer="2199" to-port="2"/>
		<edge from-layer="2197" from-port="0" to-layer="2199" to-port="3"/>
		<edge from-layer="2198" from-port="0" to-layer="2199" to-port="4"/>
		<edge from-layer="2200" from-port="0" to-layer="2201" to-port="0"/>
		<edge from-layer="2201" from-port="1" to-layer="2203" to-port="0"/>
		<edge from-layer="2202" from-port="0" to-layer="2203" to-port="1"/>
		<edge from-layer="2203" from-port="2" to-layer="2205" to-port="0"/>
		<edge from-layer="2204" from-port="0" to-layer="2205" to-port="1"/>
		<edge from-layer="2199" from-port="5" to-layer="2206" to-port="0"/>
		<edge from-layer="2205" from-port="2" to-layer="2206" to-port="1"/>
		<edge from-layer="2206" from-port="2" to-layer="2208" to-port="0"/>
		<edge from-layer="2207" from-port="0" to-layer="2208" to-port="1"/>
		<edge from-layer="2208" from-port="2" to-layer="2209" to-port="0"/>
		<edge from-layer="2209" from-port="1" to-layer="2214" to-port="0"/>
		<edge from-layer="2210" from-port="0" to-layer="2214" to-port="1"/>
		<edge from-layer="2211" from-port="0" to-layer="2214" to-port="2"/>
		<edge from-layer="2212" from-port="0" to-layer="2214" to-port="3"/>
		<edge from-layer="2213" from-port="0" to-layer="2214" to-port="4"/>
		<edge from-layer="2214" from-port="5" to-layer="2215" to-port="0"/>
		<edge from-layer="2215" from-port="1" to-layer="2220" to-port="0"/>
		<edge from-layer="2216" from-port="0" to-layer="2220" to-port="1"/>
		<edge from-layer="2217" from-port="0" to-layer="2220" to-port="2"/>
		<edge from-layer="2218" from-port="0" to-layer="2220" to-port="3"/>
		<edge from-layer="2219" from-port="0" to-layer="2220" to-port="4"/>
		<edge from-layer="2221" from-port="0" to-layer="2222" to-port="0"/>
		<edge from-layer="2222" from-port="1" to-layer="2224" to-port="0"/>
		<edge from-layer="2223" from-port="0" to-layer="2224" to-port="1"/>
		<edge from-layer="2224" from-port="2" to-layer="2226" to-port="0"/>
		<edge from-layer="2225" from-port="0" to-layer="2226" to-port="1"/>
		<edge from-layer="2220" from-port="5" to-layer="2227" to-port="0"/>
		<edge from-layer="2226" from-port="2" to-layer="2227" to-port="1"/>
		<edge from-layer="2227" from-port="2" to-layer="2229" to-port="0"/>
		<edge from-layer="2228" from-port="0" to-layer="2229" to-port="1"/>
		<edge from-layer="2229" from-port="2" to-layer="2230" to-port="0"/>
		<edge from-layer="2230" from-port="1" to-layer="2235" to-port="0"/>
		<edge from-layer="2231" from-port="0" to-layer="2235" to-port="1"/>
		<edge from-layer="2232" from-port="0" to-layer="2235" to-port="2"/>
		<edge from-layer="2233" from-port="0" to-layer="2235" to-port="3"/>
		<edge from-layer="2234" from-port="0" to-layer="2235" to-port="4"/>
		<edge from-layer="2236" from-port="0" to-layer="2237" to-port="0"/>
		<edge from-layer="2237" from-port="1" to-layer="2239" to-port="0"/>
		<edge from-layer="2238" from-port="0" to-layer="2239" to-port="1"/>
		<edge from-layer="2239" from-port="2" to-layer="2241" to-port="0"/>
		<edge from-layer="2240" from-port="0" to-layer="2241" to-port="1"/>
		<edge from-layer="2235" from-port="5" to-layer="2242" to-port="0"/>
		<edge from-layer="2241" from-port="2" to-layer="2242" to-port="1"/>
		<edge from-layer="2242" from-port="2" to-layer="2244" to-port="0"/>
		<edge from-layer="2243" from-port="0" to-layer="2244" to-port="1"/>
		<edge from-layer="2244" from-port="2" to-layer="2249" to-port="0"/>
		<edge from-layer="2245" from-port="0" to-layer="2249" to-port="1"/>
		<edge from-layer="2246" from-port="0" to-layer="2249" to-port="2"/>
		<edge from-layer="2247" from-port="0" to-layer="2249" to-port="3"/>
		<edge from-layer="2248" from-port="0" to-layer="2249" to-port="4"/>
		<edge from-layer="2250" from-port="0" to-layer="2251" to-port="0"/>
		<edge from-layer="2251" from-port="1" to-layer="2253" to-port="0"/>
		<edge from-layer="2252" from-port="0" to-layer="2253" to-port="1"/>
		<edge from-layer="2253" from-port="2" to-layer="2255" to-port="0"/>
		<edge from-layer="2254" from-port="0" to-layer="2255" to-port="1"/>
		<edge from-layer="2255" from-port="2" to-layer="2257" to-port="0"/>
		<edge from-layer="2256" from-port="0" to-layer="2257" to-port="1"/>
		<edge from-layer="2249" from-port="5" to-layer="2258" to-port="0"/>
		<edge from-layer="2257" from-port="2" to-layer="2258" to-port="1"/>
		<edge from-layer="2258" from-port="2" to-layer="2260" to-port="0"/>
		<edge from-layer="2259" from-port="0" to-layer="2260" to-port="1"/>
		<edge from-layer="2260" from-port="2" to-layer="2261" to-port="0"/>
		<edge from-layer="2261" from-port="1" to-layer="2266" to-port="0"/>
		<edge from-layer="2262" from-port="0" to-layer="2266" to-port="1"/>
		<edge from-layer="2263" from-port="0" to-layer="2266" to-port="2"/>
		<edge from-layer="2264" from-port="0" to-layer="2266" to-port="3"/>
		<edge from-layer="2265" from-port="0" to-layer="2266" to-port="4"/>
		<edge from-layer="2261" from-port="1" to-layer="2268" to-port="0"/>
		<edge from-layer="2268" from-port="1" to-layer="2269" to-port="0"/>
		<edge from-layer="2269" from-port="1" to-layer="2271" to-port="0"/>
		<edge from-layer="2270" from-port="0" to-layer="2271" to-port="1"/>
		<edge from-layer="2267" from-port="0" to-layer="2273" to-port="0"/>
		<edge from-layer="2271" from-port="2" to-layer="2273" to-port="1"/>
		<edge from-layer="2272" from-port="0" to-layer="2273" to-port="2"/>
		<edge from-layer="2266" from-port="5" to-layer="2274" to-port="0"/>
		<edge from-layer="2273" from-port="3" to-layer="2274" to-port="1"/>
		<edge from-layer="2274" from-port="2" to-layer="2276" to-port="0"/>
		<edge from-layer="2275" from-port="0" to-layer="2276" to-port="1"/>
		<edge from-layer="2276" from-port="2" to-layer="2278" to-port="0"/>
		<edge from-layer="2277" from-port="0" to-layer="2278" to-port="1"/>
		<edge from-layer="2278" from-port="2" to-layer="2279" to-port="0"/>
		<edge from-layer="2279" from-port="1" to-layer="2281" to-port="0"/>
		<edge from-layer="2280" from-port="0" to-layer="2281" to-port="1"/>
		<edge from-layer="2281" from-port="2" to-layer="2283" to-port="0"/>
		<edge from-layer="2282" from-port="0" to-layer="2283" to-port="1"/>
		<edge from-layer="2283" from-port="2" to-layer="2284" to-port="0"/>
		<edge from-layer="2284" from-port="1" to-layer="2289" to-port="0"/>
		<edge from-layer="2285" from-port="0" to-layer="2289" to-port="1"/>
		<edge from-layer="2286" from-port="0" to-layer="2289" to-port="2"/>
		<edge from-layer="2287" from-port="0" to-layer="2289" to-port="3"/>
		<edge from-layer="2288" from-port="0" to-layer="2289" to-port="4"/>
		<edge from-layer="2266" from-port="5" to-layer="2290" to-port="0"/>
		<edge from-layer="2289" from-port="5" to-layer="2290" to-port="1"/>
		<edge from-layer="2290" from-port="2" to-layer="2295" to-port="0"/>
		<edge from-layer="2291" from-port="0" to-layer="2295" to-port="1"/>
		<edge from-layer="2292" from-port="0" to-layer="2295" to-port="2"/>
		<edge from-layer="2293" from-port="0" to-layer="2295" to-port="3"/>
		<edge from-layer="2294" from-port="0" to-layer="2295" to-port="4"/>
		<edge from-layer="2296" from-port="0" to-layer="2297" to-port="0"/>
		<edge from-layer="2297" from-port="1" to-layer="2299" to-port="0"/>
		<edge from-layer="2298" from-port="0" to-layer="2299" to-port="1"/>
		<edge from-layer="2299" from-port="2" to-layer="2301" to-port="0"/>
		<edge from-layer="2300" from-port="0" to-layer="2301" to-port="1"/>
		<edge from-layer="2235" from-port="5" to-layer="2302" to-port="0"/>
		<edge from-layer="2301" from-port="2" to-layer="2302" to-port="1"/>
		<edge from-layer="2302" from-port="2" to-layer="2304" to-port="0"/>
		<edge from-layer="2303" from-port="0" to-layer="2304" to-port="1"/>
		<edge from-layer="2304" from-port="2" to-layer="2309" to-port="0"/>
		<edge from-layer="2305" from-port="0" to-layer="2309" to-port="1"/>
		<edge from-layer="2306" from-port="0" to-layer="2309" to-port="2"/>
		<edge from-layer="2307" from-port="0" to-layer="2309" to-port="3"/>
		<edge from-layer="2308" from-port="0" to-layer="2309" to-port="4"/>
		<edge from-layer="2310" from-port="0" to-layer="2311" to-port="0"/>
		<edge from-layer="2311" from-port="1" to-layer="2313" to-port="0"/>
		<edge from-layer="2312" from-port="0" to-layer="2313" to-port="1"/>
		<edge from-layer="2313" from-port="2" to-layer="2315" to-port="0"/>
		<edge from-layer="2314" from-port="0" to-layer="2315" to-port="1"/>
		<edge from-layer="2315" from-port="2" to-layer="2317" to-port="0"/>
		<edge from-layer="2316" from-port="0" to-layer="2317" to-port="1"/>
		<edge from-layer="2309" from-port="5" to-layer="2318" to-port="0"/>
		<edge from-layer="2317" from-port="2" to-layer="2318" to-port="1"/>
		<edge from-layer="2318" from-port="2" to-layer="2320" to-port="0"/>
		<edge from-layer="2319" from-port="0" to-layer="2320" to-port="1"/>
		<edge from-layer="2320" from-port="2" to-layer="2321" to-port="0"/>
		<edge from-layer="2321" from-port="1" to-layer="2326" to-port="0"/>
		<edge from-layer="2322" from-port="0" to-layer="2326" to-port="1"/>
		<edge from-layer="2323" from-port="0" to-layer="2326" to-port="2"/>
		<edge from-layer="2324" from-port="0" to-layer="2326" to-port="3"/>
		<edge from-layer="2325" from-port="0" to-layer="2326" to-port="4"/>
		<edge from-layer="2327" from-port="0" to-layer="2328" to-port="0"/>
		<edge from-layer="2328" from-port="1" to-layer="2330" to-port="0"/>
		<edge from-layer="2329" from-port="0" to-layer="2330" to-port="1"/>
		<edge from-layer="2330" from-port="2" to-layer="2332" to-port="0"/>
		<edge from-layer="2331" from-port="0" to-layer="2332" to-port="1"/>
		<edge from-layer="2326" from-port="5" to-layer="2333" to-port="0"/>
		<edge from-layer="2332" from-port="2" to-layer="2333" to-port="1"/>
		<edge from-layer="2333" from-port="2" to-layer="2335" to-port="0"/>
		<edge from-layer="2334" from-port="0" to-layer="2335" to-port="1"/>
		<edge from-layer="2335" from-port="2" to-layer="2340" to-port="0"/>
		<edge from-layer="2336" from-port="0" to-layer="2340" to-port="1"/>
		<edge from-layer="2337" from-port="0" to-layer="2340" to-port="2"/>
		<edge from-layer="2338" from-port="0" to-layer="2340" to-port="3"/>
		<edge from-layer="2339" from-port="0" to-layer="2340" to-port="4"/>
		<edge from-layer="2341" from-port="0" to-layer="2342" to-port="0"/>
		<edge from-layer="2342" from-port="1" to-layer="2344" to-port="0"/>
		<edge from-layer="2343" from-port="0" to-layer="2344" to-port="1"/>
		<edge from-layer="2344" from-port="2" to-layer="2346" to-port="0"/>
		<edge from-layer="2345" from-port="0" to-layer="2346" to-port="1"/>
		<edge from-layer="2346" from-port="2" to-layer="2348" to-port="0"/>
		<edge from-layer="2347" from-port="0" to-layer="2348" to-port="1"/>
		<edge from-layer="2340" from-port="5" to-layer="2349" to-port="0"/>
		<edge from-layer="2348" from-port="2" to-layer="2349" to-port="1"/>
		<edge from-layer="2349" from-port="2" to-layer="2351" to-port="0"/>
		<edge from-layer="2350" from-port="0" to-layer="2351" to-port="1"/>
		<edge from-layer="2351" from-port="2" to-layer="2352" to-port="0"/>
		<edge from-layer="2352" from-port="1" to-layer="2357" to-port="0"/>
		<edge from-layer="2353" from-port="0" to-layer="2357" to-port="1"/>
		<edge from-layer="2354" from-port="0" to-layer="2357" to-port="2"/>
		<edge from-layer="2355" from-port="0" to-layer="2357" to-port="3"/>
		<edge from-layer="2356" from-port="0" to-layer="2357" to-port="4"/>
		<edge from-layer="2352" from-port="1" to-layer="2359" to-port="0"/>
		<edge from-layer="2359" from-port="1" to-layer="2360" to-port="0"/>
		<edge from-layer="2360" from-port="1" to-layer="2362" to-port="0"/>
		<edge from-layer="2361" from-port="0" to-layer="2362" to-port="1"/>
		<edge from-layer="2358" from-port="0" to-layer="2364" to-port="0"/>
		<edge from-layer="2362" from-port="2" to-layer="2364" to-port="1"/>
		<edge from-layer="2363" from-port="0" to-layer="2364" to-port="2"/>
		<edge from-layer="2357" from-port="5" to-layer="2365" to-port="0"/>
		<edge from-layer="2364" from-port="3" to-layer="2365" to-port="1"/>
		<edge from-layer="2365" from-port="2" to-layer="2367" to-port="0"/>
		<edge from-layer="2366" from-port="0" to-layer="2367" to-port="1"/>
		<edge from-layer="2367" from-port="2" to-layer="2369" to-port="0"/>
		<edge from-layer="2368" from-port="0" to-layer="2369" to-port="1"/>
		<edge from-layer="2369" from-port="2" to-layer="2370" to-port="0"/>
		<edge from-layer="2370" from-port="1" to-layer="2372" to-port="0"/>
		<edge from-layer="2371" from-port="0" to-layer="2372" to-port="1"/>
		<edge from-layer="2372" from-port="2" to-layer="2374" to-port="0"/>
		<edge from-layer="2373" from-port="0" to-layer="2374" to-port="1"/>
		<edge from-layer="2374" from-port="2" to-layer="2375" to-port="0"/>
		<edge from-layer="2375" from-port="1" to-layer="2380" to-port="0"/>
		<edge from-layer="2376" from-port="0" to-layer="2380" to-port="1"/>
		<edge from-layer="2377" from-port="0" to-layer="2380" to-port="2"/>
		<edge from-layer="2378" from-port="0" to-layer="2380" to-port="3"/>
		<edge from-layer="2379" from-port="0" to-layer="2380" to-port="4"/>
		<edge from-layer="2357" from-port="5" to-layer="2381" to-port="0"/>
		<edge from-layer="2380" from-port="5" to-layer="2381" to-port="1"/>
		<edge from-layer="2381" from-port="2" to-layer="2386" to-port="0"/>
		<edge from-layer="2382" from-port="0" to-layer="2386" to-port="1"/>
		<edge from-layer="2383" from-port="0" to-layer="2386" to-port="2"/>
		<edge from-layer="2384" from-port="0" to-layer="2386" to-port="3"/>
		<edge from-layer="2385" from-port="0" to-layer="2386" to-port="4"/>
		<edge from-layer="2295" from-port="5" to-layer="2387" to-port="0"/>
		<edge from-layer="2386" from-port="5" to-layer="2387" to-port="1"/>
		<edge from-layer="2387" from-port="2" to-layer="2392" to-port="0"/>
		<edge from-layer="2388" from-port="0" to-layer="2392" to-port="1"/>
		<edge from-layer="2389" from-port="0" to-layer="2392" to-port="2"/>
		<edge from-layer="2390" from-port="0" to-layer="2392" to-port="3"/>
		<edge from-layer="2391" from-port="0" to-layer="2392" to-port="4"/>
		<edge from-layer="2393" from-port="0" to-layer="2394" to-port="0"/>
		<edge from-layer="2394" from-port="1" to-layer="2396" to-port="0"/>
		<edge from-layer="2395" from-port="0" to-layer="2396" to-port="1"/>
		<edge from-layer="2396" from-port="2" to-layer="2398" to-port="0"/>
		<edge from-layer="2397" from-port="0" to-layer="2398" to-port="1"/>
		<edge from-layer="2235" from-port="5" to-layer="2399" to-port="0"/>
		<edge from-layer="2398" from-port="2" to-layer="2399" to-port="1"/>
		<edge from-layer="2399" from-port="2" to-layer="2401" to-port="0"/>
		<edge from-layer="2400" from-port="0" to-layer="2401" to-port="1"/>
		<edge from-layer="2401" from-port="2" to-layer="2406" to-port="0"/>
		<edge from-layer="2402" from-port="0" to-layer="2406" to-port="1"/>
		<edge from-layer="2403" from-port="0" to-layer="2406" to-port="2"/>
		<edge from-layer="2404" from-port="0" to-layer="2406" to-port="3"/>
		<edge from-layer="2405" from-port="0" to-layer="2406" to-port="4"/>
		<edge from-layer="2407" from-port="0" to-layer="2408" to-port="0"/>
		<edge from-layer="2408" from-port="1" to-layer="2410" to-port="0"/>
		<edge from-layer="2409" from-port="0" to-layer="2410" to-port="1"/>
		<edge from-layer="2410" from-port="2" to-layer="2412" to-port="0"/>
		<edge from-layer="2411" from-port="0" to-layer="2412" to-port="1"/>
		<edge from-layer="2412" from-port="2" to-layer="2414" to-port="0"/>
		<edge from-layer="2413" from-port="0" to-layer="2414" to-port="1"/>
		<edge from-layer="2406" from-port="5" to-layer="2415" to-port="0"/>
		<edge from-layer="2414" from-port="2" to-layer="2415" to-port="1"/>
		<edge from-layer="2415" from-port="2" to-layer="2417" to-port="0"/>
		<edge from-layer="2416" from-port="0" to-layer="2417" to-port="1"/>
		<edge from-layer="2417" from-port="2" to-layer="2418" to-port="0"/>
		<edge from-layer="2418" from-port="1" to-layer="2423" to-port="0"/>
		<edge from-layer="2419" from-port="0" to-layer="2423" to-port="1"/>
		<edge from-layer="2420" from-port="0" to-layer="2423" to-port="2"/>
		<edge from-layer="2421" from-port="0" to-layer="2423" to-port="3"/>
		<edge from-layer="2422" from-port="0" to-layer="2423" to-port="4"/>
		<edge from-layer="2424" from-port="0" to-layer="2425" to-port="0"/>
		<edge from-layer="2425" from-port="1" to-layer="2427" to-port="0"/>
		<edge from-layer="2426" from-port="0" to-layer="2427" to-port="1"/>
		<edge from-layer="2427" from-port="2" to-layer="2429" to-port="0"/>
		<edge from-layer="2428" from-port="0" to-layer="2429" to-port="1"/>
		<edge from-layer="2423" from-port="5" to-layer="2430" to-port="0"/>
		<edge from-layer="2429" from-port="2" to-layer="2430" to-port="1"/>
		<edge from-layer="2430" from-port="2" to-layer="2432" to-port="0"/>
		<edge from-layer="2431" from-port="0" to-layer="2432" to-port="1"/>
		<edge from-layer="2432" from-port="2" to-layer="2437" to-port="0"/>
		<edge from-layer="2433" from-port="0" to-layer="2437" to-port="1"/>
		<edge from-layer="2434" from-port="0" to-layer="2437" to-port="2"/>
		<edge from-layer="2435" from-port="0" to-layer="2437" to-port="3"/>
		<edge from-layer="2436" from-port="0" to-layer="2437" to-port="4"/>
		<edge from-layer="2438" from-port="0" to-layer="2439" to-port="0"/>
		<edge from-layer="2439" from-port="1" to-layer="2441" to-port="0"/>
		<edge from-layer="2440" from-port="0" to-layer="2441" to-port="1"/>
		<edge from-layer="2441" from-port="2" to-layer="2443" to-port="0"/>
		<edge from-layer="2442" from-port="0" to-layer="2443" to-port="1"/>
		<edge from-layer="2443" from-port="2" to-layer="2445" to-port="0"/>
		<edge from-layer="2444" from-port="0" to-layer="2445" to-port="1"/>
		<edge from-layer="2437" from-port="5" to-layer="2446" to-port="0"/>
		<edge from-layer="2445" from-port="2" to-layer="2446" to-port="1"/>
		<edge from-layer="2446" from-port="2" to-layer="2448" to-port="0"/>
		<edge from-layer="2447" from-port="0" to-layer="2448" to-port="1"/>
		<edge from-layer="2448" from-port="2" to-layer="2449" to-port="0"/>
		<edge from-layer="2449" from-port="1" to-layer="2454" to-port="0"/>
		<edge from-layer="2450" from-port="0" to-layer="2454" to-port="1"/>
		<edge from-layer="2451" from-port="0" to-layer="2454" to-port="2"/>
		<edge from-layer="2452" from-port="0" to-layer="2454" to-port="3"/>
		<edge from-layer="2453" from-port="0" to-layer="2454" to-port="4"/>
		<edge from-layer="2455" from-port="0" to-layer="2456" to-port="0"/>
		<edge from-layer="2456" from-port="1" to-layer="2458" to-port="0"/>
		<edge from-layer="2457" from-port="0" to-layer="2458" to-port="1"/>
		<edge from-layer="2458" from-port="2" to-layer="2460" to-port="0"/>
		<edge from-layer="2459" from-port="0" to-layer="2460" to-port="1"/>
		<edge from-layer="2454" from-port="5" to-layer="2461" to-port="0"/>
		<edge from-layer="2460" from-port="2" to-layer="2461" to-port="1"/>
		<edge from-layer="2461" from-port="2" to-layer="2463" to-port="0"/>
		<edge from-layer="2462" from-port="0" to-layer="2463" to-port="1"/>
		<edge from-layer="2463" from-port="2" to-layer="2468" to-port="0"/>
		<edge from-layer="2464" from-port="0" to-layer="2468" to-port="1"/>
		<edge from-layer="2465" from-port="0" to-layer="2468" to-port="2"/>
		<edge from-layer="2466" from-port="0" to-layer="2468" to-port="3"/>
		<edge from-layer="2467" from-port="0" to-layer="2468" to-port="4"/>
		<edge from-layer="2469" from-port="0" to-layer="2470" to-port="0"/>
		<edge from-layer="2470" from-port="1" to-layer="2472" to-port="0"/>
		<edge from-layer="2471" from-port="0" to-layer="2472" to-port="1"/>
		<edge from-layer="2472" from-port="2" to-layer="2474" to-port="0"/>
		<edge from-layer="2473" from-port="0" to-layer="2474" to-port="1"/>
		<edge from-layer="2474" from-port="2" to-layer="2476" to-port="0"/>
		<edge from-layer="2475" from-port="0" to-layer="2476" to-port="1"/>
		<edge from-layer="2468" from-port="5" to-layer="2477" to-port="0"/>
		<edge from-layer="2476" from-port="2" to-layer="2477" to-port="1"/>
		<edge from-layer="2477" from-port="2" to-layer="2479" to-port="0"/>
		<edge from-layer="2478" from-port="0" to-layer="2479" to-port="1"/>
		<edge from-layer="2479" from-port="2" to-layer="2480" to-port="0"/>
		<edge from-layer="2480" from-port="1" to-layer="2485" to-port="0"/>
		<edge from-layer="2481" from-port="0" to-layer="2485" to-port="1"/>
		<edge from-layer="2482" from-port="0" to-layer="2485" to-port="2"/>
		<edge from-layer="2483" from-port="0" to-layer="2485" to-port="3"/>
		<edge from-layer="2484" from-port="0" to-layer="2485" to-port="4"/>
		<edge from-layer="2480" from-port="1" to-layer="2487" to-port="0"/>
		<edge from-layer="2487" from-port="1" to-layer="2488" to-port="0"/>
		<edge from-layer="2488" from-port="1" to-layer="2490" to-port="0"/>
		<edge from-layer="2489" from-port="0" to-layer="2490" to-port="1"/>
		<edge from-layer="2486" from-port="0" to-layer="2492" to-port="0"/>
		<edge from-layer="2490" from-port="2" to-layer="2492" to-port="1"/>
		<edge from-layer="2491" from-port="0" to-layer="2492" to-port="2"/>
		<edge from-layer="2485" from-port="5" to-layer="2493" to-port="0"/>
		<edge from-layer="2492" from-port="3" to-layer="2493" to-port="1"/>
		<edge from-layer="2493" from-port="2" to-layer="2495" to-port="0"/>
		<edge from-layer="2494" from-port="0" to-layer="2495" to-port="1"/>
		<edge from-layer="2495" from-port="2" to-layer="2497" to-port="0"/>
		<edge from-layer="2496" from-port="0" to-layer="2497" to-port="1"/>
		<edge from-layer="2497" from-port="2" to-layer="2498" to-port="0"/>
		<edge from-layer="2498" from-port="1" to-layer="2500" to-port="0"/>
		<edge from-layer="2499" from-port="0" to-layer="2500" to-port="1"/>
		<edge from-layer="2500" from-port="2" to-layer="2502" to-port="0"/>
		<edge from-layer="2501" from-port="0" to-layer="2502" to-port="1"/>
		<edge from-layer="2502" from-port="2" to-layer="2503" to-port="0"/>
		<edge from-layer="2503" from-port="1" to-layer="2508" to-port="0"/>
		<edge from-layer="2504" from-port="0" to-layer="2508" to-port="1"/>
		<edge from-layer="2505" from-port="0" to-layer="2508" to-port="2"/>
		<edge from-layer="2506" from-port="0" to-layer="2508" to-port="3"/>
		<edge from-layer="2507" from-port="0" to-layer="2508" to-port="4"/>
		<edge from-layer="2485" from-port="5" to-layer="2509" to-port="0"/>
		<edge from-layer="2508" from-port="5" to-layer="2509" to-port="1"/>
		<edge from-layer="2509" from-port="2" to-layer="2514" to-port="0"/>
		<edge from-layer="2510" from-port="0" to-layer="2514" to-port="1"/>
		<edge from-layer="2511" from-port="0" to-layer="2514" to-port="2"/>
		<edge from-layer="2512" from-port="0" to-layer="2514" to-port="3"/>
		<edge from-layer="2513" from-port="0" to-layer="2514" to-port="4"/>
		<edge from-layer="2392" from-port="5" to-layer="2515" to-port="0"/>
		<edge from-layer="2514" from-port="5" to-layer="2515" to-port="1"/>
		<edge from-layer="2515" from-port="2" to-layer="2520" to-port="0"/>
		<edge from-layer="2516" from-port="0" to-layer="2520" to-port="1"/>
		<edge from-layer="2517" from-port="0" to-layer="2520" to-port="2"/>
		<edge from-layer="2518" from-port="0" to-layer="2520" to-port="3"/>
		<edge from-layer="2519" from-port="0" to-layer="2520" to-port="4"/>
		<edge from-layer="2521" from-port="0" to-layer="2522" to-port="0"/>
		<edge from-layer="2522" from-port="1" to-layer="2524" to-port="0"/>
		<edge from-layer="2523" from-port="0" to-layer="2524" to-port="1"/>
		<edge from-layer="2524" from-port="2" to-layer="2526" to-port="0"/>
		<edge from-layer="2525" from-port="0" to-layer="2526" to-port="1"/>
		<edge from-layer="2235" from-port="5" to-layer="2527" to-port="0"/>
		<edge from-layer="2526" from-port="2" to-layer="2527" to-port="1"/>
		<edge from-layer="2527" from-port="2" to-layer="2529" to-port="0"/>
		<edge from-layer="2528" from-port="0" to-layer="2529" to-port="1"/>
		<edge from-layer="2529" from-port="2" to-layer="2534" to-port="0"/>
		<edge from-layer="2530" from-port="0" to-layer="2534" to-port="1"/>
		<edge from-layer="2531" from-port="0" to-layer="2534" to-port="2"/>
		<edge from-layer="2532" from-port="0" to-layer="2534" to-port="3"/>
		<edge from-layer="2533" from-port="0" to-layer="2534" to-port="4"/>
		<edge from-layer="2535" from-port="0" to-layer="2536" to-port="0"/>
		<edge from-layer="2536" from-port="1" to-layer="2538" to-port="0"/>
		<edge from-layer="2537" from-port="0" to-layer="2538" to-port="1"/>
		<edge from-layer="2538" from-port="2" to-layer="2540" to-port="0"/>
		<edge from-layer="2539" from-port="0" to-layer="2540" to-port="1"/>
		<edge from-layer="2540" from-port="2" to-layer="2542" to-port="0"/>
		<edge from-layer="2541" from-port="0" to-layer="2542" to-port="1"/>
		<edge from-layer="2534" from-port="5" to-layer="2543" to-port="0"/>
		<edge from-layer="2542" from-port="2" to-layer="2543" to-port="1"/>
		<edge from-layer="2543" from-port="2" to-layer="2545" to-port="0"/>
		<edge from-layer="2544" from-port="0" to-layer="2545" to-port="1"/>
		<edge from-layer="2545" from-port="2" to-layer="2546" to-port="0"/>
		<edge from-layer="2546" from-port="1" to-layer="2551" to-port="0"/>
		<edge from-layer="2547" from-port="0" to-layer="2551" to-port="1"/>
		<edge from-layer="2548" from-port="0" to-layer="2551" to-port="2"/>
		<edge from-layer="2549" from-port="0" to-layer="2551" to-port="3"/>
		<edge from-layer="2550" from-port="0" to-layer="2551" to-port="4"/>
		<edge from-layer="2552" from-port="0" to-layer="2553" to-port="0"/>
		<edge from-layer="2553" from-port="1" to-layer="2555" to-port="0"/>
		<edge from-layer="2554" from-port="0" to-layer="2555" to-port="1"/>
		<edge from-layer="2555" from-port="2" to-layer="2557" to-port="0"/>
		<edge from-layer="2556" from-port="0" to-layer="2557" to-port="1"/>
		<edge from-layer="2551" from-port="5" to-layer="2558" to-port="0"/>
		<edge from-layer="2557" from-port="2" to-layer="2558" to-port="1"/>
		<edge from-layer="2558" from-port="2" to-layer="2560" to-port="0"/>
		<edge from-layer="2559" from-port="0" to-layer="2560" to-port="1"/>
		<edge from-layer="2560" from-port="2" to-layer="2565" to-port="0"/>
		<edge from-layer="2561" from-port="0" to-layer="2565" to-port="1"/>
		<edge from-layer="2562" from-port="0" to-layer="2565" to-port="2"/>
		<edge from-layer="2563" from-port="0" to-layer="2565" to-port="3"/>
		<edge from-layer="2564" from-port="0" to-layer="2565" to-port="4"/>
		<edge from-layer="2566" from-port="0" to-layer="2567" to-port="0"/>
		<edge from-layer="2567" from-port="1" to-layer="2569" to-port="0"/>
		<edge from-layer="2568" from-port="0" to-layer="2569" to-port="1"/>
		<edge from-layer="2569" from-port="2" to-layer="2571" to-port="0"/>
		<edge from-layer="2570" from-port="0" to-layer="2571" to-port="1"/>
		<edge from-layer="2571" from-port="2" to-layer="2573" to-port="0"/>
		<edge from-layer="2572" from-port="0" to-layer="2573" to-port="1"/>
		<edge from-layer="2565" from-port="5" to-layer="2574" to-port="0"/>
		<edge from-layer="2573" from-port="2" to-layer="2574" to-port="1"/>
		<edge from-layer="2574" from-port="2" to-layer="2576" to-port="0"/>
		<edge from-layer="2575" from-port="0" to-layer="2576" to-port="1"/>
		<edge from-layer="2576" from-port="2" to-layer="2577" to-port="0"/>
		<edge from-layer="2577" from-port="1" to-layer="2582" to-port="0"/>
		<edge from-layer="2578" from-port="0" to-layer="2582" to-port="1"/>
		<edge from-layer="2579" from-port="0" to-layer="2582" to-port="2"/>
		<edge from-layer="2580" from-port="0" to-layer="2582" to-port="3"/>
		<edge from-layer="2581" from-port="0" to-layer="2582" to-port="4"/>
		<edge from-layer="2583" from-port="0" to-layer="2584" to-port="0"/>
		<edge from-layer="2584" from-port="1" to-layer="2586" to-port="0"/>
		<edge from-layer="2585" from-port="0" to-layer="2586" to-port="1"/>
		<edge from-layer="2586" from-port="2" to-layer="2588" to-port="0"/>
		<edge from-layer="2587" from-port="0" to-layer="2588" to-port="1"/>
		<edge from-layer="2582" from-port="5" to-layer="2589" to-port="0"/>
		<edge from-layer="2588" from-port="2" to-layer="2589" to-port="1"/>
		<edge from-layer="2589" from-port="2" to-layer="2591" to-port="0"/>
		<edge from-layer="2590" from-port="0" to-layer="2591" to-port="1"/>
		<edge from-layer="2591" from-port="2" to-layer="2596" to-port="0"/>
		<edge from-layer="2592" from-port="0" to-layer="2596" to-port="1"/>
		<edge from-layer="2593" from-port="0" to-layer="2596" to-port="2"/>
		<edge from-layer="2594" from-port="0" to-layer="2596" to-port="3"/>
		<edge from-layer="2595" from-port="0" to-layer="2596" to-port="4"/>
		<edge from-layer="2597" from-port="0" to-layer="2598" to-port="0"/>
		<edge from-layer="2598" from-port="1" to-layer="2600" to-port="0"/>
		<edge from-layer="2599" from-port="0" to-layer="2600" to-port="1"/>
		<edge from-layer="2600" from-port="2" to-layer="2602" to-port="0"/>
		<edge from-layer="2601" from-port="0" to-layer="2602" to-port="1"/>
		<edge from-layer="2602" from-port="2" to-layer="2604" to-port="0"/>
		<edge from-layer="2603" from-port="0" to-layer="2604" to-port="1"/>
		<edge from-layer="2596" from-port="5" to-layer="2605" to-port="0"/>
		<edge from-layer="2604" from-port="2" to-layer="2605" to-port="1"/>
		<edge from-layer="2605" from-port="2" to-layer="2607" to-port="0"/>
		<edge from-layer="2606" from-port="0" to-layer="2607" to-port="1"/>
		<edge from-layer="2607" from-port="2" to-layer="2608" to-port="0"/>
		<edge from-layer="2608" from-port="1" to-layer="2613" to-port="0"/>
		<edge from-layer="2609" from-port="0" to-layer="2613" to-port="1"/>
		<edge from-layer="2610" from-port="0" to-layer="2613" to-port="2"/>
		<edge from-layer="2611" from-port="0" to-layer="2613" to-port="3"/>
		<edge from-layer="2612" from-port="0" to-layer="2613" to-port="4"/>
		<edge from-layer="2614" from-port="0" to-layer="2615" to-port="0"/>
		<edge from-layer="2615" from-port="1" to-layer="2617" to-port="0"/>
		<edge from-layer="2616" from-port="0" to-layer="2617" to-port="1"/>
		<edge from-layer="2617" from-port="2" to-layer="2619" to-port="0"/>
		<edge from-layer="2618" from-port="0" to-layer="2619" to-port="1"/>
		<edge from-layer="2613" from-port="5" to-layer="2620" to-port="0"/>
		<edge from-layer="2619" from-port="2" to-layer="2620" to-port="1"/>
		<edge from-layer="2620" from-port="2" to-layer="2622" to-port="0"/>
		<edge from-layer="2621" from-port="0" to-layer="2622" to-port="1"/>
		<edge from-layer="2622" from-port="2" to-layer="2627" to-port="0"/>
		<edge from-layer="2623" from-port="0" to-layer="2627" to-port="1"/>
		<edge from-layer="2624" from-port="0" to-layer="2627" to-port="2"/>
		<edge from-layer="2625" from-port="0" to-layer="2627" to-port="3"/>
		<edge from-layer="2626" from-port="0" to-layer="2627" to-port="4"/>
		<edge from-layer="2628" from-port="0" to-layer="2629" to-port="0"/>
		<edge from-layer="2629" from-port="1" to-layer="2631" to-port="0"/>
		<edge from-layer="2630" from-port="0" to-layer="2631" to-port="1"/>
		<edge from-layer="2631" from-port="2" to-layer="2633" to-port="0"/>
		<edge from-layer="2632" from-port="0" to-layer="2633" to-port="1"/>
		<edge from-layer="2633" from-port="2" to-layer="2635" to-port="0"/>
		<edge from-layer="2634" from-port="0" to-layer="2635" to-port="1"/>
		<edge from-layer="2627" from-port="5" to-layer="2636" to-port="0"/>
		<edge from-layer="2635" from-port="2" to-layer="2636" to-port="1"/>
		<edge from-layer="2636" from-port="2" to-layer="2638" to-port="0"/>
		<edge from-layer="2637" from-port="0" to-layer="2638" to-port="1"/>
		<edge from-layer="2638" from-port="2" to-layer="2639" to-port="0"/>
		<edge from-layer="2639" from-port="1" to-layer="2644" to-port="0"/>
		<edge from-layer="2640" from-port="0" to-layer="2644" to-port="1"/>
		<edge from-layer="2641" from-port="0" to-layer="2644" to-port="2"/>
		<edge from-layer="2642" from-port="0" to-layer="2644" to-port="3"/>
		<edge from-layer="2643" from-port="0" to-layer="2644" to-port="4"/>
		<edge from-layer="2639" from-port="1" to-layer="2646" to-port="0"/>
		<edge from-layer="2646" from-port="1" to-layer="2647" to-port="0"/>
		<edge from-layer="2647" from-port="1" to-layer="2649" to-port="0"/>
		<edge from-layer="2648" from-port="0" to-layer="2649" to-port="1"/>
		<edge from-layer="2645" from-port="0" to-layer="2651" to-port="0"/>
		<edge from-layer="2649" from-port="2" to-layer="2651" to-port="1"/>
		<edge from-layer="2650" from-port="0" to-layer="2651" to-port="2"/>
		<edge from-layer="2644" from-port="5" to-layer="2652" to-port="0"/>
		<edge from-layer="2651" from-port="3" to-layer="2652" to-port="1"/>
		<edge from-layer="2652" from-port="2" to-layer="2654" to-port="0"/>
		<edge from-layer="2653" from-port="0" to-layer="2654" to-port="1"/>
		<edge from-layer="2654" from-port="2" to-layer="2656" to-port="0"/>
		<edge from-layer="2655" from-port="0" to-layer="2656" to-port="1"/>
		<edge from-layer="2656" from-port="2" to-layer="2657" to-port="0"/>
		<edge from-layer="2657" from-port="1" to-layer="2659" to-port="0"/>
		<edge from-layer="2658" from-port="0" to-layer="2659" to-port="1"/>
		<edge from-layer="2659" from-port="2" to-layer="2661" to-port="0"/>
		<edge from-layer="2660" from-port="0" to-layer="2661" to-port="1"/>
		<edge from-layer="2661" from-port="2" to-layer="2662" to-port="0"/>
		<edge from-layer="2662" from-port="1" to-layer="2667" to-port="0"/>
		<edge from-layer="2663" from-port="0" to-layer="2667" to-port="1"/>
		<edge from-layer="2664" from-port="0" to-layer="2667" to-port="2"/>
		<edge from-layer="2665" from-port="0" to-layer="2667" to-port="3"/>
		<edge from-layer="2666" from-port="0" to-layer="2667" to-port="4"/>
		<edge from-layer="2644" from-port="5" to-layer="2668" to-port="0"/>
		<edge from-layer="2667" from-port="5" to-layer="2668" to-port="1"/>
		<edge from-layer="2668" from-port="2" to-layer="2673" to-port="0"/>
		<edge from-layer="2669" from-port="0" to-layer="2673" to-port="1"/>
		<edge from-layer="2670" from-port="0" to-layer="2673" to-port="2"/>
		<edge from-layer="2671" from-port="0" to-layer="2673" to-port="3"/>
		<edge from-layer="2672" from-port="0" to-layer="2673" to-port="4"/>
		<edge from-layer="2520" from-port="5" to-layer="2674" to-port="0"/>
		<edge from-layer="2673" from-port="5" to-layer="2674" to-port="1"/>
		<edge from-layer="2674" from-port="2" to-layer="2679" to-port="0"/>
		<edge from-layer="2675" from-port="0" to-layer="2679" to-port="1"/>
		<edge from-layer="2676" from-port="0" to-layer="2679" to-port="2"/>
		<edge from-layer="2677" from-port="0" to-layer="2679" to-port="3"/>
		<edge from-layer="2678" from-port="0" to-layer="2679" to-port="4"/>
		<edge from-layer="2680" from-port="0" to-layer="2681" to-port="0"/>
		<edge from-layer="2681" from-port="1" to-layer="2683" to-port="0"/>
		<edge from-layer="2682" from-port="0" to-layer="2683" to-port="1"/>
		<edge from-layer="2683" from-port="2" to-layer="2685" to-port="0"/>
		<edge from-layer="2684" from-port="0" to-layer="2685" to-port="1"/>
		<edge from-layer="2679" from-port="5" to-layer="2686" to-port="0"/>
		<edge from-layer="2685" from-port="2" to-layer="2686" to-port="1"/>
		<edge from-layer="2686" from-port="2" to-layer="2688" to-port="0"/>
		<edge from-layer="2687" from-port="0" to-layer="2688" to-port="1"/>
		<edge from-layer="2688" from-port="2" to-layer="2693" to-port="0"/>
		<edge from-layer="2689" from-port="0" to-layer="2693" to-port="1"/>
		<edge from-layer="2690" from-port="0" to-layer="2693" to-port="2"/>
		<edge from-layer="2691" from-port="0" to-layer="2693" to-port="3"/>
		<edge from-layer="2692" from-port="0" to-layer="2693" to-port="4"/>
		<edge from-layer="2694" from-port="0" to-layer="2695" to-port="0"/>
		<edge from-layer="2695" from-port="1" to-layer="2697" to-port="0"/>
		<edge from-layer="2696" from-port="0" to-layer="2697" to-port="1"/>
		<edge from-layer="2697" from-port="2" to-layer="2699" to-port="0"/>
		<edge from-layer="2698" from-port="0" to-layer="2699" to-port="1"/>
		<edge from-layer="2220" from-port="5" to-layer="2700" to-port="0"/>
		<edge from-layer="2699" from-port="2" to-layer="2700" to-port="1"/>
		<edge from-layer="2700" from-port="2" to-layer="2702" to-port="0"/>
		<edge from-layer="2701" from-port="0" to-layer="2702" to-port="1"/>
		<edge from-layer="2702" from-port="2" to-layer="2707" to-port="0"/>
		<edge from-layer="2703" from-port="0" to-layer="2707" to-port="1"/>
		<edge from-layer="2704" from-port="0" to-layer="2707" to-port="2"/>
		<edge from-layer="2705" from-port="0" to-layer="2707" to-port="3"/>
		<edge from-layer="2706" from-port="0" to-layer="2707" to-port="4"/>
		<edge from-layer="2693" from-port="5" to-layer="2708" to-port="0"/>
		<edge from-layer="2707" from-port="5" to-layer="2708" to-port="1"/>
		<edge from-layer="2708" from-port="2" to-layer="2709" to-port="0"/>
		<edge from-layer="2709" from-port="1" to-layer="2714" to-port="0"/>
		<edge from-layer="2710" from-port="0" to-layer="2714" to-port="1"/>
		<edge from-layer="2711" from-port="0" to-layer="2714" to-port="2"/>
		<edge from-layer="2712" from-port="0" to-layer="2714" to-port="3"/>
		<edge from-layer="2713" from-port="0" to-layer="2714" to-port="4"/>
		<edge from-layer="2715" from-port="0" to-layer="2716" to-port="0"/>
		<edge from-layer="2716" from-port="1" to-layer="2718" to-port="0"/>
		<edge from-layer="2717" from-port="0" to-layer="2718" to-port="1"/>
		<edge from-layer="2718" from-port="2" to-layer="2720" to-port="0"/>
		<edge from-layer="2719" from-port="0" to-layer="2720" to-port="1"/>
		<edge from-layer="2714" from-port="5" to-layer="2721" to-port="0"/>
		<edge from-layer="2720" from-port="2" to-layer="2721" to-port="1"/>
		<edge from-layer="2721" from-port="2" to-layer="2723" to-port="0"/>
		<edge from-layer="2722" from-port="0" to-layer="2723" to-port="1"/>
		<edge from-layer="2723" from-port="2" to-layer="2724" to-port="0"/>
		<edge from-layer="2724" from-port="1" to-layer="2729" to-port="0"/>
		<edge from-layer="2725" from-port="0" to-layer="2729" to-port="1"/>
		<edge from-layer="2726" from-port="0" to-layer="2729" to-port="2"/>
		<edge from-layer="2727" from-port="0" to-layer="2729" to-port="3"/>
		<edge from-layer="2728" from-port="0" to-layer="2729" to-port="4"/>
		<edge from-layer="2730" from-port="0" to-layer="2731" to-port="0"/>
		<edge from-layer="2731" from-port="1" to-layer="2733" to-port="0"/>
		<edge from-layer="2732" from-port="0" to-layer="2733" to-port="1"/>
		<edge from-layer="2733" from-port="2" to-layer="2735" to-port="0"/>
		<edge from-layer="2734" from-port="0" to-layer="2735" to-port="1"/>
		<edge from-layer="2729" from-port="5" to-layer="2736" to-port="0"/>
		<edge from-layer="2735" from-port="2" to-layer="2736" to-port="1"/>
		<edge from-layer="2736" from-port="2" to-layer="2738" to-port="0"/>
		<edge from-layer="2737" from-port="0" to-layer="2738" to-port="1"/>
		<edge from-layer="2738" from-port="2" to-layer="2743" to-port="0"/>
		<edge from-layer="2739" from-port="0" to-layer="2743" to-port="1"/>
		<edge from-layer="2740" from-port="0" to-layer="2743" to-port="2"/>
		<edge from-layer="2741" from-port="0" to-layer="2743" to-port="3"/>
		<edge from-layer="2742" from-port="0" to-layer="2743" to-port="4"/>
		<edge from-layer="2744" from-port="0" to-layer="2745" to-port="0"/>
		<edge from-layer="2745" from-port="1" to-layer="2747" to-port="0"/>
		<edge from-layer="2746" from-port="0" to-layer="2747" to-port="1"/>
		<edge from-layer="2747" from-port="2" to-layer="2749" to-port="0"/>
		<edge from-layer="2748" from-port="0" to-layer="2749" to-port="1"/>
		<edge from-layer="2749" from-port="2" to-layer="2751" to-port="0"/>
		<edge from-layer="2750" from-port="0" to-layer="2751" to-port="1"/>
		<edge from-layer="2743" from-port="5" to-layer="2752" to-port="0"/>
		<edge from-layer="2751" from-port="2" to-layer="2752" to-port="1"/>
		<edge from-layer="2752" from-port="2" to-layer="2754" to-port="0"/>
		<edge from-layer="2753" from-port="0" to-layer="2754" to-port="1"/>
		<edge from-layer="2754" from-port="2" to-layer="2755" to-port="0"/>
		<edge from-layer="2755" from-port="1" to-layer="2760" to-port="0"/>
		<edge from-layer="2756" from-port="0" to-layer="2760" to-port="1"/>
		<edge from-layer="2757" from-port="0" to-layer="2760" to-port="2"/>
		<edge from-layer="2758" from-port="0" to-layer="2760" to-port="3"/>
		<edge from-layer="2759" from-port="0" to-layer="2760" to-port="4"/>
		<edge from-layer="2755" from-port="1" to-layer="2762" to-port="0"/>
		<edge from-layer="2762" from-port="1" to-layer="2763" to-port="0"/>
		<edge from-layer="2763" from-port="1" to-layer="2765" to-port="0"/>
		<edge from-layer="2764" from-port="0" to-layer="2765" to-port="1"/>
		<edge from-layer="2761" from-port="0" to-layer="2767" to-port="0"/>
		<edge from-layer="2765" from-port="2" to-layer="2767" to-port="1"/>
		<edge from-layer="2766" from-port="0" to-layer="2767" to-port="2"/>
		<edge from-layer="2760" from-port="5" to-layer="2768" to-port="0"/>
		<edge from-layer="2767" from-port="3" to-layer="2768" to-port="1"/>
		<edge from-layer="2768" from-port="2" to-layer="2773" to-port="0"/>
		<edge from-layer="2769" from-port="0" to-layer="2773" to-port="1"/>
		<edge from-layer="2770" from-port="0" to-layer="2773" to-port="2"/>
		<edge from-layer="2771" from-port="0" to-layer="2773" to-port="3"/>
		<edge from-layer="2772" from-port="0" to-layer="2773" to-port="4"/>
		<edge from-layer="2773" from-port="5" to-layer="2775" to-port="0"/>
		<edge from-layer="2774" from-port="0" to-layer="2775" to-port="1"/>
		<edge from-layer="2775" from-port="2" to-layer="2777" to-port="0"/>
		<edge from-layer="2777" from-port="1" to-layer="2778" to-port="0"/>
		<edge from-layer="2778" from-port="1" to-layer="2780" to-port="0"/>
		<edge from-layer="2779" from-port="0" to-layer="2780" to-port="1"/>
		<edge from-layer="2776" from-port="0" to-layer="2782" to-port="0"/>
		<edge from-layer="2780" from-port="2" to-layer="2782" to-port="1"/>
		<edge from-layer="2781" from-port="0" to-layer="2782" to-port="2"/>
		<edge from-layer="2775" from-port="2" to-layer="2783" to-port="0"/>
		<edge from-layer="2782" from-port="3" to-layer="2783" to-port="1"/>
		<edge from-layer="2783" from-port="2" to-layer="2785" to-port="0"/>
		<edge from-layer="2784" from-port="0" to-layer="2785" to-port="1"/>
		<edge from-layer="2785" from-port="2" to-layer="2787" to-port="0"/>
		<edge from-layer="2786" from-port="0" to-layer="2787" to-port="1"/>
		<edge from-layer="2787" from-port="2" to-layer="2792" to-port="0"/>
		<edge from-layer="2788" from-port="0" to-layer="2792" to-port="1"/>
		<edge from-layer="2789" from-port="0" to-layer="2792" to-port="2"/>
		<edge from-layer="2790" from-port="0" to-layer="2792" to-port="3"/>
		<edge from-layer="2791" from-port="0" to-layer="2792" to-port="4"/>
		<edge from-layer="2768" from-port="2" to-layer="2793" to-port="0"/>
		<edge from-layer="2792" from-port="5" to-layer="2794" to-port="0"/>
		<edge from-layer="2793" from-port="1" to-layer="2794" to-port="1"/>
		<edge from-layer="2794" from-port="2" to-layer="2796" to-port="0"/>
		<edge from-layer="2795" from-port="0" to-layer="2796" to-port="1"/>
		<edge from-layer="2796" from-port="2" to-layer="2798" to-port="0"/>
		<edge from-layer="2797" from-port="0" to-layer="2798" to-port="1"/>
		<edge from-layer="2798" from-port="2" to-layer="2799" to-port="0"/>
		<edge from-layer="2799" from-port="1" to-layer="2804" to-port="0"/>
		<edge from-layer="2800" from-port="0" to-layer="2804" to-port="1"/>
		<edge from-layer="2801" from-port="0" to-layer="2804" to-port="2"/>
		<edge from-layer="2802" from-port="0" to-layer="2804" to-port="3"/>
		<edge from-layer="2803" from-port="0" to-layer="2804" to-port="4"/>
		<edge from-layer="2760" from-port="5" to-layer="2805" to-port="0"/>
		<edge from-layer="2804" from-port="5" to-layer="2805" to-port="1"/>
		<edge from-layer="2805" from-port="2" to-layer="2810" to-port="0"/>
		<edge from-layer="2806" from-port="0" to-layer="2810" to-port="1"/>
		<edge from-layer="2807" from-port="0" to-layer="2810" to-port="2"/>
		<edge from-layer="2808" from-port="0" to-layer="2810" to-port="3"/>
		<edge from-layer="2809" from-port="0" to-layer="2810" to-port="4"/>
		<edge from-layer="2811" from-port="0" to-layer="2812" to-port="0"/>
		<edge from-layer="2812" from-port="1" to-layer="2814" to-port="0"/>
		<edge from-layer="2813" from-port="0" to-layer="2814" to-port="1"/>
		<edge from-layer="2814" from-port="2" to-layer="2816" to-port="0"/>
		<edge from-layer="2815" from-port="0" to-layer="2816" to-port="1"/>
		<edge from-layer="2729" from-port="5" to-layer="2817" to-port="0"/>
		<edge from-layer="2816" from-port="2" to-layer="2817" to-port="1"/>
		<edge from-layer="2817" from-port="2" to-layer="2819" to-port="0"/>
		<edge from-layer="2818" from-port="0" to-layer="2819" to-port="1"/>
		<edge from-layer="2819" from-port="2" to-layer="2824" to-port="0"/>
		<edge from-layer="2820" from-port="0" to-layer="2824" to-port="1"/>
		<edge from-layer="2821" from-port="0" to-layer="2824" to-port="2"/>
		<edge from-layer="2822" from-port="0" to-layer="2824" to-port="3"/>
		<edge from-layer="2823" from-port="0" to-layer="2824" to-port="4"/>
		<edge from-layer="2825" from-port="0" to-layer="2826" to-port="0"/>
		<edge from-layer="2826" from-port="1" to-layer="2828" to-port="0"/>
		<edge from-layer="2827" from-port="0" to-layer="2828" to-port="1"/>
		<edge from-layer="2828" from-port="2" to-layer="2830" to-port="0"/>
		<edge from-layer="2829" from-port="0" to-layer="2830" to-port="1"/>
		<edge from-layer="2830" from-port="2" to-layer="2832" to-port="0"/>
		<edge from-layer="2831" from-port="0" to-layer="2832" to-port="1"/>
		<edge from-layer="2824" from-port="5" to-layer="2833" to-port="0"/>
		<edge from-layer="2832" from-port="2" to-layer="2833" to-port="1"/>
		<edge from-layer="2833" from-port="2" to-layer="2835" to-port="0"/>
		<edge from-layer="2834" from-port="0" to-layer="2835" to-port="1"/>
		<edge from-layer="2835" from-port="2" to-layer="2836" to-port="0"/>
		<edge from-layer="2836" from-port="1" to-layer="2841" to-port="0"/>
		<edge from-layer="2837" from-port="0" to-layer="2841" to-port="1"/>
		<edge from-layer="2838" from-port="0" to-layer="2841" to-port="2"/>
		<edge from-layer="2839" from-port="0" to-layer="2841" to-port="3"/>
		<edge from-layer="2840" from-port="0" to-layer="2841" to-port="4"/>
		<edge from-layer="2842" from-port="0" to-layer="2843" to-port="0"/>
		<edge from-layer="2843" from-port="1" to-layer="2845" to-port="0"/>
		<edge from-layer="2844" from-port="0" to-layer="2845" to-port="1"/>
		<edge from-layer="2845" from-port="2" to-layer="2847" to-port="0"/>
		<edge from-layer="2846" from-port="0" to-layer="2847" to-port="1"/>
		<edge from-layer="2841" from-port="5" to-layer="2848" to-port="0"/>
		<edge from-layer="2847" from-port="2" to-layer="2848" to-port="1"/>
		<edge from-layer="2848" from-port="2" to-layer="2850" to-port="0"/>
		<edge from-layer="2849" from-port="0" to-layer="2850" to-port="1"/>
		<edge from-layer="2850" from-port="2" to-layer="2855" to-port="0"/>
		<edge from-layer="2851" from-port="0" to-layer="2855" to-port="1"/>
		<edge from-layer="2852" from-port="0" to-layer="2855" to-port="2"/>
		<edge from-layer="2853" from-port="0" to-layer="2855" to-port="3"/>
		<edge from-layer="2854" from-port="0" to-layer="2855" to-port="4"/>
		<edge from-layer="2856" from-port="0" to-layer="2857" to-port="0"/>
		<edge from-layer="2857" from-port="1" to-layer="2859" to-port="0"/>
		<edge from-layer="2858" from-port="0" to-layer="2859" to-port="1"/>
		<edge from-layer="2859" from-port="2" to-layer="2861" to-port="0"/>
		<edge from-layer="2860" from-port="0" to-layer="2861" to-port="1"/>
		<edge from-layer="2861" from-port="2" to-layer="2863" to-port="0"/>
		<edge from-layer="2862" from-port="0" to-layer="2863" to-port="1"/>
		<edge from-layer="2855" from-port="5" to-layer="2864" to-port="0"/>
		<edge from-layer="2863" from-port="2" to-layer="2864" to-port="1"/>
		<edge from-layer="2864" from-port="2" to-layer="2866" to-port="0"/>
		<edge from-layer="2865" from-port="0" to-layer="2866" to-port="1"/>
		<edge from-layer="2866" from-port="2" to-layer="2867" to-port="0"/>
		<edge from-layer="2867" from-port="1" to-layer="2872" to-port="0"/>
		<edge from-layer="2868" from-port="0" to-layer="2872" to-port="1"/>
		<edge from-layer="2869" from-port="0" to-layer="2872" to-port="2"/>
		<edge from-layer="2870" from-port="0" to-layer="2872" to-port="3"/>
		<edge from-layer="2871" from-port="0" to-layer="2872" to-port="4"/>
		<edge from-layer="2867" from-port="1" to-layer="2874" to-port="0"/>
		<edge from-layer="2874" from-port="1" to-layer="2875" to-port="0"/>
		<edge from-layer="2875" from-port="1" to-layer="2877" to-port="0"/>
		<edge from-layer="2876" from-port="0" to-layer="2877" to-port="1"/>
		<edge from-layer="2873" from-port="0" to-layer="2879" to-port="0"/>
		<edge from-layer="2877" from-port="2" to-layer="2879" to-port="1"/>
		<edge from-layer="2878" from-port="0" to-layer="2879" to-port="2"/>
		<edge from-layer="2872" from-port="5" to-layer="2880" to-port="0"/>
		<edge from-layer="2879" from-port="3" to-layer="2880" to-port="1"/>
		<edge from-layer="2880" from-port="2" to-layer="2885" to-port="0"/>
		<edge from-layer="2881" from-port="0" to-layer="2885" to-port="1"/>
		<edge from-layer="2882" from-port="0" to-layer="2885" to-port="2"/>
		<edge from-layer="2883" from-port="0" to-layer="2885" to-port="3"/>
		<edge from-layer="2884" from-port="0" to-layer="2885" to-port="4"/>
		<edge from-layer="2885" from-port="5" to-layer="2887" to-port="0"/>
		<edge from-layer="2886" from-port="0" to-layer="2887" to-port="1"/>
		<edge from-layer="2887" from-port="2" to-layer="2889" to-port="0"/>
		<edge from-layer="2889" from-port="1" to-layer="2890" to-port="0"/>
		<edge from-layer="2890" from-port="1" to-layer="2892" to-port="0"/>
		<edge from-layer="2891" from-port="0" to-layer="2892" to-port="1"/>
		<edge from-layer="2888" from-port="0" to-layer="2894" to-port="0"/>
		<edge from-layer="2892" from-port="2" to-layer="2894" to-port="1"/>
		<edge from-layer="2893" from-port="0" to-layer="2894" to-port="2"/>
		<edge from-layer="2887" from-port="2" to-layer="2895" to-port="0"/>
		<edge from-layer="2894" from-port="3" to-layer="2895" to-port="1"/>
		<edge from-layer="2895" from-port="2" to-layer="2897" to-port="0"/>
		<edge from-layer="2896" from-port="0" to-layer="2897" to-port="1"/>
		<edge from-layer="2897" from-port="2" to-layer="2899" to-port="0"/>
		<edge from-layer="2898" from-port="0" to-layer="2899" to-port="1"/>
		<edge from-layer="2899" from-port="2" to-layer="2904" to-port="0"/>
		<edge from-layer="2900" from-port="0" to-layer="2904" to-port="1"/>
		<edge from-layer="2901" from-port="0" to-layer="2904" to-port="2"/>
		<edge from-layer="2902" from-port="0" to-layer="2904" to-port="3"/>
		<edge from-layer="2903" from-port="0" to-layer="2904" to-port="4"/>
		<edge from-layer="2880" from-port="2" to-layer="2905" to-port="0"/>
		<edge from-layer="2904" from-port="5" to-layer="2906" to-port="0"/>
		<edge from-layer="2905" from-port="1" to-layer="2906" to-port="1"/>
		<edge from-layer="2906" from-port="2" to-layer="2908" to-port="0"/>
		<edge from-layer="2907" from-port="0" to-layer="2908" to-port="1"/>
		<edge from-layer="2908" from-port="2" to-layer="2910" to-port="0"/>
		<edge from-layer="2909" from-port="0" to-layer="2910" to-port="1"/>
		<edge from-layer="2910" from-port="2" to-layer="2911" to-port="0"/>
		<edge from-layer="2911" from-port="1" to-layer="2916" to-port="0"/>
		<edge from-layer="2912" from-port="0" to-layer="2916" to-port="1"/>
		<edge from-layer="2913" from-port="0" to-layer="2916" to-port="2"/>
		<edge from-layer="2914" from-port="0" to-layer="2916" to-port="3"/>
		<edge from-layer="2915" from-port="0" to-layer="2916" to-port="4"/>
		<edge from-layer="2872" from-port="5" to-layer="2917" to-port="0"/>
		<edge from-layer="2916" from-port="5" to-layer="2917" to-port="1"/>
		<edge from-layer="2917" from-port="2" to-layer="2922" to-port="0"/>
		<edge from-layer="2918" from-port="0" to-layer="2922" to-port="1"/>
		<edge from-layer="2919" from-port="0" to-layer="2922" to-port="2"/>
		<edge from-layer="2920" from-port="0" to-layer="2922" to-port="3"/>
		<edge from-layer="2921" from-port="0" to-layer="2922" to-port="4"/>
		<edge from-layer="2810" from-port="5" to-layer="2923" to-port="0"/>
		<edge from-layer="2922" from-port="5" to-layer="2923" to-port="1"/>
		<edge from-layer="2923" from-port="2" to-layer="2928" to-port="0"/>
		<edge from-layer="2924" from-port="0" to-layer="2928" to-port="1"/>
		<edge from-layer="2925" from-port="0" to-layer="2928" to-port="2"/>
		<edge from-layer="2926" from-port="0" to-layer="2928" to-port="3"/>
		<edge from-layer="2927" from-port="0" to-layer="2928" to-port="4"/>
		<edge from-layer="2929" from-port="0" to-layer="2930" to-port="0"/>
		<edge from-layer="2930" from-port="1" to-layer="2932" to-port="0"/>
		<edge from-layer="2931" from-port="0" to-layer="2932" to-port="1"/>
		<edge from-layer="2932" from-port="2" to-layer="2934" to-port="0"/>
		<edge from-layer="2933" from-port="0" to-layer="2934" to-port="1"/>
		<edge from-layer="2729" from-port="5" to-layer="2935" to-port="0"/>
		<edge from-layer="2934" from-port="2" to-layer="2935" to-port="1"/>
		<edge from-layer="2935" from-port="2" to-layer="2937" to-port="0"/>
		<edge from-layer="2936" from-port="0" to-layer="2937" to-port="1"/>
		<edge from-layer="2937" from-port="2" to-layer="2942" to-port="0"/>
		<edge from-layer="2938" from-port="0" to-layer="2942" to-port="1"/>
		<edge from-layer="2939" from-port="0" to-layer="2942" to-port="2"/>
		<edge from-layer="2940" from-port="0" to-layer="2942" to-port="3"/>
		<edge from-layer="2941" from-port="0" to-layer="2942" to-port="4"/>
		<edge from-layer="2943" from-port="0" to-layer="2944" to-port="0"/>
		<edge from-layer="2944" from-port="1" to-layer="2946" to-port="0"/>
		<edge from-layer="2945" from-port="0" to-layer="2946" to-port="1"/>
		<edge from-layer="2946" from-port="2" to-layer="2948" to-port="0"/>
		<edge from-layer="2947" from-port="0" to-layer="2948" to-port="1"/>
		<edge from-layer="2948" from-port="2" to-layer="2950" to-port="0"/>
		<edge from-layer="2949" from-port="0" to-layer="2950" to-port="1"/>
		<edge from-layer="2942" from-port="5" to-layer="2951" to-port="0"/>
		<edge from-layer="2950" from-port="2" to-layer="2951" to-port="1"/>
		<edge from-layer="2951" from-port="2" to-layer="2953" to-port="0"/>
		<edge from-layer="2952" from-port="0" to-layer="2953" to-port="1"/>
		<edge from-layer="2953" from-port="2" to-layer="2954" to-port="0"/>
		<edge from-layer="2954" from-port="1" to-layer="2959" to-port="0"/>
		<edge from-layer="2955" from-port="0" to-layer="2959" to-port="1"/>
		<edge from-layer="2956" from-port="0" to-layer="2959" to-port="2"/>
		<edge from-layer="2957" from-port="0" to-layer="2959" to-port="3"/>
		<edge from-layer="2958" from-port="0" to-layer="2959" to-port="4"/>
		<edge from-layer="2960" from-port="0" to-layer="2961" to-port="0"/>
		<edge from-layer="2961" from-port="1" to-layer="2963" to-port="0"/>
		<edge from-layer="2962" from-port="0" to-layer="2963" to-port="1"/>
		<edge from-layer="2963" from-port="2" to-layer="2965" to-port="0"/>
		<edge from-layer="2964" from-port="0" to-layer="2965" to-port="1"/>
		<edge from-layer="2959" from-port="5" to-layer="2966" to-port="0"/>
		<edge from-layer="2965" from-port="2" to-layer="2966" to-port="1"/>
		<edge from-layer="2966" from-port="2" to-layer="2968" to-port="0"/>
		<edge from-layer="2967" from-port="0" to-layer="2968" to-port="1"/>
		<edge from-layer="2968" from-port="2" to-layer="2973" to-port="0"/>
		<edge from-layer="2969" from-port="0" to-layer="2973" to-port="1"/>
		<edge from-layer="2970" from-port="0" to-layer="2973" to-port="2"/>
		<edge from-layer="2971" from-port="0" to-layer="2973" to-port="3"/>
		<edge from-layer="2972" from-port="0" to-layer="2973" to-port="4"/>
		<edge from-layer="2974" from-port="0" to-layer="2975" to-port="0"/>
		<edge from-layer="2975" from-port="1" to-layer="2977" to-port="0"/>
		<edge from-layer="2976" from-port="0" to-layer="2977" to-port="1"/>
		<edge from-layer="2977" from-port="2" to-layer="2979" to-port="0"/>
		<edge from-layer="2978" from-port="0" to-layer="2979" to-port="1"/>
		<edge from-layer="2979" from-port="2" to-layer="2981" to-port="0"/>
		<edge from-layer="2980" from-port="0" to-layer="2981" to-port="1"/>
		<edge from-layer="2973" from-port="5" to-layer="2982" to-port="0"/>
		<edge from-layer="2981" from-port="2" to-layer="2982" to-port="1"/>
		<edge from-layer="2982" from-port="2" to-layer="2984" to-port="0"/>
		<edge from-layer="2983" from-port="0" to-layer="2984" to-port="1"/>
		<edge from-layer="2984" from-port="2" to-layer="2985" to-port="0"/>
		<edge from-layer="2985" from-port="1" to-layer="2990" to-port="0"/>
		<edge from-layer="2986" from-port="0" to-layer="2990" to-port="1"/>
		<edge from-layer="2987" from-port="0" to-layer="2990" to-port="2"/>
		<edge from-layer="2988" from-port="0" to-layer="2990" to-port="3"/>
		<edge from-layer="2989" from-port="0" to-layer="2990" to-port="4"/>
		<edge from-layer="2991" from-port="0" to-layer="2992" to-port="0"/>
		<edge from-layer="2992" from-port="1" to-layer="2994" to-port="0"/>
		<edge from-layer="2993" from-port="0" to-layer="2994" to-port="1"/>
		<edge from-layer="2994" from-port="2" to-layer="2996" to-port="0"/>
		<edge from-layer="2995" from-port="0" to-layer="2996" to-port="1"/>
		<edge from-layer="2990" from-port="5" to-layer="2997" to-port="0"/>
		<edge from-layer="2996" from-port="2" to-layer="2997" to-port="1"/>
		<edge from-layer="2997" from-port="2" to-layer="2999" to-port="0"/>
		<edge from-layer="2998" from-port="0" to-layer="2999" to-port="1"/>
		<edge from-layer="2999" from-port="2" to-layer="3004" to-port="0"/>
		<edge from-layer="3000" from-port="0" to-layer="3004" to-port="1"/>
		<edge from-layer="3001" from-port="0" to-layer="3004" to-port="2"/>
		<edge from-layer="3002" from-port="0" to-layer="3004" to-port="3"/>
		<edge from-layer="3003" from-port="0" to-layer="3004" to-port="4"/>
		<edge from-layer="3005" from-port="0" to-layer="3006" to-port="0"/>
		<edge from-layer="3006" from-port="1" to-layer="3008" to-port="0"/>
		<edge from-layer="3007" from-port="0" to-layer="3008" to-port="1"/>
		<edge from-layer="3008" from-port="2" to-layer="3010" to-port="0"/>
		<edge from-layer="3009" from-port="0" to-layer="3010" to-port="1"/>
		<edge from-layer="3010" from-port="2" to-layer="3012" to-port="0"/>
		<edge from-layer="3011" from-port="0" to-layer="3012" to-port="1"/>
		<edge from-layer="3004" from-port="5" to-layer="3013" to-port="0"/>
		<edge from-layer="3012" from-port="2" to-layer="3013" to-port="1"/>
		<edge from-layer="3013" from-port="2" to-layer="3015" to-port="0"/>
		<edge from-layer="3014" from-port="0" to-layer="3015" to-port="1"/>
		<edge from-layer="3015" from-port="2" to-layer="3016" to-port="0"/>
		<edge from-layer="3016" from-port="1" to-layer="3021" to-port="0"/>
		<edge from-layer="3017" from-port="0" to-layer="3021" to-port="1"/>
		<edge from-layer="3018" from-port="0" to-layer="3021" to-port="2"/>
		<edge from-layer="3019" from-port="0" to-layer="3021" to-port="3"/>
		<edge from-layer="3020" from-port="0" to-layer="3021" to-port="4"/>
		<edge from-layer="3016" from-port="1" to-layer="3023" to-port="0"/>
		<edge from-layer="3023" from-port="1" to-layer="3024" to-port="0"/>
		<edge from-layer="3024" from-port="1" to-layer="3026" to-port="0"/>
		<edge from-layer="3025" from-port="0" to-layer="3026" to-port="1"/>
		<edge from-layer="3022" from-port="0" to-layer="3028" to-port="0"/>
		<edge from-layer="3026" from-port="2" to-layer="3028" to-port="1"/>
		<edge from-layer="3027" from-port="0" to-layer="3028" to-port="2"/>
		<edge from-layer="3021" from-port="5" to-layer="3029" to-port="0"/>
		<edge from-layer="3028" from-port="3" to-layer="3029" to-port="1"/>
		<edge from-layer="3029" from-port="2" to-layer="3034" to-port="0"/>
		<edge from-layer="3030" from-port="0" to-layer="3034" to-port="1"/>
		<edge from-layer="3031" from-port="0" to-layer="3034" to-port="2"/>
		<edge from-layer="3032" from-port="0" to-layer="3034" to-port="3"/>
		<edge from-layer="3033" from-port="0" to-layer="3034" to-port="4"/>
		<edge from-layer="3034" from-port="5" to-layer="3036" to-port="0"/>
		<edge from-layer="3035" from-port="0" to-layer="3036" to-port="1"/>
		<edge from-layer="3036" from-port="2" to-layer="3038" to-port="0"/>
		<edge from-layer="3038" from-port="1" to-layer="3039" to-port="0"/>
		<edge from-layer="3039" from-port="1" to-layer="3041" to-port="0"/>
		<edge from-layer="3040" from-port="0" to-layer="3041" to-port="1"/>
		<edge from-layer="3037" from-port="0" to-layer="3043" to-port="0"/>
		<edge from-layer="3041" from-port="2" to-layer="3043" to-port="1"/>
		<edge from-layer="3042" from-port="0" to-layer="3043" to-port="2"/>
		<edge from-layer="3036" from-port="2" to-layer="3044" to-port="0"/>
		<edge from-layer="3043" from-port="3" to-layer="3044" to-port="1"/>
		<edge from-layer="3044" from-port="2" to-layer="3046" to-port="0"/>
		<edge from-layer="3045" from-port="0" to-layer="3046" to-port="1"/>
		<edge from-layer="3046" from-port="2" to-layer="3048" to-port="0"/>
		<edge from-layer="3047" from-port="0" to-layer="3048" to-port="1"/>
		<edge from-layer="3048" from-port="2" to-layer="3053" to-port="0"/>
		<edge from-layer="3049" from-port="0" to-layer="3053" to-port="1"/>
		<edge from-layer="3050" from-port="0" to-layer="3053" to-port="2"/>
		<edge from-layer="3051" from-port="0" to-layer="3053" to-port="3"/>
		<edge from-layer="3052" from-port="0" to-layer="3053" to-port="4"/>
		<edge from-layer="3029" from-port="2" to-layer="3054" to-port="0"/>
		<edge from-layer="3053" from-port="5" to-layer="3055" to-port="0"/>
		<edge from-layer="3054" from-port="1" to-layer="3055" to-port="1"/>
		<edge from-layer="3055" from-port="2" to-layer="3057" to-port="0"/>
		<edge from-layer="3056" from-port="0" to-layer="3057" to-port="1"/>
		<edge from-layer="3057" from-port="2" to-layer="3059" to-port="0"/>
		<edge from-layer="3058" from-port="0" to-layer="3059" to-port="1"/>
		<edge from-layer="3059" from-port="2" to-layer="3060" to-port="0"/>
		<edge from-layer="3060" from-port="1" to-layer="3065" to-port="0"/>
		<edge from-layer="3061" from-port="0" to-layer="3065" to-port="1"/>
		<edge from-layer="3062" from-port="0" to-layer="3065" to-port="2"/>
		<edge from-layer="3063" from-port="0" to-layer="3065" to-port="3"/>
		<edge from-layer="3064" from-port="0" to-layer="3065" to-port="4"/>
		<edge from-layer="3021" from-port="5" to-layer="3066" to-port="0"/>
		<edge from-layer="3065" from-port="5" to-layer="3066" to-port="1"/>
		<edge from-layer="3066" from-port="2" to-layer="3071" to-port="0"/>
		<edge from-layer="3067" from-port="0" to-layer="3071" to-port="1"/>
		<edge from-layer="3068" from-port="0" to-layer="3071" to-port="2"/>
		<edge from-layer="3069" from-port="0" to-layer="3071" to-port="3"/>
		<edge from-layer="3070" from-port="0" to-layer="3071" to-port="4"/>
		<edge from-layer="2928" from-port="5" to-layer="3072" to-port="0"/>
		<edge from-layer="3071" from-port="5" to-layer="3072" to-port="1"/>
		<edge from-layer="3072" from-port="2" to-layer="3077" to-port="0"/>
		<edge from-layer="3073" from-port="0" to-layer="3077" to-port="1"/>
		<edge from-layer="3074" from-port="0" to-layer="3077" to-port="2"/>
		<edge from-layer="3075" from-port="0" to-layer="3077" to-port="3"/>
		<edge from-layer="3076" from-port="0" to-layer="3077" to-port="4"/>
		<edge from-layer="3078" from-port="0" to-layer="3079" to-port="0"/>
		<edge from-layer="3079" from-port="1" to-layer="3081" to-port="0"/>
		<edge from-layer="3080" from-port="0" to-layer="3081" to-port="1"/>
		<edge from-layer="3081" from-port="2" to-layer="3083" to-port="0"/>
		<edge from-layer="3082" from-port="0" to-layer="3083" to-port="1"/>
		<edge from-layer="2729" from-port="5" to-layer="3084" to-port="0"/>
		<edge from-layer="3083" from-port="2" to-layer="3084" to-port="1"/>
		<edge from-layer="3084" from-port="2" to-layer="3086" to-port="0"/>
		<edge from-layer="3085" from-port="0" to-layer="3086" to-port="1"/>
		<edge from-layer="3086" from-port="2" to-layer="3091" to-port="0"/>
		<edge from-layer="3087" from-port="0" to-layer="3091" to-port="1"/>
		<edge from-layer="3088" from-port="0" to-layer="3091" to-port="2"/>
		<edge from-layer="3089" from-port="0" to-layer="3091" to-port="3"/>
		<edge from-layer="3090" from-port="0" to-layer="3091" to-port="4"/>
		<edge from-layer="3092" from-port="0" to-layer="3093" to-port="0"/>
		<edge from-layer="3093" from-port="1" to-layer="3095" to-port="0"/>
		<edge from-layer="3094" from-port="0" to-layer="3095" to-port="1"/>
		<edge from-layer="3095" from-port="2" to-layer="3097" to-port="0"/>
		<edge from-layer="3096" from-port="0" to-layer="3097" to-port="1"/>
		<edge from-layer="3097" from-port="2" to-layer="3099" to-port="0"/>
		<edge from-layer="3098" from-port="0" to-layer="3099" to-port="1"/>
		<edge from-layer="3091" from-port="5" to-layer="3100" to-port="0"/>
		<edge from-layer="3099" from-port="2" to-layer="3100" to-port="1"/>
		<edge from-layer="3100" from-port="2" to-layer="3102" to-port="0"/>
		<edge from-layer="3101" from-port="0" to-layer="3102" to-port="1"/>
		<edge from-layer="3102" from-port="2" to-layer="3103" to-port="0"/>
		<edge from-layer="3103" from-port="1" to-layer="3108" to-port="0"/>
		<edge from-layer="3104" from-port="0" to-layer="3108" to-port="1"/>
		<edge from-layer="3105" from-port="0" to-layer="3108" to-port="2"/>
		<edge from-layer="3106" from-port="0" to-layer="3108" to-port="3"/>
		<edge from-layer="3107" from-port="0" to-layer="3108" to-port="4"/>
		<edge from-layer="3109" from-port="0" to-layer="3110" to-port="0"/>
		<edge from-layer="3110" from-port="1" to-layer="3112" to-port="0"/>
		<edge from-layer="3111" from-port="0" to-layer="3112" to-port="1"/>
		<edge from-layer="3112" from-port="2" to-layer="3114" to-port="0"/>
		<edge from-layer="3113" from-port="0" to-layer="3114" to-port="1"/>
		<edge from-layer="3108" from-port="5" to-layer="3115" to-port="0"/>
		<edge from-layer="3114" from-port="2" to-layer="3115" to-port="1"/>
		<edge from-layer="3115" from-port="2" to-layer="3117" to-port="0"/>
		<edge from-layer="3116" from-port="0" to-layer="3117" to-port="1"/>
		<edge from-layer="3117" from-port="2" to-layer="3122" to-port="0"/>
		<edge from-layer="3118" from-port="0" to-layer="3122" to-port="1"/>
		<edge from-layer="3119" from-port="0" to-layer="3122" to-port="2"/>
		<edge from-layer="3120" from-port="0" to-layer="3122" to-port="3"/>
		<edge from-layer="3121" from-port="0" to-layer="3122" to-port="4"/>
		<edge from-layer="3123" from-port="0" to-layer="3124" to-port="0"/>
		<edge from-layer="3124" from-port="1" to-layer="3126" to-port="0"/>
		<edge from-layer="3125" from-port="0" to-layer="3126" to-port="1"/>
		<edge from-layer="3126" from-port="2" to-layer="3128" to-port="0"/>
		<edge from-layer="3127" from-port="0" to-layer="3128" to-port="1"/>
		<edge from-layer="3128" from-port="2" to-layer="3130" to-port="0"/>
		<edge from-layer="3129" from-port="0" to-layer="3130" to-port="1"/>
		<edge from-layer="3122" from-port="5" to-layer="3131" to-port="0"/>
		<edge from-layer="3130" from-port="2" to-layer="3131" to-port="1"/>
		<edge from-layer="3131" from-port="2" to-layer="3133" to-port="0"/>
		<edge from-layer="3132" from-port="0" to-layer="3133" to-port="1"/>
		<edge from-layer="3133" from-port="2" to-layer="3134" to-port="0"/>
		<edge from-layer="3134" from-port="1" to-layer="3139" to-port="0"/>
		<edge from-layer="3135" from-port="0" to-layer="3139" to-port="1"/>
		<edge from-layer="3136" from-port="0" to-layer="3139" to-port="2"/>
		<edge from-layer="3137" from-port="0" to-layer="3139" to-port="3"/>
		<edge from-layer="3138" from-port="0" to-layer="3139" to-port="4"/>
		<edge from-layer="3140" from-port="0" to-layer="3141" to-port="0"/>
		<edge from-layer="3141" from-port="1" to-layer="3143" to-port="0"/>
		<edge from-layer="3142" from-port="0" to-layer="3143" to-port="1"/>
		<edge from-layer="3143" from-port="2" to-layer="3145" to-port="0"/>
		<edge from-layer="3144" from-port="0" to-layer="3145" to-port="1"/>
		<edge from-layer="3139" from-port="5" to-layer="3146" to-port="0"/>
		<edge from-layer="3145" from-port="2" to-layer="3146" to-port="1"/>
		<edge from-layer="3146" from-port="2" to-layer="3148" to-port="0"/>
		<edge from-layer="3147" from-port="0" to-layer="3148" to-port="1"/>
		<edge from-layer="3148" from-port="2" to-layer="3153" to-port="0"/>
		<edge from-layer="3149" from-port="0" to-layer="3153" to-port="1"/>
		<edge from-layer="3150" from-port="0" to-layer="3153" to-port="2"/>
		<edge from-layer="3151" from-port="0" to-layer="3153" to-port="3"/>
		<edge from-layer="3152" from-port="0" to-layer="3153" to-port="4"/>
		<edge from-layer="3154" from-port="0" to-layer="3155" to-port="0"/>
		<edge from-layer="3155" from-port="1" to-layer="3157" to-port="0"/>
		<edge from-layer="3156" from-port="0" to-layer="3157" to-port="1"/>
		<edge from-layer="3157" from-port="2" to-layer="3159" to-port="0"/>
		<edge from-layer="3158" from-port="0" to-layer="3159" to-port="1"/>
		<edge from-layer="3159" from-port="2" to-layer="3161" to-port="0"/>
		<edge from-layer="3160" from-port="0" to-layer="3161" to-port="1"/>
		<edge from-layer="3153" from-port="5" to-layer="3162" to-port="0"/>
		<edge from-layer="3161" from-port="2" to-layer="3162" to-port="1"/>
		<edge from-layer="3162" from-port="2" to-layer="3164" to-port="0"/>
		<edge from-layer="3163" from-port="0" to-layer="3164" to-port="1"/>
		<edge from-layer="3164" from-port="2" to-layer="3165" to-port="0"/>
		<edge from-layer="3165" from-port="1" to-layer="3170" to-port="0"/>
		<edge from-layer="3166" from-port="0" to-layer="3170" to-port="1"/>
		<edge from-layer="3167" from-port="0" to-layer="3170" to-port="2"/>
		<edge from-layer="3168" from-port="0" to-layer="3170" to-port="3"/>
		<edge from-layer="3169" from-port="0" to-layer="3170" to-port="4"/>
		<edge from-layer="3171" from-port="0" to-layer="3172" to-port="0"/>
		<edge from-layer="3172" from-port="1" to-layer="3174" to-port="0"/>
		<edge from-layer="3173" from-port="0" to-layer="3174" to-port="1"/>
		<edge from-layer="3174" from-port="2" to-layer="3176" to-port="0"/>
		<edge from-layer="3175" from-port="0" to-layer="3176" to-port="1"/>
		<edge from-layer="3170" from-port="5" to-layer="3177" to-port="0"/>
		<edge from-layer="3176" from-port="2" to-layer="3177" to-port="1"/>
		<edge from-layer="3177" from-port="2" to-layer="3179" to-port="0"/>
		<edge from-layer="3178" from-port="0" to-layer="3179" to-port="1"/>
		<edge from-layer="3179" from-port="2" to-layer="3184" to-port="0"/>
		<edge from-layer="3180" from-port="0" to-layer="3184" to-port="1"/>
		<edge from-layer="3181" from-port="0" to-layer="3184" to-port="2"/>
		<edge from-layer="3182" from-port="0" to-layer="3184" to-port="3"/>
		<edge from-layer="3183" from-port="0" to-layer="3184" to-port="4"/>
		<edge from-layer="3185" from-port="0" to-layer="3186" to-port="0"/>
		<edge from-layer="3186" from-port="1" to-layer="3188" to-port="0"/>
		<edge from-layer="3187" from-port="0" to-layer="3188" to-port="1"/>
		<edge from-layer="3188" from-port="2" to-layer="3190" to-port="0"/>
		<edge from-layer="3189" from-port="0" to-layer="3190" to-port="1"/>
		<edge from-layer="3190" from-port="2" to-layer="3192" to-port="0"/>
		<edge from-layer="3191" from-port="0" to-layer="3192" to-port="1"/>
		<edge from-layer="3184" from-port="5" to-layer="3193" to-port="0"/>
		<edge from-layer="3192" from-port="2" to-layer="3193" to-port="1"/>
		<edge from-layer="3193" from-port="2" to-layer="3195" to-port="0"/>
		<edge from-layer="3194" from-port="0" to-layer="3195" to-port="1"/>
		<edge from-layer="3195" from-port="2" to-layer="3196" to-port="0"/>
		<edge from-layer="3196" from-port="1" to-layer="3201" to-port="0"/>
		<edge from-layer="3197" from-port="0" to-layer="3201" to-port="1"/>
		<edge from-layer="3198" from-port="0" to-layer="3201" to-port="2"/>
		<edge from-layer="3199" from-port="0" to-layer="3201" to-port="3"/>
		<edge from-layer="3200" from-port="0" to-layer="3201" to-port="4"/>
		<edge from-layer="3196" from-port="1" to-layer="3203" to-port="0"/>
		<edge from-layer="3203" from-port="1" to-layer="3204" to-port="0"/>
		<edge from-layer="3204" from-port="1" to-layer="3206" to-port="0"/>
		<edge from-layer="3205" from-port="0" to-layer="3206" to-port="1"/>
		<edge from-layer="3202" from-port="0" to-layer="3208" to-port="0"/>
		<edge from-layer="3206" from-port="2" to-layer="3208" to-port="1"/>
		<edge from-layer="3207" from-port="0" to-layer="3208" to-port="2"/>
		<edge from-layer="3201" from-port="5" to-layer="3209" to-port="0"/>
		<edge from-layer="3208" from-port="3" to-layer="3209" to-port="1"/>
		<edge from-layer="3209" from-port="2" to-layer="3214" to-port="0"/>
		<edge from-layer="3210" from-port="0" to-layer="3214" to-port="1"/>
		<edge from-layer="3211" from-port="0" to-layer="3214" to-port="2"/>
		<edge from-layer="3212" from-port="0" to-layer="3214" to-port="3"/>
		<edge from-layer="3213" from-port="0" to-layer="3214" to-port="4"/>
		<edge from-layer="3214" from-port="5" to-layer="3216" to-port="0"/>
		<edge from-layer="3215" from-port="0" to-layer="3216" to-port="1"/>
		<edge from-layer="3216" from-port="2" to-layer="3218" to-port="0"/>
		<edge from-layer="3218" from-port="1" to-layer="3219" to-port="0"/>
		<edge from-layer="3219" from-port="1" to-layer="3221" to-port="0"/>
		<edge from-layer="3220" from-port="0" to-layer="3221" to-port="1"/>
		<edge from-layer="3217" from-port="0" to-layer="3223" to-port="0"/>
		<edge from-layer="3221" from-port="2" to-layer="3223" to-port="1"/>
		<edge from-layer="3222" from-port="0" to-layer="3223" to-port="2"/>
		<edge from-layer="3216" from-port="2" to-layer="3224" to-port="0"/>
		<edge from-layer="3223" from-port="3" to-layer="3224" to-port="1"/>
		<edge from-layer="3224" from-port="2" to-layer="3226" to-port="0"/>
		<edge from-layer="3225" from-port="0" to-layer="3226" to-port="1"/>
		<edge from-layer="3226" from-port="2" to-layer="3228" to-port="0"/>
		<edge from-layer="3227" from-port="0" to-layer="3228" to-port="1"/>
		<edge from-layer="3228" from-port="2" to-layer="3233" to-port="0"/>
		<edge from-layer="3229" from-port="0" to-layer="3233" to-port="1"/>
		<edge from-layer="3230" from-port="0" to-layer="3233" to-port="2"/>
		<edge from-layer="3231" from-port="0" to-layer="3233" to-port="3"/>
		<edge from-layer="3232" from-port="0" to-layer="3233" to-port="4"/>
		<edge from-layer="3209" from-port="2" to-layer="3234" to-port="0"/>
		<edge from-layer="3233" from-port="5" to-layer="3235" to-port="0"/>
		<edge from-layer="3234" from-port="1" to-layer="3235" to-port="1"/>
		<edge from-layer="3235" from-port="2" to-layer="3237" to-port="0"/>
		<edge from-layer="3236" from-port="0" to-layer="3237" to-port="1"/>
		<edge from-layer="3237" from-port="2" to-layer="3239" to-port="0"/>
		<edge from-layer="3238" from-port="0" to-layer="3239" to-port="1"/>
		<edge from-layer="3239" from-port="2" to-layer="3240" to-port="0"/>
		<edge from-layer="3240" from-port="1" to-layer="3245" to-port="0"/>
		<edge from-layer="3241" from-port="0" to-layer="3245" to-port="1"/>
		<edge from-layer="3242" from-port="0" to-layer="3245" to-port="2"/>
		<edge from-layer="3243" from-port="0" to-layer="3245" to-port="3"/>
		<edge from-layer="3244" from-port="0" to-layer="3245" to-port="4"/>
		<edge from-layer="3201" from-port="5" to-layer="3246" to-port="0"/>
		<edge from-layer="3245" from-port="5" to-layer="3246" to-port="1"/>
		<edge from-layer="3246" from-port="2" to-layer="3251" to-port="0"/>
		<edge from-layer="3247" from-port="0" to-layer="3251" to-port="1"/>
		<edge from-layer="3248" from-port="0" to-layer="3251" to-port="2"/>
		<edge from-layer="3249" from-port="0" to-layer="3251" to-port="3"/>
		<edge from-layer="3250" from-port="0" to-layer="3251" to-port="4"/>
		<edge from-layer="3077" from-port="5" to-layer="3252" to-port="0"/>
		<edge from-layer="3251" from-port="5" to-layer="3252" to-port="1"/>
		<edge from-layer="3252" from-port="2" to-layer="3257" to-port="0"/>
		<edge from-layer="3253" from-port="0" to-layer="3257" to-port="1"/>
		<edge from-layer="3254" from-port="0" to-layer="3257" to-port="2"/>
		<edge from-layer="3255" from-port="0" to-layer="3257" to-port="3"/>
		<edge from-layer="3256" from-port="0" to-layer="3257" to-port="4"/>
		<edge from-layer="3258" from-port="0" to-layer="3259" to-port="0"/>
		<edge from-layer="3259" from-port="1" to-layer="3261" to-port="0"/>
		<edge from-layer="3260" from-port="0" to-layer="3261" to-port="1"/>
		<edge from-layer="3261" from-port="2" to-layer="3263" to-port="0"/>
		<edge from-layer="3262" from-port="0" to-layer="3263" to-port="1"/>
		<edge from-layer="3257" from-port="5" to-layer="3264" to-port="0"/>
		<edge from-layer="3263" from-port="2" to-layer="3264" to-port="1"/>
		<edge from-layer="3264" from-port="2" to-layer="3266" to-port="0"/>
		<edge from-layer="3265" from-port="0" to-layer="3266" to-port="1"/>
		<edge from-layer="3266" from-port="2" to-layer="3271" to-port="0"/>
		<edge from-layer="3267" from-port="0" to-layer="3271" to-port="1"/>
		<edge from-layer="3268" from-port="0" to-layer="3271" to-port="2"/>
		<edge from-layer="3269" from-port="0" to-layer="3271" to-port="3"/>
		<edge from-layer="3270" from-port="0" to-layer="3271" to-port="4"/>
		<edge from-layer="3271" from-port="5" to-layer="3272" to-port="0"/>
		<edge from-layer="2714" from-port="5" to-layer="3272" to-port="1"/>
		<edge from-layer="3272" from-port="2" to-layer="3273" to-port="0"/>
		<edge from-layer="3273" from-port="1" to-layer="3278" to-port="0"/>
		<edge from-layer="3274" from-port="0" to-layer="3278" to-port="1"/>
		<edge from-layer="3275" from-port="0" to-layer="3278" to-port="2"/>
		<edge from-layer="3276" from-port="0" to-layer="3278" to-port="3"/>
		<edge from-layer="3277" from-port="0" to-layer="3278" to-port="4"/>
		<edge from-layer="3279" from-port="0" to-layer="3280" to-port="0"/>
		<edge from-layer="3280" from-port="1" to-layer="3282" to-port="0"/>
		<edge from-layer="3281" from-port="0" to-layer="3282" to-port="1"/>
		<edge from-layer="3282" from-port="2" to-layer="3284" to-port="0"/>
		<edge from-layer="3283" from-port="0" to-layer="3284" to-port="1"/>
		<edge from-layer="3278" from-port="5" to-layer="3285" to-port="0"/>
		<edge from-layer="3284" from-port="2" to-layer="3285" to-port="1"/>
		<edge from-layer="3285" from-port="2" to-layer="3287" to-port="0"/>
		<edge from-layer="3286" from-port="0" to-layer="3287" to-port="1"/>
		<edge from-layer="3287" from-port="2" to-layer="3288" to-port="0"/>
		<edge from-layer="3288" from-port="1" to-layer="3293" to-port="0"/>
		<edge from-layer="3289" from-port="0" to-layer="3293" to-port="1"/>
		<edge from-layer="3290" from-port="0" to-layer="3293" to-port="2"/>
		<edge from-layer="3291" from-port="0" to-layer="3293" to-port="3"/>
		<edge from-layer="3292" from-port="0" to-layer="3293" to-port="4"/>
		<edge from-layer="3294" from-port="0" to-layer="3295" to-port="0"/>
		<edge from-layer="3295" from-port="1" to-layer="3297" to-port="0"/>
		<edge from-layer="3296" from-port="0" to-layer="3297" to-port="1"/>
		<edge from-layer="3297" from-port="2" to-layer="3299" to-port="0"/>
		<edge from-layer="3298" from-port="0" to-layer="3299" to-port="1"/>
		<edge from-layer="3299" from-port="2" to-layer="3301" to-port="0"/>
		<edge from-layer="3300" from-port="0" to-layer="3301" to-port="1"/>
		<edge from-layer="3293" from-port="5" to-layer="3302" to-port="0"/>
		<edge from-layer="3301" from-port="2" to-layer="3302" to-port="1"/>
		<edge from-layer="3302" from-port="2" to-layer="3304" to-port="0"/>
		<edge from-layer="3303" from-port="0" to-layer="3304" to-port="1"/>
		<edge from-layer="3304" from-port="2" to-layer="3309" to-port="0"/>
		<edge from-layer="3305" from-port="0" to-layer="3309" to-port="1"/>
		<edge from-layer="3306" from-port="0" to-layer="3309" to-port="2"/>
		<edge from-layer="3307" from-port="0" to-layer="3309" to-port="3"/>
		<edge from-layer="3308" from-port="0" to-layer="3309" to-port="4"/>
		<edge from-layer="3304" from-port="2" to-layer="3310" to-port="0"/>
		<edge from-layer="3310" from-port="1" to-layer="3313" to-port="0"/>
		<edge from-layer="3311" from-port="0" to-layer="3313" to-port="1"/>
		<edge from-layer="3312" from-port="0" to-layer="3313" to-port="2"/>
		<edge from-layer="3313" from-port="3" to-layer="3315" to-port="0"/>
		<edge from-layer="3314" from-port="0" to-layer="3315" to-port="1"/>
		<edge from-layer="3315" from-port="2" to-layer="3317" to-port="0"/>
		<edge from-layer="3316" from-port="0" to-layer="3317" to-port="1"/>
		<edge from-layer="3309" from-port="5" to-layer="3318" to-port="0"/>
		<edge from-layer="3317" from-port="2" to-layer="3318" to-port="1"/>
		<edge from-layer="3319" from-port="0" to-layer="3320" to-port="0"/>
		<edge from-layer="3320" from-port="1" to-layer="3322" to-port="0"/>
		<edge from-layer="3321" from-port="0" to-layer="3322" to-port="1"/>
		<edge from-layer="3322" from-port="2" to-layer="3324" to-port="0"/>
		<edge from-layer="3323" from-port="0" to-layer="3324" to-port="1"/>
		<edge from-layer="3318" from-port="2" to-layer="3325" to-port="0"/>
		<edge from-layer="3324" from-port="2" to-layer="3325" to-port="1"/>
		<edge from-layer="3325" from-port="2" to-layer="3327" to-port="0"/>
		<edge from-layer="3326" from-port="0" to-layer="3327" to-port="1"/>
		<edge from-layer="3327" from-port="2" to-layer="3332" to-port="0"/>
		<edge from-layer="3328" from-port="0" to-layer="3332" to-port="1"/>
		<edge from-layer="3329" from-port="0" to-layer="3332" to-port="2"/>
		<edge from-layer="3330" from-port="0" to-layer="3332" to-port="3"/>
		<edge from-layer="3331" from-port="0" to-layer="3332" to-port="4"/>
		<edge from-layer="3318" from-port="2" to-layer="3333" to-port="0"/>
		<edge from-layer="3333" from-port="1" to-layer="3336" to-port="0"/>
		<edge from-layer="3334" from-port="0" to-layer="3336" to-port="1"/>
		<edge from-layer="3335" from-port="0" to-layer="3336" to-port="2"/>
		<edge from-layer="3336" from-port="3" to-layer="3338" to-port="0"/>
		<edge from-layer="3337" from-port="0" to-layer="3338" to-port="1"/>
		<edge from-layer="3338" from-port="2" to-layer="3341" to-port="0"/>
		<edge from-layer="3339" from-port="0" to-layer="3341" to-port="1"/>
		<edge from-layer="3340" from-port="0" to-layer="3341" to-port="2"/>
		<edge from-layer="3332" from-port="5" to-layer="3342" to-port="0"/>
		<edge from-layer="3341" from-port="3" to-layer="3342" to-port="1"/>
		<edge from-layer="3342" from-port="2" to-layer="3344" to-port="0"/>
		<edge from-layer="3343" from-port="0" to-layer="3344" to-port="1"/>
		<edge from-layer="3344" from-port="2" to-layer="3346" to-port="0"/>
		<edge from-layer="3345" from-port="0" to-layer="3346" to-port="1"/>
		<edge from-layer="3346" from-port="2" to-layer="3348" to-port="0"/>
		<edge from-layer="3347" from-port="0" to-layer="3348" to-port="1"/>
		<edge from-layer="3348" from-port="2" to-layer="3349" to-port="0"/>
		<edge from-layer="3349" from-port="1" to-layer="3352" to-port="0"/>
		<edge from-layer="3350" from-port="0" to-layer="3352" to-port="1"/>
		<edge from-layer="3351" from-port="0" to-layer="3352" to-port="2"/>
		<edge from-layer="3352" from-port="3" to-layer="3354" to-port="0"/>
		<edge from-layer="3353" from-port="0" to-layer="3354" to-port="1"/>
		<edge from-layer="3354" from-port="2" to-layer="3356" to-port="0"/>
		<edge from-layer="3355" from-port="0" to-layer="3356" to-port="1"/>
		<edge from-layer="3348" from-port="2" to-layer="3357" to-port="0"/>
		<edge from-layer="3356" from-port="2" to-layer="3357" to-port="1"/>
		<edge from-layer="3357" from-port="2" to-layer="3358" to-port="0"/>
	</edges>
	<meta_data>
		<MO_version value="unknown version"/>
		<cli_parameters>
			<caffe_parser_path value="DIR"/>
			<data_type value="FP16"/>
			<disable_nhwc_to_nchw value="False"/>
			<disable_omitting_optional value="False"/>
			<disable_resnet_optimization value="False"/>
			<disable_weights_compression value="False"/>
			<enable_concat_optimization value="False"/>
			<enable_flattening_nested_params value="False"/>
			<enable_ssd_gluoncv value="False"/>
			<extensions value="DIR"/>
			<framework value="onnx"/>
			<freeze_placeholder_with_value value="{}"/>
			<generate_deprecated_IR_V7 value="False"/>
			<input value="data"/>
			<input_model value="DIR/person-reidentification-retail-0277.onnx"/>
			<input_model_is_text value="False"/>
			<input_shape value="[1,3,256,128]"/>
			<k value="DIR/CustomLayersMapping.xml"/>
			<keep_shape_ops value="True"/>
			<legacy_mxnet_model value="False"/>
			<log_level value="ERROR"/>
			<mean_scale_values value="{'data': {'mean': array([123.675, 116.28 , 103.53 ]), 'scale': array([58.395, 57.12 , 57.375])}}"/>
			<mean_values value="data[123.675,116.28,103.53]"/>
			<model_name value="person-reidentification-retail-0277"/>
			<output value="['reid_embedding']"/>
			<output_dir value="DIR"/>
			<placeholder_data_types value="{}"/>
			<placeholder_shapes value="{'data': array([  1,   3, 256, 128])}"/>
			<progress value="False"/>
			<remove_memory value="False"/>
			<remove_output_softmax value="False"/>
			<reverse_input_channels value="True"/>
			<save_params_from_nd value="False"/>
			<scale_values value="data[58.395,57.12,57.375]"/>
			<silent value="False"/>
			<static_shape value="False"/>
			<stream_output value="False"/>
			<unset unset_cli_parameters="batch, counts, disable_fusing, disable_gfusing, finegrain_fusing, input_checkpoint, input_meta_graph, input_proto, input_symbol, mean_file, mean_file_offsets, move_to_preprocess, nd_prefix_name, pretrained_model_name, saved_model_dir, saved_model_tags, scale, tensorboard_logdir, tensorflow_custom_layer_libraries, tensorflow_custom_operations_config_update, tensorflow_object_detection_api_pipeline_config, tensorflow_use_custom_operations_config, transformations_config"/>
		</cli_parameters>
	</meta_data>
	<quantization_parameters>
		<config>{
		'compression': {
			'algorithms': [
				{
					'name': 'DefaultQuantization',
					'params': {
						'num_samples_for_tuning': 2000,
						'preset': 'performance',
						'stat_subset_size': 300,
						'use_layerwise_tuning': false
					}
				}
			],
			'dump_intermediate_model': true,
			'target_device': 'ANY'
		},
		'engine': {
			'models': [
				{
					'name': 'person-reidentification-retail-0277',
					'launchers': [
						{
							'framework': 'dlsdk',
							'adapter': 'reid',
							'device': 'CPU'
						}
					],
					'datasets': [
						{
							'name': 'market1501',
							'data_source': 'PATH',
							'annotation_conversion': {
								'converter': 'market1501_reid',
								'data_dir': 'PATH'
							},
							'annotation': 'market1501_reid.pickle',
							'preprocessing': [
								{
									'type': 'resize',
									'dst_width': 128,
									'dst_height': 256,
									'use_pillow': true,
									'interpolation': 'BILINEAR'
								}
							],
							'metrics': [
								{
									'name': 'rank@1',
									'type': 'cmc',
									'top_k': 1
								},
								{
									'type': 'reid_map'
								}
							],
							'_command_line_mapping': {
								'data_dir': 'PATH'
							}
						}
					]
				}
			],
			'stat_requests_number': null,
			'eval_requests_number': null,
			'type': 'accuracy_checker'
		}
	}</config>
		<version value="1.0"/>
		<cli_params value="{'evaluate': False, 'output_dir': 'PATH', 'direct_dump': True, 'log_level': 'INFO', 'pbar': False, 'stream_output': False, 'keep_uncompressed_weights': False}"/>
	</quantization_parameters>
</net>
